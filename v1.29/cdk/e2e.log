  I0212 19:01:08.397274      20 e2e.go:117] Starting e2e run "9bdb97e6-94a2-4de6-b7ef-44e96ca695dc" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1707764467 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Feb 12 19:01:08.602: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:01:08.603: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Feb 12 19:01:08.663: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Feb 12 19:01:08.672: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Feb 12 19:01:08.672: INFO: e2e test version: v1.29.1
  Feb 12 19:01:08.673: INFO: kube-apiserver version: v1.29.1
  Feb 12 19:01:08.673: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:01:08.677: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 02/12/24 19:01:08.859
  Feb 12 19:01:08.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:01:08.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:08.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:08.881
  STEP: creating service in namespace services-3394 @ 02/12/24 19:01:08.892
  STEP: creating service affinity-nodeport-transition in namespace services-3394 @ 02/12/24 19:01:08.892
  STEP: creating replication controller affinity-nodeport-transition in namespace services-3394 @ 02/12/24 19:01:08.922
  I0212 19:01:08.927699      20 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-3394, replica count: 3
  I0212 19:01:11.978383      20 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0212 19:01:14.978539      20 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 19:01:14.989: INFO: Creating new exec pod
  Feb 12 19:01:18.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-3394 exec execpod-affinity8h6g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Feb 12 19:01:18.125: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Feb 12 19:01:18.125: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:18.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-3394 exec execpod-affinity8h6g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.171 80'
  Feb 12 19:01:18.220: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.171 80\nConnection to 10.152.183.171 80 port [tcp/http] succeeded!\n"
  Feb 12 19:01:18.220: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:18.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-3394 exec execpod-affinity8h6g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.5.108 31657'
  Feb 12 19:01:18.320: INFO: stderr: "+ nc -v -t -w 2 172.31.5.108 31657\nConnection to 172.31.5.108 31657 port [tcp/*] succeeded!\n+ echo hostName\n"
  Feb 12 19:01:18.320: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:18.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-3394 exec execpod-affinity8h6g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.42.94 31657'
  Feb 12 19:01:18.408: INFO: stderr: "+ nc -v -t -w 2 172.31.42.94 31657\n+ echo hostName\nConnection to 172.31.42.94 31657 port [tcp/*] succeeded!\n"
  Feb 12 19:01:18.408: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:18.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-3394 exec execpod-affinity8h6g5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.42.94:31657/ ; done'
  Feb 12 19:01:18.599: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n"
  Feb 12 19:01:18.599: INFO: stdout: "\naffinity-nodeport-transition-9wnlj\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-whdfx\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-whdfx\naffinity-nodeport-transition-9wnlj\naffinity-nodeport-transition-9wnlj\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-whdfx\naffinity-nodeport-transition-whdfx\naffinity-nodeport-transition-9wnlj"
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-9wnlj
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-whdfx
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-whdfx
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-9wnlj
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-9wnlj
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-whdfx
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-whdfx
  Feb 12 19:01:18.600: INFO: Received response from host: affinity-nodeport-transition-9wnlj
  Feb 12 19:01:18.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-3394 exec execpod-affinity8h6g5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.42.94:31657/ ; done'
  Feb 12 19:01:18.777: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31657/\n"
  Feb 12 19:01:18.777: INFO: stdout: "\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv\naffinity-nodeport-transition-f98qv"
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Received response from host: affinity-nodeport-transition-f98qv
  Feb 12 19:01:18.777: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3394, will wait for the garbage collector to delete the pods @ 02/12/24 19:01:18.788
  Feb 12 19:01:18.851: INFO: Deleting ReplicationController affinity-nodeport-transition took: 7.388433ms
  Feb 12 19:01:18.951: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.517729ms
  Feb 12 19:01:24.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3394" for this suite. @ 02/12/24 19:01:24.484
• [15.633 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 02/12/24 19:01:24.492
  Feb 12 19:01:24.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:01:24.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:24.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:24.51
  STEP: Creating configMap configmap-2589/configmap-test-350c7272-554c-46fa-8f1a-41bf066c5eb6 @ 02/12/24 19:01:24.513
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:01:24.517
  STEP: Saw pod success @ 02/12/24 19:01:28.537
  Feb 12 19:01:28.541: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-8491aa40-69eb-44d0-9b8f-b80fb1eac832 container env-test: <nil>
  STEP: delete the pod @ 02/12/24 19:01:28.556
  Feb 12 19:01:28.570: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2589" for this suite. @ 02/12/24 19:01:28.574
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 02/12/24 19:01:28.585
  Feb 12 19:01:28.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubelet-test @ 02/12/24 19:01:28.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:28.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:28.603
  Feb 12 19:01:28.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3054" for this suite. @ 02/12/24 19:01:28.634
• [0.057 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 02/12/24 19:01:28.642
  Feb 12 19:01:28.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 19:01:28.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:28.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:28.661
  STEP: Saw pod success @ 02/12/24 19:01:34.718
  Feb 12 19:01:34.723: INFO: Trying to get logs from node ip-172-31-91-42 pod client-envvars-faa96b73-154f-42d0-a060-8fd77eaf4bff container env3cont: <nil>
  STEP: delete the pod @ 02/12/24 19:01:34.74
  Feb 12 19:01:34.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3690" for this suite. @ 02/12/24 19:01:34.762
• [6.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 02/12/24 19:01:34.769
  Feb 12 19:01:34.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:01:34.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:34.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:34.785
  STEP: creating service multi-endpoint-test in namespace services-2728 @ 02/12/24 19:01:34.788
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2728 to expose endpoints map[] @ 02/12/24 19:01:34.801
  Feb 12 19:01:34.807: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  Feb 12 19:01:35.817: INFO: successfully validated that service multi-endpoint-test in namespace services-2728 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2728 @ 02/12/24 19:01:35.817
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2728 to expose endpoints map[pod1:[100]] @ 02/12/24 19:01:37.842
  Feb 12 19:01:37.852: INFO: successfully validated that service multi-endpoint-test in namespace services-2728 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-2728 @ 02/12/24 19:01:37.853
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2728 to expose endpoints map[pod1:[100] pod2:[101]] @ 02/12/24 19:01:39.872
  Feb 12 19:01:39.885: INFO: successfully validated that service multi-endpoint-test in namespace services-2728 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 02/12/24 19:01:39.885
  Feb 12 19:01:39.885: INFO: Creating new exec pod
  Feb 12 19:01:42.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2728 exec execpodfkmr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Feb 12 19:01:43.005: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Feb 12 19:01:43.005: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:43.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2728 exec execpodfkmr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.59 80'
  Feb 12 19:01:43.109: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.59 80\nConnection to 10.152.183.59 80 port [tcp/http] succeeded!\n"
  Feb 12 19:01:43.109: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:43.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2728 exec execpodfkmr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Feb 12 19:01:43.210: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Feb 12 19:01:43.210: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:01:43.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2728 exec execpodfkmr7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.59 81'
  Feb 12 19:01:43.305: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.59 81\nConnection to 10.152.183.59 81 port [tcp/*] succeeded!\n"
  Feb 12 19:01:43.305: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2728 @ 02/12/24 19:01:43.305
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2728 to expose endpoints map[pod2:[101]] @ 02/12/24 19:01:43.321
  Feb 12 19:01:43.333: INFO: successfully validated that service multi-endpoint-test in namespace services-2728 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-2728 @ 02/12/24 19:01:43.333
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2728 to expose endpoints map[] @ 02/12/24 19:01:43.35
  Feb 12 19:01:43.360: INFO: successfully validated that service multi-endpoint-test in namespace services-2728 exposes endpoints map[]
  Feb 12 19:01:43.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2728" for this suite. @ 02/12/24 19:01:43.379
• [8.615 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 02/12/24 19:01:43.385
  Feb 12 19:01:43.385: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svc-latency @ 02/12/24 19:01:43.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:43.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:43.401
  Feb 12 19:01:43.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-5467 @ 02/12/24 19:01:43.406
  I0212 19:01:43.413741      20 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5467, replica count: 1
  I0212 19:01:44.465183      20 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 19:01:44.577: INFO: Created: latency-svc-qlzhl
  Feb 12 19:01:44.583: INFO: Got endpoints: latency-svc-qlzhl [17.643447ms]
  Feb 12 19:01:44.591: INFO: Created: latency-svc-l5595
  Feb 12 19:01:44.601: INFO: Got endpoints: latency-svc-l5595 [18.064922ms]
  Feb 12 19:01:44.601: INFO: Created: latency-svc-x9mq9
  Feb 12 19:01:44.609: INFO: Got endpoints: latency-svc-x9mq9 [26.447ms]
  Feb 12 19:01:44.610: INFO: Created: latency-svc-2tz87
  Feb 12 19:01:44.614: INFO: Created: latency-svc-n4hsd
  Feb 12 19:01:44.616: INFO: Got endpoints: latency-svc-2tz87 [33.09519ms]
  Feb 12 19:01:44.624: INFO: Got endpoints: latency-svc-n4hsd [40.840952ms]
  Feb 12 19:01:44.685: INFO: Created: latency-svc-g78rx
  Feb 12 19:01:44.685: INFO: Created: latency-svc-kt6sj
  Feb 12 19:01:44.689: INFO: Created: latency-svc-sbjhr
  Feb 12 19:01:44.699: INFO: Created: latency-svc-th7v8
  Feb 12 19:01:44.700: INFO: Created: latency-svc-jgpbs
  Feb 12 19:01:44.700: INFO: Created: latency-svc-8r4zg
  Feb 12 19:01:44.700: INFO: Created: latency-svc-sp9sd
  Feb 12 19:01:44.700: INFO: Created: latency-svc-cg7pm
  Feb 12 19:01:44.700: INFO: Created: latency-svc-877q2
  Feb 12 19:01:44.700: INFO: Created: latency-svc-rnmng
  Feb 12 19:01:44.701: INFO: Created: latency-svc-kqxsj
  Feb 12 19:01:44.700: INFO: Created: latency-svc-mjh78
  Feb 12 19:01:44.700: INFO: Created: latency-svc-cg76b
  Feb 12 19:01:44.700: INFO: Created: latency-svc-z8f6s
  Feb 12 19:01:44.701: INFO: Created: latency-svc-mxk7c
  Feb 12 19:01:44.706: INFO: Got endpoints: latency-svc-kt6sj [123.110458ms]
  Feb 12 19:01:44.707: INFO: Got endpoints: latency-svc-g78rx [123.01847ms]
  Feb 12 19:01:44.713: INFO: Got endpoints: latency-svc-sbjhr [129.919696ms]
  Feb 12 19:01:44.713: INFO: Got endpoints: latency-svc-sp9sd [130.190041ms]
  Feb 12 19:01:44.714: INFO: Got endpoints: latency-svc-cg76b [89.721383ms]
  Feb 12 19:01:44.717: INFO: Got endpoints: latency-svc-th7v8 [107.744349ms]
  Feb 12 19:01:44.721: INFO: Got endpoints: latency-svc-kqxsj [137.417993ms]
  Feb 12 19:01:44.721: INFO: Got endpoints: latency-svc-jgpbs [137.413656ms]
  Feb 12 19:01:44.726: INFO: Got endpoints: latency-svc-z8f6s [143.08441ms]
  Feb 12 19:01:44.729: INFO: Got endpoints: latency-svc-8r4zg [145.758489ms]
  Feb 12 19:01:44.730: INFO: Created: latency-svc-q6rcw
  Feb 12 19:01:44.732: INFO: Got endpoints: latency-svc-rnmng [148.558486ms]
  Feb 12 19:01:44.736: INFO: Got endpoints: latency-svc-877q2 [153.11653ms]
  Feb 12 19:01:44.736: INFO: Got endpoints: latency-svc-cg7pm [153.353571ms]
  Feb 12 19:01:44.737: INFO: Got endpoints: latency-svc-mxk7c [120.422658ms]
  Feb 12 19:01:44.743: INFO: Created: latency-svc-2mgx9
  Feb 12 19:01:44.743: INFO: Got endpoints: latency-svc-mjh78 [141.963834ms]
  Feb 12 19:01:44.746: INFO: Got endpoints: latency-svc-q6rcw [39.061574ms]
  Feb 12 19:01:44.748: INFO: Got endpoints: latency-svc-2mgx9 [40.978803ms]
  Feb 12 19:01:44.749: INFO: Created: latency-svc-6kd2x
  Feb 12 19:01:44.758: INFO: Got endpoints: latency-svc-6kd2x [44.286067ms]
  Feb 12 19:01:44.758: INFO: Created: latency-svc-l65xj
  Feb 12 19:01:44.768: INFO: Created: latency-svc-qbdc5
  Feb 12 19:01:44.770: INFO: Got endpoints: latency-svc-l65xj [56.624404ms]
  Feb 12 19:01:44.773: INFO: Got endpoints: latency-svc-qbdc5 [59.394314ms]
  Feb 12 19:01:44.775: INFO: Created: latency-svc-wd4nz
  Feb 12 19:01:44.785: INFO: Got endpoints: latency-svc-wd4nz [67.992736ms]
  Feb 12 19:01:44.787: INFO: Created: latency-svc-8hlgh
  Feb 12 19:01:44.793: INFO: Got endpoints: latency-svc-8hlgh [72.331874ms]
  Feb 12 19:01:44.793: INFO: Created: latency-svc-l55kx
  Feb 12 19:01:44.800: INFO: Got endpoints: latency-svc-l55kx [78.657053ms]
  Feb 12 19:01:44.800: INFO: Created: latency-svc-9w5zx
  Feb 12 19:01:44.805: INFO: Created: latency-svc-rjsfp
  Feb 12 19:01:44.808: INFO: Got endpoints: latency-svc-9w5zx [81.758139ms]
  Feb 12 19:01:44.810: INFO: Got endpoints: latency-svc-rjsfp [81.121828ms]
  Feb 12 19:01:44.817: INFO: Created: latency-svc-6gxn4
  Feb 12 19:01:44.825: INFO: Got endpoints: latency-svc-6gxn4 [93.055967ms]
  Feb 12 19:01:44.826: INFO: Created: latency-svc-fz92g
  Feb 12 19:01:44.834: INFO: Got endpoints: latency-svc-fz92g [97.859025ms]
  Feb 12 19:01:44.837: INFO: Created: latency-svc-kqjth
  Feb 12 19:01:44.844: INFO: Got endpoints: latency-svc-kqjth [107.442901ms]
  Feb 12 19:01:44.847: INFO: Created: latency-svc-pnrnv
  Feb 12 19:01:44.854: INFO: Got endpoints: latency-svc-pnrnv [117.138368ms]
  Feb 12 19:01:44.854: INFO: Created: latency-svc-27q9v
  Feb 12 19:01:44.860: INFO: Got endpoints: latency-svc-27q9v [117.030565ms]
  Feb 12 19:01:44.862: INFO: Created: latency-svc-kwfgq
  Feb 12 19:01:44.870: INFO: Created: latency-svc-pwwct
  Feb 12 19:01:44.876: INFO: Created: latency-svc-2qn4n
  Feb 12 19:01:44.885: INFO: Got endpoints: latency-svc-kwfgq [138.942132ms]
  Feb 12 19:01:44.885: INFO: Created: latency-svc-gstjn
  Feb 12 19:01:44.892: INFO: Created: latency-svc-nbpn2
  Feb 12 19:01:44.895: INFO: Created: latency-svc-5kvtv
  Feb 12 19:01:44.902: INFO: Created: latency-svc-sbjh2
  Feb 12 19:01:44.908: INFO: Created: latency-svc-jkthq
  Feb 12 19:01:44.910: INFO: Created: latency-svc-8kdzf
  Feb 12 19:01:44.916: INFO: Created: latency-svc-nqrfc
  Feb 12 19:01:44.923: INFO: Created: latency-svc-kfjrr
  Feb 12 19:01:44.927: INFO: Created: latency-svc-b4cm4
  Feb 12 19:01:44.932: INFO: Got endpoints: latency-svc-pwwct [183.706681ms]
  Feb 12 19:01:44.935: INFO: Created: latency-svc-g8gwl
  Feb 12 19:01:44.942: INFO: Created: latency-svc-vvckv
  Feb 12 19:01:44.947: INFO: Created: latency-svc-gfp8h
  Feb 12 19:01:44.953: INFO: Created: latency-svc-xjd29
  Feb 12 19:01:44.959: INFO: Created: latency-svc-5v8bz
  Feb 12 19:01:44.982: INFO: Got endpoints: latency-svc-2qn4n [224.654903ms]
  Feb 12 19:01:44.990: INFO: Created: latency-svc-2kgk8
  Feb 12 19:01:45.035: INFO: Got endpoints: latency-svc-gstjn [264.378518ms]
  Feb 12 19:01:45.044: INFO: Created: latency-svc-7h5h9
  Feb 12 19:01:45.085: INFO: Got endpoints: latency-svc-nbpn2 [312.005453ms]
  Feb 12 19:01:45.097: INFO: Created: latency-svc-b8pb2
  Feb 12 19:01:45.132: INFO: Got endpoints: latency-svc-5kvtv [346.450917ms]
  Feb 12 19:01:45.142: INFO: Created: latency-svc-qtnql
  Feb 12 19:01:45.182: INFO: Got endpoints: latency-svc-sbjh2 [388.221016ms]
  Feb 12 19:01:45.191: INFO: Created: latency-svc-nchgj
  Feb 12 19:01:45.232: INFO: Got endpoints: latency-svc-jkthq [432.407936ms]
  Feb 12 19:01:45.246: INFO: Created: latency-svc-fbpmx
  Feb 12 19:01:45.283: INFO: Got endpoints: latency-svc-8kdzf [475.250084ms]
  Feb 12 19:01:45.293: INFO: Created: latency-svc-6g2s7
  Feb 12 19:01:45.335: INFO: Got endpoints: latency-svc-nqrfc [525.040062ms]
  Feb 12 19:01:45.344: INFO: Created: latency-svc-vrp4k
  Feb 12 19:01:45.382: INFO: Got endpoints: latency-svc-kfjrr [557.147012ms]
  Feb 12 19:01:45.394: INFO: Created: latency-svc-rljff
  Feb 12 19:01:45.433: INFO: Got endpoints: latency-svc-b4cm4 [598.428734ms]
  Feb 12 19:01:45.446: INFO: Created: latency-svc-qxm4p
  Feb 12 19:01:45.484: INFO: Got endpoints: latency-svc-g8gwl [639.326114ms]
  Feb 12 19:01:45.493: INFO: Created: latency-svc-qm2vd
  Feb 12 19:01:45.534: INFO: Got endpoints: latency-svc-vvckv [679.864379ms]
  Feb 12 19:01:45.545: INFO: Created: latency-svc-vr2ss
  Feb 12 19:01:45.584: INFO: Got endpoints: latency-svc-gfp8h [723.65971ms]
  Feb 12 19:01:45.595: INFO: Created: latency-svc-tth2c
  Feb 12 19:01:45.633: INFO: Got endpoints: latency-svc-xjd29 [748.382545ms]
  Feb 12 19:01:45.643: INFO: Created: latency-svc-kkfzg
  Feb 12 19:01:45.683: INFO: Got endpoints: latency-svc-5v8bz [750.990927ms]
  Feb 12 19:01:45.693: INFO: Created: latency-svc-h69gd
  Feb 12 19:01:45.734: INFO: Got endpoints: latency-svc-2kgk8 [751.392828ms]
  Feb 12 19:01:45.745: INFO: Created: latency-svc-prgnt
  Feb 12 19:01:45.784: INFO: Got endpoints: latency-svc-7h5h9 [749.228993ms]
  Feb 12 19:01:45.792: INFO: Created: latency-svc-t7hcj
  Feb 12 19:01:45.832: INFO: Got endpoints: latency-svc-b8pb2 [747.298347ms]
  Feb 12 19:01:45.846: INFO: Created: latency-svc-z54b2
  Feb 12 19:01:45.883: INFO: Got endpoints: latency-svc-qtnql [751.374045ms]
  Feb 12 19:01:45.893: INFO: Created: latency-svc-cjjnm
  Feb 12 19:01:45.934: INFO: Got endpoints: latency-svc-nchgj [751.330735ms]
  Feb 12 19:01:45.963: INFO: Created: latency-svc-99gtd
  Feb 12 19:01:45.991: INFO: Got endpoints: latency-svc-fbpmx [758.735215ms]
  Feb 12 19:01:46.001: INFO: Created: latency-svc-xsc88
  Feb 12 19:01:46.034: INFO: Got endpoints: latency-svc-6g2s7 [750.839898ms]
  Feb 12 19:01:46.044: INFO: Created: latency-svc-7q4jm
  Feb 12 19:01:46.082: INFO: Got endpoints: latency-svc-vrp4k [746.400039ms]
  Feb 12 19:01:46.093: INFO: Created: latency-svc-nw6zj
  Feb 12 19:01:46.132: INFO: Got endpoints: latency-svc-rljff [749.971353ms]
  Feb 12 19:01:46.142: INFO: Created: latency-svc-twj4s
  Feb 12 19:01:46.183: INFO: Got endpoints: latency-svc-qxm4p [749.761423ms]
  Feb 12 19:01:46.192: INFO: Created: latency-svc-hk689
  Feb 12 19:01:46.235: INFO: Got endpoints: latency-svc-qm2vd [751.088181ms]
  Feb 12 19:01:46.242: INFO: Created: latency-svc-8tn9c
  Feb 12 19:01:46.282: INFO: Got endpoints: latency-svc-vr2ss [747.942336ms]
  Feb 12 19:01:46.294: INFO: Created: latency-svc-gdr87
  Feb 12 19:01:46.333: INFO: Got endpoints: latency-svc-tth2c [748.621515ms]
  Feb 12 19:01:46.345: INFO: Created: latency-svc-c6swj
  Feb 12 19:01:46.383: INFO: Got endpoints: latency-svc-kkfzg [749.858413ms]
  Feb 12 19:01:46.391: INFO: Created: latency-svc-xcmlw
  Feb 12 19:01:46.434: INFO: Got endpoints: latency-svc-h69gd [750.708669ms]
  Feb 12 19:01:46.444: INFO: Created: latency-svc-wtwzv
  Feb 12 19:01:46.483: INFO: Got endpoints: latency-svc-prgnt [748.661899ms]
  Feb 12 19:01:46.493: INFO: Created: latency-svc-nwfrg
  Feb 12 19:01:46.533: INFO: Got endpoints: latency-svc-t7hcj [749.157954ms]
  Feb 12 19:01:46.542: INFO: Created: latency-svc-k54wm
  Feb 12 19:01:46.583: INFO: Got endpoints: latency-svc-z54b2 [750.67985ms]
  Feb 12 19:01:46.593: INFO: Created: latency-svc-k5jv8
  Feb 12 19:01:46.634: INFO: Got endpoints: latency-svc-cjjnm [750.405303ms]
  Feb 12 19:01:46.644: INFO: Created: latency-svc-hctbg
  Feb 12 19:01:46.684: INFO: Got endpoints: latency-svc-99gtd [750.647872ms]
  Feb 12 19:01:46.692: INFO: Created: latency-svc-99qnv
  Feb 12 19:01:46.734: INFO: Got endpoints: latency-svc-xsc88 [742.771143ms]
  Feb 12 19:01:46.747: INFO: Created: latency-svc-6wb4v
  Feb 12 19:01:46.782: INFO: Got endpoints: latency-svc-7q4jm [747.871053ms]
  Feb 12 19:01:46.792: INFO: Created: latency-svc-vl68p
  Feb 12 19:01:46.833: INFO: Got endpoints: latency-svc-nw6zj [750.887791ms]
  Feb 12 19:01:46.840: INFO: Created: latency-svc-5vxgf
  Feb 12 19:01:46.883: INFO: Got endpoints: latency-svc-twj4s [750.403208ms]
  Feb 12 19:01:46.893: INFO: Created: latency-svc-bw6kh
  Feb 12 19:01:46.934: INFO: Got endpoints: latency-svc-hk689 [751.017641ms]
  Feb 12 19:01:46.943: INFO: Created: latency-svc-4gqx2
  Feb 12 19:01:46.983: INFO: Got endpoints: latency-svc-8tn9c [747.745257ms]
  Feb 12 19:01:46.992: INFO: Created: latency-svc-2lxwr
  Feb 12 19:01:47.032: INFO: Got endpoints: latency-svc-gdr87 [749.339465ms]
  Feb 12 19:01:47.051: INFO: Created: latency-svc-6hj5s
  Feb 12 19:01:47.083: INFO: Got endpoints: latency-svc-c6swj [750.233161ms]
  Feb 12 19:01:47.092: INFO: Created: latency-svc-tf867
  Feb 12 19:01:47.134: INFO: Got endpoints: latency-svc-xcmlw [750.402196ms]
  Feb 12 19:01:47.141: INFO: Created: latency-svc-xvmnj
  Feb 12 19:01:47.184: INFO: Got endpoints: latency-svc-wtwzv [749.468061ms]
  Feb 12 19:01:47.195: INFO: Created: latency-svc-cpnz4
  Feb 12 19:01:47.232: INFO: Got endpoints: latency-svc-nwfrg [748.509878ms]
  Feb 12 19:01:47.243: INFO: Created: latency-svc-pbdzp
  Feb 12 19:01:47.283: INFO: Got endpoints: latency-svc-k54wm [749.147158ms]
  Feb 12 19:01:47.292: INFO: Created: latency-svc-nn484
  Feb 12 19:01:47.334: INFO: Got endpoints: latency-svc-k5jv8 [749.935509ms]
  Feb 12 19:01:47.346: INFO: Created: latency-svc-877ln
  Feb 12 19:01:47.384: INFO: Got endpoints: latency-svc-hctbg [750.43477ms]
  Feb 12 19:01:47.395: INFO: Created: latency-svc-5s2kp
  Feb 12 19:01:47.434: INFO: Got endpoints: latency-svc-99qnv [749.740563ms]
  Feb 12 19:01:47.444: INFO: Created: latency-svc-87bh6
  Feb 12 19:01:47.482: INFO: Got endpoints: latency-svc-6wb4v [747.678266ms]
  Feb 12 19:01:47.494: INFO: Created: latency-svc-4fz4p
  Feb 12 19:01:47.532: INFO: Got endpoints: latency-svc-vl68p [749.816772ms]
  Feb 12 19:01:47.541: INFO: Created: latency-svc-sjzsm
  Feb 12 19:01:47.582: INFO: Got endpoints: latency-svc-5vxgf [749.191176ms]
  Feb 12 19:01:47.590: INFO: Created: latency-svc-mdrqx
  Feb 12 19:01:47.633: INFO: Got endpoints: latency-svc-bw6kh [749.760164ms]
  Feb 12 19:01:47.643: INFO: Created: latency-svc-sbp4m
  Feb 12 19:01:47.685: INFO: Got endpoints: latency-svc-4gqx2 [750.46956ms]
  Feb 12 19:01:47.694: INFO: Created: latency-svc-6fmjw
  Feb 12 19:01:47.734: INFO: Got endpoints: latency-svc-2lxwr [751.354467ms]
  Feb 12 19:01:47.743: INFO: Created: latency-svc-4xlfl
  Feb 12 19:01:47.783: INFO: Got endpoints: latency-svc-6hj5s [751.237638ms]
  Feb 12 19:01:47.795: INFO: Created: latency-svc-hhkpf
  Feb 12 19:01:47.832: INFO: Got endpoints: latency-svc-tf867 [748.989952ms]
  Feb 12 19:01:47.842: INFO: Created: latency-svc-njx55
  Feb 12 19:01:47.883: INFO: Got endpoints: latency-svc-xvmnj [749.576532ms]
  Feb 12 19:01:47.891: INFO: Created: latency-svc-tgwvc
  Feb 12 19:01:47.933: INFO: Got endpoints: latency-svc-cpnz4 [748.940421ms]
  Feb 12 19:01:47.943: INFO: Created: latency-svc-qrkf9
  Feb 12 19:01:47.986: INFO: Got endpoints: latency-svc-pbdzp [754.466009ms]
  Feb 12 19:01:48.003: INFO: Created: latency-svc-6lthd
  Feb 12 19:01:48.033: INFO: Got endpoints: latency-svc-nn484 [750.04562ms]
  Feb 12 19:01:48.042: INFO: Created: latency-svc-dw2nl
  Feb 12 19:01:48.082: INFO: Got endpoints: latency-svc-877ln [747.726065ms]
  Feb 12 19:01:48.097: INFO: Created: latency-svc-fbh4n
  Feb 12 19:01:48.134: INFO: Got endpoints: latency-svc-5s2kp [750.044379ms]
  Feb 12 19:01:48.145: INFO: Created: latency-svc-mwzgk
  Feb 12 19:01:48.185: INFO: Got endpoints: latency-svc-87bh6 [750.647153ms]
  Feb 12 19:01:48.193: INFO: Created: latency-svc-rfsd8
  Feb 12 19:01:48.234: INFO: Got endpoints: latency-svc-4fz4p [751.584426ms]
  Feb 12 19:01:48.244: INFO: Created: latency-svc-twxnh
  Feb 12 19:01:48.282: INFO: Got endpoints: latency-svc-sjzsm [749.825158ms]
  Feb 12 19:01:48.292: INFO: Created: latency-svc-67x5c
  Feb 12 19:01:48.334: INFO: Got endpoints: latency-svc-mdrqx [752.00579ms]
  Feb 12 19:01:48.343: INFO: Created: latency-svc-6f595
  Feb 12 19:01:48.383: INFO: Got endpoints: latency-svc-sbp4m [749.810652ms]
  Feb 12 19:01:48.397: INFO: Created: latency-svc-8hgqv
  Feb 12 19:01:48.434: INFO: Got endpoints: latency-svc-6fmjw [748.903732ms]
  Feb 12 19:01:48.443: INFO: Created: latency-svc-lwjts
  Feb 12 19:01:48.483: INFO: Got endpoints: latency-svc-4xlfl [748.792647ms]
  Feb 12 19:01:48.491: INFO: Created: latency-svc-ww7rh
  Feb 12 19:01:48.532: INFO: Got endpoints: latency-svc-hhkpf [748.161338ms]
  Feb 12 19:01:48.544: INFO: Created: latency-svc-qvbjz
  Feb 12 19:01:48.583: INFO: Got endpoints: latency-svc-njx55 [750.432093ms]
  Feb 12 19:01:48.598: INFO: Created: latency-svc-9mscp
  Feb 12 19:01:48.633: INFO: Got endpoints: latency-svc-tgwvc [749.991261ms]
  Feb 12 19:01:48.655: INFO: Created: latency-svc-qdttg
  Feb 12 19:01:48.683: INFO: Got endpoints: latency-svc-qrkf9 [749.94565ms]
  Feb 12 19:01:48.695: INFO: Created: latency-svc-cgfsv
  Feb 12 19:01:48.734: INFO: Got endpoints: latency-svc-6lthd [747.226457ms]
  Feb 12 19:01:48.744: INFO: Created: latency-svc-p7zlc
  Feb 12 19:01:48.782: INFO: Got endpoints: latency-svc-dw2nl [749.348833ms]
  Feb 12 19:01:48.793: INFO: Created: latency-svc-997q6
  Feb 12 19:01:48.834: INFO: Got endpoints: latency-svc-fbh4n [752.361246ms]
  Feb 12 19:01:48.844: INFO: Created: latency-svc-kd4vc
  Feb 12 19:01:48.885: INFO: Got endpoints: latency-svc-mwzgk [750.538229ms]
  Feb 12 19:01:48.894: INFO: Created: latency-svc-kqdmd
  Feb 12 19:01:48.934: INFO: Got endpoints: latency-svc-rfsd8 [749.244575ms]
  Feb 12 19:01:48.945: INFO: Created: latency-svc-2dg84
  Feb 12 19:01:48.982: INFO: Got endpoints: latency-svc-twxnh [748.206821ms]
  Feb 12 19:01:48.992: INFO: Created: latency-svc-psxgx
  Feb 12 19:01:49.032: INFO: Got endpoints: latency-svc-67x5c [750.42546ms]
  Feb 12 19:01:49.042: INFO: Created: latency-svc-dbsb5
  Feb 12 19:01:49.084: INFO: Got endpoints: latency-svc-6f595 [748.847036ms]
  Feb 12 19:01:49.094: INFO: Created: latency-svc-mmljp
  Feb 12 19:01:49.134: INFO: Got endpoints: latency-svc-8hgqv [751.220687ms]
  Feb 12 19:01:49.144: INFO: Created: latency-svc-2p64d
  Feb 12 19:01:49.184: INFO: Got endpoints: latency-svc-lwjts [749.811972ms]
  Feb 12 19:01:49.194: INFO: Created: latency-svc-jbcz6
  Feb 12 19:01:49.232: INFO: Got endpoints: latency-svc-ww7rh [748.526416ms]
  Feb 12 19:01:49.247: INFO: Created: latency-svc-tph74
  Feb 12 19:01:49.283: INFO: Got endpoints: latency-svc-qvbjz [750.60614ms]
  Feb 12 19:01:49.293: INFO: Created: latency-svc-tjwh2
  Feb 12 19:01:49.335: INFO: Got endpoints: latency-svc-9mscp [752.645351ms]
  Feb 12 19:01:49.345: INFO: Created: latency-svc-sbcr2
  Feb 12 19:01:49.384: INFO: Got endpoints: latency-svc-qdttg [750.838018ms]
  Feb 12 19:01:49.394: INFO: Created: latency-svc-9djmv
  Feb 12 19:01:49.439: INFO: Got endpoints: latency-svc-cgfsv [755.483215ms]
  Feb 12 19:01:49.447: INFO: Created: latency-svc-l762b
  Feb 12 19:01:49.482: INFO: Got endpoints: latency-svc-p7zlc [748.621694ms]
  Feb 12 19:01:49.495: INFO: Created: latency-svc-wqmfx
  Feb 12 19:01:49.532: INFO: Got endpoints: latency-svc-997q6 [750.217363ms]
  Feb 12 19:01:49.546: INFO: Created: latency-svc-64kv7
  Feb 12 19:01:49.585: INFO: Got endpoints: latency-svc-kd4vc [750.589546ms]
  Feb 12 19:01:49.594: INFO: Created: latency-svc-ljpzz
  Feb 12 19:01:49.633: INFO: Got endpoints: latency-svc-kqdmd [747.417699ms]
  Feb 12 19:01:49.642: INFO: Created: latency-svc-fqzlt
  Feb 12 19:01:49.685: INFO: Got endpoints: latency-svc-2dg84 [750.634982ms]
  Feb 12 19:01:49.694: INFO: Created: latency-svc-bqwmv
  Feb 12 19:01:49.732: INFO: Got endpoints: latency-svc-psxgx [750.046666ms]
  Feb 12 19:01:49.743: INFO: Created: latency-svc-sp4wr
  Feb 12 19:01:49.782: INFO: Got endpoints: latency-svc-dbsb5 [749.658694ms]
  Feb 12 19:01:49.792: INFO: Created: latency-svc-j8hjv
  Feb 12 19:01:49.833: INFO: Got endpoints: latency-svc-mmljp [749.211106ms]
  Feb 12 19:01:49.843: INFO: Created: latency-svc-dmwdx
  Feb 12 19:01:49.899: INFO: Got endpoints: latency-svc-2p64d [764.813366ms]
  Feb 12 19:01:49.909: INFO: Created: latency-svc-szqxq
  Feb 12 19:01:49.933: INFO: Got endpoints: latency-svc-jbcz6 [749.380761ms]
  Feb 12 19:01:49.944: INFO: Created: latency-svc-vkdhm
  Feb 12 19:01:49.982: INFO: Got endpoints: latency-svc-tph74 [749.432872ms]
  Feb 12 19:01:49.992: INFO: Created: latency-svc-w7qs7
  Feb 12 19:01:50.034: INFO: Got endpoints: latency-svc-tjwh2 [750.648401ms]
  Feb 12 19:01:50.045: INFO: Created: latency-svc-cwv6c
  Feb 12 19:01:50.082: INFO: Got endpoints: latency-svc-sbcr2 [746.670345ms]
  Feb 12 19:01:50.092: INFO: Created: latency-svc-w2kph
  Feb 12 19:01:50.134: INFO: Got endpoints: latency-svc-9djmv [749.808086ms]
  Feb 12 19:01:50.143: INFO: Created: latency-svc-vh68f
  Feb 12 19:01:50.184: INFO: Got endpoints: latency-svc-l762b [744.970158ms]
  Feb 12 19:01:50.193: INFO: Created: latency-svc-hzjdb
  Feb 12 19:01:50.232: INFO: Got endpoints: latency-svc-wqmfx [748.842196ms]
  Feb 12 19:01:50.241: INFO: Created: latency-svc-pwp66
  Feb 12 19:01:50.283: INFO: Got endpoints: latency-svc-64kv7 [750.609906ms]
  Feb 12 19:01:50.294: INFO: Created: latency-svc-dz6xs
  Feb 12 19:01:50.335: INFO: Got endpoints: latency-svc-ljpzz [749.55687ms]
  Feb 12 19:01:50.345: INFO: Created: latency-svc-cxxfg
  Feb 12 19:01:50.384: INFO: Got endpoints: latency-svc-fqzlt [750.901209ms]
  Feb 12 19:01:50.394: INFO: Created: latency-svc-ct28f
  Feb 12 19:01:50.432: INFO: Got endpoints: latency-svc-bqwmv [746.921242ms]
  Feb 12 19:01:50.443: INFO: Created: latency-svc-4jx44
  Feb 12 19:01:50.482: INFO: Got endpoints: latency-svc-sp4wr [749.573861ms]
  Feb 12 19:01:50.491: INFO: Created: latency-svc-5f9jx
  Feb 12 19:01:50.533: INFO: Got endpoints: latency-svc-j8hjv [750.401683ms]
  Feb 12 19:01:50.541: INFO: Created: latency-svc-9g4wc
  Feb 12 19:01:50.586: INFO: Got endpoints: latency-svc-dmwdx [752.856869ms]
  Feb 12 19:01:50.595: INFO: Created: latency-svc-dfxcr
  Feb 12 19:01:50.634: INFO: Got endpoints: latency-svc-szqxq [734.507732ms]
  Feb 12 19:01:50.643: INFO: Created: latency-svc-z5sb2
  Feb 12 19:01:50.682: INFO: Got endpoints: latency-svc-vkdhm [748.882527ms]
  Feb 12 19:01:50.694: INFO: Created: latency-svc-r2xbg
  Feb 12 19:01:50.734: INFO: Got endpoints: latency-svc-w7qs7 [752.120272ms]
  Feb 12 19:01:50.745: INFO: Created: latency-svc-6x65s
  Feb 12 19:01:50.785: INFO: Got endpoints: latency-svc-cwv6c [751.240722ms]
  Feb 12 19:01:50.796: INFO: Created: latency-svc-kvvwp
  Feb 12 19:01:50.834: INFO: Got endpoints: latency-svc-w2kph [751.740491ms]
  Feb 12 19:01:50.843: INFO: Created: latency-svc-dr6jn
  Feb 12 19:01:50.882: INFO: Got endpoints: latency-svc-vh68f [748.427877ms]
  Feb 12 19:01:50.893: INFO: Created: latency-svc-wptlm
  Feb 12 19:01:50.932: INFO: Got endpoints: latency-svc-hzjdb [748.363152ms]
  Feb 12 19:01:50.941: INFO: Created: latency-svc-xd7hb
  Feb 12 19:01:50.984: INFO: Got endpoints: latency-svc-pwp66 [752.011262ms]
  Feb 12 19:01:50.994: INFO: Created: latency-svc-kqmqt
  Feb 12 19:01:51.035: INFO: Got endpoints: latency-svc-dz6xs [751.92097ms]
  Feb 12 19:01:51.044: INFO: Created: latency-svc-zxdkn
  Feb 12 19:01:51.084: INFO: Got endpoints: latency-svc-cxxfg [748.364588ms]
  Feb 12 19:01:51.094: INFO: Created: latency-svc-jlkxf
  Feb 12 19:01:51.133: INFO: Got endpoints: latency-svc-ct28f [749.097412ms]
  Feb 12 19:01:51.143: INFO: Created: latency-svc-s47zs
  Feb 12 19:01:51.183: INFO: Got endpoints: latency-svc-4jx44 [751.349261ms]
  Feb 12 19:01:51.194: INFO: Created: latency-svc-9g57d
  Feb 12 19:01:51.235: INFO: Got endpoints: latency-svc-5f9jx [752.908159ms]
  Feb 12 19:01:51.244: INFO: Created: latency-svc-s2kzw
  Feb 12 19:01:51.286: INFO: Got endpoints: latency-svc-9g4wc [753.735957ms]
  Feb 12 19:01:51.295: INFO: Created: latency-svc-9vq84
  Feb 12 19:01:51.334: INFO: Got endpoints: latency-svc-dfxcr [748.174919ms]
  Feb 12 19:01:51.344: INFO: Created: latency-svc-tg64m
  Feb 12 19:01:51.382: INFO: Got endpoints: latency-svc-z5sb2 [747.537821ms]
  Feb 12 19:01:51.392: INFO: Created: latency-svc-vvbzs
  Feb 12 19:01:51.434: INFO: Got endpoints: latency-svc-r2xbg [751.246504ms]
  Feb 12 19:01:51.443: INFO: Created: latency-svc-6z72h
  Feb 12 19:01:51.483: INFO: Got endpoints: latency-svc-6x65s [749.535221ms]
  Feb 12 19:01:51.493: INFO: Created: latency-svc-j5r6n
  Feb 12 19:01:51.534: INFO: Got endpoints: latency-svc-kvvwp [749.412366ms]
  Feb 12 19:01:51.543: INFO: Created: latency-svc-sdxc2
  Feb 12 19:01:51.582: INFO: Got endpoints: latency-svc-dr6jn [748.161601ms]
  Feb 12 19:01:51.594: INFO: Created: latency-svc-gq69j
  Feb 12 19:01:51.633: INFO: Got endpoints: latency-svc-wptlm [750.03445ms]
  Feb 12 19:01:51.644: INFO: Created: latency-svc-fn8vr
  Feb 12 19:01:51.681: INFO: Got endpoints: latency-svc-xd7hb [748.989382ms]
  Feb 12 19:01:51.692: INFO: Created: latency-svc-4t5fg
  Feb 12 19:01:51.732: INFO: Got endpoints: latency-svc-kqmqt [748.155683ms]
  Feb 12 19:01:51.743: INFO: Created: latency-svc-hkb6f
  Feb 12 19:01:51.783: INFO: Got endpoints: latency-svc-zxdkn [747.687175ms]
  Feb 12 19:01:51.792: INFO: Created: latency-svc-pw4tv
  Feb 12 19:01:51.836: INFO: Got endpoints: latency-svc-jlkxf [751.995302ms]
  Feb 12 19:01:51.848: INFO: Created: latency-svc-mcmlr
  Feb 12 19:01:51.885: INFO: Got endpoints: latency-svc-s47zs [751.864716ms]
  Feb 12 19:01:51.895: INFO: Created: latency-svc-dfp98
  Feb 12 19:01:51.934: INFO: Got endpoints: latency-svc-9g57d [750.274002ms]
  Feb 12 19:01:51.948: INFO: Created: latency-svc-rvz2b
  Feb 12 19:01:51.983: INFO: Got endpoints: latency-svc-s2kzw [747.605274ms]
  Feb 12 19:01:51.992: INFO: Created: latency-svc-7hnns
  Feb 12 19:01:52.034: INFO: Got endpoints: latency-svc-9vq84 [747.477809ms]
  Feb 12 19:01:52.044: INFO: Created: latency-svc-m4725
  Feb 12 19:01:52.087: INFO: Got endpoints: latency-svc-tg64m [752.470046ms]
  Feb 12 19:01:52.097: INFO: Created: latency-svc-6gm7q
  Feb 12 19:01:52.132: INFO: Got endpoints: latency-svc-vvbzs [749.881171ms]
  Feb 12 19:01:52.141: INFO: Created: latency-svc-jlwfj
  Feb 12 19:01:52.183: INFO: Got endpoints: latency-svc-6z72h [749.428213ms]
  Feb 12 19:01:52.194: INFO: Created: latency-svc-v7hf2
  Feb 12 19:01:52.251: INFO: Got endpoints: latency-svc-j5r6n [767.737505ms]
  Feb 12 19:01:52.263: INFO: Created: latency-svc-q6bft
  Feb 12 19:01:52.286: INFO: Got endpoints: latency-svc-sdxc2 [752.096559ms]
  Feb 12 19:01:52.296: INFO: Created: latency-svc-qwbpr
  Feb 12 19:01:52.337: INFO: Got endpoints: latency-svc-gq69j [754.679627ms]
  Feb 12 19:01:52.359: INFO: Created: latency-svc-fvhq5
  Feb 12 19:01:52.382: INFO: Got endpoints: latency-svc-fn8vr [749.492523ms]
  Feb 12 19:01:52.392: INFO: Created: latency-svc-4smbj
  Feb 12 19:01:52.433: INFO: Got endpoints: latency-svc-4t5fg [751.356898ms]
  Feb 12 19:01:52.484: INFO: Got endpoints: latency-svc-hkb6f [751.718435ms]
  Feb 12 19:01:52.534: INFO: Got endpoints: latency-svc-pw4tv [750.404186ms]
  Feb 12 19:01:52.584: INFO: Got endpoints: latency-svc-mcmlr [748.215208ms]
  Feb 12 19:01:52.634: INFO: Got endpoints: latency-svc-dfp98 [749.216117ms]
  Feb 12 19:01:52.685: INFO: Got endpoints: latency-svc-rvz2b [750.561087ms]
  Feb 12 19:01:52.733: INFO: Got endpoints: latency-svc-7hnns [750.06687ms]
  Feb 12 19:01:52.786: INFO: Got endpoints: latency-svc-m4725 [751.677362ms]
  Feb 12 19:01:52.833: INFO: Got endpoints: latency-svc-6gm7q [745.834402ms]
  Feb 12 19:01:52.885: INFO: Got endpoints: latency-svc-jlwfj [753.73512ms]
  Feb 12 19:01:52.932: INFO: Got endpoints: latency-svc-v7hf2 [748.995175ms]
  Feb 12 19:01:52.986: INFO: Got endpoints: latency-svc-q6bft [734.213883ms]
  Feb 12 19:01:53.034: INFO: Got endpoints: latency-svc-qwbpr [747.415748ms]
  Feb 12 19:01:53.083: INFO: Got endpoints: latency-svc-fvhq5 [745.513367ms]
  Feb 12 19:01:53.133: INFO: Got endpoints: latency-svc-4smbj [751.285594ms]
  Feb 12 19:01:53.134: INFO: Latencies: [18.064922ms 26.447ms 33.09519ms 39.061574ms 40.840952ms 40.978803ms 44.286067ms 56.624404ms 59.394314ms 67.992736ms 72.331874ms 78.657053ms 81.121828ms 81.758139ms 89.721383ms 93.055967ms 97.859025ms 107.442901ms 107.744349ms 117.030565ms 117.138368ms 120.422658ms 123.01847ms 123.110458ms 129.919696ms 130.190041ms 137.413656ms 137.417993ms 138.942132ms 141.963834ms 143.08441ms 145.758489ms 148.558486ms 153.11653ms 153.353571ms 183.706681ms 224.654903ms 264.378518ms 312.005453ms 346.450917ms 388.221016ms 432.407936ms 475.250084ms 525.040062ms 557.147012ms 598.428734ms 639.326114ms 679.864379ms 723.65971ms 734.213883ms 734.507732ms 742.771143ms 744.970158ms 745.513367ms 745.834402ms 746.400039ms 746.670345ms 746.921242ms 747.226457ms 747.298347ms 747.415748ms 747.417699ms 747.477809ms 747.537821ms 747.605274ms 747.678266ms 747.687175ms 747.726065ms 747.745257ms 747.871053ms 747.942336ms 748.155683ms 748.161338ms 748.161601ms 748.174919ms 748.206821ms 748.215208ms 748.363152ms 748.364588ms 748.382545ms 748.427877ms 748.509878ms 748.526416ms 748.621515ms 748.621694ms 748.661899ms 748.792647ms 748.842196ms 748.847036ms 748.882527ms 748.903732ms 748.940421ms 748.989382ms 748.989952ms 748.995175ms 749.097412ms 749.147158ms 749.157954ms 749.191176ms 749.211106ms 749.216117ms 749.228993ms 749.244575ms 749.339465ms 749.348833ms 749.380761ms 749.412366ms 749.428213ms 749.432872ms 749.468061ms 749.492523ms 749.535221ms 749.55687ms 749.573861ms 749.576532ms 749.658694ms 749.740563ms 749.760164ms 749.761423ms 749.808086ms 749.810652ms 749.811972ms 749.816772ms 749.825158ms 749.858413ms 749.881171ms 749.935509ms 749.94565ms 749.971353ms 749.991261ms 750.03445ms 750.044379ms 750.04562ms 750.046666ms 750.06687ms 750.217363ms 750.233161ms 750.274002ms 750.401683ms 750.402196ms 750.403208ms 750.404186ms 750.405303ms 750.42546ms 750.432093ms 750.43477ms 750.46956ms 750.538229ms 750.561087ms 750.589546ms 750.60614ms 750.609906ms 750.634982ms 750.647153ms 750.647872ms 750.648401ms 750.67985ms 750.708669ms 750.838018ms 750.839898ms 750.887791ms 750.901209ms 750.990927ms 751.017641ms 751.088181ms 751.220687ms 751.237638ms 751.240722ms 751.246504ms 751.285594ms 751.330735ms 751.349261ms 751.354467ms 751.356898ms 751.374045ms 751.392828ms 751.584426ms 751.677362ms 751.718435ms 751.740491ms 751.864716ms 751.92097ms 751.995302ms 752.00579ms 752.011262ms 752.096559ms 752.120272ms 752.361246ms 752.470046ms 752.645351ms 752.856869ms 752.908159ms 753.73512ms 753.735957ms 754.466009ms 754.679627ms 755.483215ms 758.735215ms 764.813366ms 767.737505ms]
  Feb 12 19:01:53.134: INFO: 50 %ile: 749.216117ms
  Feb 12 19:01:53.134: INFO: 90 %ile: 751.864716ms
  Feb 12 19:01:53.134: INFO: 99 %ile: 764.813366ms
  Feb 12 19:01:53.134: INFO: Total sample count: 200
  Feb 12 19:01:53.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-5467" for this suite. @ 02/12/24 19:01:53.138
• [9.759 seconds]
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 02/12/24 19:01:53.143
  Feb 12 19:01:53.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-pred @ 02/12/24 19:01:53.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:53.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:53.163
  Feb 12 19:01:53.165: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb 12 19:01:53.172: INFO: Waiting for terminating namespaces to be deleted...
  Feb 12 19:01:53.176: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-42-94 before test
  Feb 12 19:01:53.182: INFO: nginx-ingress-controller-kubernetes-worker-4n7x6 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: calico-node-nknc4 from kube-system started at 2024-02-12 18:57:51 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: coredns-bddfd76d7-hpmdx from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container coredns ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: kube-state-metrics-78c475f58b-mmvpb from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container kube-state-metrics ready: true, restart count 4
  Feb 12 19:01:53.182: INFO: metrics-server-v0.6.3-69d7fbfdf8-q42bs from kube-system started at 2024-02-12 18:46:29 +0000 UTC (2 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container metrics-server ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: dashboard-metrics-scraper-5dd7cb5fc-94q8l from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: kubernetes-dashboard-7b899cb9d9-kxlk9 from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container kubernetes-dashboard ready: true, restart count 6
  Feb 12 19:01:53.182: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-hxjsb from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:01:53.182: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 19:01:53.182: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-5-108 before test
  Feb 12 19:01:53.187: INFO: nginx-ingress-controller-kubernetes-worker-b6d84 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.187: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:01:53.187: INFO: calico-node-tcvrl from kube-system started at 2024-02-12 18:59:18 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.187: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:01:53.187: INFO: sonobuoy from sonobuoy started at 2024-02-12 19:00:55 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.187: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb 12 19:01:53.187: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-dq5wt from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:01:53.187: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:01:53.187: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 19:01:53.187: INFO: svc-latency-rc-jbhnl from svc-latency-5467 started at 2024-02-12 19:01:43 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.187: INFO: 	Container svc-latency-rc ready: true, restart count 0
  Feb 12 19:01:53.187: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-91-42 before test
  Feb 12 19:01:53.191: INFO: nginx-ingress-controller-kubernetes-worker-89brg from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:34 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.191: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:01:53.191: INFO: calico-node-5zt4h from kube-system started at 2024-02-12 18:57:41 +0000 UTC (1 container statuses recorded)
  Feb 12 19:01:53.191: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:01:53.191: INFO: sonobuoy-e2e-job-6d99262b73344895 from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:01:53.191: INFO: 	Container e2e ready: true, restart count 0
  Feb 12 19:01:53.191: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:01:53.191: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-pcznp from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:01:53.191: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:01:53.191: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 02/12/24 19:01:53.191
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17b332c6d1e1c2df], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 02/12/24 19:01:53.216
  Feb 12 19:01:54.214: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7687" for this suite. @ 02/12/24 19:01:54.217
• [1.081 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 02/12/24 19:01:54.224
  Feb 12 19:01:54.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replication-controller @ 02/12/24 19:01:54.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:01:54.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:01:54.244
  STEP: Given a ReplicationController is created @ 02/12/24 19:01:54.246
  STEP: When the matched label of one of its pods change @ 02/12/24 19:01:54.251
  Feb 12 19:01:54.254: INFO: Pod name pod-release: Found 0 pods out of 1
  Feb 12 19:01:59.260: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 02/12/24 19:01:59.27
  Feb 12 19:02:00.279: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3164" for this suite. @ 02/12/24 19:02:00.282
• [6.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 02/12/24 19:02:00.288
  Feb 12 19:02:00.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 19:02:00.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:00.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:00.307
  STEP: Create a pod @ 02/12/24 19:02:00.309
  STEP: patching /status @ 02/12/24 19:02:02.331
  Feb 12 19:02:02.339: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Feb 12 19:02:02.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8307" for this suite. @ 02/12/24 19:02:02.343
• [2.061 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 02/12/24 19:02:02.349
  Feb 12 19:02:02.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:02:02.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:02.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:02.367
  STEP: Setting up server cert @ 02/12/24 19:02:02.393
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:02:02.705
  STEP: Deploying the webhook pod @ 02/12/24 19:02:02.714
  STEP: Wait for the deployment to be ready @ 02/12/24 19:02:02.723
  Feb 12 19:02:02.735: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:02:04.746
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:02:04.758
  Feb 12 19:02:05.758: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 19:02:05.761: INFO: Unexpected error trying to get Endpoints for e2e-test-webhook : endpoints "e2e-test-webhook" not found
  Feb 12 19:02:06.759: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 19:02:06.762: INFO: Unexpected error trying to get Endpoints for e2e-test-webhook : endpoints "e2e-test-webhook" not found
  Feb 12 19:02:07.759: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 19:02:07.762: INFO: Unexpected error trying to get Endpoints for e2e-test-webhook : endpoints "e2e-test-webhook" not found
  Feb 12 19:02:08.759: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 02/12/24 19:02:08.767
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 02/12/24 19:02:08.768
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 02/12/24 19:02:08.768
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 02/12/24 19:02:08.768
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 02/12/24 19:02:08.77
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 02/12/24 19:02:08.77
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 02/12/24 19:02:08.771
  Feb 12 19:02:08.814: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2135" for this suite. @ 02/12/24 19:02:08.825
  STEP: Destroying namespace "webhook-markers-4698" for this suite. @ 02/12/24 19:02:08.832
• [6.494 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 02/12/24 19:02:08.843
  Feb 12 19:02:08.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 19:02:08.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:08.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:08.861
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 02/12/24 19:02:08.866
  Feb 12 19:02:08.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:02:10.228: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:02:15.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1431" for this suite. @ 02/12/24 19:02:15.209
• [6.373 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 02/12/24 19:02:15.217
  Feb 12 19:02:15.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:02:15.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:15.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:15.24
  Feb 12 19:02:15.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6103 version'
  Feb 12 19:02:15.280: INFO: stderr: ""
  Feb 12 19:02:15.280: INFO: stdout: "Client Version: v1.29.1\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.1\n"
  Feb 12 19:02:15.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6103" for this suite. @ 02/12/24 19:02:15.285
• [0.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 02/12/24 19:02:15.294
  Feb 12 19:02:15.294: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/12/24 19:02:15.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:15.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:15.316
  Feb 12 19:02:15.320: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:02:18.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8178" for this suite. @ 02/12/24 19:02:18.415
• [3.129 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 02/12/24 19:02:18.423
  Feb 12 19:02:18.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:02:18.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:18.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:18.443
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:02:18.446
  STEP: Saw pod success @ 02/12/24 19:02:22.466
  Feb 12 19:02:22.471: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-5a26f642-7053-48cc-b928-7693a64ead1a container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:02:22.483
  Feb 12 19:02:22.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8664" for this suite. @ 02/12/24 19:02:22.503
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 02/12/24 19:02:22.512
  Feb 12 19:02:22.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl-logs @ 02/12/24 19:02:22.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:22.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:22.533
  STEP: creating an pod @ 02/12/24 19:02:22.536
  Feb 12 19:02:22.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Feb 12 19:02:22.592: INFO: stderr: ""
  Feb 12 19:02:22.592: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 02/12/24 19:02:22.592
  Feb 12 19:02:22.592: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  Feb 12 19:02:24.600: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 02/12/24 19:02:24.601
  Feb 12 19:02:24.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 logs logs-generator logs-generator'
  Feb 12 19:02:24.653: INFO: stderr: ""
  Feb 12 19:02:24.653: INFO: stdout: "I0212 19:02:23.129731       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/njtj 521\nI0212 19:02:23.329817       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/x7zj 528\nI0212 19:02:23.530305       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/l7qz 514\nI0212 19:02:23.730588       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/5pfp 479\nI0212 19:02:23.929826       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/xhnk 508\nI0212 19:02:24.130120       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/w8c 478\nI0212 19:02:24.330309       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/4xx 241\nI0212 19:02:24.530551       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/ks7 261\n"
  STEP: limiting log lines @ 02/12/24 19:02:24.653
  Feb 12 19:02:24.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 logs logs-generator logs-generator --tail=1'
  Feb 12 19:02:24.706: INFO: stderr: ""
  Feb 12 19:02:24.706: INFO: stdout: "I0212 19:02:24.530551       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/ks7 261\n"
  Feb 12 19:02:24.706: INFO: got output "I0212 19:02:24.530551       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/ks7 261\n"
  STEP: limiting log bytes @ 02/12/24 19:02:24.706
  Feb 12 19:02:24.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 logs logs-generator logs-generator --limit-bytes=1'
  Feb 12 19:02:24.759: INFO: stderr: ""
  Feb 12 19:02:24.759: INFO: stdout: "I"
  Feb 12 19:02:24.759: INFO: got output "I"
  STEP: exposing timestamps @ 02/12/24 19:02:24.759
  Feb 12 19:02:24.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 logs logs-generator logs-generator --tail=1 --timestamps'
  Feb 12 19:02:24.807: INFO: stderr: ""
  Feb 12 19:02:24.807: INFO: stdout: "2024-02-12T19:02:24.729921205Z I0212 19:02:24.729840       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/5266 436\n"
  Feb 12 19:02:24.807: INFO: got output "2024-02-12T19:02:24.729921205Z I0212 19:02:24.729840       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/5266 436\n"
  STEP: restricting to a time range @ 02/12/24 19:02:24.807
  Feb 12 19:02:27.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 logs logs-generator logs-generator --since=1s'
  Feb 12 19:02:27.356: INFO: stderr: ""
  Feb 12 19:02:27.356: INFO: stdout: "I0212 19:02:26.530297       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/ntv 413\nI0212 19:02:26.730603       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/wjj6 450\nI0212 19:02:26.929825       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/lkh6 262\nI0212 19:02:27.130107       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/zpl 502\nI0212 19:02:27.330399       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/v9s 523\n"
  Feb 12 19:02:27.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 logs logs-generator logs-generator --since=24h'
  Feb 12 19:02:27.409: INFO: stderr: ""
  Feb 12 19:02:27.409: INFO: stdout: "I0212 19:02:23.129731       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/njtj 521\nI0212 19:02:23.329817       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/x7zj 528\nI0212 19:02:23.530305       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/l7qz 514\nI0212 19:02:23.730588       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/5pfp 479\nI0212 19:02:23.929826       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/xhnk 508\nI0212 19:02:24.130120       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/w8c 478\nI0212 19:02:24.330309       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/4xx 241\nI0212 19:02:24.530551       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/ks7 261\nI0212 19:02:24.729840       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/5266 436\nI0212 19:02:24.930135       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/whs 565\nI0212 19:02:25.130418       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/sbm 374\nI0212 19:02:25.330721       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/h8h 320\nI0212 19:02:25.529962       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/lh6l 355\nI0212 19:02:25.730236       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/v69 585\nI0212 19:02:25.930526       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/k678 552\nI0212 19:02:26.129774       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/vls 419\nI0212 19:02:26.330054       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/j768 461\nI0212 19:02:26.530297       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/ntv 413\nI0212 19:02:26.730603       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/wjj6 450\nI0212 19:02:26.929825       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/lkh6 262\nI0212 19:02:27.130107       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/zpl 502\nI0212 19:02:27.330399       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/v9s 523\n"
  Feb 12 19:02:27.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-logs-8902 delete pod logs-generator'
  Feb 12 19:02:28.458: INFO: stderr: ""
  Feb 12 19:02:28.458: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Feb 12 19:02:28.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-8902" for this suite. @ 02/12/24 19:02:28.462
• [5.956 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 02/12/24 19:02:28.469
  Feb 12 19:02:28.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:02:28.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:28.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:28.488
  STEP: Creating projection with secret that has name projected-secret-test-map-1547edbb-4ed2-4c5c-b16c-00c97fbd8e51 @ 02/12/24 19:02:28.492
  STEP: Creating a pod to test consume secrets @ 02/12/24 19:02:28.496
  STEP: Saw pod success @ 02/12/24 19:02:32.52
  Feb 12 19:02:32.523: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-secrets-a64e5279-389f-4fba-bfc0-a80c4a563243 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 19:02:32.532
  Feb 12 19:02:32.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5886" for this suite. @ 02/12/24 19:02:32.557
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 02/12/24 19:02:32.565
  Feb 12 19:02:32.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/12/24 19:02:32.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:32.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:32.589
  Feb 12 19:02:32.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:02:38.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1285" for this suite. @ 02/12/24 19:02:38.808
• [6.251 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 02/12/24 19:02:38.816
  Feb 12 19:02:38.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 19:02:38.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:02:38.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:02:38.837
  STEP: Creating service test in namespace statefulset-7669 @ 02/12/24 19:02:38.84
  STEP: Creating stateful set ss in namespace statefulset-7669 @ 02/12/24 19:02:38.845
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7669 @ 02/12/24 19:02:38.85
  Feb 12 19:02:38.856: INFO: Found 0 stateful pods, waiting for 1
  Feb 12 19:02:48.856: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 02/12/24 19:02:48.856
  Feb 12 19:02:48.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:02:48.954: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:02:48.954: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:02:48.954: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:02:48.959: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Feb 12 19:02:58.960: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:02:58.960: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb 12 19:02:58.978: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
  Feb 12 19:02:58.978: INFO: ss-0  ip-172-31-5-108  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:38 +0000 UTC  }]
  Feb 12 19:02:58.978: INFO: 
  Feb 12 19:02:58.978: INFO: StatefulSet ss has not reached scale 3, at 1
  Feb 12 19:02:59.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996299272s
  Feb 12 19:03:00.990: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990405907s
  Feb 12 19:03:01.995: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984231211s
  Feb 12 19:03:03.001: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978863493s
  Feb 12 19:03:04.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972959776s
  Feb 12 19:03:05.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966631284s
  Feb 12 19:03:06.020: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96027618s
  Feb 12 19:03:07.026: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953884311s
  Feb 12 19:03:08.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.797125ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7669 @ 02/12/24 19:03:09.03
  Feb 12 19:03:09.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:03:09.123: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:03:09.123: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:03:09.123: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:03:09.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:03:09.215: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Feb 12 19:03:09.215: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:03:09.215: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:03:09.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:03:09.316: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Feb 12 19:03:09.316: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:03:09.316: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:03:09.322: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:03:09.322: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:03:09.322: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 02/12/24 19:03:09.322
  Feb 12 19:03:09.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:03:09.415: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:03:09.415: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:03:09.415: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:03:09.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:03:09.506: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:03:09.506: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:03:09.506: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:03:09.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-7669 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:03:09.598: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:03:09.598: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:03:09.598: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:03:09.598: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb 12 19:03:09.603: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  Feb 12 19:03:19.608: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:03:19.608: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:03:19.608: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:03:19.623: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
  Feb 12 19:03:19.623: INFO: ss-0  ip-172-31-5-108  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:38 +0000 UTC  }]
  Feb 12 19:03:19.623: INFO: ss-1  ip-172-31-91-42  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:00 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:58 +0000 UTC  }]
  Feb 12 19:03:19.623: INFO: ss-2  ip-172-31-42-94  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:01 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:58 +0000 UTC  }]
  Feb 12 19:03:19.623: INFO: 
  Feb 12 19:03:19.623: INFO: StatefulSet ss has not reached scale 0, at 3
  Feb 12 19:03:20.628: INFO: POD   NODE             PHASE      GRACE  CONDITIONS
  Feb 12 19:03:20.628: INFO: ss-2  ip-172-31-42-94  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:20 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:58 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:03:10 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 19:02:58 +0000 UTC  }]
  Feb 12 19:03:20.628: INFO: 
  Feb 12 19:03:20.628: INFO: StatefulSet ss has not reached scale 0, at 1
  Feb 12 19:03:21.633: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991109162s
  Feb 12 19:03:22.638: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.98584381s
  Feb 12 19:03:23.643: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.979853733s
  Feb 12 19:03:24.649: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.975541168s
  Feb 12 19:03:25.653: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.970120097s
  Feb 12 19:03:26.658: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965005619s
  Feb 12 19:03:27.664: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.960632937s
  Feb 12 19:03:28.670: INFO: Verifying statefulset ss doesn't scale past 0 for another 954.443827ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7669 @ 02/12/24 19:03:29.67
  Feb 12 19:03:29.675: INFO: Scaling statefulset ss to 0
  Feb 12 19:03:29.688: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:03:29.692: INFO: Deleting all statefulset in ns statefulset-7669
  Feb 12 19:03:29.696: INFO: Scaling statefulset ss to 0
  Feb 12 19:03:29.708: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:03:29.711: INFO: Deleting statefulset ss
  Feb 12 19:03:29.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7669" for this suite. @ 02/12/24 19:03:29.729
• [50.921 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 02/12/24 19:03:29.737
  Feb 12 19:03:29.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename cronjob @ 02/12/24 19:03:29.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:03:29.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:03:29.757
  STEP: Creating a cronjob @ 02/12/24 19:03:29.76
  STEP: Ensuring more than one job is running at a time @ 02/12/24 19:03:29.767
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 02/12/24 19:05:01.773
  STEP: Removing cronjob @ 02/12/24 19:05:01.777
  Feb 12 19:05:01.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-384" for this suite. @ 02/12/24 19:05:01.792
• [92.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 02/12/24 19:05:01.801
  Feb 12 19:05:01.802: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename server-version @ 02/12/24 19:05:01.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:05:01.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:05:01.84
  STEP: Request ServerVersion @ 02/12/24 19:05:01.849
  STEP: Confirm major version @ 02/12/24 19:05:01.855
  Feb 12 19:05:01.855: INFO: Major version: 1
  STEP: Confirm minor version @ 02/12/24 19:05:01.855
  Feb 12 19:05:01.855: INFO: cleanMinorVersion: 29
  Feb 12 19:05:01.855: INFO: Minor version: 29
  Feb 12 19:05:01.855: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-3041" for this suite. @ 02/12/24 19:05:01.86
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 02/12/24 19:05:01.879
  Feb 12 19:05:01.879: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename runtimeclass @ 02/12/24 19:05:01.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:05:01.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:05:01.9
  Feb 12 19:05:03.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3720" for this suite. @ 02/12/24 19:05:03.94
• [2.069 seconds]
------------------------------
SSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 02/12/24 19:05:03.948
  Feb 12 19:05:03.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:05:03.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:05:03.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:05:03.968
  STEP: Creating a pod to test downward api env vars @ 02/12/24 19:05:03.972
  STEP: Saw pod success @ 02/12/24 19:05:05.992
  Feb 12 19:05:05.996: INFO: Trying to get logs from node ip-172-31-5-108 pod downward-api-dda4bed2-dcd6-4642-914d-48958d4eeb88 container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:05:06.008
  Feb 12 19:05:06.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8713" for this suite. @ 02/12/24 19:05:06.028
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 02/12/24 19:05:06.037
  Feb 12 19:05:06.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 19:05:06.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:05:06.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:05:06.055
  STEP: Creating pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633 @ 02/12/24 19:05:06.058
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 19:05:08.074
  Feb 12 19:05:08.078: INFO: Initial restart count of pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 is 0
  Feb 12 19:05:08.081: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:10.087: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:12.092: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:14.097: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:16.103: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:18.108: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:20.115: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:22.120: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:24.124: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:26.131: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:28.136: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:30.141: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:32.146: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:34.151: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:36.157: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:38.162: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:40.168: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:42.174: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:44.180: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:46.185: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:48.192: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:50.199: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:52.203: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:54.210: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:56.215: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:05:58.220: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:00.226: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:02.232: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:04.237: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:06.242: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:08.248: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:10.254: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:12.260: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:14.267: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:16.273: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:18.278: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:20.285: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:22.291: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:24.296: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:26.303: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:28.309: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:30.314: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:32.320: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:34.325: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:36.331: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:38.337: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:40.342: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:42.349: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:44.353: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:46.359: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:48.363: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:50.370: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:52.376: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:54.380: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:56.386: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:06:58.392: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:00.398: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:02.404: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:04.409: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:06.414: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:08.419: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:10.429: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:12.435: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:14.441: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:16.447: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:18.453: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:20.458: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:22.464: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:24.470: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:26.475: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:28.481: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:30.488: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:32.494: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:34.500: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:36.505: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:38.511: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:40.517: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:42.522: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:44.528: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:46.535: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:48.539: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:50.545: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:52.552: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:54.557: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:56.563: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:07:58.569: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:00.574: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:02.579: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:04.586: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:06.590: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:08.596: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:10.601: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:12.607: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:14.613: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:16.617: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:18.624: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:20.629: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:22.634: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:24.640: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:26.645: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:28.650: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:30.655: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:32.661: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:34.666: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:36.671: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:38.677: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:40.684: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:42.689: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:44.696: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:46.702: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:48.707: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:50.712: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:52.719: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:54.724: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:56.730: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:08:58.734: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:09:00.739: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:09:02.745: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:09:04.750: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  Feb 12 19:09:06.755: INFO: Get pod busybox-40ea67db-99ba-4aa2-a43c-57537e5aeb50 in namespace container-probe-2633
  STEP: deleting the pod @ 02/12/24 19:09:08.756
  Feb 12 19:09:08.772: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2633" for this suite. @ 02/12/24 19:09:08.779
• [242.749 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 02/12/24 19:09:08.786
  Feb 12 19:09:08.786: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename cronjob @ 02/12/24 19:09:08.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:09:08.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:09:08.806
  STEP: Creating a ForbidConcurrent cronjob @ 02/12/24 19:09:08.808
  STEP: Ensuring a job is scheduled @ 02/12/24 19:09:08.814
  STEP: Ensuring exactly one is scheduled @ 02/12/24 19:10:00.82
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 02/12/24 19:10:00.824
  STEP: Ensuring no more jobs are scheduled @ 02/12/24 19:10:00.827
  STEP: Removing cronjob @ 02/12/24 19:15:00.837
  Feb 12 19:15:00.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9692" for this suite. @ 02/12/24 19:15:00.851
• [352.072 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 02/12/24 19:15:00.858
  Feb 12 19:15:00.858: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 19:15:00.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:00.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:00.882
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 02/12/24 19:15:00.885
  STEP: Saw pod success @ 02/12/24 19:15:04.907
  Feb 12 19:15:04.912: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-4d06ffb2-c35d-4d2e-a1a0-ef2a02210c55 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 19:15:04.929
  Feb 12 19:15:04.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6286" for this suite. @ 02/12/24 19:15:04.95
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 02/12/24 19:15:04.958
  Feb 12 19:15:04.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 19:15:04.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:04.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:04.978
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 02/12/24 19:15:04.981
  STEP: Saw pod success @ 02/12/24 19:15:09.005
  Feb 12 19:15:09.009: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-54028ec6-f5b6-4376-b0a0-4bc64d86b33f container test-container: <nil>
  STEP: delete the pod @ 02/12/24 19:15:09.027
  Feb 12 19:15:09.044: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2261" for this suite. @ 02/12/24 19:15:09.048
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 02/12/24 19:15:09.057
  Feb 12 19:15:09.057: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename security-context @ 02/12/24 19:15:09.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:09.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:09.079
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 02/12/24 19:15:09.082
  STEP: Saw pod success @ 02/12/24 19:15:13.108
  Feb 12 19:15:13.112: INFO: Trying to get logs from node ip-172-31-5-108 pod security-context-4aef75ed-3787-4227-893c-2305631d207e container test-container: <nil>
  STEP: delete the pod @ 02/12/24 19:15:13.12
  Feb 12 19:15:13.135: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-305" for this suite. @ 02/12/24 19:15:13.139
• [4.097 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 02/12/24 19:15:13.153
  Feb 12 19:15:13.153: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 19:15:13.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:13.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:13.176
  Feb 12 19:15:13.178: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Feb 12 19:15:13.188: INFO: Pod name sample-pod: Found 0 pods out of 1
  Feb 12 19:15:18.193: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/12/24 19:15:18.193
  Feb 12 19:15:18.193: INFO: Creating deployment "test-rolling-update-deployment"
  Feb 12 19:15:18.199: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Feb 12 19:15:18.205: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Feb 12 19:15:20.216: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Feb 12 19:15:20.220: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Feb 12 19:15:20.231: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bb8f83e3-eeea-4ad1-9099-54aaf3044595",
      ResourceVersion: (string) (len=4) "8269",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362118,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=82) "ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 19:15:20.236: INFO: New ReplicaSet "test-rolling-update-deployment-7f5c55c64" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1fee87d0-5dbb-4ce7-80de-d68c05b31938",
      ResourceVersion: (string) (len=4) "8259",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362118,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64",
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "bb8f83e3-eeea-4ad1-9099-54aaf3044595",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 62 38 66 38 33  65 33 2d 65 65 65 61 2d  |\"bb8f83e3-eeea-|
              00000120  34 61 64 31 2d 39 30 39  39 2d 35 34 61 61 66 33  |4ad1-9099-54aaf3|
              00000130  30 34 34 35 39 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |044595\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:15:20.237: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Feb 12 19:15:20.237: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fb45f2c9-32fb-4558-963e-2910af2213fc",
      ResourceVersion: (string) (len=4) "8268",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362113,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "bb8f83e3-eeea-4ad1-9099-54aaf3044595",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362113,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 62 62 38 66 38 33 65  |"uid\":\"bb8f83e|
              000000b0  33 2d 65 65 65 61 2d 34  61 64 31 2d 39 30 39 39  |3-eeea-4ad1-9099|
              000000c0  2d 35 34 61 61 66 33 30  34 34 35 39 35 5c 22 7d  |-54aaf3044595\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:15:20.243: INFO: Pod "test-rolling-update-deployment-7f5c55c64-vtdtx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=46) "test-rolling-update-deployment-7f5c55c64-vtdtx",
      GenerateName: (string) (len=41) "test-rolling-update-deployment-7f5c55c64-",
      Namespace: (string) (len=14) "deployment-628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2cae7275-8508-4b4a-94ce-58801366915e",
      ResourceVersion: (string) (len=4) "8258",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362118,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
          UID: (types.UID) (len=36) "1fee87d0-5dbb-4ce7-80de-d68c05b31938",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 66  65 65 38 37 64 30 2d 35  |d\":\"1fee87d0-5|
              00000090  64 62 62 2d 34 63 65 37  2d 38 30 64 65 2d 64 36  |dbb-4ce7-80de-d6|
              000000a0  38 63 30 35 62 33 31 39  33 38 5c 22 7d 22 3a 7b  |8c05b31938\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 37 31  2e 32 30 32 5c 22 7d 22  |2.168.71.202\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w6r57",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w6r57",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362119,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362118,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.202",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.202"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362118,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843362118,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://828f88408be2a70afd572c1f7d59946e9e33acfed1500aced3e283fee5205def",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:15:20.244: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-628" for this suite. @ 02/12/24 19:15:20.248
• [7.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 02/12/24 19:15:20.256
  Feb 12 19:15:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 19:15:20.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:20.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:20.277
  STEP: Creating a test externalName service @ 02/12/24 19:15:20.28
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5660.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5660.svc.cluster.local; sleep 1; done
   @ 02/12/24 19:15:20.284
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5660.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5660.svc.cluster.local; sleep 1; done
   @ 02/12/24 19:15:20.285
  STEP: creating a pod to probe DNS @ 02/12/24 19:15:20.285
  STEP: submitting the pod to kubernetes @ 02/12/24 19:15:20.285
  STEP: retrieving the pod @ 02/12/24 19:15:26.316
  STEP: looking for the results for each expected name from probers @ 02/12/24 19:15:26.32
  Feb 12 19:15:26.331: INFO: DNS probes using dns-test-3df44de6-3bf7-4a94-9073-933606358bc6 succeeded

  STEP: changing the externalName to bar.example.com @ 02/12/24 19:15:26.331
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5660.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5660.svc.cluster.local; sleep 1; done
   @ 02/12/24 19:15:26.341
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5660.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5660.svc.cluster.local; sleep 1; done
   @ 02/12/24 19:15:26.341
  STEP: creating a second pod to probe DNS @ 02/12/24 19:15:26.341
  STEP: submitting the pod to kubernetes @ 02/12/24 19:15:26.341
  STEP: retrieving the pod @ 02/12/24 19:15:32.371
  STEP: looking for the results for each expected name from probers @ 02/12/24 19:15:32.375
  Feb 12 19:15:32.387: INFO: DNS probes using dns-test-4c1f9576-2658-45d6-9aad-289fffbe31b1 succeeded

  STEP: changing the service to type=ClusterIP @ 02/12/24 19:15:32.387
  W0212 19:15:32.403639      20 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5660.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5660.svc.cluster.local; sleep 1; done
   @ 02/12/24 19:15:32.403
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5660.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5660.svc.cluster.local; sleep 1; done
   @ 02/12/24 19:15:32.403
  STEP: creating a third pod to probe DNS @ 02/12/24 19:15:32.403
  STEP: submitting the pod to kubernetes @ 02/12/24 19:15:32.407
  STEP: retrieving the pod @ 02/12/24 19:15:34.427
  STEP: looking for the results for each expected name from probers @ 02/12/24 19:15:34.431
  Feb 12 19:15:34.443: INFO: DNS probes using dns-test-9af89b60-1103-4642-9021-ed613ea76db3 succeeded

  STEP: deleting the pod @ 02/12/24 19:15:34.443
  STEP: deleting the pod @ 02/12/24 19:15:34.459
  STEP: deleting the pod @ 02/12/24 19:15:34.47
  STEP: deleting the test externalName service @ 02/12/24 19:15:34.481
  Feb 12 19:15:34.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5660" for this suite. @ 02/12/24 19:15:34.502
• [14.253 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 02/12/24 19:15:34.509
  Feb 12 19:15:34.509: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:15:34.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:34.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:34.529
  STEP: creating a Service @ 02/12/24 19:15:34.536
  STEP: watching for the Service to be added @ 02/12/24 19:15:34.551
  Feb 12 19:15:34.552: INFO: Found Service test-service-kqzps in namespace services-9856 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30791}]
  Feb 12 19:15:34.553: INFO: Service test-service-kqzps created
  STEP: Getting /status @ 02/12/24 19:15:34.553
  Feb 12 19:15:34.558: INFO: Service test-service-kqzps has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 02/12/24 19:15:34.558
  STEP: watching for the Service to be patched @ 02/12/24 19:15:34.566
  Feb 12 19:15:34.569: INFO: observed Service test-service-kqzps in namespace services-9856 with annotations: map[] & LoadBalancer: {[]}
  Feb 12 19:15:34.569: INFO: Found Service test-service-kqzps in namespace services-9856 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  Feb 12 19:15:34.569: INFO: Service test-service-kqzps has service status patched
  STEP: updating the ServiceStatus @ 02/12/24 19:15:34.569
  Feb 12 19:15:34.583: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 02/12/24 19:15:34.583
  Feb 12 19:15:34.585: INFO: Observed Service test-service-kqzps in namespace services-9856 with annotations: map[] & Conditions: {[]}
  Feb 12 19:15:34.585: INFO: Observed event: &Service{ObjectMeta:{test-service-kqzps  services-9856  068a35be-75c7-4fd8-9f49-c66fc12ed190 8415 0 2024-02-12 19:15:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-02-12 19:15:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-02-12 19:15:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:30791,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.232,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.232],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Feb 12 19:15:34.585: INFO: Found Service test-service-kqzps in namespace services-9856 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb 12 19:15:34.585: INFO: Service test-service-kqzps has service status updated
  STEP: patching the service @ 02/12/24 19:15:34.585
  STEP: watching for the Service to be patched @ 02/12/24 19:15:34.607
  Feb 12 19:15:34.609: INFO: observed Service test-service-kqzps in namespace services-9856 with labels: map[test-service-static:true]
  Feb 12 19:15:34.609: INFO: observed Service test-service-kqzps in namespace services-9856 with labels: map[test-service-static:true]
  Feb 12 19:15:34.609: INFO: observed Service test-service-kqzps in namespace services-9856 with labels: map[test-service-static:true]
  Feb 12 19:15:34.609: INFO: Found Service test-service-kqzps in namespace services-9856 with labels: map[test-service:patched test-service-static:true]
  Feb 12 19:15:34.609: INFO: Service test-service-kqzps patched
  STEP: deleting the service @ 02/12/24 19:15:34.609
  STEP: watching for the Service to be deleted @ 02/12/24 19:15:34.636
  Feb 12 19:15:34.638: INFO: Observed event: ADDED
  Feb 12 19:15:34.638: INFO: Observed event: MODIFIED
  Feb 12 19:15:34.638: INFO: Observed event: MODIFIED
  Feb 12 19:15:34.638: INFO: Observed event: MODIFIED
  Feb 12 19:15:34.638: INFO: Found Service test-service-kqzps in namespace services-9856 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Feb 12 19:15:34.638: INFO: Service test-service-kqzps deleted
  Feb 12 19:15:34.638: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9856" for this suite. @ 02/12/24 19:15:34.643
• [0.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 02/12/24 19:15:34.651
  Feb 12 19:15:34.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:15:34.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:34.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:34.672
  STEP: creating a replication controller @ 02/12/24 19:15:34.675
  Feb 12 19:15:34.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 create -f -'
  Feb 12 19:15:34.772: INFO: stderr: ""
  Feb 12 19:15:34.772: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/12/24 19:15:34.772
  Feb 12 19:15:34.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 19:15:34.826: INFO: stderr: ""
  Feb 12 19:15:34.826: INFO: stdout: "update-demo-nautilus-sgtb7 update-demo-nautilus-z5ftz "
  Feb 12 19:15:34.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:34.870: INFO: stderr: ""
  Feb 12 19:15:34.870: INFO: stdout: ""
  Feb 12 19:15:34.870: INFO: update-demo-nautilus-sgtb7 is created but not running
  Feb 12 19:15:39.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 19:15:39.916: INFO: stderr: ""
  Feb 12 19:15:39.916: INFO: stdout: "update-demo-nautilus-sgtb7 update-demo-nautilus-z5ftz "
  Feb 12 19:15:39.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:39.960: INFO: stderr: ""
  Feb 12 19:15:39.960: INFO: stdout: "true"
  Feb 12 19:15:39.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 19:15:40.002: INFO: stderr: ""
  Feb 12 19:15:40.003: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 19:15:40.003: INFO: validating pod update-demo-nautilus-sgtb7
  Feb 12 19:15:40.009: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 19:15:40.010: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 19:15:40.010: INFO: update-demo-nautilus-sgtb7 is verified up and running
  Feb 12 19:15:40.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-z5ftz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:40.054: INFO: stderr: ""
  Feb 12 19:15:40.054: INFO: stdout: "true"
  Feb 12 19:15:40.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-z5ftz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 19:15:40.099: INFO: stderr: ""
  Feb 12 19:15:40.099: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 19:15:40.099: INFO: validating pod update-demo-nautilus-z5ftz
  Feb 12 19:15:40.105: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 19:15:40.105: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 19:15:40.105: INFO: update-demo-nautilus-z5ftz is verified up and running
  STEP: scaling down the replication controller @ 02/12/24 19:15:40.105
  Feb 12 19:15:40.106: INFO: scanned /root for discovery docs: <nil>
  Feb 12 19:15:40.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  Feb 12 19:15:41.170: INFO: stderr: ""
  Feb 12 19:15:41.170: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/12/24 19:15:41.17
  Feb 12 19:15:41.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 19:15:41.219: INFO: stderr: ""
  Feb 12 19:15:41.219: INFO: stdout: "update-demo-nautilus-sgtb7 update-demo-nautilus-z5ftz "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 02/12/24 19:15:41.219
  Feb 12 19:15:46.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 19:15:46.265: INFO: stderr: ""
  Feb 12 19:15:46.265: INFO: stdout: "update-demo-nautilus-sgtb7 "
  Feb 12 19:15:46.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:46.309: INFO: stderr: ""
  Feb 12 19:15:46.309: INFO: stdout: "true"
  Feb 12 19:15:46.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 19:15:46.351: INFO: stderr: ""
  Feb 12 19:15:46.351: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 19:15:46.351: INFO: validating pod update-demo-nautilus-sgtb7
  Feb 12 19:15:46.357: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 19:15:46.357: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 19:15:46.357: INFO: update-demo-nautilus-sgtb7 is verified up and running
  STEP: scaling up the replication controller @ 02/12/24 19:15:46.357
  Feb 12 19:15:46.358: INFO: scanned /root for discovery docs: <nil>
  Feb 12 19:15:46.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  Feb 12 19:15:47.422: INFO: stderr: ""
  Feb 12 19:15:47.422: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/12/24 19:15:47.422
  Feb 12 19:15:47.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 19:15:47.467: INFO: stderr: ""
  Feb 12 19:15:47.467: INFO: stdout: "update-demo-nautilus-bzhx8 update-demo-nautilus-sgtb7 "
  Feb 12 19:15:47.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-bzhx8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:47.512: INFO: stderr: ""
  Feb 12 19:15:47.512: INFO: stdout: ""
  Feb 12 19:15:47.512: INFO: update-demo-nautilus-bzhx8 is created but not running
  Feb 12 19:15:52.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 19:15:52.560: INFO: stderr: ""
  Feb 12 19:15:52.560: INFO: stdout: "update-demo-nautilus-bzhx8 update-demo-nautilus-sgtb7 "
  Feb 12 19:15:52.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-bzhx8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:52.603: INFO: stderr: ""
  Feb 12 19:15:52.603: INFO: stdout: "true"
  Feb 12 19:15:52.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-bzhx8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 19:15:52.647: INFO: stderr: ""
  Feb 12 19:15:52.647: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 19:15:52.647: INFO: validating pod update-demo-nautilus-bzhx8
  Feb 12 19:15:52.654: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 19:15:52.654: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 19:15:52.654: INFO: update-demo-nautilus-bzhx8 is verified up and running
  Feb 12 19:15:52.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 19:15:52.696: INFO: stderr: ""
  Feb 12 19:15:52.696: INFO: stdout: "true"
  Feb 12 19:15:52.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods update-demo-nautilus-sgtb7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 19:15:52.739: INFO: stderr: ""
  Feb 12 19:15:52.739: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 19:15:52.739: INFO: validating pod update-demo-nautilus-sgtb7
  Feb 12 19:15:52.743: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 19:15:52.743: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 19:15:52.743: INFO: update-demo-nautilus-sgtb7 is verified up and running
  STEP: using delete to clean up resources @ 02/12/24 19:15:52.743
  Feb 12 19:15:52.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 delete --grace-period=0 --force -f -'
  Feb 12 19:15:52.790: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:15:52.790: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Feb 12 19:15:52.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get rc,svc -l name=update-demo --no-headers'
  Feb 12 19:15:52.850: INFO: stderr: "No resources found in kubectl-6501 namespace.\n"
  Feb 12 19:15:52.850: INFO: stdout: ""
  Feb 12 19:15:52.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6501 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Feb 12 19:15:52.918: INFO: stderr: ""
  Feb 12 19:15:52.918: INFO: stdout: ""
  Feb 12 19:15:52.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6501" for this suite. @ 02/12/24 19:15:52.922
• [18.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 02/12/24 19:15:52.931
  Feb 12 19:15:52.931: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 19:15:52.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:15:52.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:15:52.952
  STEP: Creating service test in namespace statefulset-3791 @ 02/12/24 19:15:52.956
  STEP: Looking for a node to schedule stateful set and pod @ 02/12/24 19:15:52.961
  STEP: Creating pod with conflicting port in namespace statefulset-3791 @ 02/12/24 19:15:52.967
  STEP: Waiting until pod test-pod will start running in namespace statefulset-3791 @ 02/12/24 19:15:52.977
  STEP: Creating statefulset with conflicting port in namespace statefulset-3791 @ 02/12/24 19:15:54.986
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3791 @ 02/12/24 19:15:54.991
  Feb 12 19:15:55.003: INFO: Observed stateful pod in namespace: statefulset-3791, name: ss-0, uid: ef3599d2-688c-429f-8faf-32bad0c68e54, status phase: Pending. Waiting for statefulset controller to delete.
  Feb 12 19:15:55.022: INFO: Observed stateful pod in namespace: statefulset-3791, name: ss-0, uid: ef3599d2-688c-429f-8faf-32bad0c68e54, status phase: Failed. Waiting for statefulset controller to delete.
  Feb 12 19:15:55.030: INFO: Observed stateful pod in namespace: statefulset-3791, name: ss-0, uid: ef3599d2-688c-429f-8faf-32bad0c68e54, status phase: Failed. Waiting for statefulset controller to delete.
  Feb 12 19:15:55.035: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3791
  STEP: Removing pod with conflicting port in namespace statefulset-3791 @ 02/12/24 19:15:55.035
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3791 and will be in running state @ 02/12/24 19:15:55.05
  Feb 12 19:15:57.060: INFO: Deleting all statefulset in ns statefulset-3791
  Feb 12 19:15:57.065: INFO: Scaling statefulset ss to 0
  Feb 12 19:16:07.083: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:16:07.089: INFO: Deleting statefulset ss
  Feb 12 19:16:07.105: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3791" for this suite. @ 02/12/24 19:16:07.11
• [14.188 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 02/12/24 19:16:07.12
  Feb 12 19:16:07.120: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:16:07.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:07.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:07.141
  STEP: Creating configMap with name configmap-test-volume-map-f0a8a072-782b-4337-a6bc-198ed758185b @ 02/12/24 19:16:07.144
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:16:07.149
  STEP: Saw pod success @ 02/12/24 19:16:11.17
  Feb 12 19:16:11.175: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-cca711bc-d634-41df-a714-f8c6e610ff57 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:16:11.183
  Feb 12 19:16:11.199: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7488" for this suite. @ 02/12/24 19:16:11.203
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 02/12/24 19:16:11.21
  Feb 12 19:16:11.210: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 19:16:11.21
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:11.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:11.236
  STEP: apply creating a deployment @ 02/12/24 19:16:11.239
  Feb 12 19:16:11.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1101" for this suite. @ 02/12/24 19:16:11.26
• [0.057 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 02/12/24 19:16:11.267
  Feb 12 19:16:11.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:16:11.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:11.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:11.286
  STEP: Creating projection with secret that has name projected-secret-test-1e01b686-3b24-4add-8cf8-c7fb4dee3518 @ 02/12/24 19:16:11.289
  STEP: Creating a pod to test consume secrets @ 02/12/24 19:16:11.293
  STEP: Saw pod success @ 02/12/24 19:16:15.314
  Feb 12 19:16:15.319: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-secrets-24d936a4-07cb-4ce0-ab00-723110a24215 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 19:16:15.326
  Feb 12 19:16:15.341: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1510" for this suite. @ 02/12/24 19:16:15.344
• [4.085 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 02/12/24 19:16:15.353
  Feb 12 19:16:15.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 19:16:15.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:15.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:15.371
  Feb 12 19:16:15.375: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  W0212 19:16:15.375532      20 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc001458a20 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0212 19:16:17.916132      20 warnings.go:70] unknown field "alpha"
  W0212 19:16:17.916151      20 warnings.go:70] unknown field "beta"
  W0212 19:16:17.916155      20 warnings.go:70] unknown field "delta"
  W0212 19:16:17.916158      20 warnings.go:70] unknown field "epsilon"
  W0212 19:16:17.916161      20 warnings.go:70] unknown field "gamma"
  Feb 12 19:16:18.465: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5848" for this suite. @ 02/12/24 19:16:18.47
• [3.125 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 02/12/24 19:16:18.478
  Feb 12 19:16:18.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:16:18.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:18.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:18.499
  STEP: Creating configMap with name projected-configmap-test-volume-6eee2ac6-1147-400a-8e2c-f19e2293a983 @ 02/12/24 19:16:18.502
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:16:18.509
  STEP: Saw pod success @ 02/12/24 19:16:22.531
  Feb 12 19:16:22.536: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-configmaps-55050c52-636f-4d6d-a949-be304ce0673b container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:16:22.544
  Feb 12 19:16:22.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6460" for this suite. @ 02/12/24 19:16:22.563
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 02/12/24 19:16:22.572
  Feb 12 19:16:22.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 19:16:22.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:22.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:22.592
  STEP: Creating secret with name secret-test-e7a24e23-2cfa-4e6a-b57a-0f2ddd8d9f9c @ 02/12/24 19:16:22.595
  STEP: Creating a pod to test consume secrets @ 02/12/24 19:16:22.6
  STEP: Saw pod success @ 02/12/24 19:16:26.625
  Feb 12 19:16:26.630: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-d4bb5400-fe96-4ae1-b06e-618866b7c90b container secret-env-test: <nil>
  STEP: delete the pod @ 02/12/24 19:16:26.638
  Feb 12 19:16:26.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4700" for this suite. @ 02/12/24 19:16:26.658
• [4.093 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 02/12/24 19:16:26.666
  Feb 12 19:16:26.666: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 19:16:26.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:26.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:26.69
  STEP: Creating pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222 @ 02/12/24 19:16:26.697
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 19:16:28.724
  Feb 12 19:16:28.728: INFO: Initial restart count of pod liveness-56460ef5-f95a-46be-924b-0cc69805305c is 0
  Feb 12 19:16:28.731: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:30.738: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:32.743: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:34.749: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:36.755: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:38.759: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:40.765: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:42.771: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:44.777: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:46.783: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:48.789: INFO: Get pod liveness-56460ef5-f95a-46be-924b-0cc69805305c in namespace container-probe-3222
  Feb 12 19:16:48.789: INFO: Restart count of pod container-probe-3222/liveness-56460ef5-f95a-46be-924b-0cc69805305c is now 1 (20.06076773s elapsed)
  STEP: deleting the pod @ 02/12/24 19:16:48.789
  Feb 12 19:16:48.801: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3222" for this suite. @ 02/12/24 19:16:48.805
• [22.146 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 02/12/24 19:16:48.812
  Feb 12 19:16:48.812: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replicaset @ 02/12/24 19:16:48.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:48.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:48.833
  STEP: Create a Replicaset @ 02/12/24 19:16:48.84
  STEP: Verify that the required pods have come up. @ 02/12/24 19:16:48.844
  Feb 12 19:16:48.848: INFO: Pod name sample-pod: Found 0 pods out of 1
  Feb 12 19:16:53.854: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/12/24 19:16:53.854
  STEP: Getting /status @ 02/12/24 19:16:53.854
  Feb 12 19:16:53.859: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 02/12/24 19:16:53.859
  Feb 12 19:16:53.868: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 02/12/24 19:16:53.868
  Feb 12 19:16:53.870: INFO: Observed &ReplicaSet event: ADDED
  Feb 12 19:16:53.870: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.870: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.870: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.870: INFO: Found replicaset test-rs in namespace replicaset-3469 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb 12 19:16:53.870: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 02/12/24 19:16:53.87
  Feb 12 19:16:53.870: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Feb 12 19:16:53.876: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 02/12/24 19:16:53.876
  Feb 12 19:16:53.878: INFO: Observed &ReplicaSet event: ADDED
  Feb 12 19:16:53.878: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.878: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.878: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.878: INFO: Observed replicaset test-rs in namespace replicaset-3469 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb 12 19:16:53.878: INFO: Observed &ReplicaSet event: MODIFIED
  Feb 12 19:16:53.878: INFO: Found replicaset test-rs in namespace replicaset-3469 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Feb 12 19:16:53.878: INFO: Replicaset test-rs has a patched status
  Feb 12 19:16:53.878: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3469" for this suite. @ 02/12/24 19:16:53.882
• [5.079 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 02/12/24 19:16:53.891
  Feb 12 19:16:53.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:16:53.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:16:53.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:16:53.912
  STEP: creating service multiprotocol-test in namespace services-4106 @ 02/12/24 19:16:53.914
  STEP: creating pod pod1 in namespace services-4106 @ 02/12/24 19:16:53.927
  STEP: Creating pod pod1 in namespace services-4106 @ 02/12/24 19:16:53.927
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-4106 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 02/12/24 19:16:55.948
  Feb 12 19:16:55.961: INFO: successfully validated that service multiprotocol-test in namespace services-4106 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 02/12/24 19:16:55.961
  Feb 12 19:16:55.961: INFO: Creating new exec pod
  Feb 12 19:16:57.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80'
  Feb 12 19:16:58.073: INFO: stderr: "+ nc -v -t -w 2 10.152.183.60 80\n+ echo hostName\nConnection to 10.152.183.60 80 port [tcp/http] succeeded!\n"
  Feb 12 19:16:58.073: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:16:58.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.60 80'
  Feb 12 19:17:02.160: INFO: stderr: "+ nc -v -u -w 2 10.152.183.60 80\n+ echo hostName\nConnection to 10.152.183.60 80 port [udp/*] succeeded!\n"
  Feb 12 19:17:02.160: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 02/12/24 19:17:02.16
  Feb 12 19:17:02.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80'
  Feb 12 19:17:02.273: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.60 80\nConnection to 10.152.183.60 80 port [tcp/http] succeeded!\n"
  Feb 12 19:17:02.273: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:17:02.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.60 80'
  Feb 12 19:17:06.361: INFO: stderr: "+ nc -v -u -w 2 10.152.183.60 80\n+ echo hostName\nConnection to 10.152.183.60 80 port [udp/*] succeeded!\n"
  Feb 12 19:17:06.361: INFO: stdout: ""
  Feb 12 19:17:06.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.60 80'
  Feb 12 19:17:10.453: INFO: stderr: "+ nc -v -u -w 2 10.152.183.60 80\n+ echo hostName\nConnection to 10.152.183.60 80 port [udp/*] succeeded!\n"
  Feb 12 19:17:10.453: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 02/12/24 19:17:10.453
  Feb 12 19:17:10.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.60 80'
  Feb 12 19:17:14.558: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.60 80\nConnection to 10.152.183.60 80 port [udp/*] succeeded!\n"
  Feb 12 19:17:14.558: INFO: stdout: "pod1"
  Feb 12 19:17:14.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80'
  Feb 12 19:17:16.653: INFO: rc: 1
  Feb 12 19:17:16.654: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.60 80
  + echo hostName
  nc: connect to 10.152.183.60 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb 12 19:17:16.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80'
  Feb 12 19:17:18.749: INFO: rc: 1
  Feb 12 19:17:18.749: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.60 80
  + echo hostName
  nc: connect to 10.152.183.60 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb 12 19:17:18.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80'
  Feb 12 19:17:20.841: INFO: rc: 1
  Feb 12 19:17:20.841: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4106 exec execpodl9krl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.60 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.60 80
  nc: connect to 10.152.183.60 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb 12 19:17:20.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4106" for this suite. @ 02/12/24 19:17:20.846
• [26.963 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 02/12/24 19:17:20.854
  Feb 12 19:17:20.854: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:17:20.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:17:20.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:17:20.876
  STEP: validating cluster-info @ 02/12/24 19:17:20.879
  Feb 12 19:17:20.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2794 cluster-info'
  Feb 12 19:17:20.921: INFO: stderr: ""
  Feb 12 19:17:20.921: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Feb 12 19:17:20.921: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2794" for this suite. @ 02/12/24 19:17:20.926
• [0.079 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 02/12/24 19:17:20.933
  Feb 12 19:17:20.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 19:17:20.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:17:20.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:17:20.951
  STEP: Creating secret with name s-test-opt-del-ca8b3484-1134-4d9c-9c50-5ffa302d6712 @ 02/12/24 19:17:20.958
  STEP: Creating secret with name s-test-opt-upd-85f7bfcc-8c3f-4ec5-8884-5bcb2a457e91 @ 02/12/24 19:17:20.963
  STEP: Creating the pod @ 02/12/24 19:17:20.967
  STEP: Deleting secret s-test-opt-del-ca8b3484-1134-4d9c-9c50-5ffa302d6712 @ 02/12/24 19:17:23.016
  STEP: Updating secret s-test-opt-upd-85f7bfcc-8c3f-4ec5-8884-5bcb2a457e91 @ 02/12/24 19:17:23.024
  STEP: Creating secret with name s-test-opt-create-696a0ff1-fd34-44b3-805c-bd516fd60031 @ 02/12/24 19:17:23.031
  STEP: waiting to observe update in volume @ 02/12/24 19:17:23.036
  Feb 12 19:18:55.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4403" for this suite. @ 02/12/24 19:18:55.521
• [94.595 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 02/12/24 19:18:55.529
  Feb 12 19:18:55.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename runtimeclass @ 02/12/24 19:18:55.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:18:55.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:18:55.551
  STEP: Deleting RuntimeClass runtimeclass-2935-delete-me @ 02/12/24 19:18:55.559
  STEP: Waiting for the RuntimeClass to disappear @ 02/12/24 19:18:55.566
  Feb 12 19:18:55.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2935" for this suite. @ 02/12/24 19:18:55.582
• [0.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 02/12/24 19:18:55.591
  Feb 12 19:18:55.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 19:18:55.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:18:55.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:18:55.609
  STEP: creating the pod @ 02/12/24 19:18:55.612
  STEP: submitting the pod to kubernetes @ 02/12/24 19:18:55.612
  STEP: verifying the pod is in kubernetes @ 02/12/24 19:18:57.632
  STEP: updating the pod @ 02/12/24 19:18:57.637
  Feb 12 19:18:58.151: INFO: Successfully updated pod "pod-update-c597cefb-c07e-4876-b1e6-b3d1b54c698e"
  STEP: verifying the updated pod is in kubernetes @ 02/12/24 19:18:58.156
  Feb 12 19:18:58.160: INFO: Pod update OK
  Feb 12 19:18:58.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5839" for this suite. @ 02/12/24 19:18:58.165
• [2.582 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 02/12/24 19:18:58.173
  Feb 12 19:18:58.173: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:18:58.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:18:58.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:18:58.202
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-2386 @ 02/12/24 19:18:58.205
  STEP: changing the ExternalName service to type=ClusterIP @ 02/12/24 19:18:58.211
  STEP: creating replication controller externalname-service in namespace services-2386 @ 02/12/24 19:18:58.224
  I0212 19:18:58.231690      20 runners.go:197] Created replication controller with name: externalname-service, namespace: services-2386, replica count: 2
  I0212 19:19:01.282772      20 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 19:19:01.282: INFO: Creating new exec pod
  Feb 12 19:19:04.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2386 exec execpodssvvl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Feb 12 19:19:04.402: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Feb 12 19:19:04.402: INFO: stdout: "externalname-service-d46l6"
  Feb 12 19:19:04.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2386 exec execpodssvvl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.77 80'
  Feb 12 19:19:04.484: INFO: stderr: "+ nc -v -t -w 2 10.152.183.77 80\n+ echo hostName\nConnection to 10.152.183.77 80 port [tcp/http] succeeded!\n"
  Feb 12 19:19:04.484: INFO: stdout: "externalname-service-d46l6"
  Feb 12 19:19:04.484: INFO: Cleaning up the ExternalName to ClusterIP test service
  Feb 12 19:19:04.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2386" for this suite. @ 02/12/24 19:19:04.507
• [6.343 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 02/12/24 19:19:04.516
  Feb 12 19:19:04.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 19:19:04.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:04.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:04.54
  Feb 12 19:19:04.544: INFO: Creating deployment "test-recreate-deployment"
  Feb 12 19:19:04.550: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Feb 12 19:19:04.568: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  Feb 12 19:19:06.577: INFO: Waiting deployment "test-recreate-deployment" to complete
  Feb 12 19:19:06.582: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Feb 12 19:19:06.592: INFO: Updating deployment test-recreate-deployment
  Feb 12 19:19:06.592: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Feb 12 19:19:06.661: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4981",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3e98a06c-c91a-4259-915f-fb8b090db117",
      ResourceVersion: (string) (len=4) "9657",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362344,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362344,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 19:19:06.666: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4981",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "54f3e624-15e7-4166-bff9-7e8320a4b898",
      ResourceVersion: (string) (len=4) "9656",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362346,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "3e98a06c-c91a-4259-915f-fb8b090db117",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 65 39 38 61 30  36 63 2d 63 39 31 61 2d  |\"3e98a06c-c91a-|
              00000120  34 32 35 39 2d 39 31 35  66 2d 66 62 38 62 30 39  |4259-915f-fb8b09|
              00000130  30 64 62 31 31 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0db117\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:19:06.667: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Feb 12 19:19:06.667: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-dd4bc9d6d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4981",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b1f6371b-1a0c-443d-8ffd-01e7f346a06a",
      ResourceVersion: (string) (len=4) "9646",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362344,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "3e98a06c-c91a-4259-915f-fb8b090db117",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 65 39 38 61 30  36 63 2d 63 39 31 61 2d  |\"3e98a06c-c91a-|
              00000120  34 32 35 39 2d 39 31 35  66 2d 66 62 38 62 30 39  |4259-915f-fb8b09|
              00000130  30 64 62 31 31 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0db117\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:19:06.672: INFO: Pod "test-recreate-deployment-76fb77d45-frlhx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-frlhx",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-4981",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "68d1a69b-cd65-4950-b78f-0988c3cc489a",
      ResourceVersion: (string) (len=4) "9658",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362346,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "54f3e624-15e7-4166-bff9-7e8320a4b898",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 34  66 33 65 36 32 34 2d 31  |d\":\"54f3e624-1|
              00000090  35 65 37 2d 34 31 36 36  2d 62 66 66 39 2d 37 65  |5e7-4166-bff9-7e|
              000000a0  38 33 32 30 61 34 62 38  39 38 5c 22 7d 22 3a 7b  |8320a4b898\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w5rq9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w5rq9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362346,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:19:06.675: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4981" for this suite. @ 02/12/24 19:19:06.68
• [2.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 02/12/24 19:19:06.688
  Feb 12 19:19:06.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 19:19:06.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:06.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:06.708
  Feb 12 19:19:06.733: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 02/12/24 19:19:06.737
  Feb 12 19:19:06.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:06.740: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 02/12/24 19:19:06.74
  Feb 12 19:19:06.760: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:06.760: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  Feb 12 19:19:07.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:07.761: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  Feb 12 19:19:08.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb 12 19:19:08.761: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 02/12/24 19:19:08.765
  Feb 12 19:19:08.781: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb 12 19:19:08.781: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Feb 12 19:19:09.782: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:09.783: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 02/12/24 19:19:09.783
  Feb 12 19:19:09.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:09.796: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  Feb 12 19:19:10.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:10.794: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  Feb 12 19:19:11.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb 12 19:19:11.794: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 02/12/24 19:19:11.805
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5065, will wait for the garbage collector to delete the pods @ 02/12/24 19:19:11.806
  Feb 12 19:19:11.869: INFO: Deleting DaemonSet.extensions daemon-set took: 7.983886ms
  Feb 12 19:19:11.970: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.518391ms
  Feb 12 19:19:13.274: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:19:13.274: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb 12 19:19:13.278: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9812"},"items":null}

  Feb 12 19:19:13.283: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9812"},"items":null}

  Feb 12 19:19:13.305: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5065" for this suite. @ 02/12/24 19:19:13.309
• [6.628 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 02/12/24 19:19:13.317
  Feb 12 19:19:13.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename events @ 02/12/24 19:19:13.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:13.332
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:13.335
  STEP: creating a test event @ 02/12/24 19:19:13.338
  STEP: listing events in all namespaces @ 02/12/24 19:19:13.348
  STEP: listing events in test namespace @ 02/12/24 19:19:13.36
  STEP: listing events with field selection filtering on source @ 02/12/24 19:19:13.364
  STEP: listing events with field selection filtering on reportingController @ 02/12/24 19:19:13.368
  STEP: getting the test event @ 02/12/24 19:19:13.372
  STEP: patching the test event @ 02/12/24 19:19:13.375
  STEP: getting the test event @ 02/12/24 19:19:13.384
  STEP: updating the test event @ 02/12/24 19:19:13.387
  STEP: getting the test event @ 02/12/24 19:19:13.395
  STEP: deleting the test event @ 02/12/24 19:19:13.399
  STEP: listing events in all namespaces @ 02/12/24 19:19:13.408
  STEP: listing events in test namespace @ 02/12/24 19:19:13.421
  Feb 12 19:19:13.425: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-887" for this suite. @ 02/12/24 19:19:13.429
• [0.120 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 02/12/24 19:19:13.438
  Feb 12 19:19:13.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename chunking @ 02/12/24 19:19:13.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:13.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:13.458
  STEP: creating a large number of resources @ 02/12/24 19:19:13.461
  STEP: retrieving those results in paged fashion several times @ 02/12/24 19:19:31.144
  Feb 12 19:19:31.195: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Feb 12 19:19:31.244: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Feb 12 19:19:31.293: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Feb 12 19:19:31.345: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Feb 12 19:19:31.394: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Feb 12 19:19:31.443: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Feb 12 19:19:31.494: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Feb 12 19:19:31.544: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Feb 12 19:19:31.598: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Feb 12 19:19:31.644: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Feb 12 19:19:31.694: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Feb 12 19:19:31.743: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Feb 12 19:19:31.794: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Feb 12 19:19:31.854: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Feb 12 19:19:31.893: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Feb 12 19:19:31.945: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Feb 12 19:19:31.994: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Feb 12 19:19:32.044: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Feb 12 19:19:32.094: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Feb 12 19:19:32.144: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Feb 12 19:19:32.194: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Feb 12 19:19:32.244: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Feb 12 19:19:32.294: INFO: Retrieved 17/17 results with rv 10290 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTAsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Feb 12 19:19:32.343: INFO: Retrieved 9/17 results with rv 10290 and continue 
  Feb 12 19:19:32.394: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Feb 12 19:19:32.443: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Feb 12 19:19:32.493: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Feb 12 19:19:32.544: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Feb 12 19:19:32.594: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Feb 12 19:19:32.643: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Feb 12 19:19:32.694: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Feb 12 19:19:32.744: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Feb 12 19:19:32.794: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Feb 12 19:19:32.844: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Feb 12 19:19:32.894: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Feb 12 19:19:32.944: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Feb 12 19:19:32.994: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Feb 12 19:19:33.044: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Feb 12 19:19:33.093: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Feb 12 19:19:33.144: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Feb 12 19:19:33.194: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Feb 12 19:19:33.243: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Feb 12 19:19:33.294: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Feb 12 19:19:33.343: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Feb 12 19:19:33.393: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Feb 12 19:19:33.445: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Feb 12 19:19:33.494: INFO: Retrieved 17/17 results with rv 10291 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTEsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Feb 12 19:19:33.543: INFO: Retrieved 9/17 results with rv 10291 and continue 
  Feb 12 19:19:33.595: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Feb 12 19:19:33.644: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Feb 12 19:19:33.694: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Feb 12 19:19:33.744: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Feb 12 19:19:33.795: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Feb 12 19:19:33.843: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Feb 12 19:19:33.895: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Feb 12 19:19:33.944: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Feb 12 19:19:33.993: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Feb 12 19:19:34.045: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Feb 12 19:19:34.094: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Feb 12 19:19:34.143: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Feb 12 19:19:34.195: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Feb 12 19:19:34.244: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Feb 12 19:19:34.293: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Feb 12 19:19:34.344: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Feb 12 19:19:34.394: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Feb 12 19:19:34.442: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Feb 12 19:19:34.495: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Feb 12 19:19:34.544: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Feb 12 19:19:34.594: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Feb 12 19:19:34.644: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Feb 12 19:19:34.694: INFO: Retrieved 17/17 results with rv 10293 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAyOTMsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Feb 12 19:19:34.742: INFO: Retrieved 9/17 results with rv 10293 and continue 
  STEP: retrieving those results all at once @ 02/12/24 19:19:34.742
  Feb 12 19:19:34.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-2159" for this suite. @ 02/12/24 19:19:34.844
• [21.459 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 02/12/24 19:19:34.897
  Feb 12 19:19:34.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/12/24 19:19:34.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:34.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:34.919
  STEP: create the container to handle the HTTPGet hook request. @ 02/12/24 19:19:34.926
  STEP: create the pod with lifecycle hook @ 02/12/24 19:19:36.949
  STEP: check poststart hook @ 02/12/24 19:19:38.972
  STEP: delete the pod with lifecycle hook @ 02/12/24 19:19:38.987
  Feb 12 19:19:41.004: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5914" for this suite. @ 02/12/24 19:19:41.008
• [6.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 02/12/24 19:19:41.016
  Feb 12 19:19:41.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:19:41.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:41.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:41.037
  STEP: Setting up server cert @ 02/12/24 19:19:41.064
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:19:41.352
  STEP: Deploying the webhook pod @ 02/12/24 19:19:41.361
  STEP: Wait for the deployment to be ready @ 02/12/24 19:19:41.39
  Feb 12 19:19:41.399: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:19:43.413
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:19:43.425
  Feb 12 19:19:44.425: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 02/12/24 19:19:44.434
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/12/24 19:19:44.451
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 02/12/24 19:19:44.458
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/12/24 19:19:44.469
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 02/12/24 19:19:44.482
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/12/24 19:19:44.491
  Feb 12 19:19:44.542: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9143" for this suite. @ 02/12/24 19:19:44.548
  STEP: Destroying namespace "webhook-markers-6802" for this suite. @ 02/12/24 19:19:44.556
• [3.548 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 02/12/24 19:19:44.564
  Feb 12 19:19:44.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:19:44.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:19:44.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:19:44.584
  STEP: Creating secret with name s-test-opt-del-99044372-d60a-4d3c-91d5-3dadcd2df9b8 @ 02/12/24 19:19:44.591
  STEP: Creating secret with name s-test-opt-upd-16e676cb-c54b-4af4-b078-ce1fd7b7828b @ 02/12/24 19:19:44.595
  STEP: Creating the pod @ 02/12/24 19:19:44.6
  STEP: Deleting secret s-test-opt-del-99044372-d60a-4d3c-91d5-3dadcd2df9b8 @ 02/12/24 19:19:46.648
  STEP: Updating secret s-test-opt-upd-16e676cb-c54b-4af4-b078-ce1fd7b7828b @ 02/12/24 19:19:46.656
  STEP: Creating secret with name s-test-opt-create-35c30212-bb21-47bb-b8ac-b4f1198c750e @ 02/12/24 19:19:46.66
  STEP: waiting to observe update in volume @ 02/12/24 19:19:46.666
  Feb 12 19:21:15.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5014" for this suite. @ 02/12/24 19:21:15.139
• [90.583 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 02/12/24 19:21:15.147
  Feb 12 19:21:15.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:21:15.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:21:15.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:21:15.166
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:21:15.169
  STEP: Saw pod success @ 02/12/24 19:21:19.193
  Feb 12 19:21:19.198: INFO: Trying to get logs from node ip-172-31-91-42 pod downwardapi-volume-0d4f8e56-29a0-420e-a5a1-6510f73a86d2 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:21:19.217
  Feb 12 19:21:19.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6140" for this suite. @ 02/12/24 19:21:19.24
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 02/12/24 19:21:19.247
  Feb 12 19:21:19.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replicaset @ 02/12/24 19:21:19.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:21:19.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:21:19.266
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 02/12/24 19:21:19.27
  STEP: When a replicaset with a matching selector is created @ 02/12/24 19:21:21.294
  STEP: Then the orphan pod is adopted @ 02/12/24 19:21:21.301
  STEP: When the matched label of one of its pods change @ 02/12/24 19:21:22.311
  Feb 12 19:21:22.315: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 02/12/24 19:21:22.327
  Feb 12 19:21:23.338: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1243" for this suite. @ 02/12/24 19:21:23.343
• [4.103 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 02/12/24 19:21:23.35
  Feb 12 19:21:23.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename endpointslice @ 02/12/24 19:21:23.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:21:23.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:21:23.371
  STEP: getting /apis @ 02/12/24 19:21:23.374
  STEP: getting /apis/discovery.k8s.io @ 02/12/24 19:21:23.378
  STEP: getting /apis/discovery.k8s.iov1 @ 02/12/24 19:21:23.38
  STEP: creating @ 02/12/24 19:21:23.381
  STEP: getting @ 02/12/24 19:21:23.396
  STEP: listing @ 02/12/24 19:21:23.4
  STEP: watching @ 02/12/24 19:21:23.404
  Feb 12 19:21:23.404: INFO: starting watch
  STEP: cluster-wide listing @ 02/12/24 19:21:23.405
  STEP: cluster-wide watching @ 02/12/24 19:21:23.408
  Feb 12 19:21:23.408: INFO: starting watch
  STEP: patching @ 02/12/24 19:21:23.41
  STEP: updating @ 02/12/24 19:21:23.417
  Feb 12 19:21:23.425: INFO: waiting for watch events with expected annotations
  Feb 12 19:21:23.425: INFO: saw patched and updated annotations
  STEP: deleting @ 02/12/24 19:21:23.425
  STEP: deleting a collection @ 02/12/24 19:21:23.44
  Feb 12 19:21:23.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2203" for this suite. @ 02/12/24 19:21:23.461
• [0.118 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 02/12/24 19:21:23.468
  Feb 12 19:21:23.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:21:23.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:21:23.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:21:23.49
  STEP: Creating configMap configmap-8830/configmap-test-e27e28e9-dad0-4a65-bd6c-64cd3358c6d3 @ 02/12/24 19:21:23.493
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:21:23.498
  STEP: Saw pod success @ 02/12/24 19:21:25.516
  Feb 12 19:21:25.520: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-07686ef9-84d8-4e52-8d97-aca6654fd55b container env-test: <nil>
  STEP: delete the pod @ 02/12/24 19:21:25.528
  Feb 12 19:21:25.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8830" for this suite. @ 02/12/24 19:21:25.55
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 02/12/24 19:21:25.559
  Feb 12 19:21:25.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-pred @ 02/12/24 19:21:25.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:21:25.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:21:25.58
  Feb 12 19:21:25.583: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb 12 19:21:25.590: INFO: Waiting for terminating namespaces to be deleted...
  Feb 12 19:21:25.593: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-42-94 before test
  Feb 12 19:21:25.600: INFO: nginx-ingress-controller-kubernetes-worker-4n7x6 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: calico-node-nknc4 from kube-system started at 2024-02-12 18:57:51 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: coredns-bddfd76d7-hpmdx from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container coredns ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: kube-state-metrics-78c475f58b-mmvpb from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container kube-state-metrics ready: true, restart count 4
  Feb 12 19:21:25.600: INFO: metrics-server-v0.6.3-69d7fbfdf8-q42bs from kube-system started at 2024-02-12 18:46:29 +0000 UTC (2 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container metrics-server ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: dashboard-metrics-scraper-5dd7cb5fc-94q8l from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: kubernetes-dashboard-7b899cb9d9-kxlk9 from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container kubernetes-dashboard ready: true, restart count 6
  Feb 12 19:21:25.600: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-hxjsb from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:21:25.600: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 19:21:25.600: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-5-108 before test
  Feb 12 19:21:25.606: INFO: nginx-ingress-controller-kubernetes-worker-b6d84 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.606: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:21:25.606: INFO: calico-node-tcvrl from kube-system started at 2024-02-12 18:59:18 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.606: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:21:25.606: INFO: pod-adoption-release-8n5vt from replicaset-1243 started at 2024-02-12 19:21:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.606: INFO: 	Container pod-adoption-release ready: true, restart count 0
  Feb 12 19:21:25.606: INFO: sonobuoy from sonobuoy started at 2024-02-12 19:00:55 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.606: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb 12 19:21:25.606: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-dq5wt from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:21:25.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:21:25.606: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 19:21:25.606: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-91-42 before test
  Feb 12 19:21:25.611: INFO: nginx-ingress-controller-kubernetes-worker-89brg from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:34 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.611: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:21:25.611: INFO: calico-node-5zt4h from kube-system started at 2024-02-12 18:57:41 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.611: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:21:25.611: INFO: pod-adoption-release from replicaset-1243 started at 2024-02-12 19:21:19 +0000 UTC (1 container statuses recorded)
  Feb 12 19:21:25.611: INFO: 	Container pod-adoption-release ready: true, restart count 0
  Feb 12 19:21:25.611: INFO: sonobuoy-e2e-job-6d99262b73344895 from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:21:25.611: INFO: 	Container e2e ready: true, restart count 0
  Feb 12 19:21:25.611: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:21:25.611: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-pcznp from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:21:25.611: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:21:25.611: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 02/12/24 19:21:25.611
  STEP: Explicitly delete pod here to free the resource it takes. @ 02/12/24 19:21:27.638
  STEP: Trying to apply a random label on the found node. @ 02/12/24 19:21:27.657
  STEP: verifying the node has the label kubernetes.io/e2e-4cd090c0-2dbc-45b1-855b-6b40d328761a 95 @ 02/12/24 19:21:27.665
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 02/12/24 19:21:27.669
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.5.108 on the node which pod4 resides and expect not scheduled @ 02/12/24 19:21:29.686
  STEP: removing the label kubernetes.io/e2e-4cd090c0-2dbc-45b1-855b-6b40d328761a off the node ip-172-31-5-108 @ 02/12/24 19:26:29.694
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-4cd090c0-2dbc-45b1-855b-6b40d328761a @ 02/12/24 19:26:29.708
  Feb 12 19:26:29.712: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8488" for this suite. @ 02/12/24 19:26:29.716
• [304.167 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 02/12/24 19:26:29.726
  Feb 12 19:26:29.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename proxy @ 02/12/24 19:26:29.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:26:29.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:26:29.745
  Feb 12 19:26:29.748: INFO: Creating pod...
  Feb 12 19:26:31.765: INFO: Creating service...
  Feb 12 19:26:31.782: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/DELETE
  Feb 12 19:26:31.790: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb 12 19:26:31.790: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/GET
  Feb 12 19:26:31.795: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Feb 12 19:26:31.795: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/HEAD
  Feb 12 19:26:31.801: INFO: http.Client request:HEAD | StatusCode:200
  Feb 12 19:26:31.801: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/OPTIONS
  Feb 12 19:26:31.809: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb 12 19:26:31.809: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/PATCH
  Feb 12 19:26:31.816: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb 12 19:26:31.816: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/POST
  Feb 12 19:26:31.821: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb 12 19:26:31.821: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/pods/agnhost/proxy/some/path/with/PUT
  Feb 12 19:26:31.826: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb 12 19:26:31.826: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/DELETE
  Feb 12 19:26:31.843: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb 12 19:26:31.843: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/GET
  Feb 12 19:26:31.853: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Feb 12 19:26:31.853: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/HEAD
  Feb 12 19:26:31.861: INFO: http.Client request:HEAD | StatusCode:200
  Feb 12 19:26:31.861: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/OPTIONS
  Feb 12 19:26:31.869: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb 12 19:26:31.869: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/PATCH
  Feb 12 19:26:31.874: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb 12 19:26:31.875: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/POST
  Feb 12 19:26:31.881: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb 12 19:26:31.881: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3783/services/test-service/proxy/some/path/with/PUT
  Feb 12 19:26:31.887: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb 12 19:26:31.888: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3783" for this suite. @ 02/12/24 19:26:31.891
• [2.175 seconds]
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 02/12/24 19:26:31.9
  Feb 12 19:26:31.900: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 19:26:31.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:26:31.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:26:31.922
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 02/12/24 19:26:31.925
  STEP: Saw pod success @ 02/12/24 19:26:33.944
  Feb 12 19:26:33.948: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-db27b968-56d0-4a77-87c4-f1d8e041afb4 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 19:26:33.966
  Feb 12 19:26:33.982: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1252" for this suite. @ 02/12/24 19:26:33.986
• [2.093 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 02/12/24 19:26:33.994
  Feb 12 19:26:33.994: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-webhook @ 02/12/24 19:26:33.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:26:34.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:26:34.013
  STEP: Setting up server cert @ 02/12/24 19:26:34.016
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 02/12/24 19:26:34.211
  STEP: Deploying the custom resource conversion webhook pod @ 02/12/24 19:26:34.222
  STEP: Wait for the deployment to be ready @ 02/12/24 19:26:34.236
  Feb 12 19:26:34.246: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:26:36.26
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:26:36.272
  Feb 12 19:26:37.272: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Feb 12 19:26:37.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Creating a v1 custom resource @ 02/12/24 19:26:39.841
  STEP: Create a v2 custom resource @ 02/12/24 19:26:39.858
  STEP: List CRs in v1 @ 02/12/24 19:26:39.885
  STEP: List CRs in v2 @ 02/12/24 19:26:39.89
  Feb 12 19:26:40.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-7070" for this suite. @ 02/12/24 19:26:40.455
• [6.473 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 02/12/24 19:26:40.467
  Feb 12 19:26:40.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:26:40.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:26:40.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:26:40.489
  STEP: Creating configMap with name cm-test-opt-del-99033dfc-a9ca-477a-bfa1-e03f0bda7f75 @ 02/12/24 19:26:40.497
  STEP: Creating configMap with name cm-test-opt-upd-5f635289-4bc2-47e1-9311-2613497c7227 @ 02/12/24 19:26:40.503
  STEP: Creating the pod @ 02/12/24 19:26:40.507
  STEP: Deleting configmap cm-test-opt-del-99033dfc-a9ca-477a-bfa1-e03f0bda7f75 @ 02/12/24 19:26:42.568
  STEP: Updating configmap cm-test-opt-upd-5f635289-4bc2-47e1-9311-2613497c7227 @ 02/12/24 19:26:42.575
  STEP: Creating configMap with name cm-test-opt-create-92f140e6-428e-4511-abef-fd8435177ba6 @ 02/12/24 19:26:42.581
  STEP: waiting to observe update in volume @ 02/12/24 19:26:42.585
  Feb 12 19:28:11.048: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5992" for this suite. @ 02/12/24 19:28:11.052
• [90.592 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 02/12/24 19:28:11.059
  Feb 12 19:28:11.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:28:11.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:11.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:11.083
  STEP: Creating configMap with name configmap-test-upd-d58da439-6712-405a-b537-9e705a17c102 @ 02/12/24 19:28:11.09
  STEP: Creating the pod @ 02/12/24 19:28:11.095
  STEP: Waiting for pod with text data @ 02/12/24 19:28:13.112
  STEP: Waiting for pod with binary data @ 02/12/24 19:28:13.127
  Feb 12 19:28:13.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2615" for this suite. @ 02/12/24 19:28:13.141
• [2.089 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 02/12/24 19:28:13.149
  Feb 12 19:28:13.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename limitrange @ 02/12/24 19:28:13.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:13.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:13.172
  STEP: Creating LimitRange "e2e-limitrange-967qt" in namespace "limitrange-1586" @ 02/12/24 19:28:13.175
  STEP: Creating another limitRange in another namespace @ 02/12/24 19:28:13.181
  Feb 12 19:28:13.196: INFO: Namespace "e2e-limitrange-967qt-6283" created
  Feb 12 19:28:13.196: INFO: Creating LimitRange "e2e-limitrange-967qt" in namespace "e2e-limitrange-967qt-6283"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-967qt" @ 02/12/24 19:28:13.207
  Feb 12 19:28:13.211: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-967qt" in "limitrange-1586" namespace @ 02/12/24 19:28:13.211
  Feb 12 19:28:13.217: INFO: LimitRange "e2e-limitrange-967qt" has been patched
  STEP: Delete LimitRange "e2e-limitrange-967qt" by Collection with labelSelector: "e2e-limitrange-967qt=patched" @ 02/12/24 19:28:13.217
  STEP: Confirm that the limitRange "e2e-limitrange-967qt" has been deleted @ 02/12/24 19:28:13.226
  Feb 12 19:28:13.226: INFO: Requesting list of LimitRange to confirm quantity
  Feb 12 19:28:13.230: INFO: Found 0 LimitRange with label "e2e-limitrange-967qt=patched"
  Feb 12 19:28:13.230: INFO: LimitRange "e2e-limitrange-967qt" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-967qt" @ 02/12/24 19:28:13.23
  Feb 12 19:28:13.233: INFO: Found 1 limitRange
  Feb 12 19:28:13.233: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-1586" for this suite. @ 02/12/24 19:28:13.238
  STEP: Destroying namespace "e2e-limitrange-967qt-6283" for this suite. @ 02/12/24 19:28:13.245
• [0.104 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 02/12/24 19:28:13.253
  Feb 12 19:28:13.253: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:28:13.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:13.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:13.275
  STEP: creating Agnhost RC @ 02/12/24 19:28:13.279
  Feb 12 19:28:13.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-9568 create -f -'
  Feb 12 19:28:13.454: INFO: stderr: ""
  Feb 12 19:28:13.455: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 02/12/24 19:28:13.455
  Feb 12 19:28:14.460: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 19:28:14.460: INFO: Found 0 / 1
  Feb 12 19:28:15.460: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 19:28:15.460: INFO: Found 1 / 1
  Feb 12 19:28:15.460: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 02/12/24 19:28:15.46
  Feb 12 19:28:15.464: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 19:28:15.464: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb 12 19:28:15.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-9568 patch pod agnhost-primary-4dmxh -p {"metadata":{"annotations":{"x":"y"}}}'
  Feb 12 19:28:15.517: INFO: stderr: ""
  Feb 12 19:28:15.517: INFO: stdout: "pod/agnhost-primary-4dmxh patched\n"
  STEP: checking annotations @ 02/12/24 19:28:15.517
  Feb 12 19:28:15.521: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 19:28:15.521: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb 12 19:28:15.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9568" for this suite. @ 02/12/24 19:28:15.525
• [2.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 02/12/24 19:28:15.534
  Feb 12 19:28:15.534: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename aggregator @ 02/12/24 19:28:15.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:15.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:15.559
  Feb 12 19:28:15.562: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Registering the sample API server. @ 02/12/24 19:28:15.562
  Feb 12 19:28:15.758: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Feb 12 19:28:15.790: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  Feb 12 19:28:17.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:19.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:21.851: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:23.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:25.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:27.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:29.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:31.850: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:33.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:35.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:37.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:39.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Feb 12 19:28:41.969: INFO: Waited 112.517291ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 02/12/24 19:28:42.004
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 02/12/24 19:28:42.009
  STEP: List APIServices @ 02/12/24 19:28:42.016
  Feb 12 19:28:42.021: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 02/12/24 19:28:42.021
  Feb 12 19:28:42.035: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 02/12/24 19:28:42.035
  Feb 12 19:28:42.045: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 41, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 02/12/24 19:28:42.045
  Feb 12 19:28:42.049: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-02-12 19:28:41 +0000 UTC Passed all checks passed}
  Feb 12 19:28:42.049: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb 12 19:28:42.049: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 02/12/24 19:28:42.049
  Feb 12 19:28:42.060: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1931850219" @ 02/12/24 19:28:42.06
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 02/12/24 19:28:42.07
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 02/12/24 19:28:42.076
  STEP: Patch APIService Status @ 02/12/24 19:28:42.081
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 02/12/24 19:28:42.087
  Feb 12 19:28:42.092: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-02-12 19:28:41 +0000 UTC Passed all checks passed}
  Feb 12 19:28:42.092: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb 12 19:28:42.092: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Feb 12 19:28:42.092: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 02/12/24 19:28:42.092
  STEP: Confirm that the generated APIService has been deleted @ 02/12/24 19:28:42.104
  Feb 12 19:28:42.104: INFO: Requesting list of APIServices to confirm quantity
  Feb 12 19:28:42.109: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  Feb 12 19:28:42.109: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Feb 12 19:28:42.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-8070" for this suite. @ 02/12/24 19:28:42.22
• [26.694 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 02/12/24 19:28:42.229
  Feb 12 19:28:42.229: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 19:28:42.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:42.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:42.25
  STEP: Creating projection with secret that has name secret-emptykey-test-e0b72ac4-1ba0-4e06-b58a-75571f0dc280 @ 02/12/24 19:28:42.253
  Feb 12 19:28:42.255: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7668" for this suite. @ 02/12/24 19:28:42.259
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 02/12/24 19:28:42.265
  Feb 12 19:28:42.265: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:28:42.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:42.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:42.285
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:28:42.288
  STEP: Saw pod success @ 02/12/24 19:28:46.312
  Feb 12 19:28:46.315: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-6189ad65-fe2e-48b9-b87e-521ef42ae4c9 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:28:46.323
  Feb 12 19:28:46.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6811" for this suite. @ 02/12/24 19:28:46.344
• [4.086 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 02/12/24 19:28:46.351
  Feb 12 19:28:46.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 19:28:46.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:46.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:46.369
  STEP: creating a Deployment @ 02/12/24 19:28:46.376
  Feb 12 19:28:46.376: INFO: Creating simple deployment test-deployment-9x5kb
  Feb 12 19:28:46.388: INFO: deployment "test-deployment-9x5kb" doesn't have the required revision set
  STEP: Getting /status @ 02/12/24 19:28:48.405
  Feb 12 19:28:48.409: INFO: Deployment test-deployment-9x5kb has Conditions: [{Available True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9x5kb-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 02/12/24 19:28:48.409
  Feb 12 19:28:48.420: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 47, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 19, 28, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 19, 28, 46, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-9x5kb-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 02/12/24 19:28:48.42
  Feb 12 19:28:48.422: INFO: Observed &Deployment event: ADDED
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9x5kb-5d576bd769"}
  Feb 12 19:28:48.422: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9x5kb-5d576bd769"}
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb 12 19:28:48.422: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9x5kb-5d576bd769" is progressing.}
  Feb 12 19:28:48.422: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb 12 19:28:48.422: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9x5kb-5d576bd769" has successfully progressed.}
  Feb 12 19:28:48.423: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.423: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb 12 19:28:48.423: INFO: Observed Deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9x5kb-5d576bd769" has successfully progressed.}
  Feb 12 19:28:48.423: INFO: Found Deployment test-deployment-9x5kb in namespace deployment-5129 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb 12 19:28:48.423: INFO: Deployment test-deployment-9x5kb has an updated status
  STEP: patching the Statefulset Status @ 02/12/24 19:28:48.423
  Feb 12 19:28:48.423: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Feb 12 19:28:48.430: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 02/12/24 19:28:48.43
  Feb 12 19:28:48.432: INFO: Observed &Deployment event: ADDED
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9x5kb-5d576bd769"}
  Feb 12 19:28:48.432: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9x5kb-5d576bd769"}
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb 12 19:28:48.432: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:46 +0000 UTC 2024-02-12 19:28:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9x5kb-5d576bd769" is progressing.}
  Feb 12 19:28:48.432: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9x5kb-5d576bd769" has successfully progressed.}
  Feb 12 19:28:48.432: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb 12 19:28:48.432: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-12 19:28:47 +0000 UTC 2024-02-12 19:28:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9x5kb-5d576bd769" has successfully progressed.}
  Feb 12 19:28:48.433: INFO: Observed deployment test-deployment-9x5kb in namespace deployment-5129 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb 12 19:28:48.433: INFO: Observed &Deployment event: MODIFIED
  Feb 12 19:28:48.433: INFO: Found deployment test-deployment-9x5kb in namespace deployment-5129 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Feb 12 19:28:48.433: INFO: Deployment test-deployment-9x5kb has a patched status
  Feb 12 19:28:48.438: INFO: Deployment "test-deployment-9x5kb":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-9x5kb",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5129",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "877a61b3-3576-46d8-8a4e-a784b3af50d4",
      ResourceVersion: (string) (len=5) "12672",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362926,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362926,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362928,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362928,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362928,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362928,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-9x5kb-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 19:28:48.447: INFO: New ReplicaSet "test-deployment-9x5kb-5d576bd769" of Deployment "test-deployment-9x5kb":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-9x5kb-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5129",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1c27dfa2-120c-40ea-8e32-67470e05901a",
      ResourceVersion: (string) (len=5) "12667",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362926,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-9x5kb",
          UID: (types.UID) (len=36) "877a61b3-3576-46d8-8a4e-a784b3af50d4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362926,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 38 37 37  |k:{\"uid\":\"877|
              00000120  61 36 31 62 33 2d 33 35  37 36 2d 34 36 64 38 2d  |a61b3-3576-46d8-|
              00000130  38 61 34 65 2d 61 37 38  34 62 33 61 66 35 30 64  |8a4e-a784b3af50d|
              00000140  34 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |4\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362927,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:28:48.452: INFO: Pod "test-deployment-9x5kb-5d576bd769-zmtrp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-9x5kb-5d576bd769-zmtrp",
      GenerateName: (string) (len=33) "test-deployment-9x5kb-5d576bd769-",
      Namespace: (string) (len=15) "deployment-5129",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "93c487df-cb57-4994-bcf3-15c830dd73ec",
      ResourceVersion: (string) (len=5) "12666",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362926,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-9x5kb-5d576bd769",
          UID: (types.UID) (len=36) "1c27dfa2-120c-40ea-8e32-67470e05901a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362926,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 31 63 32 37 64 66 61  32 2d 31 32 30 63 2d 34  |"1c27dfa2-120c-4|
              000000a0  30 65 61 2d 38 65 33 32  2d 36 37 34 37 30 65 30  |0ea-8e32-67470e0|
              000000b0  35 39 30 31 61 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |5901a\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362927,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  30 2e 32 33 39 5c 22 7d  |2.168.150.239\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tt5cj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tt5cj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362927,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362926,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362927,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362927,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843362926,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.239",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.239"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843362926,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843362926,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://3d0f314283f84b060b692111742a5771a11fe539f1fee07b37225ae1601cbb02",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:28:48.454: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5129" for this suite. @ 02/12/24 19:28:48.458
• [2.112 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 02/12/24 19:28:48.464
  Feb 12 19:28:48.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:28:48.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:48.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:48.484
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:28:48.488
  STEP: Saw pod success @ 02/12/24 19:28:52.514
  Feb 12 19:28:52.517: INFO: Trying to get logs from node ip-172-31-91-42 pod downwardapi-volume-ed8d2e98-024b-45ee-858a-2bfdb32b0ace container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:28:52.526
  Feb 12 19:28:52.543: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8862" for this suite. @ 02/12/24 19:28:52.548
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 02/12/24 19:28:52.556
  Feb 12 19:28:52.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-pred @ 02/12/24 19:28:52.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:52.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:52.576
  Feb 12 19:28:52.579: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb 12 19:28:52.589: INFO: Waiting for terminating namespaces to be deleted...
  Feb 12 19:28:52.593: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-42-94 before test
  Feb 12 19:28:52.599: INFO: nginx-ingress-controller-kubernetes-worker-4n7x6 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: calico-node-nknc4 from kube-system started at 2024-02-12 18:57:51 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: coredns-bddfd76d7-hpmdx from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container coredns ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: kube-state-metrics-78c475f58b-mmvpb from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container kube-state-metrics ready: true, restart count 4
  Feb 12 19:28:52.599: INFO: metrics-server-v0.6.3-69d7fbfdf8-q42bs from kube-system started at 2024-02-12 18:46:29 +0000 UTC (2 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container metrics-server ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: dashboard-metrics-scraper-5dd7cb5fc-94q8l from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: kubernetes-dashboard-7b899cb9d9-kxlk9 from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container kubernetes-dashboard ready: true, restart count 6
  Feb 12 19:28:52.599: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-hxjsb from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:28:52.599: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 19:28:52.599: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-5-108 before test
  Feb 12 19:28:52.605: INFO: test-deployment-9x5kb-5d576bd769-zmtrp from deployment-5129 started at 2024-02-12 19:28:46 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.605: INFO: 	Container httpd ready: true, restart count 0
  Feb 12 19:28:52.605: INFO: nginx-ingress-controller-kubernetes-worker-b6d84 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.605: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:28:52.605: INFO: calico-node-tcvrl from kube-system started at 2024-02-12 18:59:18 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.605: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:28:52.605: INFO: sonobuoy from sonobuoy started at 2024-02-12 19:00:55 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.605: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb 12 19:28:52.605: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-dq5wt from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:28:52.605: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:28:52.605: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 19:28:52.605: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-91-42 before test
  Feb 12 19:28:52.610: INFO: nginx-ingress-controller-kubernetes-worker-89brg from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:34 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.610: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 19:28:52.610: INFO: calico-node-5zt4h from kube-system started at 2024-02-12 18:57:41 +0000 UTC (1 container statuses recorded)
  Feb 12 19:28:52.610: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 19:28:52.610: INFO: sonobuoy-e2e-job-6d99262b73344895 from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:28:52.610: INFO: 	Container e2e ready: true, restart count 0
  Feb 12 19:28:52.610: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:28:52.610: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-pcznp from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 19:28:52.610: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 19:28:52.610: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-42-94 @ 02/12/24 19:28:52.627
  STEP: verifying the node has the label node ip-172-31-5-108 @ 02/12/24 19:28:52.639
  STEP: verifying the node has the label node ip-172-31-91-42 @ 02/12/24 19:28:52.651
  Feb 12 19:28:52.664: INFO: Pod test-deployment-9x5kb-5d576bd769-zmtrp requesting resource cpu=0m on Node ip-172-31-5-108
  Feb 12 19:28:52.664: INFO: Pod nginx-ingress-controller-kubernetes-worker-4n7x6 requesting resource cpu=0m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod nginx-ingress-controller-kubernetes-worker-89brg requesting resource cpu=0m on Node ip-172-31-91-42
  Feb 12 19:28:52.664: INFO: Pod nginx-ingress-controller-kubernetes-worker-b6d84 requesting resource cpu=0m on Node ip-172-31-5-108
  Feb 12 19:28:52.664: INFO: Pod calico-node-5zt4h requesting resource cpu=250m on Node ip-172-31-91-42
  Feb 12 19:28:52.664: INFO: Pod calico-node-nknc4 requesting resource cpu=250m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod calico-node-tcvrl requesting resource cpu=250m on Node ip-172-31-5-108
  Feb 12 19:28:52.664: INFO: Pod coredns-bddfd76d7-hpmdx requesting resource cpu=100m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod kube-state-metrics-78c475f58b-mmvpb requesting resource cpu=0m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod metrics-server-v0.6.3-69d7fbfdf8-q42bs requesting resource cpu=5m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod dashboard-metrics-scraper-5dd7cb5fc-94q8l requesting resource cpu=0m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod kubernetes-dashboard-7b899cb9d9-kxlk9 requesting resource cpu=0m on Node ip-172-31-42-94
  Feb 12 19:28:52.664: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-5-108
  Feb 12 19:28:52.665: INFO: Pod sonobuoy-e2e-job-6d99262b73344895 requesting resource cpu=0m on Node ip-172-31-91-42
  Feb 12 19:28:52.665: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-dq5wt requesting resource cpu=0m on Node ip-172-31-5-108
  Feb 12 19:28:52.665: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-hxjsb requesting resource cpu=0m on Node ip-172-31-42-94
  Feb 12 19:28:52.665: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-pcznp requesting resource cpu=0m on Node ip-172-31-91-42
  STEP: Starting Pods to consume most of the cluster CPU. @ 02/12/24 19:28:52.665
  Feb 12 19:28:52.665: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-5-108
  Feb 12 19:28:52.674: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-91-42
  Feb 12 19:28:52.681: INFO: Creating a pod which consumes cpu=1151m on Node ip-172-31-42-94
  STEP: Creating another pod that requires unavailable amount of CPU. @ 02/12/24 19:28:54.712
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807.17b3343fe27db538], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6564/filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807 to ip-172-31-91-42] @ 02/12/24 19:28:54.716
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807.17b3344000f6c780], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807.17b3344001e80c05], Reason = [Created], Message = [Created container filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807.17b33440045c3879], Reason = [Started], Message = [Started container filler-pod-ac8ea7f0-6cc7-42f0-acb2-bcbbe5272807] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43.17b3343fe1db9e0c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6564/filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43 to ip-172-31-5-108] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43.17b3343fffa3cc76], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43.17b334400087a4e0], Reason = [Created], Message = [Created container filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43.17b33440037f1a22], Reason = [Started], Message = [Started container filler-pod-ce2a31eb-0a8d-4119-b550-309194168c43] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34.17b3343fe2a4d0d0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6564/filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34 to ip-172-31-42-94] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34.17b3344001e9d9a0], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.9"] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34.17b33440065387eb], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.9" in 73ms (74ms including waiting)] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34.17b33440075bdcf8], Reason = [Created], Message = [Created container filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34.17b3344009df254f], Reason = [Started], Message = [Started container filler-pod-cfb8649f-c3b2-403a-b576-6d8df9a29b34] @ 02/12/24 19:28:54.717
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17b334405bc0ada9], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 02/12/24 19:28:54.731
  STEP: removing the label node off the node ip-172-31-42-94 @ 02/12/24 19:28:55.73
  STEP: verifying the node doesn't have the label node @ 02/12/24 19:28:55.742
  STEP: removing the label node off the node ip-172-31-5-108 @ 02/12/24 19:28:55.751
  STEP: verifying the node doesn't have the label node @ 02/12/24 19:28:55.764
  STEP: removing the label node off the node ip-172-31-91-42 @ 02/12/24 19:28:55.77
  STEP: verifying the node doesn't have the label node @ 02/12/24 19:28:55.78
  Feb 12 19:28:55.786: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6564" for this suite. @ 02/12/24 19:28:55.791
• [3.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 02/12/24 19:28:55.798
  Feb 12 19:28:55.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename namespaces @ 02/12/24 19:28:55.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:55.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:28:55.821
  STEP: Creating a test namespace @ 02/12/24 19:28:55.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:28:55.845
  STEP: Creating a pod in the namespace @ 02/12/24 19:28:55.848
  STEP: Waiting for the pod to have running status @ 02/12/24 19:28:55.857
  STEP: Deleting the namespace @ 02/12/24 19:28:57.867
  STEP: Waiting for the namespace to be removed. @ 02/12/24 19:28:57.877
  STEP: Recreating the namespace @ 02/12/24 19:29:08.883
  STEP: Verifying there are no pods in the namespace @ 02/12/24 19:29:08.902
  Feb 12 19:29:08.905: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3630" for this suite. @ 02/12/24 19:29:08.908
  STEP: Destroying namespace "nsdeletetest-8420" for this suite. @ 02/12/24 19:29:08.915
  Feb 12 19:29:08.918: INFO: Namespace nsdeletetest-8420 was already deleted
  STEP: Destroying namespace "nsdeletetest-4950" for this suite. @ 02/12/24 19:29:08.919
• [13.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 02/12/24 19:29:08.927
  Feb 12 19:29:08.927: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:29:08.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:29:08.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:29:08.947
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-862 @ 02/12/24 19:29:08.95
  STEP: changing the ExternalName service to type=NodePort @ 02/12/24 19:29:08.955
  STEP: creating replication controller externalname-service in namespace services-862 @ 02/12/24 19:29:08.975
  I0212 19:29:08.984616      20 runners.go:197] Created replication controller with name: externalname-service, namespace: services-862, replica count: 2
  I0212 19:29:12.035821      20 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 19:29:12.035: INFO: Creating new exec pod
  Feb 12 19:29:15.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-862 exec execpodfx4rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Feb 12 19:29:15.170: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Feb 12 19:29:15.170: INFO: stdout: "externalname-service-9gr4r"
  Feb 12 19:29:15.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-862 exec execpodfx4rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
  Feb 12 19:29:15.255: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
  Feb 12 19:29:15.255: INFO: stdout: ""
  Feb 12 19:29:16.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-862 exec execpodfx4rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
  Feb 12 19:29:16.265: INFO: stderr: "+ nc -v -t -w 2 10.152.183.28 80\n+ echo hostName\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
  Feb 12 19:29:16.265: INFO: stdout: "externalname-service-9gr4r"
  Feb 12 19:29:16.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-862 exec execpodfx4rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.42.94 30213'
  Feb 12 19:29:16.366: INFO: stderr: "+ nc -v -t -w 2 172.31.42.94 30213\n+ echo hostName\nConnection to 172.31.42.94 30213 port [tcp/*] succeeded!\n"
  Feb 12 19:29:16.366: INFO: stdout: ""
  Feb 12 19:29:17.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-862 exec execpodfx4rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.42.94 30213'
  Feb 12 19:29:17.358: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.42.94 30213\nConnection to 172.31.42.94 30213 port [tcp/*] succeeded!\n"
  Feb 12 19:29:17.358: INFO: stdout: "externalname-service-rn2nk"
  Feb 12 19:29:17.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-862 exec execpodfx4rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.5.108 30213'
  Feb 12 19:29:17.453: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.5.108 30213\nConnection to 172.31.5.108 30213 port [tcp/*] succeeded!\n"
  Feb 12 19:29:17.453: INFO: stdout: "externalname-service-9gr4r"
  Feb 12 19:29:17.453: INFO: Cleaning up the ExternalName to NodePort test service
  Feb 12 19:29:17.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-862" for this suite. @ 02/12/24 19:29:17.482
• [8.563 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 02/12/24 19:29:17.49
  Feb 12 19:29:17.490: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 19:29:17.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:29:17.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:29:17.513
  STEP: Creating service test in namespace statefulset-3014 @ 02/12/24 19:29:17.517
  STEP: Creating a new StatefulSet @ 02/12/24 19:29:17.523
  Feb 12 19:29:17.535: INFO: Found 0 stateful pods, waiting for 3
  Feb 12 19:29:27.539: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:29:27.539: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:29:27.539: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 02/12/24 19:29:27.55
  Feb 12 19:29:27.572: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 02/12/24 19:29:27.572
  STEP: Not applying an update when the partition is greater than the number of replicas @ 02/12/24 19:29:37.584
  STEP: Performing a canary update @ 02/12/24 19:29:37.584
  Feb 12 19:29:37.604: INFO: Updating stateful set ss2
  Feb 12 19:29:37.615: INFO: Waiting for Pod statefulset-3014/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  STEP: Restoring Pods to the correct revision when they are deleted @ 02/12/24 19:29:47.614
  Feb 12 19:29:47.648: INFO: Found 1 stateful pods, waiting for 3
  Feb 12 19:29:57.652: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:29:57.652: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:29:57.652: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 02/12/24 19:29:57.658
  Feb 12 19:29:57.680: INFO: Updating stateful set ss2
  Feb 12 19:29:57.690: INFO: Waiting for Pod statefulset-3014/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Feb 12 19:30:07.713: INFO: Updating stateful set ss2
  Feb 12 19:30:07.724: INFO: Waiting for StatefulSet statefulset-3014/ss2 to complete update
  Feb 12 19:30:07.724: INFO: Waiting for Pod statefulset-3014/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Feb 12 19:30:17.727: INFO: Deleting all statefulset in ns statefulset-3014
  Feb 12 19:30:17.730: INFO: Scaling statefulset ss2 to 0
  Feb 12 19:30:27.747: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:30:27.750: INFO: Deleting statefulset ss2
  Feb 12 19:30:27.768: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3014" for this suite. @ 02/12/24 19:30:27.774
• [70.291 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 02/12/24 19:30:27.781
  Feb 12 19:30:27.781: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-runtime @ 02/12/24 19:30:27.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:30:27.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:30:27.803
  STEP: create the container @ 02/12/24 19:30:27.806
  W0212 19:30:27.814773      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 02/12/24 19:30:27.814
  STEP: get the container status @ 02/12/24 19:30:30.837
  STEP: the container should be terminated @ 02/12/24 19:30:30.842
  STEP: the termination message should be set @ 02/12/24 19:30:30.842
  Feb 12 19:30:30.842: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 02/12/24 19:30:30.842
  Feb 12 19:30:30.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9229" for this suite. @ 02/12/24 19:30:30.863
• [3.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 02/12/24 19:30:30.872
  Feb 12 19:30:30.872: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-preemption @ 02/12/24 19:30:30.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:30:30.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:30:30.894
  Feb 12 19:30:30.914: INFO: Waiting up to 1m0s for all nodes to be ready
  Feb 12 19:31:30.919: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 02/12/24 19:31:30.923
  Feb 12 19:31:30.941: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Feb 12 19:31:30.949: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Feb 12 19:31:30.966: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Feb 12 19:31:30.975: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Feb 12 19:31:30.991: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Feb 12 19:31:30.998: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 02/12/24 19:31:30.998
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 02/12/24 19:31:33.027
  Feb 12 19:31:37.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-8252" for this suite. @ 02/12/24 19:31:37.136
• [66.272 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 02/12/24 19:31:37.144
  Feb 12 19:31:37.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 19:31:37.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:37.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:37.163
  STEP: Creating simple DaemonSet "daemon-set" @ 02/12/24 19:31:37.186
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/12/24 19:31:37.192
  Feb 12 19:31:37.198: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:37.198: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:37.201: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:31:37.201: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  Feb 12 19:31:38.196: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:38.196: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:38.200: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:31:38.200: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  Feb 12 19:31:39.199: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:39.199: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:39.203: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:31:39.203: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 02/12/24 19:31:39.207
  Feb 12 19:31:39.224: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:39.224: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:39.228: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:31:39.228: INFO: Node ip-172-31-91-42 is running 0 daemon pod, expected 1
  Feb 12 19:31:40.224: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:40.224: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:31:40.228: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:31:40.228: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 02/12/24 19:31:40.232
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9039, will wait for the garbage collector to delete the pods @ 02/12/24 19:31:40.232
  Feb 12 19:31:40.295: INFO: Deleting DaemonSet.extensions daemon-set took: 8.230604ms
  Feb 12 19:31:40.395: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.271432ms
  Feb 12 19:31:42.202: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:31:42.202: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb 12 19:31:42.205: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13966"},"items":null}

  Feb 12 19:31:42.208: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13967"},"items":null}

  Feb 12 19:31:42.226: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9039" for this suite. @ 02/12/24 19:31:42.232
• [5.095 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 02/12/24 19:31:42.239
  Feb 12 19:31:42.240: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:31:42.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:42.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:42.26
  STEP: Creating configMap with name configmap-test-volume-73f9c41c-810c-4776-a052-6ebc4c10a9ba @ 02/12/24 19:31:42.262
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:31:42.268
  STEP: Saw pod success @ 02/12/24 19:31:46.292
  Feb 12 19:31:46.295: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-dab432a7-7710-46e4-b93e-b816bbabd3cb container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:31:46.315
  Feb 12 19:31:46.335: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9128" for this suite. @ 02/12/24 19:31:46.34
• [4.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 02/12/24 19:31:46.348
  Feb 12 19:31:46.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubelet-test @ 02/12/24 19:31:46.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:46.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:46.37
  Feb 12 19:31:48.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2135" for this suite. @ 02/12/24 19:31:48.408
• [2.067 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 02/12/24 19:31:48.415
  Feb 12 19:31:48.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename containers @ 02/12/24 19:31:48.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:48.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:48.439
  STEP: Creating a pod to test override arguments @ 02/12/24 19:31:48.442
  STEP: Saw pod success @ 02/12/24 19:31:50.472
  Feb 12 19:31:50.476: INFO: Trying to get logs from node ip-172-31-91-42 pod client-containers-e13aaf54-b5e1-4790-95f4-b1c00469e8b1 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:31:50.496
  Feb 12 19:31:50.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9786" for this suite. @ 02/12/24 19:31:50.515
• [2.106 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 02/12/24 19:31:50.522
  Feb 12 19:31:50.522: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 19:31:50.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:50.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:50.542
  Feb 12 19:31:50.545: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: creating the pod @ 02/12/24 19:31:50.545
  STEP: submitting the pod to kubernetes @ 02/12/24 19:31:50.546
  Feb 12 19:31:52.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9803" for this suite. @ 02/12/24 19:31:52.586
• [2.071 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 02/12/24 19:31:52.594
  Feb 12 19:31:52.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:31:52.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:52.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:52.615
  STEP: create deployment with httpd image @ 02/12/24 19:31:52.618
  Feb 12 19:31:52.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6561 create -f -'
  Feb 12 19:31:52.686: INFO: stderr: ""
  Feb 12 19:31:52.686: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 02/12/24 19:31:52.686
  Feb 12 19:31:52.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6561 diff -f -'
  Feb 12 19:31:52.770: INFO: rc: 1
  Feb 12 19:31:52.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6561 delete -f -'
  Feb 12 19:31:52.817: INFO: stderr: ""
  Feb 12 19:31:52.817: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Feb 12 19:31:52.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6561" for this suite. @ 02/12/24 19:31:52.822
• [0.235 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 02/12/24 19:31:52.829
  Feb 12 19:31:52.829: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename csistoragecapacity @ 02/12/24 19:31:52.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:52.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:52.852
  STEP: getting /apis @ 02/12/24 19:31:52.855
  STEP: getting /apis/storage.k8s.io @ 02/12/24 19:31:52.859
  STEP: getting /apis/storage.k8s.io/v1 @ 02/12/24 19:31:52.86
  STEP: creating @ 02/12/24 19:31:52.861
  STEP: watching @ 02/12/24 19:31:52.878
  Feb 12 19:31:52.878: INFO: starting watch
  STEP: getting @ 02/12/24 19:31:52.884
  STEP: listing in namespace @ 02/12/24 19:31:52.889
  STEP: listing across namespaces @ 02/12/24 19:31:52.892
  STEP: patching @ 02/12/24 19:31:52.895
  STEP: updating @ 02/12/24 19:31:52.901
  Feb 12 19:31:52.908: INFO: waiting for watch events with expected annotations in namespace
  Feb 12 19:31:52.908: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 02/12/24 19:31:52.908
  STEP: deleting a collection @ 02/12/24 19:31:52.92
  Feb 12 19:31:52.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-4119" for this suite. @ 02/12/24 19:31:52.941
• [0.119 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 02/12/24 19:31:52.948
  Feb 12 19:31:52.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 19:31:52.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:52.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:52.971
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 02/12/24 19:31:52.974
  STEP: Saw pod success @ 02/12/24 19:31:57
  Feb 12 19:31:57.004: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-af0d0844-b63e-4b93-8f5f-77e0bc90bfcd container test-container: <nil>
  STEP: delete the pod @ 02/12/24 19:31:57.01
  Feb 12 19:31:57.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3251" for this suite. @ 02/12/24 19:31:57.03
• [4.090 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 02/12/24 19:31:57.038
  Feb 12 19:31:57.038: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename init-container @ 02/12/24 19:31:57.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:31:57.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:31:57.06
  STEP: creating the pod @ 02/12/24 19:31:57.063
  Feb 12 19:31:57.063: INFO: PodSpec: initContainers in spec.initContainers
  Feb 12 19:32:00.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1924" for this suite. @ 02/12/24 19:32:00.221
• [3.191 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 02/12/24 19:32:00.229
  Feb 12 19:32:00.229: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:32:00.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:00.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:00.255
  STEP: creating all guestbook components @ 02/12/24 19:32:00.261
  Feb 12 19:32:00.261: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Feb 12 19:32:00.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 create -f -'
  Feb 12 19:32:00.352: INFO: stderr: ""
  Feb 12 19:32:00.352: INFO: stdout: "service/agnhost-replica created\n"
  Feb 12 19:32:00.352: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Feb 12 19:32:00.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 create -f -'
  Feb 12 19:32:00.445: INFO: stderr: ""
  Feb 12 19:32:00.445: INFO: stdout: "service/agnhost-primary created\n"
  Feb 12 19:32:00.445: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Feb 12 19:32:00.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 create -f -'
  Feb 12 19:32:00.533: INFO: stderr: ""
  Feb 12 19:32:00.533: INFO: stdout: "service/frontend created\n"
  Feb 12 19:32:00.533: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Feb 12 19:32:00.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 create -f -'
  Feb 12 19:32:00.595: INFO: stderr: ""
  Feb 12 19:32:00.595: INFO: stdout: "deployment.apps/frontend created\n"
  Feb 12 19:32:00.596: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Feb 12 19:32:00.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 create -f -'
  Feb 12 19:32:00.664: INFO: stderr: ""
  Feb 12 19:32:00.664: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Feb 12 19:32:00.665: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Feb 12 19:32:00.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 create -f -'
  Feb 12 19:32:00.728: INFO: stderr: ""
  Feb 12 19:32:00.728: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 02/12/24 19:32:00.728
  Feb 12 19:32:00.728: INFO: Waiting for all frontend pods to be Running.
  Feb 12 19:32:05.780: INFO: Waiting for frontend to serve content.
  Feb 12 19:32:05.792: INFO: Trying to add a new entry to the guestbook.
  Feb 12 19:32:05.806: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 02/12/24 19:32:05.816
  Feb 12 19:32:05.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 delete --grace-period=0 --force -f -'
  Feb 12 19:32:05.877: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:32:05.877: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 02/12/24 19:32:05.877
  Feb 12 19:32:05.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 delete --grace-period=0 --force -f -'
  Feb 12 19:32:05.944: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:32:05.944: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 02/12/24 19:32:05.944
  Feb 12 19:32:05.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 delete --grace-period=0 --force -f -'
  Feb 12 19:32:06.003: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:32:06.003: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 02/12/24 19:32:06.003
  Feb 12 19:32:06.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 delete --grace-period=0 --force -f -'
  Feb 12 19:32:06.051: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:32:06.051: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 02/12/24 19:32:06.051
  Feb 12 19:32:06.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 delete --grace-period=0 --force -f -'
  Feb 12 19:32:06.113: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:32:06.113: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 02/12/24 19:32:06.113
  Feb 12 19:32:06.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3411 delete --grace-period=0 --force -f -'
  Feb 12 19:32:06.167: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:32:06.167: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Feb 12 19:32:06.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3411" for this suite. @ 02/12/24 19:32:06.171
• [5.952 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 02/12/24 19:32:06.181
  Feb 12 19:32:06.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 19:32:06.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:06.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:06.201
  Feb 12 19:32:06.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  W0212 19:32:08.744277      20 warnings.go:70] unknown field "alpha"
  W0212 19:32:08.744302      20 warnings.go:70] unknown field "beta"
  W0212 19:32:08.744306      20 warnings.go:70] unknown field "delta"
  W0212 19:32:08.744309      20 warnings.go:70] unknown field "epsilon"
  W0212 19:32:08.744311      20 warnings.go:70] unknown field "gamma"
  Feb 12 19:32:09.295: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6222" for this suite. @ 02/12/24 19:32:09.3
• [3.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 02/12/24 19:32:09.308
  Feb 12 19:32:09.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:32:09.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:09.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:09.329
  STEP: Creating configMap with name configmap-projected-all-test-volume-bab16fa5-2e01-4fc2-a100-a24329792fae @ 02/12/24 19:32:09.332
  STEP: Creating secret with name secret-projected-all-test-volume-df3798e8-781d-43c7-964a-2220b8078cd3 @ 02/12/24 19:32:09.337
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 02/12/24 19:32:09.342
  STEP: Saw pod success @ 02/12/24 19:32:13.382
  Feb 12 19:32:13.386: INFO: Trying to get logs from node ip-172-31-91-42 pod projected-volume-496acab3-f513-4904-a23f-ee9d6c580ad2 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 19:32:13.393
  Feb 12 19:32:13.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3768" for this suite. @ 02/12/24 19:32:13.413
• [4.111 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 02/12/24 19:32:13.42
  Feb 12 19:32:13.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename discovery @ 02/12/24 19:32:13.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:13.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:13.44
  STEP: Setting up server cert @ 02/12/24 19:32:13.444
  Feb 12 19:32:13.653: INFO: Checking APIGroup: apiregistration.k8s.io
  Feb 12 19:32:13.655: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Feb 12 19:32:13.655: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Feb 12 19:32:13.655: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Feb 12 19:32:13.655: INFO: Checking APIGroup: apps
  Feb 12 19:32:13.657: INFO: PreferredVersion.GroupVersion: apps/v1
  Feb 12 19:32:13.657: INFO: Versions found [{apps/v1 v1}]
  Feb 12 19:32:13.657: INFO: apps/v1 matches apps/v1
  Feb 12 19:32:13.657: INFO: Checking APIGroup: events.k8s.io
  Feb 12 19:32:13.661: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Feb 12 19:32:13.661: INFO: Versions found [{events.k8s.io/v1 v1}]
  Feb 12 19:32:13.661: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Feb 12 19:32:13.661: INFO: Checking APIGroup: authentication.k8s.io
  Feb 12 19:32:13.663: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Feb 12 19:32:13.663: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Feb 12 19:32:13.663: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Feb 12 19:32:13.663: INFO: Checking APIGroup: authorization.k8s.io
  Feb 12 19:32:13.665: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Feb 12 19:32:13.665: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Feb 12 19:32:13.665: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Feb 12 19:32:13.665: INFO: Checking APIGroup: autoscaling
  Feb 12 19:32:13.666: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Feb 12 19:32:13.666: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Feb 12 19:32:13.666: INFO: autoscaling/v2 matches autoscaling/v2
  Feb 12 19:32:13.666: INFO: Checking APIGroup: batch
  Feb 12 19:32:13.668: INFO: PreferredVersion.GroupVersion: batch/v1
  Feb 12 19:32:13.668: INFO: Versions found [{batch/v1 v1}]
  Feb 12 19:32:13.668: INFO: batch/v1 matches batch/v1
  Feb 12 19:32:13.668: INFO: Checking APIGroup: certificates.k8s.io
  Feb 12 19:32:13.669: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Feb 12 19:32:13.669: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Feb 12 19:32:13.669: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Feb 12 19:32:13.669: INFO: Checking APIGroup: networking.k8s.io
  Feb 12 19:32:13.671: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Feb 12 19:32:13.671: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Feb 12 19:32:13.671: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Feb 12 19:32:13.671: INFO: Checking APIGroup: policy
  Feb 12 19:32:13.673: INFO: PreferredVersion.GroupVersion: policy/v1
  Feb 12 19:32:13.673: INFO: Versions found [{policy/v1 v1}]
  Feb 12 19:32:13.673: INFO: policy/v1 matches policy/v1
  Feb 12 19:32:13.673: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Feb 12 19:32:13.674: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Feb 12 19:32:13.674: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Feb 12 19:32:13.674: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Feb 12 19:32:13.674: INFO: Checking APIGroup: storage.k8s.io
  Feb 12 19:32:13.675: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Feb 12 19:32:13.675: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Feb 12 19:32:13.675: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Feb 12 19:32:13.675: INFO: Checking APIGroup: admissionregistration.k8s.io
  Feb 12 19:32:13.676: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Feb 12 19:32:13.676: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Feb 12 19:32:13.676: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Feb 12 19:32:13.676: INFO: Checking APIGroup: apiextensions.k8s.io
  Feb 12 19:32:13.678: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Feb 12 19:32:13.678: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Feb 12 19:32:13.678: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Feb 12 19:32:13.678: INFO: Checking APIGroup: scheduling.k8s.io
  Feb 12 19:32:13.679: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Feb 12 19:32:13.679: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Feb 12 19:32:13.679: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Feb 12 19:32:13.679: INFO: Checking APIGroup: coordination.k8s.io
  Feb 12 19:32:13.680: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Feb 12 19:32:13.680: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Feb 12 19:32:13.680: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Feb 12 19:32:13.680: INFO: Checking APIGroup: node.k8s.io
  Feb 12 19:32:13.681: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Feb 12 19:32:13.681: INFO: Versions found [{node.k8s.io/v1 v1}]
  Feb 12 19:32:13.681: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Feb 12 19:32:13.681: INFO: Checking APIGroup: discovery.k8s.io
  Feb 12 19:32:13.682: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Feb 12 19:32:13.682: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Feb 12 19:32:13.682: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Feb 12 19:32:13.682: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Feb 12 19:32:13.684: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  Feb 12 19:32:13.684: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  Feb 12 19:32:13.684: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  Feb 12 19:32:13.684: INFO: Checking APIGroup: metrics.k8s.io
  Feb 12 19:32:13.685: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Feb 12 19:32:13.685: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Feb 12 19:32:13.685: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Feb 12 19:32:13.685: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6048" for this suite. @ 02/12/24 19:32:13.69
• [0.278 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 02/12/24 19:32:13.697
  Feb 12 19:32:13.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 19:32:13.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:13.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:13.717
  STEP: apply creating a deployment @ 02/12/24 19:32:13.721
  Feb 12 19:32:13.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4688" for this suite. @ 02/12/24 19:32:13.741
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 02/12/24 19:32:13.749
  Feb 12 19:32:13.749: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:32:13.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:13.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:13.77
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:32:13.773
  STEP: Saw pod success @ 02/12/24 19:32:17.801
  Feb 12 19:32:17.805: INFO: Trying to get logs from node ip-172-31-91-42 pod downwardapi-volume-dc08f3b5-0d24-4999-8727-eb2aa98883d2 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:32:17.814
  Feb 12 19:32:17.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-674" for this suite. @ 02/12/24 19:32:17.838
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 02/12/24 19:32:17.845
  Feb 12 19:32:17.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 19:32:17.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:17.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:17.864
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 02/12/24 19:32:17.867
  STEP: Saw pod success @ 02/12/24 19:32:21.892
  Feb 12 19:32:21.897: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-a759f708-8568-42c8-b154-900c4e6c7afc container test-container: <nil>
  STEP: delete the pod @ 02/12/24 19:32:21.905
  Feb 12 19:32:21.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6308" for this suite. @ 02/12/24 19:32:21.924
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 02/12/24 19:32:21.933
  Feb 12 19:32:21.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename cronjob @ 02/12/24 19:32:21.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:21.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:21.951
  STEP: Creating a cronjob @ 02/12/24 19:32:21.954
  STEP: creating @ 02/12/24 19:32:21.955
  STEP: getting @ 02/12/24 19:32:21.959
  STEP: listing @ 02/12/24 19:32:21.963
  STEP: watching @ 02/12/24 19:32:21.967
  Feb 12 19:32:21.967: INFO: starting watch
  STEP: cluster-wide listing @ 02/12/24 19:32:21.968
  STEP: cluster-wide watching @ 02/12/24 19:32:21.971
  Feb 12 19:32:21.971: INFO: starting watch
  STEP: patching @ 02/12/24 19:32:21.972
  STEP: updating @ 02/12/24 19:32:21.979
  Feb 12 19:32:21.989: INFO: waiting for watch events with expected annotations
  Feb 12 19:32:21.989: INFO: saw patched and updated annotations
  STEP: patching /status @ 02/12/24 19:32:21.989
  STEP: updating /status @ 02/12/24 19:32:21.994
  STEP: get /status @ 02/12/24 19:32:22.003
  STEP: deleting @ 02/12/24 19:32:22.007
  STEP: deleting a collection @ 02/12/24 19:32:22.024
  Feb 12 19:32:22.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4565" for this suite. @ 02/12/24 19:32:22.038
• [0.113 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 02/12/24 19:32:22.046
  Feb 12 19:32:22.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 19:32:22.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:22.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:22.067
  Feb 12 19:32:22.091: INFO: created pod pod-service-account-defaultsa
  Feb 12 19:32:22.091: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Feb 12 19:32:22.099: INFO: created pod pod-service-account-mountsa
  Feb 12 19:32:22.100: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Feb 12 19:32:22.112: INFO: created pod pod-service-account-nomountsa
  Feb 12 19:32:22.112: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Feb 12 19:32:22.128: INFO: created pod pod-service-account-defaultsa-mountspec
  Feb 12 19:32:22.128: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Feb 12 19:32:22.132: INFO: created pod pod-service-account-mountsa-mountspec
  Feb 12 19:32:22.132: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Feb 12 19:32:22.140: INFO: created pod pod-service-account-nomountsa-mountspec
  Feb 12 19:32:22.140: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Feb 12 19:32:22.144: INFO: created pod pod-service-account-defaultsa-nomountspec
  Feb 12 19:32:22.144: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Feb 12 19:32:22.151: INFO: created pod pod-service-account-mountsa-nomountspec
  Feb 12 19:32:22.151: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Feb 12 19:32:22.160: INFO: created pod pod-service-account-nomountsa-nomountspec
  Feb 12 19:32:22.160: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Feb 12 19:32:22.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-945" for this suite. @ 02/12/24 19:32:22.168
• [0.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 02/12/24 19:32:22.181
  Feb 12 19:32:22.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:32:22.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:22.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:22.206
  STEP: Setting up server cert @ 02/12/24 19:32:22.234
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:32:22.543
  STEP: Deploying the webhook pod @ 02/12/24 19:32:22.553
  STEP: Wait for the deployment to be ready @ 02/12/24 19:32:22.566
  Feb 12 19:32:22.574: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:32:24.586
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:32:24.599
  Feb 12 19:32:25.600: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 19:32:25.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6923-crds.webhook.example.com via the AdmissionRegistration API @ 02/12/24 19:32:26.12
  STEP: Creating a custom resource that should be mutated by the webhook @ 02/12/24 19:32:26.136
  Feb 12 19:32:28.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5880" for this suite. @ 02/12/24 19:32:28.73
  STEP: Destroying namespace "webhook-markers-2399" for this suite. @ 02/12/24 19:32:28.737
• [6.563 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 02/12/24 19:32:28.744
  Feb 12 19:32:28.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 19:32:28.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:28.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:28.763
  STEP: Creating a pod to test substitution in container's args @ 02/12/24 19:32:28.766
  STEP: Saw pod success @ 02/12/24 19:32:32.791
  Feb 12 19:32:32.794: INFO: Trying to get logs from node ip-172-31-5-108 pod var-expansion-5b897344-7fd0-43df-8cfc-cf9555d14edb container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:32:32.802
  Feb 12 19:32:32.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8815" for this suite. @ 02/12/24 19:32:32.824
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 02/12/24 19:32:32.834
  Feb 12 19:32:32.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:32:32.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:32.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:32.853
  STEP: Creating the pod @ 02/12/24 19:32:32.856
  Feb 12 19:32:35.402: INFO: Successfully updated pod "labelsupdate79101714-7275-4791-ae26-0516ff0e43c6"
  Feb 12 19:32:39.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8080" for this suite. @ 02/12/24 19:32:39.435
• [6.609 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 02/12/24 19:32:39.443
  Feb 12 19:32:39.443: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename apf @ 02/12/24 19:32:39.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:39.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:39.464
  STEP: getting /apis @ 02/12/24 19:32:39.467
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 02/12/24 19:32:39.47
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 02/12/24 19:32:39.471
  STEP: creating @ 02/12/24 19:32:39.472
  STEP: getting @ 02/12/24 19:32:39.486
  STEP: listing @ 02/12/24 19:32:39.489
  STEP: watching @ 02/12/24 19:32:39.493
  Feb 12 19:32:39.493: INFO: starting watch
  STEP: patching @ 02/12/24 19:32:39.494
  STEP: updating @ 02/12/24 19:32:39.5
  Feb 12 19:32:39.509: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 02/12/24 19:32:39.509
  STEP: patching /status @ 02/12/24 19:32:39.513
  STEP: updating /status @ 02/12/24 19:32:39.517
  STEP: deleting @ 02/12/24 19:32:39.526
  STEP: deleting a collection @ 02/12/24 19:32:39.54
  Feb 12 19:32:39.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-3133" for this suite. @ 02/12/24 19:32:39.567
• [0.132 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 02/12/24 19:32:39.576
  Feb 12 19:32:39.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:32:39.576
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:32:39.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:32:39.6
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-274ee3b5-871f-438a-86bd-eb5310332c84 @ 02/12/24 19:32:39.611
  STEP: Creating the pod @ 02/12/24 19:32:39.615
  STEP: Updating configmap projected-configmap-test-upd-274ee3b5-871f-438a-86bd-eb5310332c84 @ 02/12/24 19:32:41.654
  STEP: waiting to observe update in volume @ 02/12/24 19:32:41.66
  Feb 12 19:33:50.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8073" for this suite. @ 02/12/24 19:33:50.01
• [70.444 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 02/12/24 19:33:50.019
  Feb 12 19:33:50.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:33:50.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:33:50.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:33:50.041
  STEP: Creating the pod @ 02/12/24 19:33:50.044
  Feb 12 19:33:52.592: INFO: Successfully updated pod "annotationupdateb259a83f-2239-43c8-850a-acc3a3abb492"
  Feb 12 19:33:54.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9708" for this suite. @ 02/12/24 19:33:54.614
• [4.602 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 02/12/24 19:33:54.623
  Feb 12 19:33:54.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename taint-single-pod @ 02/12/24 19:33:54.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:33:54.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:33:54.649
  Feb 12 19:33:54.652: INFO: Waiting up to 1m0s for all nodes to be ready
  Feb 12 19:34:54.652: INFO: Waiting for terminating namespaces to be deleted...
  Feb 12 19:34:54.658: INFO: Starting informer...
  STEP: Starting pod... @ 02/12/24 19:34:54.658
  Feb 12 19:34:54.876: INFO: Pod is running on ip-172-31-5-108. Tainting Node
  STEP: Trying to apply a taint on the Node @ 02/12/24 19:34:54.876
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/12/24 19:34:54.887
  STEP: Waiting short time to make sure Pod is queued for deletion @ 02/12/24 19:34:54.892
  Feb 12 19:34:54.892: INFO: Pod wasn't evicted. Proceeding
  Feb 12 19:34:54.892: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/12/24 19:34:54.908
  STEP: Waiting some time to make sure that toleration time passed. @ 02/12/24 19:34:54.913
  Feb 12 19:36:09.913: INFO: Pod wasn't evicted. Test successful
  Feb 12 19:36:09.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-8856" for this suite. @ 02/12/24 19:36:09.918
• [135.304 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 02/12/24 19:36:09.927
  Feb 12 19:36:09.927: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename namespaces @ 02/12/24 19:36:09.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:09.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:09.949
  STEP: Creating a test namespace @ 02/12/24 19:36:09.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:09.969
  STEP: Creating a service in the namespace @ 02/12/24 19:36:09.972
  STEP: Deleting the namespace @ 02/12/24 19:36:09.983
  STEP: Waiting for the namespace to be removed. @ 02/12/24 19:36:09.993
  STEP: Recreating the namespace @ 02/12/24 19:36:15.998
  STEP: Verifying there is no service in the namespace @ 02/12/24 19:36:16.019
  Feb 12 19:36:16.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3921" for this suite. @ 02/12/24 19:36:16.027
  STEP: Destroying namespace "nsdeletetest-2014" for this suite. @ 02/12/24 19:36:16.034
  Feb 12 19:36:16.037: INFO: Namespace nsdeletetest-2014 was already deleted
  STEP: Destroying namespace "nsdeletetest-324" for this suite. @ 02/12/24 19:36:16.037
• [6.120 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 02/12/24 19:36:16.047
  Feb 12 19:36:16.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:36:16.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:16.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:16.066
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:36:16.069
  STEP: Saw pod success @ 02/12/24 19:36:20.095
  Feb 12 19:36:20.099: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-2aa0b797-945d-443f-872e-7020a2d256d7 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:36:20.11
  Feb 12 19:36:20.126: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5099" for this suite. @ 02/12/24 19:36:20.13
• [4.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 02/12/24 19:36:20.136
  Feb 12 19:36:20.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:36:20.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:20.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:20.158
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-6497 @ 02/12/24 19:36:20.161
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 02/12/24 19:36:20.177
  STEP: creating service externalsvc in namespace services-6497 @ 02/12/24 19:36:20.178
  STEP: creating replication controller externalsvc in namespace services-6497 @ 02/12/24 19:36:20.192
  I0212 19:36:20.199202      20 runners.go:197] Created replication controller with name: externalsvc, namespace: services-6497, replica count: 2
  I0212 19:36:23.250086      20 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 02/12/24 19:36:23.254
  Feb 12 19:36:23.275: INFO: Creating new exec pod
  Feb 12 19:36:25.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6497 exec execpod9tcmb -- /bin/sh -x -c nslookup nodeport-service.services-6497.svc.cluster.local'
  Feb 12 19:36:25.411: INFO: stderr: "+ nslookup nodeport-service.services-6497.svc.cluster.local\n"
  Feb 12 19:36:25.411: INFO: stdout: "Server:\t\t10.152.183.33\nAddress:\t10.152.183.33#53\n\nnodeport-service.services-6497.svc.cluster.local\tcanonical name = externalsvc.services-6497.svc.cluster.local.\nName:\texternalsvc.services-6497.svc.cluster.local\nAddress: 10.152.183.107\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-6497, will wait for the garbage collector to delete the pods @ 02/12/24 19:36:25.411
  Feb 12 19:36:25.475: INFO: Deleting ReplicationController externalsvc took: 8.549999ms
  Feb 12 19:36:25.576: INFO: Terminating ReplicationController externalsvc pods took: 101.000289ms
  Feb 12 19:36:28.793: INFO: Cleaning up the NodePort to ExternalName test service
  Feb 12 19:36:28.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6497" for this suite. @ 02/12/24 19:36:28.808
• [8.680 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 02/12/24 19:36:28.816
  Feb 12 19:36:28.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:36:28.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:28.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:28.837
  STEP: Starting the proxy @ 02/12/24 19:36:28.839
  Feb 12 19:36:28.840: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3307 proxy --unix-socket=/tmp/kubectl-proxy-unix805698874/test'
  STEP: retrieving proxy /api/ output @ 02/12/24 19:36:28.872
  Feb 12 19:36:28.873: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3307" for this suite. @ 02/12/24 19:36:28.877
• [0.067 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 02/12/24 19:36:28.884
  Feb 12 19:36:28.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename namespaces @ 02/12/24 19:36:28.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:28.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:28.903
  STEP: Updating Namespace "namespaces-9157" @ 02/12/24 19:36:28.906
  Feb 12 19:36:28.915: INFO: Namespace "namespaces-9157" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"9bdb97e6-94a2-4de6-b7ef-44e96ca695dc", "kubernetes.io/metadata.name":"namespaces-9157", "namespaces-9157":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Feb 12 19:36:28.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9157" for this suite. @ 02/12/24 19:36:28.918
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 02/12/24 19:36:28.926
  Feb 12 19:36:28.926: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-runtime @ 02/12/24 19:36:28.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:28.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:28.948
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 02/12/24 19:36:28.961
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 02/12/24 19:36:45.054
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 02/12/24 19:36:45.059
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 02/12/24 19:36:45.066
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 02/12/24 19:36:45.066
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 02/12/24 19:36:45.088
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 02/12/24 19:36:47.102
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 02/12/24 19:36:48.112
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 02/12/24 19:36:48.12
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 02/12/24 19:36:48.12
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 02/12/24 19:36:48.144
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 02/12/24 19:36:49.156
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 02/12/24 19:36:51.172
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 02/12/24 19:36:51.18
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 02/12/24 19:36:51.18
  Feb 12 19:36:51.205: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5200" for this suite. @ 02/12/24 19:36:51.21
• [22.290 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 02/12/24 19:36:51.217
  Feb 12 19:36:51.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:36:51.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:51.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:51.237
  STEP: Setting up server cert @ 02/12/24 19:36:51.263
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:36:51.498
  STEP: Deploying the webhook pod @ 02/12/24 19:36:51.508
  STEP: Wait for the deployment to be ready @ 02/12/24 19:36:51.52
  Feb 12 19:36:51.528: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:36:53.541
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:36:53.554
  Feb 12 19:36:54.555: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 02/12/24 19:36:54.564
  STEP: create a pod @ 02/12/24 19:36:54.578
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 02/12/24 19:36:56.598
  Feb 12 19:36:56.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=webhook-9542 attach --namespace=webhook-9542 to-be-attached-pod -i -c=container1'
  Feb 12 19:36:56.651: INFO: rc: 1
  Feb 12 19:36:56.702: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9542" for this suite. @ 02/12/24 19:36:56.709
  STEP: Destroying namespace "webhook-markers-2264" for this suite. @ 02/12/24 19:36:56.718
• [5.509 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 02/12/24 19:36:56.727
  Feb 12 19:36:56.727: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:36:56.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:36:56.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:36:56.762
  STEP: Setting up server cert @ 02/12/24 19:36:56.793
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:36:56.992
  STEP: Deploying the webhook pod @ 02/12/24 19:36:56.999
  STEP: Wait for the deployment to be ready @ 02/12/24 19:36:57.009
  Feb 12 19:36:57.019: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:36:59.033
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:36:59.049
  Feb 12 19:37:00.050: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 02/12/24 19:37:00.059
  STEP: Creating a custom resource definition that should be denied by the webhook @ 02/12/24 19:37:00.074
  Feb 12 19:37:00.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:37:00.131: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5362" for this suite. @ 02/12/24 19:37:00.134
  STEP: Destroying namespace "webhook-markers-1720" for this suite. @ 02/12/24 19:37:00.141
• [3.422 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 02/12/24 19:37:00.149
  Feb 12 19:37:00.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename job @ 02/12/24 19:37:00.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:37:00.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:37:00.169
  STEP: Creating Indexed job @ 02/12/24 19:37:00.172
  STEP: Ensuring job reaches completions @ 02/12/24 19:37:00.178
  STEP: Ensuring pods with index for job exist @ 02/12/24 19:37:08.184
  Feb 12 19:37:08.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7931" for this suite. @ 02/12/24 19:37:08.193
• [8.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 02/12/24 19:37:08.2
  Feb 12 19:37:08.200: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 19:37:08.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:37:08.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:37:08.222
  Feb 12 19:37:08.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 02/12/24 19:37:09.445
  Feb 12 19:37:09.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-6534 --namespace=crd-publish-openapi-6534 create -f -'
  Feb 12 19:37:11.513: INFO: stderr: ""
  Feb 12 19:37:11.513: INFO: stdout: "e2e-test-crd-publish-openapi-4269-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Feb 12 19:37:11.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-6534 --namespace=crd-publish-openapi-6534 delete e2e-test-crd-publish-openapi-4269-crds test-cr'
  Feb 12 19:37:11.562: INFO: stderr: ""
  Feb 12 19:37:11.562: INFO: stdout: "e2e-test-crd-publish-openapi-4269-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Feb 12 19:37:11.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-6534 --namespace=crd-publish-openapi-6534 apply -f -'
  Feb 12 19:37:11.614: INFO: stderr: ""
  Feb 12 19:37:11.614: INFO: stdout: "e2e-test-crd-publish-openapi-4269-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Feb 12 19:37:11.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-6534 --namespace=crd-publish-openapi-6534 delete e2e-test-crd-publish-openapi-4269-crds test-cr'
  Feb 12 19:37:11.674: INFO: stderr: ""
  Feb 12 19:37:11.674: INFO: stdout: "e2e-test-crd-publish-openapi-4269-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 02/12/24 19:37:11.674
  Feb 12 19:37:11.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-6534 explain e2e-test-crd-publish-openapi-4269-crds'
  Feb 12 19:37:11.715: INFO: stderr: ""
  Feb 12 19:37:11.715: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-4269-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Feb 12 19:37:13.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6534" for this suite. @ 02/12/24 19:37:13.09
• [4.898 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 02/12/24 19:37:13.097
  Feb 12 19:37:13.097: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:37:13.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:37:13.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:37:13.118
  STEP: Setting up server cert @ 02/12/24 19:37:13.142
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:37:13.436
  STEP: Deploying the webhook pod @ 02/12/24 19:37:13.44
  STEP: Wait for the deployment to be ready @ 02/12/24 19:37:13.453
  Feb 12 19:37:13.462: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/12/24 19:37:15.474
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:37:15.486
  Feb 12 19:37:16.486: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 02/12/24 19:37:16.494
  STEP: create a pod that should be denied by the webhook @ 02/12/24 19:37:16.51
  STEP: create a pod that causes the webhook to hang @ 02/12/24 19:37:16.521
  STEP: create a configmap that should be denied by the webhook @ 02/12/24 19:37:26.53
  STEP: create a configmap that should be admitted by the webhook @ 02/12/24 19:37:26.561
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 02/12/24 19:37:26.571
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 02/12/24 19:37:26.58
  STEP: create a namespace that bypass the webhook @ 02/12/24 19:37:26.586
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 02/12/24 19:37:26.603
  Feb 12 19:37:26.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7420" for this suite. @ 02/12/24 19:37:26.666
  STEP: Destroying namespace "webhook-markers-5032" for this suite. @ 02/12/24 19:37:26.673
  STEP: Destroying namespace "exempted-namespace-5368" for this suite. @ 02/12/24 19:37:26.679
• [13.589 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 02/12/24 19:37:26.687
  Feb 12 19:37:26.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replication-controller @ 02/12/24 19:37:26.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:37:26.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:37:26.708
  STEP: creating a ReplicationController @ 02/12/24 19:37:26.714
  STEP: waiting for RC to be added @ 02/12/24 19:37:26.721
  STEP: waiting for available Replicas @ 02/12/24 19:37:26.721
  STEP: patching ReplicationController @ 02/12/24 19:37:28.863
  STEP: waiting for RC to be modified @ 02/12/24 19:37:28.872
  STEP: patching ReplicationController status @ 02/12/24 19:37:28.872
  STEP: waiting for RC to be modified @ 02/12/24 19:37:28.877
  STEP: waiting for available Replicas @ 02/12/24 19:37:28.878
  STEP: fetching ReplicationController status @ 02/12/24 19:37:28.884
  STEP: patching ReplicationController scale @ 02/12/24 19:37:28.888
  STEP: waiting for RC to be modified @ 02/12/24 19:37:28.895
  STEP: waiting for ReplicationController's scale to be the max amount @ 02/12/24 19:37:28.895
  STEP: fetching ReplicationController; ensuring that it's patched @ 02/12/24 19:37:30.808
  STEP: updating ReplicationController status @ 02/12/24 19:37:30.811
  STEP: waiting for RC to be modified @ 02/12/24 19:37:30.817
  STEP: listing all ReplicationControllers @ 02/12/24 19:37:30.817
  STEP: checking that ReplicationController has expected values @ 02/12/24 19:37:30.824
  STEP: deleting ReplicationControllers by collection @ 02/12/24 19:37:30.824
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 02/12/24 19:37:30.833
  Feb 12 19:37:30.877: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0212 19:37:30.877568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9947" for this suite. @ 02/12/24 19:37:30.881
• [4.201 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 02/12/24 19:37:30.888
  Feb 12 19:37:30.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename events @ 02/12/24 19:37:30.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:37:30.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:37:30.911
  STEP: creating a test event @ 02/12/24 19:37:30.915
  STEP: listing all events in all namespaces @ 02/12/24 19:37:30.92
  STEP: patching the test event @ 02/12/24 19:37:30.932
  STEP: fetching the test event @ 02/12/24 19:37:30.94
  STEP: updating the test event @ 02/12/24 19:37:30.942
  STEP: getting the test event @ 02/12/24 19:37:30.955
  STEP: deleting the test event @ 02/12/24 19:37:30.96
  STEP: listing all events in all namespaces @ 02/12/24 19:37:30.969
  Feb 12 19:37:30.982: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-9778" for this suite. @ 02/12/24 19:37:30.987
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 02/12/24 19:37:30.995
  Feb 12 19:37:30.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 19:37:30.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:37:31.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:37:31.015
  STEP: Creating service test in namespace statefulset-3478 @ 02/12/24 19:37:31.021
  STEP: Creating a new StatefulSet @ 02/12/24 19:37:31.025
  Feb 12 19:37:31.037: INFO: Found 0 stateful pods, waiting for 3
  E0212 19:37:31.877901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:32.877949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:33.878109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:34.878938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:35.879038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:36.879131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:37.879211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:38.879336      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:39.879633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:40.879724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:37:41.038: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:37:41.038: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:37:41.038: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:37:41.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-3478 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:37:41.155: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:37:41.155: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:37:41.155: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0212 19:37:41.879840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:42.880061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:43.880927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:44.881058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:45.881167      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:46.881324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:47.881476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:48.882185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:49.882291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:50.882422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 02/12/24 19:37:51.167
  Feb 12 19:37:51.189: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 02/12/24 19:37:51.19
  E0212 19:37:51.882902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:52.883012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:53.883605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:54.883685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:55.883805      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:56.883856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:57.884678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:58.884800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:37:59.884921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:00.885006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 02/12/24 19:38:01.198
  Feb 12 19:38:01.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-3478 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:38:01.304: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:38:01.304: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:38:01.304: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0212 19:38:01.885082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:02.885169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:03.885271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:04.885358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:05.885459      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:06.885564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:07.886263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:08.886384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:09.886461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:10.886913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 02/12/24 19:38:11.323
  Feb 12 19:38:11.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-3478 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:38:11.417: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:38:11.417: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:38:11.417: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0212 19:38:11.887007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:12.887106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:13.888021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:14.888225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:15.888343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:16.888482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:17.888650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:18.889269      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:19.889448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:20.889647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:38:21.447: INFO: Updating stateful set ss2
  E0212 19:38:21.890666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:22.890842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:23.890954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:24.891044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:25.891201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:26.891443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:27.891513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:28.891591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:29.892614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:30.893094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 02/12/24 19:38:31.456
  Feb 12 19:38:31.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-3478 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:38:31.551: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:38:31.551: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:38:31.551: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0212 19:38:31.893827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:32.894009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:33.894924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:34.895605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:35.896341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:36.897120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:37.897303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:38.897647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:39.897825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:40.897916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:38:41.568: INFO: Deleting all statefulset in ns statefulset-3478
  Feb 12 19:38:41.572: INFO: Scaling statefulset ss2 to 0
  E0212 19:38:41.898321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:42.898485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:43.898922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:44.899110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:45.899357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:46.899442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:47.899623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:48.899789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:49.900049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:50.900206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:38:51.589: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:38:51.593: INFO: Deleting statefulset ss2
  Feb 12 19:38:51.608: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3478" for this suite. @ 02/12/24 19:38:51.615
• [80.627 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 02/12/24 19:38:51.623
  Feb 12 19:38:51.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 19:38:51.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:38:51.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:38:51.647
  STEP: creating the pod with failed condition @ 02/12/24 19:38:51.65
  E0212 19:38:51.901269      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:52.901356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:53.901467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:54.901569      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:55.902464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:56.902931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:57.903769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:58.903867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:38:59.904900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:00.905565      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:01.906289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:02.906371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:03.906435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:04.906542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:05.906606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:06.906917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:07.907184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:08.907271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:09.907684      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:10.907773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:11.908079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:12.908449      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:13.908454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:14.908662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:15.909263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:16.909422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:17.910466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:18.910945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:19.911415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:20.911596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:21.912158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:22.912253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:23.912974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:24.913084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:25.913233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:26.913408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:27.913963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:28.914206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:29.914555      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:30.914710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:31.915456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:32.915562      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:33.916363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:34.917306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:35.917648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:36.917839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:37.918541      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:38.919045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:39.920039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:40.920232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:41.921308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:42.921398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:43.921763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:44.921839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:45.922877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:46.923059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:47.923164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:48.923640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:49.924492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:50.924595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:51.924653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:52.925472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:53.926244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:54.927040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:55.928036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:56.928102      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:57.928163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:58.928537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:39:59.928647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:00.929010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:01.930013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:02.930098      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:03.930976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:04.931185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:05.931354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:06.931551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:07.932123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:08.932156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:09.932483      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:10.932667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:11.933010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:12.933110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:13.933497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:14.933720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:15.934484      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:16.934617      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:17.935398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:18.935492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:19.935804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:20.935985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:21.936471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:22.936591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:23.937398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:24.937571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:25.938415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:26.938896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:27.939582      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:28.940093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:29.940373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:30.940610      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:31.940799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:32.940976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:33.941068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:34.941823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:35.942906      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:36.943189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:37.943410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:38.944084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:39.944257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:40.944566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:41.944829      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:42.945361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:43.946417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:44.946491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:45.946606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:46.947170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:47.947495      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:48.947640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:49.947766      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:50.948325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 02/12/24 19:40:51.66
  E0212 19:40:51.948431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:40:52.174: INFO: Successfully updated pod "var-expansion-4fd60fc7-1349-4b7a-a452-88972886ceb7"
  STEP: waiting for pod running @ 02/12/24 19:40:52.174
  E0212 19:40:52.948987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:53.949164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 02/12/24 19:40:54.183
  Feb 12 19:40:54.183: INFO: Deleting pod "var-expansion-4fd60fc7-1349-4b7a-a452-88972886ceb7" in namespace "var-expansion-4725"
  Feb 12 19:40:54.191: INFO: Wait up to 5m0s for pod "var-expansion-4fd60fc7-1349-4b7a-a452-88972886ceb7" to be fully deleted
  E0212 19:40:54.949403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:55.949502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:56.949613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:57.949891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:58.949982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:40:59.950901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:00.951013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:01.951120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:02.952006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:03.952089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:04.952206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:05.952300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:06.952411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:07.952763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:08.953344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:09.953452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:10.953866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:11.953988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:12.954355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:13.954917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:14.955601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:15.955838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:16.956489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:17.956853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:18.957542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:19.957660      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:20.957825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:21.958957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:22.959681      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:23.959890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:24.960073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:25.960158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:41:26.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4725" for this suite. @ 02/12/24 19:41:26.287
• [154.671 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 02/12/24 19:41:26.294
  Feb 12 19:41:26.294: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename watch @ 02/12/24 19:41:26.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:26.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:26.316
  STEP: creating a watch on configmaps @ 02/12/24 19:41:26.319
  STEP: creating a new configmap @ 02/12/24 19:41:26.32
  STEP: modifying the configmap once @ 02/12/24 19:41:26.325
  STEP: closing the watch once it receives two notifications @ 02/12/24 19:41:26.334
  Feb 12 19:41:26.334: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5132  9ed56957-46c1-4167-a393-f3a4754baffa 17717 0 2024-02-12 19:41:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-12 19:41:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 19:41:26.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5132  9ed56957-46c1-4167-a393-f3a4754baffa 17718 0 2024-02-12 19:41:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-12 19:41:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 02/12/24 19:41:26.334
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 02/12/24 19:41:26.342
  STEP: deleting the configmap @ 02/12/24 19:41:26.344
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 02/12/24 19:41:26.351
  Feb 12 19:41:26.351: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5132  9ed56957-46c1-4167-a393-f3a4754baffa 17720 0 2024-02-12 19:41:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-12 19:41:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 19:41:26.351: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5132  9ed56957-46c1-4167-a393-f3a4754baffa 17721 0 2024-02-12 19:41:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-12 19:41:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 19:41:26.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5132" for this suite. @ 02/12/24 19:41:26.356
• [0.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 02/12/24 19:41:26.363
  Feb 12 19:41:26.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 19:41:26.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:26.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:26.385
  STEP: Discovering how many secrets are in namespace by default @ 02/12/24 19:41:26.389
  E0212 19:41:26.960629      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:27.961471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:28.962405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:29.962519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:30.962918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 02/12/24 19:41:31.393
  E0212 19:41:31.963900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:32.964249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:33.964985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:34.965384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:35.965464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 19:41:36.399
  STEP: Ensuring resource quota status is calculated @ 02/12/24 19:41:36.405
  E0212 19:41:36.966464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:37.966915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 02/12/24 19:41:38.411
  STEP: Ensuring resource quota status captures secret creation @ 02/12/24 19:41:38.422
  E0212 19:41:38.967565      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:39.967688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 02/12/24 19:41:40.428
  STEP: Ensuring resource quota status released usage @ 02/12/24 19:41:40.436
  E0212 19:41:40.967761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:41.967883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:41:42.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1321" for this suite. @ 02/12/24 19:41:42.444
• [16.090 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 02/12/24 19:41:42.453
  Feb 12 19:41:42.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename csiinlinevolumes @ 02/12/24 19:41:42.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:42.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:42.475
  STEP: creating @ 02/12/24 19:41:42.479
  STEP: getting @ 02/12/24 19:41:42.497
  STEP: listing in namespace @ 02/12/24 19:41:42.501
  STEP: patching @ 02/12/24 19:41:42.505
  STEP: deleting @ 02/12/24 19:41:42.512
  Feb 12 19:41:42.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4421" for this suite. @ 02/12/24 19:41:42.532
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 02/12/24 19:41:42.54
  Feb 12 19:41:42.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 19:41:42.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:42.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:42.563
  STEP: Creating a pod to test substitution in container's command @ 02/12/24 19:41:42.566
  E0212 19:41:42.967960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:43.968122      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:44.968896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:45.969479      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:41:46.591
  Feb 12 19:41:46.595: INFO: Trying to get logs from node ip-172-31-91-42 pod var-expansion-1c9f4bec-7de8-4f11-85fd-cf6ba025c74a container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:41:46.613
  Feb 12 19:41:46.629: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8298" for this suite. @ 02/12/24 19:41:46.633
• [4.100 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 02/12/24 19:41:46.641
  Feb 12 19:41:46.641: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:41:46.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:46.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:46.661
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:41:46.664
  E0212 19:41:46.970071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:47.970498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:48.971343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:49.971767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:41:50.69
  Feb 12 19:41:50.694: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-abb52128-16cd-4ace-a070-0c50cd2bc732 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:41:50.709
  Feb 12 19:41:50.729: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2952" for this suite. @ 02/12/24 19:41:50.734
• [4.101 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 02/12/24 19:41:50.742
  Feb 12 19:41:50.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:41:50.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:50.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:50.763
  STEP: Creating a pod to test downward api env vars @ 02/12/24 19:41:50.766
  E0212 19:41:50.972398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:51.972774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:52.973251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:53.973522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:41:54.79
  Feb 12 19:41:54.794: INFO: Trying to get logs from node ip-172-31-5-108 pod downward-api-848345b3-5616-4d03-93df-a6ac99fcb56d container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:41:54.802
  Feb 12 19:41:54.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8000" for this suite. @ 02/12/24 19:41:54.822
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 02/12/24 19:41:54.833
  Feb 12 19:41:54.833: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-preemption @ 02/12/24 19:41:54.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:41:54.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:41:54.853
  Feb 12 19:41:54.870: INFO: Waiting up to 1m0s for all nodes to be ready
  E0212 19:41:54.973999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:55.974101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:56.974638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:57.975450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:58.976294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:41:59.976502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:00.976851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:01.976939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:02.977800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:03.977904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:04.978931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:05.978975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:06.979084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:07.979418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:08.979984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:09.980173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:10.980211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:11.981287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:12.981838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:13.981863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:14.981962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:15.982041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:16.982433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:17.982798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:18.983402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:19.983570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:20.983966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:21.984070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:22.984439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:23.985766      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:24.986322      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:25.986416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:26.987439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:27.987663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:28.988158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:29.988266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:30.989325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:31.989426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:32.990214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:33.990736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:34.991075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:35.991289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:36.992104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:37.992489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:38.992902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:39.993037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:40.993335      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:41.993449      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:42.994004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:43.994883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:44.995842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:45.996117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:46.996335      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:47.996639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:48.996956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:49.997191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:50.997318      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:51.997842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:52.998459      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:53.999529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:42:54.876: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 02/12/24 19:42:54.882
  Feb 12 19:42:54.901: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Feb 12 19:42:54.909: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Feb 12 19:42:54.925: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Feb 12 19:42:54.933: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Feb 12 19:42:54.945: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Feb 12 19:42:54.952: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 02/12/24 19:42:54.953
  E0212 19:42:54.999942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:56.000039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 02/12/24 19:42:56.983
  E0212 19:42:57.000825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:58.001904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:42:59.002594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:00.002754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:01.002804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:01.076: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3688" for this suite. @ 02/12/24 19:43:01.082
• [66.255 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 02/12/24 19:43:01.088
  Feb 12 19:43:01.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:43:01.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:01.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:01.112
  STEP: Setting up server cert @ 02/12/24 19:43:01.135
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:43:01.263
  STEP: Deploying the webhook pod @ 02/12/24 19:43:01.272
  STEP: Wait for the deployment to be ready @ 02/12/24 19:43:01.286
  Feb 12 19:43:01.294: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 19:43:02.003492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:03.003603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 19:43:03.307
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:43:03.321
  E0212 19:43:04.003911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:04.321: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 02/12/24 19:43:04.33
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 02/12/24 19:43:04.346
  STEP: Creating a dummy validating-webhook-configuration object @ 02/12/24 19:43:04.361
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 02/12/24 19:43:04.37
  STEP: Creating a dummy mutating-webhook-configuration object @ 02/12/24 19:43:04.378
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 02/12/24 19:43:04.387
  Feb 12 19:43:04.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8529" for this suite. @ 02/12/24 19:43:04.45
  STEP: Destroying namespace "webhook-markers-7257" for this suite. @ 02/12/24 19:43:04.456
• [3.376 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 02/12/24 19:43:04.464
  Feb 12 19:43:04.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 19:43:04.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:04.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:04.485
  STEP: create the rc @ 02/12/24 19:43:04.488
  W0212 19:43:04.494274      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0212 19:43:05.004539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:06.004685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:07.004803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:08.005422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:09.005494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 02/12/24 19:43:09.498
  STEP: wait for all pods to be garbage collected @ 02/12/24 19:43:09.505
  E0212 19:43:10.005862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:11.005959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:12.006048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:13.006140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:14.006928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/12/24 19:43:14.516
  W0212 19:43:14.521604      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb 12 19:43:14.521: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb 12 19:43:14.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2758" for this suite. @ 02/12/24 19:43:14.525
• [10.069 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 02/12/24 19:43:14.533
  Feb 12 19:43:14.533: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 19:43:14.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:14.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:14.555
  STEP: creating pod @ 02/12/24 19:43:14.558
  E0212 19:43:15.006978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:16.007063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:16.584: INFO: Pod pod-hostip-a3f19e38-02d4-44bd-afa7-74cb1d94ad4c has hostIP: 172.31.5.108
  Feb 12 19:43:16.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9870" for this suite. @ 02/12/24 19:43:16.589
• [2.063 seconds]
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 02/12/24 19:43:16.596
  Feb 12 19:43:16.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename endpointslice @ 02/12/24 19:43:16.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:16.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:16.617
  E0212 19:43:17.007174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:18.007526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:19.007638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:20.007870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:21.007948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 02/12/24 19:43:21.685
  E0212 19:43:22.008174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:23.008325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:24.008815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:25.009034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:26.009233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 02/12/24 19:43:26.694
  E0212 19:43:27.009845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:28.010194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:29.010281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:30.010387      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:31.010935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 02/12/24 19:43:31.702
  E0212 19:43:32.011903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:33.012115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:34.012368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:35.012602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:36.012827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 02/12/24 19:43:36.71
  Feb 12 19:43:36.732: INFO: EndpointSlice for Service endpointslice-3859/example-named-port not found
  E0212 19:43:37.013419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:38.013586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:39.013840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:40.014019      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:41.014119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:42.014688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:43.014792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:44.014867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:45.015079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:46.015192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:46.739: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3859" for this suite. @ 02/12/24 19:43:46.744
• [30.155 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 02/12/24 19:43:46.751
  Feb 12 19:43:46.751: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 19:43:46.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:46.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:46.774
  STEP: Creating a pod to test env composition @ 02/12/24 19:43:46.777
  E0212 19:43:47.016162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:48.016480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:43:48.796
  Feb 12 19:43:48.800: INFO: Trying to get logs from node ip-172-31-5-108 pod var-expansion-9bc83343-36f6-431f-99ae-af30198524bc container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:43:48.812
  Feb 12 19:43:48.830: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2893" for this suite. @ 02/12/24 19:43:48.835
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 02/12/24 19:43:48.842
  Feb 12 19:43:48.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:43:48.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:48.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:48.865
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/12/24 19:43:48.868
  Feb 12 19:43:48.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-4264 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Feb 12 19:43:48.917: INFO: stderr: ""
  Feb 12 19:43:48.917: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 02/12/24 19:43:48.917
  Feb 12 19:43:48.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-4264 delete pods e2e-test-httpd-pod'
  E0212 19:43:49.016718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:43:50.016815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:50.480: INFO: stderr: ""
  Feb 12 19:43:50.480: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Feb 12 19:43:50.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4264" for this suite. @ 02/12/24 19:43:50.485
• [1.652 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 02/12/24 19:43:50.494
  Feb 12 19:43:50.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 19:43:50.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:50.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:50.515
  STEP: Creating simple DaemonSet "daemon-set" @ 02/12/24 19:43:50.543
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/12/24 19:43:50.55
  Feb 12 19:43:50.557: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:50.557: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:50.560: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:43:50.560: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 19:43:51.017165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:51.556: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:51.556: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:51.560: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:43:51.561: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 19:43:52.018220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:52.555: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:52.555: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:52.559: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:43:52.559: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 02/12/24 19:43:52.562
  Feb 12 19:43:52.567: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 02/12/24 19:43:52.567
  Feb 12 19:43:52.577: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 02/12/24 19:43:52.577
  Feb 12 19:43:52.579: INFO: Observed &DaemonSet event: ADDED
  Feb 12 19:43:52.579: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.579: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.580: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.580: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.580: INFO: Found daemon set daemon-set in namespace daemonsets-5769 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb 12 19:43:52.580: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 02/12/24 19:43:52.58
  STEP: watching for the daemon set status to be patched @ 02/12/24 19:43:52.587
  Feb 12 19:43:52.589: INFO: Observed &DaemonSet event: ADDED
  Feb 12 19:43:52.589: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.589: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.589: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.589: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.590: INFO: Observed daemon set daemon-set in namespace daemonsets-5769 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb 12 19:43:52.590: INFO: Observed &DaemonSet event: MODIFIED
  Feb 12 19:43:52.590: INFO: Found daemon set daemon-set in namespace daemonsets-5769 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Feb 12 19:43:52.590: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 02/12/24 19:43:52.595
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5769, will wait for the garbage collector to delete the pods @ 02/12/24 19:43:52.595
  Feb 12 19:43:52.659: INFO: Deleting DaemonSet.extensions daemon-set took: 9.605936ms
  Feb 12 19:43:52.759: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.446491ms
  E0212 19:43:53.018597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:53.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:43:53.765: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb 12 19:43:53.768: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18763"},"items":null}

  Feb 12 19:43:53.772: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18763"},"items":null}

  Feb 12 19:43:53.790: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5769" for this suite. @ 02/12/24 19:43:53.795
• [3.313 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 02/12/24 19:43:53.807
  Feb 12 19:43:53.807: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 19:43:53.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:53.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:53.835
  STEP: Creating a simple DaemonSet "daemon-set" @ 02/12/24 19:43:53.862
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/12/24 19:43:53.868
  Feb 12 19:43:53.875: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:53.875: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:53.879: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:43:53.879: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 19:43:54.018764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:54.874: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:54.874: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:54.878: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:43:54.878: INFO: Node ip-172-31-91-42 is running 0 daemon pod, expected 1
  E0212 19:43:55.018826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:55.873: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:55.873: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:55.878: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:43:55.878: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 02/12/24 19:43:55.882
  Feb 12 19:43:55.901: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:55.901: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:55.908: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:43:55.908: INFO: Node ip-172-31-91-42 is running 0 daemon pod, expected 1
  E0212 19:43:56.019769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:56.902: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:56.902: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:56.906: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:43:56.906: INFO: Node ip-172-31-91-42 is running 0 daemon pod, expected 1
  E0212 19:43:57.020532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:57.902: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:57.902: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:43:57.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:43:57.907: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 02/12/24 19:43:57.907
  STEP: Deleting DaemonSet "daemon-set" @ 02/12/24 19:43:57.914
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4855, will wait for the garbage collector to delete the pods @ 02/12/24 19:43:57.914
  Feb 12 19:43:57.977: INFO: Deleting DaemonSet.extensions daemon-set took: 7.839593ms
  E0212 19:43:58.021436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:58.077: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.598385ms
  E0212 19:43:59.022336      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:43:59.583: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:43:59.583: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb 12 19:43:59.587: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18924"},"items":null}

  Feb 12 19:43:59.591: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18924"},"items":null}

  Feb 12 19:43:59.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4855" for this suite. @ 02/12/24 19:43:59.611
• [5.811 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 02/12/24 19:43:59.619
  Feb 12 19:43:59.619: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 19:43:59.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:43:59.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:43:59.642
  Feb 12 19:43:59.645: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: creating the pod @ 02/12/24 19:43:59.645
  STEP: submitting the pod to kubernetes @ 02/12/24 19:43:59.645
  E0212 19:44:00.022456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:01.022542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:01.720: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8359" for this suite. @ 02/12/24 19:44:01.724
• [2.113 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 02/12/24 19:44:01.732
  Feb 12 19:44:01.732: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename csiinlinevolumes @ 02/12/24 19:44:01.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:44:01.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:44:01.753
  STEP: Creating two CSIDrivers @ 02/12/24 19:44:01.756
  STEP: Getting "inline-driver-46bb981e-fc6c-4123-a53a-75a83149bc4b" & "inline-driver-bb09bac7-9e7a-4b7a-ad97-34742a1dcb30" @ 02/12/24 19:44:01.774
  STEP: Patching the CSIDriver "inline-driver-bb09bac7-9e7a-4b7a-ad97-34742a1dcb30" @ 02/12/24 19:44:01.782
  STEP: Updating the CSIDriver "inline-driver-bb09bac7-9e7a-4b7a-ad97-34742a1dcb30" @ 02/12/24 19:44:01.787
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-47" @ 02/12/24 19:44:01.796
  STEP: Deleting CSIDriver "inline-driver-46bb981e-fc6c-4123-a53a-75a83149bc4b" @ 02/12/24 19:44:01.799
  STEP: Confirm deletion of CSIDriver "inline-driver-46bb981e-fc6c-4123-a53a-75a83149bc4b" @ 02/12/24 19:44:01.807
  STEP: Deleting CSIDriver "inline-driver-bb09bac7-9e7a-4b7a-ad97-34742a1dcb30" via DeleteCollection @ 02/12/24 19:44:01.811
  STEP: Confirm deletion of CSIDriver "inline-driver-bb09bac7-9e7a-4b7a-ad97-34742a1dcb30" @ 02/12/24 19:44:01.823
  Feb 12 19:44:01.827: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-47" for this suite. @ 02/12/24 19:44:01.832
• [0.108 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 02/12/24 19:44:01.841
  Feb 12 19:44:01.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 19:44:01.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:44:01.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:44:01.865
  Feb 12 19:44:01.869: INFO: Creating deployment "webserver-deployment"
  Feb 12 19:44:01.875: INFO: Waiting for observed generation 1
  E0212 19:44:02.022644      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:03.022739      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:03.886: INFO: Waiting for all required pods to come up
  Feb 12 19:44:03.890: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 02/12/24 19:44:03.89
  Feb 12 19:44:03.890: INFO: Waiting for deployment "webserver-deployment" to complete
  Feb 12 19:44:03.899: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Feb 12 19:44:03.909: INFO: Updating deployment webserver-deployment
  Feb 12 19:44:03.909: INFO: Waiting for observed generation 2
  E0212 19:44:04.023115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:05.023728      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:05.919: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Feb 12 19:44:05.923: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Feb 12 19:44:05.926: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Feb 12 19:44:05.937: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Feb 12 19:44:05.937: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Feb 12 19:44:05.941: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Feb 12 19:44:05.948: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Feb 12 19:44:05.948: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Feb 12 19:44:05.959: INFO: Updating deployment webserver-deployment
  Feb 12 19:44:05.959: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Feb 12 19:44:05.968: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Feb 12 19:44:05.972: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Feb 12 19:44:05.980: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dc30a0ca-bc2f-4d1a-a70e-f750ed8b97b6",
      ResourceVersion: (string) (len=5) "19253",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 19:44:05.993: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
      ResourceVersion: (string) (len=5) "19257",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "dc30a0ca-bc2f-4d1a-a70e-f750ed8b97b6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 63 33 30 61 30  63 61 2d 62 63 32 66 2d  |\"dc30a0ca-bc2f-|
              00000120  34 64 31 61 2d 61 37 30  65 2d 66 37 35 30 65 64  |4d1a-a70e-f750ed|
              00000130  38 62 39 37 62 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |8b97b6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:44:05.994: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Feb 12 19:44:05.994: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
      ResourceVersion: (string) (len=5) "19254",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "dc30a0ca-bc2f-4d1a-a70e-f750ed8b97b6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 63 33 30 61 30  63 61 2d 62 63 32 66 2d  |\"dc30a0ca-bc2f-|
              00000120  34 64 31 61 2d 61 37 30  65 2d 66 37 35 30 65 64  |4d1a-a70e-f750ed|
              00000130  38 62 39 37 62 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |8b97b6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 19:44:06.000: INFO: Pod "webserver-deployment-557759b7c7-2ptr9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-2ptr9",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6019aaf1-8a05-402f-9867-6a6f9fbc5f0d",
      ResourceVersion: (string) (len=5) "19109",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  39 2e 39 35 5c 22 7d 22  |2.168.169.95\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-74tr4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-74tr4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-42-94",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.42.94",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.42.94"
        }
      },
      PodIP: (string) (len=14) "192.168.169.95",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.169.95"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://234c86c472e22451aba3b9c0a32ae6fb743dd1be387da928812068fba57b8d3d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.006: INFO: Pod "webserver-deployment-557759b7c7-5d9vw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5d9vw",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "190082f5-8f00-40cf-b53f-37b6a5ee9e11",
      ResourceVersion: (string) (len=5) "19112",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  39 2e 39 36 5c 22 7d 22  |2.168.169.96\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h4kz6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h4kz6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-42-94",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.42.94",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.42.94"
        }
      },
      PodIP: (string) (len=14) "192.168.169.96",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.169.96"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://1303f370d4f7244646f39e1ddfbd8bc128729b744f390c1fe183d78548797530",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.008: INFO: Pod "webserver-deployment-557759b7c7-6srx6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-6srx6",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "14517291-984b-4df2-90fe-de4887dc6fb5",
      ResourceVersion: (string) (len=5) "19085",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 37 31  2e 32 34 39 5c 22 7d 22  |2.168.71.249\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dvw8m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dvw8m",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.249",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.249"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f6d1ba96504cb7d1c217889e67c930e7096b0ae80c1ee59d8b5f9e1191521f17",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.010: INFO: Pod "webserver-deployment-557759b7c7-7vp7g" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7vp7g",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e7976f4d-99c0-4a74-a446-88e4b801848f",
      ResourceVersion: (string) (len=5) "19096",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  30 2e 32 33 33 5c 22 7d  |2.168.150.233\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fhp8d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fhp8d",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.233",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.233"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://ebd662e175b37d86b0c6dd35dc90f8b64afb5b522a56614b92773c9cdcc57483",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.011: INFO: Pod "webserver-deployment-557759b7c7-9xdwk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-9xdwk",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ecff6615-3b21-4239-89b6-8fa9f04cc26e",
      ResourceVersion: (string) (len=5) "19102",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  30 2e 32 33 31 5c 22 7d  |2.168.150.231\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fdvh7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fdvh7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.231",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.231"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://1fd0f7e7360f22a78ccb81bb780922bb9c0f9d0e3993b0b46ad95ee52da4197f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.012: INFO: Pod "webserver-deployment-557759b7c7-fblzj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-fblzj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f4e79477-be23-4015-96b5-149f2c4e637a",
      ResourceVersion: (string) (len=5) "19088",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 37 31  2e 32 34 38 5c 22 7d 22  |2.168.71.248\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2nwcx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2nwcx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.248",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.248"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://16098738ab7e6c2ac6cd2bdfc9fe340c32a5390160714b73abc20e8d062ef7c2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.013: INFO: Pod "webserver-deployment-557759b7c7-pbdnd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-pbdnd",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7b420c13-33fd-45c3-9f64-2a8f3a0040bd",
      ResourceVersion: (string) (len=5) "19106",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  39 2e 39 37 5c 22 7d 22  |2.168.169.97\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7sngb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7sngb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-42-94",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.42.94",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.42.94"
        }
      },
      PodIP: (string) (len=14) "192.168.169.97",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.169.97"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://fe355d15b22d774a7f64dbf18bd18572624e705095ba385353fdc2e983ecb89b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.018: INFO: Pod "webserver-deployment-557759b7c7-pxs4h" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-pxs4h",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "53c532d0-8b0d-41ee-884e-843af509f89d",
      ResourceVersion: (string) (len=5) "19258",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nmnkf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nmnkf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.019: INFO: Pod "webserver-deployment-557759b7c7-qlr7r" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-qlr7r",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "acd0aaa7-ff7e-43e2-957b-cca23200fdca",
      ResourceVersion: (string) (len=5) "19099",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 37 31  2e 32 35 31 5c 22 7d 22  |2.168.71.251\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d52t5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d52t5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.251",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.251"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843363842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://78bf85560561d60e9bf0d8683e7c9d04b6aac961e5ceb162d1f3cf0e8c0478d3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.021: INFO: Pod "webserver-deployment-557759b7c7-v9s4z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-v9s4z",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "469baf88-e429-4199-951b-d070bd7d1978",
      ResourceVersion: (string) (len=5) "19265",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d5dnw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d5dnw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.022: INFO: Pod "webserver-deployment-557759b7c7-xztpz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xztpz",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c04f5b9b-d959-4da0-a133-b958580ddd97",
      ResourceVersion: (string) (len=5) "19262",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "83257e9a-bb3d-4762-a2d9-38b344c95cad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  32 35 37 65 39 61 2d 62  |d\":\"83257e9a-b|
              00000090  62 33 64 2d 34 37 36 32  2d 61 32 64 39 2d 33 38  |b3d-4762-a2d9-38|
              000000a0  62 33 34 34 63 39 35 63  61 64 5c 22 7d 22 3a 7b  |b344c95cad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-29p98",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-29p98",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.023: INFO: Pod "webserver-deployment-9b4f5bf69-46bvc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-46bvc",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f6f5ea4a-ebb7-485d-95be-3c2f0c6f6283",
      ResourceVersion: (string) (len=5) "19250",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 36 39 2e 39  38 5c 22 7d 22 3a 7b 22  |68.169.98\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zxqwp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zxqwp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-42-94",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.42.94",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.42.94"
        }
      },
      PodIP: (string) (len=14) "192.168.169.98",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.169.98"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.025: INFO: Pod "webserver-deployment-9b4f5bf69-5dcgr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-5dcgr",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2efdb805-7128-4c05-a84f-a1217bddb22b",
      ResourceVersion: (string) (len=5) "19261",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dz67t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dz67t",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  E0212 19:44:06.024524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:06.026: INFO: Pod "webserver-deployment-9b4f5bf69-gsr2r" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-gsr2r",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "648fd39e-bd4a-4576-a0a7-4106042f7d80",
      ResourceVersion: (string) (len=5) "19242",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 37 31 2e 32 35  32 5c 22 7d 22 3a 7b 22  |68.71.252\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-45l26",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-45l26",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.252",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.252"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.028: INFO: Pod "webserver-deployment-9b4f5bf69-nhq7k" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-nhq7k",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "45785b49-7fa6-4395-9c47-4b6205cc7178",
      ResourceVersion: (string) (len=5) "19266",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-b9fz9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-b9fz9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.031: INFO: Pod "webserver-deployment-9b4f5bf69-s7dhn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-s7dhn",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bbaf7223-3d55-4252-a3c6-faf5b72c875f",
      ResourceVersion: (string) (len=5) "19241",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 35 30 2e 32  33 35 5c 22 7d 22 3a 7b  |68.150.235\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6m5r6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6m5r6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.235",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.235"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.032: INFO: Pod "webserver-deployment-9b4f5bf69-wt89g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-wt89g",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ce7004b1-c852-442e-84dd-82ebe5137a2b",
      ResourceVersion: (string) (len=5) "19247",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 35 30 2e 32  33 36 5c 22 7d 22 3a 7b  |68.150.236\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hjp7b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hjp7b",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.236",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.236"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.034: INFO: Pod "webserver-deployment-9b4f5bf69-xwfnb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-xwfnb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e7ca695f-97e7-4268-a1a7-faf5f552d7eb",
      ResourceVersion: (string) (len=5) "19246",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363843,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 37 31 2e 32 35  33 5c 22 7d 22 3a 7b 22  |68.71.253\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z974v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z974v",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363844,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.253",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.253"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363844,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.037: INFO: Pod "webserver-deployment-9b4f5bf69-zbb8n" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-zbb8n",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-6075",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d461754a-1bb7-4fc4-a593-ddaeabcb6522",
      ResourceVersion: (string) (len=5) "19267",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843363845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "a1ab1059-90fa-4826-a2e5-e6f4d485cb75",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843363845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 31  61 62 31 30 35 39 2d 39  |d\":\"a1ab1059-9|
              00000090  30 66 61 2d 34 38 32 36  2d 61 32 65 35 2d 65 36  |0fa-4826-a2e5-e6|
              000000a0  66 34 64 34 38 35 63 62  37 35 5c 22 7d 22 3a 7b  |f4d485cb75\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8fqrz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8fqrz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 19:44:06.042: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6075" for this suite. @ 02/12/24 19:44:06.047
• [4.214 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 02/12/24 19:44:06.055
  Feb 12 19:44:06.055: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 19:44:06.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:44:06.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:44:06.194
  STEP: Creating pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320 @ 02/12/24 19:44:06.198
  E0212 19:44:07.024675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:08.024996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 19:44:08.222
  Feb 12 19:44:08.226: INFO: Initial restart count of pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c is 0
  Feb 12 19:44:08.230: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:09.025841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:10.025997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:10.236: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:11.026646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:12.027627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:12.242: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:13.027732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:14.027972      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:14.248: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:15.028900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:16.029125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:16.252: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:17.029339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:18.029570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:18.258: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:19.029840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:20.030002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:20.263: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:21.030093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:22.030184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:22.269: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:23.030929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:24.031016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:24.275: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:25.031049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:26.032047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:26.279: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:27.032142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:28.032416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:28.284: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:29.032569      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:30.032747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:30.290: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:31.033714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:32.033853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:32.296: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:33.034192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:34.034903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:34.301: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:35.035007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:36.035161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:36.308: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:37.036673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:38.037489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:38.314: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:39.037883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:40.038009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:40.320: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:41.038775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:42.038982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:42.325: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:43.039475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:44.039701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:44.331: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:45.040696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:46.040781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:46.337: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:47.041620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:48.042023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:48.343: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:49.042948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:50.043056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:50.350: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:51.043925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:52.044020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:52.355: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:53.044537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:54.044663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:54.360: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:55.045580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:56.045804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:56.366: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:57.046084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:44:58.046448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:44:58.371: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:44:59.046705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:00.046811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:00.378: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:01.047084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:02.047350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:02.384: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:03.047900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:04.048325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:04.389: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:05.049277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:06.049510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:06.395: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:07.049727      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:08.050110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:08.401: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:09.050936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:10.051136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:10.407: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:11.051250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:12.051465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:12.413: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:13.052153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:14.052247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:14.419: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:15.052741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:16.052982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:16.424: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:17.053100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:18.053609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:18.430: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:19.054152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:20.054274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:20.435: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:21.054949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:22.055174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:22.441: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:23.056175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:24.057246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:24.447: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:25.057353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:26.057560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:26.452: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:27.058428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:28.058851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:28.459: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:29.059830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:30.060060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:30.464: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:31.060092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:32.060188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:32.470: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:33.061024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:34.061187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:34.475: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:35.061325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:36.061600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:36.481: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:37.062594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:38.063569      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:38.487: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:39.064139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:40.064224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:40.492: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:41.064586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:42.064869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:42.498: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:43.065628      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:44.065848      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:44.503: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:45.065946      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:46.066896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:46.509: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:47.067976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:48.068566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:48.515: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:49.068909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:50.069003      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:50.520: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:51.069159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:52.069261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:52.524: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:53.070306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:54.070417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:54.531: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:55.070641      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:56.070842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:56.535: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:57.071023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:45:58.071529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:45:58.541: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:45:59.071585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:00.071673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:00.547: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:01.071789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:02.072325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:02.552: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:03.073165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:04.073361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:04.558: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:05.073528      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:06.073773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:06.564: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:07.074627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:08.075508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:08.570: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:09.076577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:10.077231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:10.577: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:11.077350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:12.077563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:12.582: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:13.078401      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:14.078769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:14.589: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:15.079772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:16.079889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:16.593: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:17.080580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:18.081615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:18.599: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:19.081848      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:20.082909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:20.605: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:21.082982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:22.083059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:22.610: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:23.083573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:24.083959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:24.616: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:25.084664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:26.085872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:26.621: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:27.085962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:28.086441      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:28.626: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:29.087371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:30.087575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:30.633: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:31.088648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:32.088843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:32.638: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:33.089172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:34.089287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:34.643: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:35.090085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:36.090916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:36.649: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:37.090990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:38.091521      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:38.655: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:39.091655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:40.091935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:40.660: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:41.092151      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:42.092611      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:42.666: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:43.093310      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:44.093606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:44.671: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:45.094167      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:46.095104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:46.677: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:47.095723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:48.096523      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:48.682: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:49.097375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:50.097488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:50.688: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:51.097531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:52.097626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:52.695: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:53.098545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:54.099500      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:54.699: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:55.100241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:56.100449      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:56.705: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:57.100665      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:46:58.100901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:46:58.711: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:46:59.101436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:00.101649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:00.716: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:01.101766      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:02.101866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:02.721: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:03.102880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:04.103144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:04.726: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:05.103247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:06.103433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:06.732: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:07.103551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:08.103798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:08.737: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:09.104683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:10.104918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:10.742: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:11.105814      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:12.105912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:12.748: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:13.106779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:14.106877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:14.754: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:15.106971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:16.107615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:16.760: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:17.107711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:18.108677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:18.765: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:19.109643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:20.109836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:20.769: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:21.110411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:22.110493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:22.774: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:23.110598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:24.110944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:24.779: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:25.112133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:26.112247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:26.785: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:27.112949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:28.113010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:28.790: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:29.113728      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:30.113883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:30.796: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:31.114832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:32.115606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:32.802: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:33.116217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:34.116307      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:34.807: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:35.117184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:36.117284      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:36.813: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:37.117803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:38.118147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:38.818: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:39.118422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:40.118620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:40.823: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:41.118637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:42.118826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:42.829: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:43.118908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:44.119241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:44.834: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:45.119706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:46.119800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:46.839: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:47.120097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:48.120491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:48.845: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:49.121042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:50.122000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:50.850: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:51.122924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:52.123045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:52.856: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:53.123436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:54.123718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:54.862: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:55.124721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:56.125285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:56.867: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:57.125761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:47:58.126676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:47:58.873: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:47:59.126766      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:00.126948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:00.878: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:48:01.127721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:02.127894      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:02.883: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:48:03.128356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:04.128624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:04.889: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:48:05.129438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:06.129637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:06.894: INFO: Get pod liveness-96ff15b4-7481-4a27-87ca-8c3ad46e657c in namespace container-probe-320
  E0212 19:48:07.129745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:08.130712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/12/24 19:48:08.894
  Feb 12 19:48:08.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-320" for this suite. @ 02/12/24 19:48:08.914
• [242.866 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 02/12/24 19:48:08.921
  Feb 12 19:48:08.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sysctl @ 02/12/24 19:48:08.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:08.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:08.944
  STEP: Creating a pod with one valid and two invalid sysctls @ 02/12/24 19:48:08.947
  Feb 12 19:48:08.952: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2913" for this suite. @ 02/12/24 19:48:08.956
• [0.041 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 02/12/24 19:48:08.963
  Feb 12 19:48:08.963: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 19:48:08.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:08.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:08.986
  STEP: Creating a test headless service @ 02/12/24 19:48:08.989
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8666.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8666.svc.cluster.local;sleep 1; done
   @ 02/12/24 19:48:08.995
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8666.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8666.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8666.svc.cluster.local;sleep 1; done
   @ 02/12/24 19:48:08.995
  STEP: creating a pod to probe DNS @ 02/12/24 19:48:08.995
  STEP: submitting the pod to kubernetes @ 02/12/24 19:48:08.995
  E0212 19:48:09.131208      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:10.131445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/12/24 19:48:11.019
  STEP: looking for the results for each expected name from probers @ 02/12/24 19:48:11.022
  Feb 12 19:48:11.028: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.033: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.038: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.043: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.048: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.052: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.058: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.063: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8666.svc.cluster.local from pod dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6: the server could not find the requested resource (get pods dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6)
  Feb 12 19:48:11.063: INFO: Lookups using dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8666.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8666.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8666.svc.cluster.local jessie_udp@dns-test-service-2.dns-8666.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8666.svc.cluster.local]

  Feb 12 19:48:11.080: INFO: Pod client logs for webserver: 
  Feb 12 19:48:11.088: INFO: Pod client logs for querier: 
  Feb 12 19:48:11.096: INFO: Pod client logs for jessie-querier: 
  E0212 19:48:11.131558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:12.131718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:13.131819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:14.131904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:15.132160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:16.063: INFO: DNS probes using dns-8666/dns-test-8aa155e7-650a-447e-97b4-f03c2eaf66f6 succeeded

  STEP: deleting the pod @ 02/12/24 19:48:16.063
  STEP: deleting the test headless service @ 02/12/24 19:48:16.077
  Feb 12 19:48:16.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8666" for this suite. @ 02/12/24 19:48:16.094
• [7.139 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 02/12/24 19:48:16.102
  Feb 12 19:48:16.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename disruption @ 02/12/24 19:48:16.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:16.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:16.125
  E0212 19:48:16.132429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 02/12/24 19:48:16.134
  E0212 19:48:17.132643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:18.133607      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 02/12/24 19:48:18.139
  STEP: Waiting for all pods to be running @ 02/12/24 19:48:18.149
  Feb 12 19:48:18.156: INFO: running pods: 0 < 1
  E0212 19:48:19.133920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:20.134885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 02/12/24 19:48:20.155
  STEP: Waiting for the pdb to be processed @ 02/12/24 19:48:20.171
  STEP: Patching PodDisruptionBudget status @ 02/12/24 19:48:20.18
  STEP: Waiting for the pdb to be processed @ 02/12/24 19:48:20.189
  Feb 12 19:48:20.194: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3652" for this suite. @ 02/12/24 19:48:20.199
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 02/12/24 19:48:20.207
  Feb 12 19:48:20.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-runtime @ 02/12/24 19:48:20.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:20.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:20.231
  STEP: create the container @ 02/12/24 19:48:20.234
  W0212 19:48:20.241900      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 02/12/24 19:48:20.242
  E0212 19:48:21.135943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:22.136034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/12/24 19:48:22.255
  STEP: the container should be terminated @ 02/12/24 19:48:22.26
  STEP: the termination message should be set @ 02/12/24 19:48:22.26
  Feb 12 19:48:22.260: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 02/12/24 19:48:22.26
  Feb 12 19:48:22.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1390" for this suite. @ 02/12/24 19:48:22.279
• [2.079 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 02/12/24 19:48:22.286
  Feb 12 19:48:22.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replicaset @ 02/12/24 19:48:22.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:22.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:22.305
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 02/12/24 19:48:22.308
  Feb 12 19:48:22.320: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0212 19:48:23.136129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:24.136381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:25.136533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:26.136641      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:27.137161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:27.325: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/12/24 19:48:27.325
  STEP: getting scale subresource @ 02/12/24 19:48:27.325
  STEP: updating a scale subresource @ 02/12/24 19:48:27.331
  STEP: verifying the replicaset Spec.Replicas was modified @ 02/12/24 19:48:27.337
  STEP: Patch a scale subresource @ 02/12/24 19:48:27.341
  Feb 12 19:48:27.353: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-263" for this suite. @ 02/12/24 19:48:27.356
• [5.081 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 02/12/24 19:48:27.367
  Feb 12 19:48:27.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 19:48:27.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:27.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:27.391
  Feb 12 19:48:27.416: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/12/24 19:48:27.423
  Feb 12 19:48:27.427: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:27.427: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:27.431: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:48:27.431: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 19:48:28.137448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:28.428: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:28.428: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:28.432: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:48:28.432: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 19:48:29.137846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:29.429: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:29.429: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:29.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:48:29.433: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 02/12/24 19:48:29.45
  STEP: Check that daemon pods images are updated. @ 02/12/24 19:48:29.461
  Feb 12 19:48:29.464: INFO: Wrong image for pod: daemon-set-29q2z. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:29.464: INFO: Wrong image for pod: daemon-set-r7jlc. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:29.464: INFO: Wrong image for pod: daemon-set-vzxjr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:29.470: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:29.470: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0212 19:48:30.138038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:30.466: INFO: Wrong image for pod: daemon-set-29q2z. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:30.466: INFO: Pod daemon-set-k9q2t is not available
  Feb 12 19:48:30.466: INFO: Wrong image for pod: daemon-set-vzxjr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:30.470: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:30.470: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0212 19:48:31.139049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:31.470: INFO: Wrong image for pod: daemon-set-vzxjr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:31.470: INFO: Pod daemon-set-xvtjh is not available
  Feb 12 19:48:31.474: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:31.474: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0212 19:48:32.139325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:32.466: INFO: Wrong image for pod: daemon-set-vzxjr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb 12 19:48:32.466: INFO: Pod daemon-set-xvtjh is not available
  Feb 12 19:48:32.470: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:32.470: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0212 19:48:33.140294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:33.466: INFO: Pod daemon-set-qgszx is not available
  Feb 12 19:48:33.470: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:33.470: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 02/12/24 19:48:33.47
  Feb 12 19:48:33.475: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:33.475: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:33.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb 12 19:48:33.479: INFO: Node ip-172-31-91-42 is running 0 daemon pod, expected 1
  E0212 19:48:34.140411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:34.475: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:34.475: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:48:34.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:48:34.480: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 02/12/24 19:48:34.499
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1495, will wait for the garbage collector to delete the pods @ 02/12/24 19:48:34.499
  Feb 12 19:48:34.564: INFO: Deleting DaemonSet.extensions daemon-set took: 10.773114ms
  Feb 12 19:48:34.664: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.286084ms
  E0212 19:48:35.141351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:48:36.069: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:48:36.069: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb 12 19:48:36.072: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20587"},"items":null}

  Feb 12 19:48:36.075: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20587"},"items":null}

  Feb 12 19:48:36.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1495" for this suite. @ 02/12/24 19:48:36.094
• [8.734 seconds]
------------------------------
SSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 02/12/24 19:48:36.102
  Feb 12 19:48:36.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:48:36.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:36.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:36.123
  STEP: Creating a pod to test downward api env vars @ 02/12/24 19:48:36.125
  E0212 19:48:36.141757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:37.141904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:38.142301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:48:38.145
  Feb 12 19:48:38.149: INFO: Trying to get logs from node ip-172-31-5-108 pod downward-api-51025e1f-e58c-4d51-8c2b-488ea12fe95f container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:48:38.158
  Feb 12 19:48:38.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5823" for this suite. @ 02/12/24 19:48:38.178
• [2.085 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 02/12/24 19:48:38.187
  Feb 12 19:48:38.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/12/24 19:48:38.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:38.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:38.206
  STEP: create the container to handle the HTTPGet hook request. @ 02/12/24 19:48:38.213
  E0212 19:48:39.142451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:40.142558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/12/24 19:48:40.235
  E0212 19:48:41.142783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:42.143147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 02/12/24 19:48:42.256
  E0212 19:48:43.143342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:44.144113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 02/12/24 19:48:44.273
  Feb 12 19:48:44.292: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8676" for this suite. @ 02/12/24 19:48:44.296
• [6.117 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 02/12/24 19:48:44.304
  Feb 12 19:48:44.304: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 19:48:44.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:44.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:44.327
  STEP: Creating secret with name secret-test-129ec175-8b6e-4551-90be-f618a35a6db4 @ 02/12/24 19:48:44.33
  STEP: Creating a pod to test consume secrets @ 02/12/24 19:48:44.335
  E0212 19:48:45.144314      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:46.145270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:48:46.355
  Feb 12 19:48:46.360: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-50219f07-27b7-470b-bf22-0f3eeb6eb734 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 19:48:46.367
  Feb 12 19:48:46.384: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1155" for this suite. @ 02/12/24 19:48:46.389
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 02/12/24 19:48:46.398
  Feb 12 19:48:46.398: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pod-network-test @ 02/12/24 19:48:46.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:48:46.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:48:46.42
  STEP: Performing setup for networking test in namespace pod-network-test-2366 @ 02/12/24 19:48:46.423
  STEP: creating a selector @ 02/12/24 19:48:46.423
  STEP: Creating the service pods in kubernetes @ 02/12/24 19:48:46.423
  Feb 12 19:48:46.423: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0212 19:48:47.145400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:48.145548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:49.145958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:50.146031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:51.146133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:52.146209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:53.146996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:54.147124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:55.148150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:56.148251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:57.148417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:58.149027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:48:59.149985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:00.150152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:01.150263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:02.150374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:03.150476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:04.150547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:05.150986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:06.151072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:07.151978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:08.152674      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/12/24 19:49:08.542
  E0212 19:49:09.153231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:10.153332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:10.579: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Feb 12 19:49:10.579: INFO: Going to poll 192.168.169.102 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Feb 12 19:49:10.582: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.169.102:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:10.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:10.582: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:10.582: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.169.102%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb 12 19:49:10.642: INFO: Found all 1 expected endpoints: [netserver-0]
  Feb 12 19:49:10.642: INFO: Going to poll 192.168.150.245 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Feb 12 19:49:10.647: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.150.245:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:10.647: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:10.647: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:10.647: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.150.245%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb 12 19:49:10.696: INFO: Found all 1 expected endpoints: [netserver-1]
  Feb 12 19:49:10.696: INFO: Going to poll 192.168.71.196 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Feb 12 19:49:10.700: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.71.196:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:10.700: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:10.701: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:10.701: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.71.196%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb 12 19:49:10.749: INFO: Found all 1 expected endpoints: [netserver-2]
  Feb 12 19:49:10.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2366" for this suite. @ 02/12/24 19:49:10.754
• [24.366 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 02/12/24 19:49:10.764
  Feb 12 19:49:10.764: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:49:10.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:10.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:10.793
  STEP: Creating projection with secret that has name projected-secret-test-fe7ec7f1-45d4-4cc8-a993-030185e8acce @ 02/12/24 19:49:10.796
  STEP: Creating a pod to test consume secrets @ 02/12/24 19:49:10.802
  E0212 19:49:11.153477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:12.153753      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:13.154179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:14.154257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:49:14.83
  Feb 12 19:49:14.833: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-projected-secrets-97f7782c-1ea3-4a0b-a818-767da7b91fe4 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 19:49:14.852
  Feb 12 19:49:14.870: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5734" for this suite. @ 02/12/24 19:49:14.875
• [4.120 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 02/12/24 19:49:14.884
  Feb 12 19:49:14.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 02/12/24 19:49:14.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:14.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:14.907
  STEP: creating a target pod @ 02/12/24 19:49:14.913
  E0212 19:49:15.154880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:16.154972      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 02/12/24 19:49:16.935
  E0212 19:49:17.155934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:18.156688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 02/12/24 19:49:18.956
  Feb 12 19:49:18.956: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-41 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:18.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:18.956: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:18.956: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-41/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Feb 12 19:49:19.006: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 02/12/24 19:49:19.016
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 02/12/24 19:49:19.02
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 02/12/24 19:49:19.033
  Feb 12 19:49:19.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-41" for this suite. @ 02/12/24 19:49:19.042
• [4.168 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 02/12/24 19:49:19.052
  Feb 12 19:49:19.052: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename proxy @ 02/12/24 19:49:19.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:19.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:19.072
  Feb 12 19:49:19.076: INFO: Creating pod...
  E0212 19:49:19.157411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:20.157517      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:21.097: INFO: Creating service...
  Feb 12 19:49:21.107: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=DELETE
  Feb 12 19:49:21.114: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb 12 19:49:21.114: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=OPTIONS
  Feb 12 19:49:21.118: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb 12 19:49:21.118: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=PATCH
  Feb 12 19:49:21.121: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb 12 19:49:21.122: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=POST
  Feb 12 19:49:21.126: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb 12 19:49:21.126: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=PUT
  Feb 12 19:49:21.130: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb 12 19:49:21.131: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=DELETE
  Feb 12 19:49:21.136: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb 12 19:49:21.136: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Feb 12 19:49:21.149: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb 12 19:49:21.149: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=PATCH
  Feb 12 19:49:21.157: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb 12 19:49:21.157: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=POST
  E0212 19:49:21.158121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:21.163: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb 12 19:49:21.163: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=PUT
  Feb 12 19:49:21.170: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb 12 19:49:21.170: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=GET
  Feb 12 19:49:21.174: INFO: http.Client request:GET StatusCode:301
  Feb 12 19:49:21.174: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=GET
  Feb 12 19:49:21.178: INFO: http.Client request:GET StatusCode:301
  Feb 12 19:49:21.178: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/pods/agnhost/proxy?method=HEAD
  Feb 12 19:49:21.182: INFO: http.Client request:HEAD StatusCode:301
  Feb 12 19:49:21.182: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3721/services/e2e-proxy-test-service/proxy?method=HEAD
  Feb 12 19:49:21.187: INFO: http.Client request:HEAD StatusCode:301
  Feb 12 19:49:21.187: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3721" for this suite. @ 02/12/24 19:49:21.19
• [2.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 02/12/24 19:49:21.199
  Feb 12 19:49:21.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:49:21.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:21.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:21.219
  STEP: Creating a pod to test downward api env vars @ 02/12/24 19:49:21.222
  E0212 19:49:22.158930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:23.159144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:49:23.24
  Feb 12 19:49:23.244: INFO: Trying to get logs from node ip-172-31-5-108 pod downward-api-33861e1c-e5bd-410a-9143-41f2b0fce55b container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:49:23.252
  Feb 12 19:49:23.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8518" for this suite. @ 02/12/24 19:49:23.273
• [2.081 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 02/12/24 19:49:23.281
  Feb 12 19:49:23.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pod-network-test @ 02/12/24 19:49:23.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:23.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:23.302
  STEP: Performing setup for networking test in namespace pod-network-test-335 @ 02/12/24 19:49:23.305
  STEP: creating a selector @ 02/12/24 19:49:23.305
  STEP: Creating the service pods in kubernetes @ 02/12/24 19:49:23.305
  Feb 12 19:49:23.305: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0212 19:49:24.160067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:25.160338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:26.160928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:27.161138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:28.161270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:29.161354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:30.161445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:31.161544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:32.161855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:33.161953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:34.162067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:35.162161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/12/24 19:49:35.391
  E0212 19:49:36.162923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:37.163035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:37.410: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Feb 12 19:49:37.410: INFO: Breadth first check of 192.168.169.103 on host 172.31.42.94...
  Feb 12 19:49:37.415: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.249:9080/dial?request=hostname&protocol=udp&host=192.168.169.103&port=8081&tries=1'] Namespace:pod-network-test-335 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:37.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:37.416: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:37.416: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-335/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.150.249%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.169.103%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb 12 19:49:37.465: INFO: Waiting for responses: map[]
  Feb 12 19:49:37.465: INFO: reached 192.168.169.103 after 0/1 tries
  Feb 12 19:49:37.465: INFO: Breadth first check of 192.168.150.248 on host 172.31.5.108...
  Feb 12 19:49:37.469: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.249:9080/dial?request=hostname&protocol=udp&host=192.168.150.248&port=8081&tries=1'] Namespace:pod-network-test-335 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:37.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:37.470: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:37.470: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-335/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.150.249%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.150.248%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb 12 19:49:37.515: INFO: Waiting for responses: map[]
  Feb 12 19:49:37.515: INFO: reached 192.168.150.248 after 0/1 tries
  Feb 12 19:49:37.515: INFO: Breadth first check of 192.168.71.199 on host 172.31.91.42...
  Feb 12 19:49:37.521: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.249:9080/dial?request=hostname&protocol=udp&host=192.168.71.199&port=8081&tries=1'] Namespace:pod-network-test-335 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 19:49:37.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 19:49:37.521: INFO: ExecWithOptions: Clientset creation
  Feb 12 19:49:37.521: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-335/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.150.249%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.71.199%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb 12 19:49:37.581: INFO: Waiting for responses: map[]
  Feb 12 19:49:37.581: INFO: reached 192.168.71.199 after 0/1 tries
  Feb 12 19:49:37.581: INFO: Going to retry 0 out of 3 pods....
  Feb 12 19:49:37.581: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-335" for this suite. @ 02/12/24 19:49:37.585
• [14.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 02/12/24 19:49:37.594
  Feb 12 19:49:37.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename security-context-test @ 02/12/24 19:49:37.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:37.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:37.614
  E0212 19:49:38.163187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:39.163286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:40.163490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:41.164519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:41.651: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4097" for this suite. @ 02/12/24 19:49:41.657
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 02/12/24 19:49:41.664
  Feb 12 19:49:41.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 19:49:41.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:41.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:41.686
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 02/12/24 19:49:41.689
  Feb 12 19:49:41.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 19:49:42.165228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:43.165384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:44.165580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:45.166093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:46.166132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 02/12/24 19:49:46.701
  Feb 12 19:49:46.702: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 19:49:47.166874      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:47.909: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 19:49:48.167736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:49.168237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:50.168523      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:51.168751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:52.168782      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:52.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5476" for this suite. @ 02/12/24 19:49:52.854
• [11.197 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 02/12/24 19:49:52.861
  Feb 12 19:49:52.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 19:49:52.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:52.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:52.883
  STEP: creating a Deployment @ 02/12/24 19:49:52.889
  STEP: waiting for Deployment to be created @ 02/12/24 19:49:52.896
  STEP: waiting for all Replicas to be Ready @ 02/12/24 19:49:52.898
  Feb 12 19:49:52.899: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.899: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.913: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.913: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.928: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.928: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.953: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb 12 19:49:52.953: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0212 19:49:53.169353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:54.124: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Feb 12 19:49:54.124: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Feb 12 19:49:54.166: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 02/12/24 19:49:54.166
  E0212 19:49:54.169978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:54.176: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 02/12/24 19:49:54.176
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 0
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.178: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.187: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.187: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.205: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.205: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:54.221: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:54.221: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:54.227: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:54.227: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:55.143: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:55.143: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:55.166: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  STEP: listing Deployments @ 02/12/24 19:49:55.166
  E0212 19:49:55.170107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:55.170: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 02/12/24 19:49:55.17
  Feb 12 19:49:55.182: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 02/12/24 19:49:55.182
  Feb 12 19:49:55.188: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb 12 19:49:55.192: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb 12 19:49:55.222: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb 12 19:49:55.240: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb 12 19:49:55.253: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb 12 19:49:56.164: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0212 19:49:56.170374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:56.189: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Feb 12 19:49:56.206: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0212 19:49:57.171165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:49:57.197: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 02/12/24 19:49:57.218
  STEP: fetching the DeploymentStatus @ 02/12/24 19:49:57.226
  Feb 12 19:49:57.232: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:57.232: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 1
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 2
  Feb 12 19:49:57.233: INFO: observed Deployment test-deployment in namespace deployment-4286 with ReadyReplicas 3
  STEP: deleting the Deployment @ 02/12/24 19:49:57.233
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.244: INFO: observed event type MODIFIED
  Feb 12 19:49:57.250: INFO: Log out all the ReplicaSets if there is no deployment created
  Feb 12 19:49:57.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4286" for this suite. @ 02/12/24 19:49:57.26
• [4.409 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 02/12/24 19:49:57.27
  Feb 12 19:49:57.270: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:49:57.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:57.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:57.29
  STEP: Creating configMap with name projected-configmap-test-volume-map-3bd1daf5-f479-4141-abca-20a7dff8fea0 @ 02/12/24 19:49:57.293
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:49:57.299
  E0212 19:49:58.171591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:49:59.171713      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:49:59.319
  Feb 12 19:49:59.322: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-configmaps-f2ee1a82-a917-4847-ad9d-45f5f910bd4c container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:49:59.331
  Feb 12 19:49:59.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5628" for this suite. @ 02/12/24 19:49:59.354
• [2.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 02/12/24 19:49:59.362
  Feb 12 19:49:59.362: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename containers @ 02/12/24 19:49:59.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:49:59.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:49:59.384
  E0212 19:50:00.171864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:01.172453      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:01.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5616" for this suite. @ 02/12/24 19:50:01.416
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 02/12/24 19:50:01.426
  Feb 12 19:50:01.426: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replication-controller @ 02/12/24 19:50:01.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:01.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:01.445
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 02/12/24 19:50:01.451
  E0212 19:50:02.172559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:03.172701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 02/12/24 19:50:03.474
  STEP: Then the orphan pod is adopted @ 02/12/24 19:50:03.48
  E0212 19:50:04.173554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:04.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5287" for this suite. @ 02/12/24 19:50:04.492
• [3.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 02/12/24 19:50:04.499
  Feb 12 19:50:04.499: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename namespaces @ 02/12/24 19:50:04.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:04.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:04.52
  STEP: Read namespace status @ 02/12/24 19:50:04.523
  Feb 12 19:50:04.526: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 02/12/24 19:50:04.526
  Feb 12 19:50:04.533: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 02/12/24 19:50:04.533
  Feb 12 19:50:04.541: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Feb 12 19:50:04.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5469" for this suite. @ 02/12/24 19:50:04.545
• [0.054 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 02/12/24 19:50:04.553
  Feb 12 19:50:04.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:50:04.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:04.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:04.574
  STEP: Setting up server cert @ 02/12/24 19:50:04.597
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:50:04.747
  STEP: Deploying the webhook pod @ 02/12/24 19:50:04.757
  STEP: Wait for the deployment to be ready @ 02/12/24 19:50:04.771
  Feb 12 19:50:04.779: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 19:50:05.173853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:06.175842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 19:50:06.791
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:50:06.801
  E0212 19:50:07.176007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:07.802: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 02/12/24 19:50:07.812
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 02/12/24 19:50:07.83
  STEP: Creating a configMap that should not be mutated @ 02/12/24 19:50:07.838
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 02/12/24 19:50:07.85
  STEP: Creating a configMap that should be mutated @ 02/12/24 19:50:07.857
  Feb 12 19:50:07.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6391" for this suite. @ 02/12/24 19:50:07.927
  STEP: Destroying namespace "webhook-markers-7381" for this suite. @ 02/12/24 19:50:07.94
• [3.393 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 02/12/24 19:50:07.946
  Feb 12 19:50:07.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replication-controller @ 02/12/24 19:50:07.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:07.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:07.967
  Feb 12 19:50:07.970: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0212 19:50:08.176472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 02/12/24 19:50:08.985
  STEP: Checking rc "condition-test" has the desired failure condition set @ 02/12/24 19:50:08.99
  E0212 19:50:09.177212      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 02/12/24 19:50:09.999
  Feb 12 19:50:10.011: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 02/12/24 19:50:10.011
  E0212 19:50:10.177929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:11.020: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-80" for this suite. @ 02/12/24 19:50:11.023
• [3.086 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 02/12/24 19:50:11.033
  Feb 12 19:50:11.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replicaset @ 02/12/24 19:50:11.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:11.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:11.056
  Feb 12 19:50:11.074: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0212 19:50:11.178535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:12.178573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:13.178663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:14.179050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:15.179134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:16.080: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/12/24 19:50:16.08
  STEP: Scaling up "test-rs" replicaset @ 02/12/24 19:50:16.081
  Feb 12 19:50:16.093: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 02/12/24 19:50:16.093
  Feb 12 19:50:16.103: INFO: observed ReplicaSet test-rs in namespace replicaset-8757 with ReadyReplicas 1, AvailableReplicas 1
  Feb 12 19:50:16.117: INFO: observed ReplicaSet test-rs in namespace replicaset-8757 with ReadyReplicas 1, AvailableReplicas 1
  Feb 12 19:50:16.141: INFO: observed ReplicaSet test-rs in namespace replicaset-8757 with ReadyReplicas 1, AvailableReplicas 1
  Feb 12 19:50:16.147: INFO: observed ReplicaSet test-rs in namespace replicaset-8757 with ReadyReplicas 1, AvailableReplicas 1
  E0212 19:50:16.179175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:17.179444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:17.222: INFO: observed ReplicaSet test-rs in namespace replicaset-8757 with ReadyReplicas 2, AvailableReplicas 2
  Feb 12 19:50:17.353: INFO: observed Replicaset test-rs in namespace replicaset-8757 with ReadyReplicas 3 found true
  Feb 12 19:50:17.353: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8757" for this suite. @ 02/12/24 19:50:17.358
• [6.333 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 02/12/24 19:50:17.366
  Feb 12 19:50:17.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:50:17.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:17.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:17.386
  STEP: Creating configMap with name projected-configmap-test-volume-51ae83ea-6398-4c01-8ccb-505d3bd844da @ 02/12/24 19:50:17.389
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:50:17.393
  E0212 19:50:18.179666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:19.179772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:50:19.414
  Feb 12 19:50:19.417: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-configmaps-c563770f-136e-430a-8d04-d5bf801b2778 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:50:19.425
  Feb 12 19:50:19.444: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6931" for this suite. @ 02/12/24 19:50:19.448
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 02/12/24 19:50:19.456
  Feb 12 19:50:19.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:50:19.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:19.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:19.485
  STEP: creating service in namespace services-6288 @ 02/12/24 19:50:19.488
  STEP: creating service affinity-clusterip in namespace services-6288 @ 02/12/24 19:50:19.488
  STEP: creating replication controller affinity-clusterip in namespace services-6288 @ 02/12/24 19:50:19.5
  I0212 19:50:19.508943      20 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-6288, replica count: 3
  E0212 19:50:20.180601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:21.180682      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:22.180875      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 19:50:22.559408      20 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 19:50:22.569: INFO: Creating new exec pod
  E0212 19:50:23.181593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:24.181856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:25.181950      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:25.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6288 exec execpod-affinity4pddt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Feb 12 19:50:25.673: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Feb 12 19:50:25.673: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:50:25.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6288 exec execpod-affinity4pddt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.22 80'
  Feb 12 19:50:25.759: INFO: stderr: "+ nc -v -t -w 2 10.152.183.22 80\n+ echo hostName\nConnection to 10.152.183.22 80 port [tcp/http] succeeded!\n"
  Feb 12 19:50:25.759: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 19:50:25.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6288 exec execpod-affinity4pddt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.22:80/ ; done'
  Feb 12 19:50:25.895: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.22:80/\n"
  Feb 12 19:50:25.895: INFO: stdout: "\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv\naffinity-clusterip-cgvnv"
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Received response from host: affinity-clusterip-cgvnv
  Feb 12 19:50:25.895: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-6288, will wait for the garbage collector to delete the pods @ 02/12/24 19:50:25.908
  Feb 12 19:50:25.970: INFO: Deleting ReplicationController affinity-clusterip took: 8.796321ms
  Feb 12 19:50:26.071: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.83728ms
  E0212 19:50:26.182640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:27.182817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:28.183871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:29.184701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:29.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6288" for this suite. @ 02/12/24 19:50:29.293
• [9.844 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 02/12/24 19:50:29.301
  Feb 12 19:50:29.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 19:50:29.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:29.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:29.32
  STEP: Setting up server cert @ 02/12/24 19:50:29.348
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 19:50:29.485
  STEP: Deploying the webhook pod @ 02/12/24 19:50:29.492
  STEP: Wait for the deployment to be ready @ 02/12/24 19:50:29.505
  Feb 12 19:50:29.513: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 19:50:30.185773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:31.185868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 19:50:31.528
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 19:50:31.539
  E0212 19:50:32.186016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:50:32.540: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 02/12/24 19:50:32.55
  STEP: create a configmap that should be updated by the webhook @ 02/12/24 19:50:32.566
  Feb 12 19:50:32.633: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-555" for this suite. @ 02/12/24 19:50:32.637
  STEP: Destroying namespace "webhook-markers-7455" for this suite. @ 02/12/24 19:50:32.644
• [3.351 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 02/12/24 19:50:32.652
  Feb 12 19:50:32.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:50:32.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:32.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:32.672
  STEP: starting the proxy server @ 02/12/24 19:50:32.676
  Feb 12 19:50:32.676: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6293 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 02/12/24 19:50:32.706
  Feb 12 19:50:32.712: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6293" for this suite. @ 02/12/24 19:50:32.716
• [0.073 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 02/12/24 19:50:32.724
  Feb 12 19:50:32.724: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:50:32.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:32.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:32.744
  STEP: creating the pod @ 02/12/24 19:50:32.747
  Feb 12 19:50:32.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 create -f -'
  Feb 12 19:50:32.829: INFO: stderr: ""
  Feb 12 19:50:32.829: INFO: stdout: "pod/pause created\n"
  E0212 19:50:33.186097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:34.186901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 02/12/24 19:50:34.839
  Feb 12 19:50:34.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 label pods pause testing-label=testing-label-value'
  Feb 12 19:50:34.889: INFO: stderr: ""
  Feb 12 19:50:34.889: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 02/12/24 19:50:34.889
  Feb 12 19:50:34.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 get pod pause -L testing-label'
  Feb 12 19:50:34.932: INFO: stderr: ""
  Feb 12 19:50:34.933: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 02/12/24 19:50:34.933
  Feb 12 19:50:34.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 label pods pause testing-label-'
  Feb 12 19:50:34.982: INFO: stderr: ""
  Feb 12 19:50:34.982: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 02/12/24 19:50:34.982
  Feb 12 19:50:34.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 get pod pause -L testing-label'
  Feb 12 19:50:35.024: INFO: stderr: ""
  Feb 12 19:50:35.024: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 02/12/24 19:50:35.024
  Feb 12 19:50:35.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 delete --grace-period=0 --force -f -'
  Feb 12 19:50:35.087: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 19:50:35.087: INFO: stdout: "pod \"pause\" force deleted\n"
  Feb 12 19:50:35.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 get rc,svc -l name=pause --no-headers'
  Feb 12 19:50:35.136: INFO: stderr: "No resources found in kubectl-2449 namespace.\n"
  Feb 12 19:50:35.136: INFO: stdout: ""
  Feb 12 19:50:35.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-2449 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Feb 12 19:50:35.182: INFO: stderr: ""
  Feb 12 19:50:35.182: INFO: stdout: ""
  Feb 12 19:50:35.182: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2449" for this suite. @ 02/12/24 19:50:35.186
  E0212 19:50:35.186996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.469 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 02/12/24 19:50:35.193
  Feb 12 19:50:35.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 19:50:35.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:35.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:35.212
  STEP: Creating ServiceAccount "e2e-sa-s69cw"  @ 02/12/24 19:50:35.215
  Feb 12 19:50:35.220: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-s69cw"  @ 02/12/24 19:50:35.22
  Feb 12 19:50:35.229: INFO: AutomountServiceAccountToken: true
  Feb 12 19:50:35.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4001" for this suite. @ 02/12/24 19:50:35.234
• [0.049 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 02/12/24 19:50:35.243
  Feb 12 19:50:35.243: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename job @ 02/12/24 19:50:35.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:35.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:35.262
  STEP: Creating a suspended job @ 02/12/24 19:50:35.269
  STEP: Patching the Job @ 02/12/24 19:50:35.274
  STEP: Watching for Job to be patched @ 02/12/24 19:50:35.288
  Feb 12 19:50:35.290: INFO: Event ADDED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm] and annotations: map[]
  Feb 12 19:50:35.290: INFO: Event MODIFIED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm] and annotations: map[]
  Feb 12 19:50:35.290: INFO: Event MODIFIED found for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[]
  STEP: Updating the job @ 02/12/24 19:50:35.29
  STEP: Watching for Job to be updated @ 02/12/24 19:50:35.299
  Feb 12 19:50:35.300: INFO: Event MODIFIED found for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  Feb 12 19:50:35.300: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 02/12/24 19:50:35.3
  Feb 12 19:50:35.319: INFO: Job: e2e-qzjgm as labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched]
  STEP: Waiting for job to complete @ 02/12/24 19:50:35.319
  E0212 19:50:36.188092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:37.188221      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:38.188616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:39.188724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:40.189297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:41.189391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:42.189486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:43.189659      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 02/12/24 19:50:43.325
  STEP: Watching for Job to be deleted @ 02/12/24 19:50:43.335
  Feb 12 19:50:43.336: INFO: Event MODIFIED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  Feb 12 19:50:43.336: INFO: Event MODIFIED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  Feb 12 19:50:43.336: INFO: Event MODIFIED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  Feb 12 19:50:43.336: INFO: Event MODIFIED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  Feb 12 19:50:43.337: INFO: Event MODIFIED observed for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  Feb 12 19:50:43.337: INFO: Event DELETED found for Job e2e-qzjgm in namespace job-4257 with labels: map[e2e-job-label:e2e-qzjgm e2e-qzjgm:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 02/12/24 19:50:43.337
  Feb 12 19:50:43.340: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4257" for this suite. @ 02/12/24 19:50:43.352
• [8.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 02/12/24 19:50:43.366
  Feb 12 19:50:43.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 19:50:43.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:43.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:43.384
  STEP: Creating configMap with name configmap-test-volume-d401a0ad-8ee1-44da-8a6f-2ae0162092ad @ 02/12/24 19:50:43.387
  STEP: Creating a pod to test consume configMaps @ 02/12/24 19:50:43.393
  E0212 19:50:44.189877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:45.189964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:50:45.413
  Feb 12 19:50:45.417: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-ea8a43ff-f437-48a5-928d-589f9cf10990 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 19:50:45.424
  Feb 12 19:50:45.439: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8935" for this suite. @ 02/12/24 19:50:45.443
• [2.086 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 02/12/24 19:50:45.452
  Feb 12 19:50:45.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename disruption @ 02/12/24 19:50:45.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:45.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:45.481
  STEP: creating the pdb @ 02/12/24 19:50:45.485
  STEP: Waiting for the pdb to be processed @ 02/12/24 19:50:45.489
  STEP: updating the pdb @ 02/12/24 19:50:45.494
  STEP: Waiting for the pdb to be processed @ 02/12/24 19:50:45.502
  STEP: patching the pdb @ 02/12/24 19:50:45.508
  STEP: Waiting for the pdb to be processed @ 02/12/24 19:50:45.515
  STEP: Waiting for the pdb to be deleted @ 02/12/24 19:50:45.526
  Feb 12 19:50:45.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9423" for this suite. @ 02/12/24 19:50:45.533
• [0.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 02/12/24 19:50:45.542
  Feb 12 19:50:45.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename endpointslice @ 02/12/24 19:50:45.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:45.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:45.56
  Feb 12 19:50:45.573: INFO: Endpoints addresses: [172.31.35.5 172.31.5.243] , ports: [6443]
  Feb 12 19:50:45.573: INFO: EndpointSlices addresses: [172.31.35.5 172.31.5.243] , ports: [6443]
  Feb 12 19:50:45.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7163" for this suite. @ 02/12/24 19:50:45.576
• [0.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 02/12/24 19:50:45.584
  Feb 12 19:50:45.584: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename subpath @ 02/12/24 19:50:45.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:50:45.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:50:45.602
  STEP: Setting up data @ 02/12/24 19:50:45.605
  STEP: Creating pod pod-subpath-test-configmap-znp5 @ 02/12/24 19:50:45.615
  STEP: Creating a pod to test atomic-volume-subpath @ 02/12/24 19:50:45.616
  E0212 19:50:46.190066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:47.190912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:48.191383      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:49.191496      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:50.191595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:51.191927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:52.192063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:53.192163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:54.193140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:55.193337      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:56.193599      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:57.193841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:58.194276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:50:59.194406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:00.195033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:01.195109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:02.195513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:03.195613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:04.196616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:05.197003      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:06.197904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:07.198007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:51:07.693
  Feb 12 19:51:07.697: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-subpath-test-configmap-znp5 container test-container-subpath-configmap-znp5: <nil>
  STEP: delete the pod @ 02/12/24 19:51:07.706
  STEP: Deleting pod pod-subpath-test-configmap-znp5 @ 02/12/24 19:51:07.724
  Feb 12 19:51:07.724: INFO: Deleting pod "pod-subpath-test-configmap-znp5" in namespace "subpath-4488"
  Feb 12 19:51:07.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4488" for this suite. @ 02/12/24 19:51:07.733
• [22.157 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 02/12/24 19:51:07.74
  Feb 12 19:51:07.740: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/12/24 19:51:07.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:07.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:07.762
  STEP: create the container to handle the HTTPGet hook request. @ 02/12/24 19:51:07.769
  E0212 19:51:08.198690      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:09.198775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/12/24 19:51:09.794
  E0212 19:51:10.199452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:11.199566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 02/12/24 19:51:11.819
  STEP: delete the pod with lifecycle hook @ 02/12/24 19:51:11.834
  E0212 19:51:12.200048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:13.200381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:13.854: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5607" for this suite. @ 02/12/24 19:51:13.859
• [6.126 seconds]
------------------------------
SSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 02/12/24 19:51:13.866
  Feb 12 19:51:13.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename certificates @ 02/12/24 19:51:13.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:13.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:13.89
  STEP: getting /apis @ 02/12/24 19:51:14.185
  STEP: getting /apis/certificates.k8s.io @ 02/12/24 19:51:14.189
  STEP: getting /apis/certificates.k8s.io/v1 @ 02/12/24 19:51:14.19
  STEP: creating @ 02/12/24 19:51:14.192
  E0212 19:51:14.200925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting @ 02/12/24 19:51:14.211
  STEP: listing @ 02/12/24 19:51:14.215
  STEP: watching @ 02/12/24 19:51:14.218
  Feb 12 19:51:14.218: INFO: starting watch
  STEP: patching @ 02/12/24 19:51:14.219
  STEP: updating @ 02/12/24 19:51:14.226
  Feb 12 19:51:14.231: INFO: waiting for watch events with expected annotations
  Feb 12 19:51:14.231: INFO: saw patched and updated annotations
  STEP: getting /approval @ 02/12/24 19:51:14.231
  STEP: patching /approval @ 02/12/24 19:51:14.234
  STEP: updating /approval @ 02/12/24 19:51:14.241
  STEP: getting /status @ 02/12/24 19:51:14.247
  STEP: patching /status @ 02/12/24 19:51:14.25
  STEP: updating /status @ 02/12/24 19:51:14.258
  STEP: deleting @ 02/12/24 19:51:14.265
  STEP: deleting a collection @ 02/12/24 19:51:14.279
  Feb 12 19:51:14.296: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-7787" for this suite. @ 02/12/24 19:51:14.3
• [0.440 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 02/12/24 19:51:14.307
  Feb 12 19:51:14.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:51:14.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:14.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:14.328
  STEP: Creating a pod to test downward api env vars @ 02/12/24 19:51:14.331
  E0212 19:51:15.201268      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:16.201478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:17.201575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:18.201616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:51:18.354
  Feb 12 19:51:18.358: INFO: Trying to get logs from node ip-172-31-5-108 pod downward-api-2b3b7f94-a81a-4e42-8587-812fecce7e19 container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 19:51:18.368
  Feb 12 19:51:18.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9919" for this suite. @ 02/12/24 19:51:18.392
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 02/12/24 19:51:18.403
  Feb 12 19:51:18.403: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 19:51:18.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:18.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:18.423
  Feb 12 19:51:18.449: INFO: Create a RollingUpdate DaemonSet
  Feb 12 19:51:18.455: INFO: Check that daemon pods launch on every node of the cluster
  Feb 12 19:51:18.459: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:18.459: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:18.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:51:18.463: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 19:51:19.201872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:19.460: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:19.460: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:19.465: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 19:51:19.465: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Feb 12 19:51:19.465: INFO: Update the DaemonSet to trigger a rollout
  Feb 12 19:51:19.475: INFO: Updating DaemonSet daemon-set
  E0212 19:51:20.201951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:21.202056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:21.493: INFO: Roll back the DaemonSet before rollout is complete
  Feb 12 19:51:21.504: INFO: Updating DaemonSet daemon-set
  Feb 12 19:51:21.504: INFO: Make sure DaemonSet rollback is complete
  Feb 12 19:51:21.508: INFO: Wrong image for pod: daemon-set-tmm6k. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Feb 12 19:51:21.508: INFO: Pod daemon-set-tmm6k is not available
  Feb 12 19:51:21.512: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:21.512: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0212 19:51:22.202149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:22.513: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:22.513: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0212 19:51:23.202245      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:23.508: INFO: Pod daemon-set-v787z is not available
  Feb 12 19:51:23.513: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 19:51:23.513: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 02/12/24 19:51:23.52
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6887, will wait for the garbage collector to delete the pods @ 02/12/24 19:51:23.52
  Feb 12 19:51:23.583: INFO: Deleting DaemonSet.extensions daemon-set took: 7.767557ms
  Feb 12 19:51:23.684: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.24268ms
  E0212 19:51:24.203235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:25.204116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:25.589: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 19:51:25.589: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb 12 19:51:25.592: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23019"},"items":null}

  Feb 12 19:51:25.595: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23019"},"items":null}

  Feb 12 19:51:25.610: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6887" for this suite. @ 02/12/24 19:51:25.614
• [7.220 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 02/12/24 19:51:25.624
  Feb 12 19:51:25.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename limitrange @ 02/12/24 19:51:25.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:25.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:25.645
  STEP: Creating a LimitRange @ 02/12/24 19:51:25.65
  STEP: Setting up watch @ 02/12/24 19:51:25.651
  STEP: Submitting a LimitRange @ 02/12/24 19:51:25.755
  STEP: Verifying LimitRange creation was observed @ 02/12/24 19:51:25.763
  STEP: Fetching the LimitRange to ensure it has proper values @ 02/12/24 19:51:25.763
  Feb 12 19:51:25.768: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Feb 12 19:51:25.768: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 02/12/24 19:51:25.768
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 02/12/24 19:51:25.774
  Feb 12 19:51:25.781: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Feb 12 19:51:25.781: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 02/12/24 19:51:25.781
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 02/12/24 19:51:25.787
  Feb 12 19:51:25.794: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Feb 12 19:51:25.794: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 02/12/24 19:51:25.794
  STEP: Failing to create a Pod with more than max resources @ 02/12/24 19:51:25.796
  STEP: Updating a LimitRange @ 02/12/24 19:51:25.798
  STEP: Verifying LimitRange updating is effective @ 02/12/24 19:51:25.803
  E0212 19:51:26.204455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:27.204578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 02/12/24 19:51:27.81
  STEP: Failing to create a Pod with more than max resources @ 02/12/24 19:51:27.817
  STEP: Deleting a LimitRange @ 02/12/24 19:51:27.819
  STEP: Verifying the LimitRange was deleted @ 02/12/24 19:51:27.826
  E0212 19:51:28.204643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:29.204737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:30.204818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:31.204917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:32.205034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:32.832: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 02/12/24 19:51:32.832
  Feb 12 19:51:32.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4846" for this suite. @ 02/12/24 19:51:32.847
• [7.229 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 02/12/24 19:51:32.853
  Feb 12 19:51:32.853: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:51:32.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:32.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:32.872
  STEP: creating a collection of services @ 02/12/24 19:51:32.875
  Feb 12 19:51:32.875: INFO: Creating e2e-svc-a-z6cxl
  Feb 12 19:51:32.887: INFO: Creating e2e-svc-b-5tmvh
  Feb 12 19:51:32.900: INFO: Creating e2e-svc-c-2gtbr
  STEP: deleting service collection @ 02/12/24 19:51:32.915
  Feb 12 19:51:32.946: INFO: Collection of services has been deleted
  Feb 12 19:51:32.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5830" for this suite. @ 02/12/24 19:51:32.95
• [0.105 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 02/12/24 19:51:32.958
  Feb 12 19:51:32.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 19:51:32.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:51:32.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:51:32.979
  STEP: Creating service test in namespace statefulset-929 @ 02/12/24 19:51:32.983
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 02/12/24 19:51:32.987
  STEP: Creating stateful set ss in namespace statefulset-929 @ 02/12/24 19:51:32.991
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-929 @ 02/12/24 19:51:32.998
  Feb 12 19:51:33.001: INFO: Found 0 stateful pods, waiting for 1
  E0212 19:51:33.205973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:34.206468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:35.206562      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:36.207064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:37.207283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:38.208082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:39.208140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:40.208259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:41.208382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:42.208577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:43.004: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 02/12/24 19:51:43.004
  Feb 12 19:51:43.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:51:43.097: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:51:43.097: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:51:43.097: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:51:43.102: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0212 19:51:43.209187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:44.210189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:45.210881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:46.210938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:47.211253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:48.211632      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:49.211732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:50.211933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:51.212122      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:51:52.212243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:53.104: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:51:53.104: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb 12 19:51:53.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999774s
  E0212 19:51:53.213047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:54.128: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994971285s
  E0212 19:51:54.213496      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:55.133: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990341267s
  E0212 19:51:55.214184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:56.140: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984062434s
  E0212 19:51:56.214494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:57.146: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.97833774s
  E0212 19:51:57.215338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:58.151: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.972214975s
  E0212 19:51:58.216387      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:51:59.157: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967487343s
  E0212 19:51:59.217404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:00.162: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.961400445s
  E0212 19:52:00.218128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:01.167: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.955719265s
  E0212 19:52:01.218968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:02.173: INFO: Verifying statefulset ss doesn't scale past 1 for another 950.836497ms
  E0212 19:52:02.219672      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-929 @ 02/12/24 19:52:03.173
  Feb 12 19:52:03.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0212 19:52:03.220217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:03.263: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:52:03.263: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:52:03.263: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:52:03.267: INFO: Found 1 stateful pods, waiting for 3
  E0212 19:52:04.221111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:05.221218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:06.221410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:07.221737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:08.221872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:09.221966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:10.222047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:11.222139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:12.222895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:13.222990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:13.269: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:52:13.269: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 19:52:13.269: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 02/12/24 19:52:13.269
  STEP: Scale down will halt with unhealthy stateful pod @ 02/12/24 19:52:13.269
  Feb 12 19:52:13.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:52:13.380: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:52:13.380: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:52:13.380: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:52:13.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:52:13.470: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:52:13.470: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:52:13.470: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:52:13.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb 12 19:52:13.567: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb 12 19:52:13.567: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb 12 19:52:13.567: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb 12 19:52:13.567: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb 12 19:52:13.572: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0212 19:52:14.224022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:15.224204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:16.225473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:17.225551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:18.225839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:19.225941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:20.226020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:21.226122      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:22.226928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:23.227033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:23.576: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:52:23.576: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:52:23.576: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Feb 12 19:52:23.591: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999838s
  E0212 19:52:24.227144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:24.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995460416s
  E0212 19:52:25.227666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:25.604: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98894885s
  E0212 19:52:26.227774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:26.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983884983s
  E0212 19:52:27.228591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:27.614: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97906286s
  E0212 19:52:28.229603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:28.620: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972995915s
  E0212 19:52:29.229851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:29.624: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967637515s
  E0212 19:52:30.229966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:30.630: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962842796s
  E0212 19:52:31.230145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:31.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956447405s
  E0212 19:52:32.231062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:32.643: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.453869ms
  E0212 19:52:33.231140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-929 @ 02/12/24 19:52:33.643
  Feb 12 19:52:33.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:52:33.743: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:52:33.743: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:52:33.743: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:52:33.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:52:33.836: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:52:33.836: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:52:33.836: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:52:33.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=statefulset-929 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb 12 19:52:33.932: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb 12 19:52:33.932: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb 12 19:52:33.932: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb 12 19:52:33.932: INFO: Scaling statefulset ss to 0
  E0212 19:52:34.231698      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:35.232466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:36.233298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:37.234211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:38.234554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:39.234683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:40.234774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:41.234954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:42.235632      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:43.236022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 02/12/24 19:52:43.947
  Feb 12 19:52:43.947: INFO: Deleting all statefulset in ns statefulset-929
  Feb 12 19:52:43.951: INFO: Scaling statefulset ss to 0
  Feb 12 19:52:43.963: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:52:43.966: INFO: Deleting statefulset ss
  Feb 12 19:52:43.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-929" for this suite. @ 02/12/24 19:52:43.986
• [71.036 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 02/12/24 19:52:43.995
  Feb 12 19:52:43.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename job @ 02/12/24 19:52:43.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:52:44.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:52:44.016
  STEP: Creating a job @ 02/12/24 19:52:44.019
  STEP: Ensuring job reaches completions @ 02/12/24 19:52:44.025
  E0212 19:52:44.236537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:45.236727      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:46.236837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:47.236941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:48.237034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:49.237253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:50.237416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:51.237563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:52.238139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:53.238243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:52:54.031: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8291" for this suite. @ 02/12/24 19:52:54.036
• [10.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 02/12/24 19:52:54.044
  Feb 12 19:52:54.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename subpath @ 02/12/24 19:52:54.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:52:54.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:52:54.064
  STEP: Setting up data @ 02/12/24 19:52:54.067
  STEP: Creating pod pod-subpath-test-projected-66w4 @ 02/12/24 19:52:54.076
  STEP: Creating a pod to test atomic-volume-subpath @ 02/12/24 19:52:54.076
  E0212 19:52:54.239071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:55.239286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:56.239924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:57.240138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:58.241185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:52:59.241346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:00.242024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:01.242144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:02.242187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:03.242277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:04.242320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:05.242438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:06.242900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:07.243002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:08.243319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:09.243417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:10.244135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:11.244434      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:12.245467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:13.245767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:14.246619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:15.246739      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:16.247062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:17.247160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:53:18.155
  Feb 12 19:53:18.160: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-subpath-test-projected-66w4 container test-container-subpath-projected-66w4: <nil>
  STEP: delete the pod @ 02/12/24 19:53:18.179
  STEP: Deleting pod pod-subpath-test-projected-66w4 @ 02/12/24 19:53:18.195
  Feb 12 19:53:18.195: INFO: Deleting pod "pod-subpath-test-projected-66w4" in namespace "subpath-27"
  Feb 12 19:53:18.200: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-27" for this suite. @ 02/12/24 19:53:18.204
• [24.167 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 02/12/24 19:53:18.211
  Feb 12 19:53:18.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename namespaces @ 02/12/24 19:53:18.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:53:18.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:53:18.232
  STEP: Creating namespace "e2e-ns-t7r7h" @ 02/12/24 19:53:18.235
  E0212 19:53:18.248157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:53:18.253: INFO: Namespace "e2e-ns-t7r7h-2165" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-t7r7h-2165" @ 02/12/24 19:53:18.253
  Feb 12 19:53:18.262: INFO: Namespace "e2e-ns-t7r7h-2165" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-t7r7h-2165" @ 02/12/24 19:53:18.262
  Feb 12 19:53:18.272: INFO: Namespace "e2e-ns-t7r7h-2165" has []v1.FinalizerName{"kubernetes"}
  Feb 12 19:53:18.272: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3942" for this suite. @ 02/12/24 19:53:18.275
  STEP: Destroying namespace "e2e-ns-t7r7h-2165" for this suite. @ 02/12/24 19:53:18.283
• [0.078 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 02/12/24 19:53:18.29
  Feb 12 19:53:18.290: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubelet-test @ 02/12/24 19:53:18.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:53:18.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:53:18.309
  E0212 19:53:19.249197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:20.250105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:53:20.342: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8464" for this suite. @ 02/12/24 19:53:20.347
• [2.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 02/12/24 19:53:20.355
  Feb 12 19:53:20.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/12/24 19:53:20.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:53:20.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:53:20.375
  STEP: create the container to handle the HTTPGet hook request. @ 02/12/24 19:53:20.382
  E0212 19:53:21.250928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:22.251032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/12/24 19:53:22.405
  E0212 19:53:23.251139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:24.251377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 02/12/24 19:53:24.43
  E0212 19:53:25.251767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:26.252332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 02/12/24 19:53:26.448
  Feb 12 19:53:26.460: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8891" for this suite. @ 02/12/24 19:53:26.464
• [6.118 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 02/12/24 19:53:26.473
  Feb 12 19:53:26.473: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 19:53:26.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:53:26.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:53:26.493
  STEP: Creating service test in namespace statefulset-9437 @ 02/12/24 19:53:26.496
  STEP: Creating statefulset ss in namespace statefulset-9437 @ 02/12/24 19:53:26.503
  Feb 12 19:53:26.515: INFO: Found 0 stateful pods, waiting for 1
  E0212 19:53:27.252734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:28.252857      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:29.253042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:30.253824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:31.253925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:32.254908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:33.255000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:34.256064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:35.256144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:36.256423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:53:36.516: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 02/12/24 19:53:36.522
  STEP: updating a scale subresource @ 02/12/24 19:53:36.527
  STEP: verifying the statefulset Spec.Replicas was modified @ 02/12/24 19:53:36.533
  STEP: Patch a scale subresource @ 02/12/24 19:53:36.539
  STEP: verifying the statefulset Spec.Replicas was modified @ 02/12/24 19:53:36.55
  Feb 12 19:53:36.553: INFO: Deleting all statefulset in ns statefulset-9437
  Feb 12 19:53:36.556: INFO: Scaling statefulset ss to 0
  E0212 19:53:37.256544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:38.256871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:39.257083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:40.257925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:41.258029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:42.258133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:43.258908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:44.259010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:45.259104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:46.259489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:53:46.577: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 19:53:46.581: INFO: Deleting statefulset ss
  Feb 12 19:53:46.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9437" for this suite. @ 02/12/24 19:53:46.599
• [20.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 02/12/24 19:53:46.606
  Feb 12 19:53:46.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename job @ 02/12/24 19:53:46.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:53:46.623
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:53:46.626
  STEP: Creating a job @ 02/12/24 19:53:46.629
  STEP: Ensuring active pods == parallelism @ 02/12/24 19:53:46.635
  E0212 19:53:47.259934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:48.260391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 02/12/24 19:53:48.641
  STEP: deleting Job.batch foo in namespace job-7610, will wait for the garbage collector to delete the pods @ 02/12/24 19:53:48.641
  Feb 12 19:53:48.704: INFO: Deleting Job.batch foo took: 8.103469ms
  Feb 12 19:53:48.804: INFO: Terminating Job.batch foo pods took: 100.108309ms
  E0212 19:53:49.261178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 02/12/24 19:53:49.704
  Feb 12 19:53:49.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7610" for this suite. @ 02/12/24 19:53:49.714
• [3.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 02/12/24 19:53:49.725
  Feb 12 19:53:49.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 19:53:49.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:53:49.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:53:49.744
  STEP: Creating resourceQuota "e2e-rq-status-fpfp8" @ 02/12/24 19:53:49.75
  Feb 12 19:53:49.761: INFO: Resource quota "e2e-rq-status-fpfp8" reports spec: hard cpu limit of 500m
  Feb 12 19:53:49.761: INFO: Resource quota "e2e-rq-status-fpfp8" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-fpfp8" /status @ 02/12/24 19:53:49.761
  STEP: Confirm /status for "e2e-rq-status-fpfp8" resourceQuota via watch @ 02/12/24 19:53:49.77
  Feb 12 19:53:49.772: INFO: observed resourceQuota "e2e-rq-status-fpfp8" in namespace "resourcequota-1930" with hard status: v1.ResourceList(nil)
  Feb 12 19:53:49.772: INFO: Found resourceQuota "e2e-rq-status-fpfp8" in namespace "resourcequota-1930" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Feb 12 19:53:49.772: INFO: ResourceQuota "e2e-rq-status-fpfp8" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 02/12/24 19:53:49.776
  Feb 12 19:53:49.783: INFO: Resource quota "e2e-rq-status-fpfp8" reports spec: hard cpu limit of 1
  Feb 12 19:53:49.783: INFO: Resource quota "e2e-rq-status-fpfp8" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-fpfp8" /status @ 02/12/24 19:53:49.783
  STEP: Confirm /status for "e2e-rq-status-fpfp8" resourceQuota via watch @ 02/12/24 19:53:49.791
  Feb 12 19:53:49.793: INFO: observed resourceQuota "e2e-rq-status-fpfp8" in namespace "resourcequota-1930" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Feb 12 19:53:49.793: INFO: Found resourceQuota "e2e-rq-status-fpfp8" in namespace "resourcequota-1930" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Feb 12 19:53:49.793: INFO: ResourceQuota "e2e-rq-status-fpfp8" /status was patched
  STEP: Get "e2e-rq-status-fpfp8" /status @ 02/12/24 19:53:49.793
  Feb 12 19:53:49.797: INFO: Resourcequota "e2e-rq-status-fpfp8" reports status: hard cpu of 1
  Feb 12 19:53:49.797: INFO: Resourcequota "e2e-rq-status-fpfp8" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-fpfp8" /status before checking Spec is unchanged @ 02/12/24 19:53:49.8
  Feb 12 19:53:49.806: INFO: Resourcequota "e2e-rq-status-fpfp8" reports status: hard cpu of 2
  Feb 12 19:53:49.806: INFO: Resourcequota "e2e-rq-status-fpfp8" reports status: hard memory of 2Gi
  Feb 12 19:53:49.808: INFO: Found resourceQuota "e2e-rq-status-fpfp8" in namespace "resourcequota-1930" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Feb 12 19:53:49.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c42d98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c42dc8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c42e10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:53:50.261804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:51.261865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:52.261981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:53.262037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:54.262148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:53:54.812: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c430f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43140), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43188), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:53:55.262913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:56.262999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:57.263290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:58.263955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:53:59.264053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:53:59.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004083458), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040834b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040834e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:00.264246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:01.264333      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:02.265016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:03.265114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:04.265228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:04.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43590), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c435f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43620), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:05.265630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:06.265843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:07.265931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:08.266246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:09.266703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:09.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040838d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004083920), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004083950), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:10.267153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:11.267440      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:12.268068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:13.268157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:14.268445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:14.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43a70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43ab8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43b18), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:15.269362      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:16.269595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:17.269834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:18.270042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:19.270340      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:19.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43f80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c43fc8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e0000), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:20.270896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:21.271241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:22.271346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:23.271528      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:24.271657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:24.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e0420), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e0468), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e04b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:25.271707      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:26.271888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:27.272844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:28.273750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:29.273833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:29.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004083e60), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004083ea8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004083ef0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:30.274698      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:31.275635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:32.275730      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:33.276031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:34.276124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:34.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12240), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f122b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f122e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:35.276619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:36.277316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:37.277590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:38.277646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:39.277835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:39.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e0b28), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e0bd0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e0c18), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:40.278567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:41.278612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:42.278693      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:43.278790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:44.279209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:44.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e10e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1110), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1158), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:45.279661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:46.279906      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:47.280127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:48.280678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:49.280926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:49.815: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f128d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12918), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f129a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:50.281188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:51.281321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:52.281487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:53.281707      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:54.281820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:54.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1638), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1698), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e16f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:54:55.282767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:56.283426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:57.283523      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:58.284008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:54:59.284101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:54:59.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12fa8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13008), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13050), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:00.284383      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:01.284545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:02.284643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:03.284718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:04.285014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:04.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1ba8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1bd8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040e1c20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:05.285808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:06.285905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:07.285993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:08.286264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:09.286353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:09.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f134b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13518), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13548), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:10.287141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:11.287251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:12.287430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:13.287599      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:14.287699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:14.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012e108), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012e1c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012e678), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:15.288667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:16.288851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:17.289754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:18.289820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:19.289916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:19.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13968), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f139c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13a58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:20.290639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:21.290845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:22.291038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:23.291124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:24.291236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:24.816: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012f338), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012f458), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012f5d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:25.292008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:26.292415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:27.292539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:28.292614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:29.292941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:29.815: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f122b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f122e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12330), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:30.293787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:31.293903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:32.294885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:33.295761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:34.295870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:34.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012eea0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012f818), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00012f8a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:35.296764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:36.296949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:37.297197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:38.297561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:39.297837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:39.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f127b0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12840), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f128d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:40.298442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:41.298980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:42.299090      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:43.299182      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:44.299296      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:44.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ec1c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ec210), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ec240), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:45.299384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:46.299530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:47.299731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:48.299792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:49.299879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:49.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12d80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12de0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f12ea0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:50.300785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:51.300958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:52.301105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:53.301275      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:54.301370      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:54.815: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13308), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13338), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13398), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:55:55.302352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:56.302459      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:57.302546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:58.302635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:55:59.302737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:55:59.815: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13728), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13770), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f137b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:00.302844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:01.303297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:02.303431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:03.303661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:04.303816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:04.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13b48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13b78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002f13bd8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:05.304661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:06.304772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:07.305597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:08.305825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:09.305935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:09.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ec8d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ec918), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ec960), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:10.306788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:11.306879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:12.307045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:13.307229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:14.307332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:14.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb0708), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb0750), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb0b10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:15.307881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:16.308076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:17.309134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:18.309757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:19.309859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:19.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb10c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb1110), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb1188), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:20.309965      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:21.310923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:22.311129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:23.311246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:24.311402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:24.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb14e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb15a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb15d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:25.311765      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:26.311869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:27.312705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:28.312703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:29.313050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:29.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb1938), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb1998), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000cb1a58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:30.313973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:31.314035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:32.314143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:33.314949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:34.315013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:34.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ed038), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ed080), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ed0c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:35.315865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:36.316077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:37.316388      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:38.316887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:39.317259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:39.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ed470), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ed4b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042ed500), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:40.318262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:41.318316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:42.318876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:43.318953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:44.319243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:44.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be018), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be090), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be0c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:45.319788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:46.319885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:47.320150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:48.320695      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:49.321029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:49.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be390), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be3c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be450), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:50.321192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:51.321479      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:52.321564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:53.321795      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:54.321863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:54.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be690), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be6d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041be708), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:56:55.322563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:56.322913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:57.323005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:58.323606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:56:59.323725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:56:59.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bea20), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bea50), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bea80), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:57:00.323788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:01.323889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:02.323964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:03.324122      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:04.324243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:04.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bee40), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bee70), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041beeb8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:57:05.324623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:06.324711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:07.324757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:08.325792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:09.325863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:09.815: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042edd28), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042edd58), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042edd88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:57:10.326647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:11.327068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:12.327166      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:13.327256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:14.327581      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:14.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00438a078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00438a0c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00438a108), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:57:15.328588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:16.328816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:17.329014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:18.329297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:19.329460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:19.814: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-fpfp8", GenerateName:"", Namespace:"resourcequota-1930", SelfLink:"", UID:"74d3977f-90d1-48e6-9d44-df2c1fd92263", ResourceVersion:"24084", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-fpfp8"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bf458), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bf488), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 19, 53, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0041bf4d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0212 19:57:20.330415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:21.330542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:22.330903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:23.331034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:24.331398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:24.813: INFO: ResourceQuota "e2e-rq-status-fpfp8" Spec was unchanged and /status reset
  Feb 12 19:57:24.813: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1930" for this suite. @ 02/12/24 19:57:24.818
• [215.102 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 02/12/24 19:57:24.827
  Feb 12 19:57:24.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 19:57:24.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:24.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:24.852
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:57:24.857
  E0212 19:57:25.332299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:26.332486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:27.332657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:28.332790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:57:28.882
  Feb 12 19:57:28.885: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-cf27c9bb-5ad7-4de0-ae39-30f03ad84c50 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:57:28.897
  Feb 12 19:57:28.916: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8367" for this suite. @ 02/12/24 19:57:28.919
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 02/12/24 19:57:28.928
  Feb 12 19:57:28.928: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 19:57:28.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:28.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:28.95
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/12/24 19:57:28.956
  Feb 12 19:57:28.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1621 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Feb 12 19:57:29.003: INFO: stderr: ""
  Feb 12 19:57:29.003: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 02/12/24 19:57:29.003
  E0212 19:57:29.333851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:30.334454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:31.334533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:32.334917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:33.335024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 02/12/24 19:57:34.054
  Feb 12 19:57:34.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1621 get pod e2e-test-httpd-pod -o json'
  Feb 12 19:57:34.098: INFO: stderr: ""
  Feb 12 19:57:34.098: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-02-12T19:57:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1621\",\n        \"resourceVersion\": \"24613\",\n        \"uid\": \"647a728e-2a35-4299-bae8-9ce484ee7bd9\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-rtjst\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-5-108\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-rtjst\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-12T19:57:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-12T19:57:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-12T19:57:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-12T19:57:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-12T19:57:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://4ff6ecb294c751a5fa1166644ac28b1d7169c606307274f9a99a13d0678ae1dd\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-02-12T19:57:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.5.108\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.5.108\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.150.219\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.150.219\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-02-12T19:57:29Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 02/12/24 19:57:34.098
  Feb 12 19:57:34.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1621 replace -f -'
  Feb 12 19:57:34.182: INFO: stderr: ""
  Feb 12 19:57:34.182: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 02/12/24 19:57:34.182
  Feb 12 19:57:34.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1621 delete pods e2e-test-httpd-pod'
  E0212 19:57:34.335126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:35.335213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:35.946: INFO: stderr: ""
  Feb 12 19:57:35.946: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Feb 12 19:57:35.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1621" for this suite. @ 02/12/24 19:57:35.952
• [7.032 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 02/12/24 19:57:35.959
  Feb 12 19:57:35.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename security-context-test @ 02/12/24 19:57:35.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:35.976
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:35.979
  E0212 19:57:36.335699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:37.335790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:38.336403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:39.336664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:40.007: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3943" for this suite. @ 02/12/24 19:57:40.012
• [4.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 02/12/24 19:57:40.021
  Feb 12 19:57:40.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 19:57:40.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:40.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:40.039
  Feb 12 19:57:40.071: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"289554ca-368b-4ca0-a0e6-68f83955f3ff", Controller:(*bool)(0xc002dfc946), BlockOwnerDeletion:(*bool)(0xc002dfc947)}}
  Feb 12 19:57:40.081: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"bcc0a436-48e9-4f30-aeac-a4bb4e28131f", Controller:(*bool)(0xc0029c8696), BlockOwnerDeletion:(*bool)(0xc0029c8697)}}
  Feb 12 19:57:40.093: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"27508932-470e-40be-ac56-5fb831970f3c", Controller:(*bool)(0xc0029c88ce), BlockOwnerDeletion:(*bool)(0xc0029c88cf)}}
  E0212 19:57:40.337645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:41.337879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:42.337981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:43.338078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:44.338198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:45.105: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1076" for this suite. @ 02/12/24 19:57:45.11
• [5.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 02/12/24 19:57:45.118
  Feb 12 19:57:45.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename watch @ 02/12/24 19:57:45.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:45.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:45.136
  STEP: getting a starting resourceVersion @ 02/12/24 19:57:45.139
  STEP: starting a background goroutine to produce watch events @ 02/12/24 19:57:45.143
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 02/12/24 19:57:45.143
  E0212 19:57:45.338567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:46.339352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:47.340005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:47.925: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-792" for this suite. @ 02/12/24 19:57:47.974
• [2.910 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 02/12/24 19:57:48.028
  Feb 12 19:57:48.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:57:48.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:48.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:48.049
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2228 @ 02/12/24 19:57:48.052
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 02/12/24 19:57:48.062
  STEP: creating service externalsvc in namespace services-2228 @ 02/12/24 19:57:48.062
  STEP: creating replication controller externalsvc in namespace services-2228 @ 02/12/24 19:57:48.076
  I0212 19:57:48.087058      20 runners.go:197] Created replication controller with name: externalsvc, namespace: services-2228, replica count: 2
  E0212 19:57:48.340253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:49.340341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:50.340533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 19:57:51.137463      20 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 02/12/24 19:57:51.141
  Feb 12 19:57:51.156: INFO: Creating new exec pod
  E0212 19:57:51.341537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:52.341652      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:53.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-2228 exec execpod75mh5 -- /bin/sh -x -c nslookup clusterip-service.services-2228.svc.cluster.local'
  Feb 12 19:57:53.291: INFO: stderr: "+ nslookup clusterip-service.services-2228.svc.cluster.local\n"
  Feb 12 19:57:53.291: INFO: stdout: "Server:\t\t10.152.183.33\nAddress:\t10.152.183.33#53\n\nclusterip-service.services-2228.svc.cluster.local\tcanonical name = externalsvc.services-2228.svc.cluster.local.\nName:\texternalsvc.services-2228.svc.cluster.local\nAddress: 10.152.183.66\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-2228, will wait for the garbage collector to delete the pods @ 02/12/24 19:57:53.291
  E0212 19:57:53.341896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:53.354: INFO: Deleting ReplicationController externalsvc took: 8.71025ms
  Feb 12 19:57:53.455: INFO: Terminating ReplicationController externalsvc pods took: 100.655982ms
  E0212 19:57:54.342400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:55.342489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:57:56.074: INFO: Cleaning up the ClusterIP to ExternalName test service
  Feb 12 19:57:56.090: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2228" for this suite. @ 02/12/24 19:57:56.093
• [8.073 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 02/12/24 19:57:56.101
  Feb 12 19:57:56.101: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 19:57:56.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:56.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:56.12
  STEP: Creating secret with name secret-test-8e5fb260-b694-4ca7-89f2-99841a6f48f4 @ 02/12/24 19:57:56.123
  STEP: Creating a pod to test consume secrets @ 02/12/24 19:57:56.128
  E0212 19:57:56.342920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:57.343194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:57:58.148
  Feb 12 19:57:58.152: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-9b542518-9556-4298-876a-e84dee31b12c container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 19:57:58.16
  Feb 12 19:57:58.189: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8653" for this suite. @ 02/12/24 19:57:58.192
• [2.098 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 02/12/24 19:57:58.199
  Feb 12 19:57:58.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 19:57:58.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:57:58.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:57:58.219
  STEP: create the rc @ 02/12/24 19:57:58.226
  W0212 19:57:58.231247      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0212 19:57:58.343532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:57:59.343720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:00.344349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:01.348226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:02.351621      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:03.352426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 02/12/24 19:58:04.235
  STEP: wait for the rc to be deleted @ 02/12/24 19:58:04.244
  E0212 19:58:04.353283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:05.353533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:06.353706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:07.353849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:08.354852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 02/12/24 19:58:09.25
  E0212 19:58:09.355650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:10.355756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:11.355985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:12.356208      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:13.356499      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:14.356631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:15.356804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:16.356859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:17.356953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:18.357993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:19.358080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:20.358189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:21.359091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:22.359195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:23.359346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:24.359726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:25.360550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:26.360658      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:27.360870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:28.361155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:29.361433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:30.361655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:31.361820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:32.361877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:33.362916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:34.362987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:35.363753      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:36.363929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:37.364682      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:38.364781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/12/24 19:58:39.26
  W0212 19:58:39.266221      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb 12 19:58:39.266: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb 12 19:58:39.267: INFO: Deleting pod "simpletest.rc-26n5t" in namespace "gc-5869"
  Feb 12 19:58:39.278: INFO: Deleting pod "simpletest.rc-2cb5l" in namespace "gc-5869"
  Feb 12 19:58:39.291: INFO: Deleting pod "simpletest.rc-2dv4z" in namespace "gc-5869"
  Feb 12 19:58:39.302: INFO: Deleting pod "simpletest.rc-2fh2v" in namespace "gc-5869"
  Feb 12 19:58:39.317: INFO: Deleting pod "simpletest.rc-2qn6x" in namespace "gc-5869"
  Feb 12 19:58:39.333: INFO: Deleting pod "simpletest.rc-47b2d" in namespace "gc-5869"
  Feb 12 19:58:39.345: INFO: Deleting pod "simpletest.rc-47s9w" in namespace "gc-5869"
  Feb 12 19:58:39.360: INFO: Deleting pod "simpletest.rc-47zmw" in namespace "gc-5869"
  E0212 19:58:39.365248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:58:39.376: INFO: Deleting pod "simpletest.rc-4f4zn" in namespace "gc-5869"
  Feb 12 19:58:39.389: INFO: Deleting pod "simpletest.rc-4gdsr" in namespace "gc-5869"
  Feb 12 19:58:39.405: INFO: Deleting pod "simpletest.rc-4hvxx" in namespace "gc-5869"
  Feb 12 19:58:39.417: INFO: Deleting pod "simpletest.rc-4nsp8" in namespace "gc-5869"
  Feb 12 19:58:39.429: INFO: Deleting pod "simpletest.rc-5stfj" in namespace "gc-5869"
  Feb 12 19:58:39.441: INFO: Deleting pod "simpletest.rc-5w7b5" in namespace "gc-5869"
  Feb 12 19:58:39.454: INFO: Deleting pod "simpletest.rc-6bbzq" in namespace "gc-5869"
  Feb 12 19:58:39.465: INFO: Deleting pod "simpletest.rc-6bfdd" in namespace "gc-5869"
  Feb 12 19:58:39.489: INFO: Deleting pod "simpletest.rc-6jdbp" in namespace "gc-5869"
  Feb 12 19:58:39.505: INFO: Deleting pod "simpletest.rc-6spjj" in namespace "gc-5869"
  Feb 12 19:58:39.519: INFO: Deleting pod "simpletest.rc-6wj8t" in namespace "gc-5869"
  Feb 12 19:58:39.529: INFO: Deleting pod "simpletest.rc-79m2d" in namespace "gc-5869"
  Feb 12 19:58:39.541: INFO: Deleting pod "simpletest.rc-7lb75" in namespace "gc-5869"
  Feb 12 19:58:39.559: INFO: Deleting pod "simpletest.rc-87gwq" in namespace "gc-5869"
  Feb 12 19:58:39.571: INFO: Deleting pod "simpletest.rc-889wj" in namespace "gc-5869"
  Feb 12 19:58:39.582: INFO: Deleting pod "simpletest.rc-894n6" in namespace "gc-5869"
  Feb 12 19:58:39.597: INFO: Deleting pod "simpletest.rc-8qt5j" in namespace "gc-5869"
  Feb 12 19:58:39.611: INFO: Deleting pod "simpletest.rc-8tbcl" in namespace "gc-5869"
  Feb 12 19:58:39.626: INFO: Deleting pod "simpletest.rc-92jzs" in namespace "gc-5869"
  Feb 12 19:58:39.644: INFO: Deleting pod "simpletest.rc-9cwx6" in namespace "gc-5869"
  Feb 12 19:58:39.657: INFO: Deleting pod "simpletest.rc-9d96s" in namespace "gc-5869"
  Feb 12 19:58:39.672: INFO: Deleting pod "simpletest.rc-9smtg" in namespace "gc-5869"
  Feb 12 19:58:39.685: INFO: Deleting pod "simpletest.rc-9vtk9" in namespace "gc-5869"
  Feb 12 19:58:39.705: INFO: Deleting pod "simpletest.rc-blwbd" in namespace "gc-5869"
  Feb 12 19:58:39.721: INFO: Deleting pod "simpletest.rc-bmsf2" in namespace "gc-5869"
  Feb 12 19:58:39.744: INFO: Deleting pod "simpletest.rc-brrfr" in namespace "gc-5869"
  Feb 12 19:58:39.755: INFO: Deleting pod "simpletest.rc-bwhhd" in namespace "gc-5869"
  Feb 12 19:58:39.773: INFO: Deleting pod "simpletest.rc-c6sbm" in namespace "gc-5869"
  Feb 12 19:58:39.786: INFO: Deleting pod "simpletest.rc-cm42c" in namespace "gc-5869"
  Feb 12 19:58:39.803: INFO: Deleting pod "simpletest.rc-cs849" in namespace "gc-5869"
  Feb 12 19:58:39.817: INFO: Deleting pod "simpletest.rc-dp7bl" in namespace "gc-5869"
  Feb 12 19:58:39.829: INFO: Deleting pod "simpletest.rc-dprp6" in namespace "gc-5869"
  Feb 12 19:58:39.841: INFO: Deleting pod "simpletest.rc-dq7br" in namespace "gc-5869"
  Feb 12 19:58:39.853: INFO: Deleting pod "simpletest.rc-f5txq" in namespace "gc-5869"
  Feb 12 19:58:39.881: INFO: Deleting pod "simpletest.rc-fdp5z" in namespace "gc-5869"
  Feb 12 19:58:39.909: INFO: Deleting pod "simpletest.rc-fr5nm" in namespace "gc-5869"
  Feb 12 19:58:39.926: INFO: Deleting pod "simpletest.rc-frxxc" in namespace "gc-5869"
  Feb 12 19:58:39.942: INFO: Deleting pod "simpletest.rc-g5cqc" in namespace "gc-5869"
  Feb 12 19:58:39.956: INFO: Deleting pod "simpletest.rc-gcgt2" in namespace "gc-5869"
  Feb 12 19:58:39.970: INFO: Deleting pod "simpletest.rc-gpdvr" in namespace "gc-5869"
  Feb 12 19:58:39.988: INFO: Deleting pod "simpletest.rc-h42kx" in namespace "gc-5869"
  Feb 12 19:58:40.000: INFO: Deleting pod "simpletest.rc-h7mtj" in namespace "gc-5869"
  Feb 12 19:58:40.013: INFO: Deleting pod "simpletest.rc-hnz44" in namespace "gc-5869"
  Feb 12 19:58:40.025: INFO: Deleting pod "simpletest.rc-hv65f" in namespace "gc-5869"
  Feb 12 19:58:40.036: INFO: Deleting pod "simpletest.rc-hv928" in namespace "gc-5869"
  Feb 12 19:58:40.051: INFO: Deleting pod "simpletest.rc-hwp9w" in namespace "gc-5869"
  Feb 12 19:58:40.065: INFO: Deleting pod "simpletest.rc-j7wdl" in namespace "gc-5869"
  Feb 12 19:58:40.077: INFO: Deleting pod "simpletest.rc-jfm9r" in namespace "gc-5869"
  Feb 12 19:58:40.092: INFO: Deleting pod "simpletest.rc-jkk6w" in namespace "gc-5869"
  Feb 12 19:58:40.112: INFO: Deleting pod "simpletest.rc-jwg59" in namespace "gc-5869"
  Feb 12 19:58:40.123: INFO: Deleting pod "simpletest.rc-kfpvf" in namespace "gc-5869"
  Feb 12 19:58:40.137: INFO: Deleting pod "simpletest.rc-krl25" in namespace "gc-5869"
  Feb 12 19:58:40.148: INFO: Deleting pod "simpletest.rc-l5zgn" in namespace "gc-5869"
  Feb 12 19:58:40.160: INFO: Deleting pod "simpletest.rc-lgjpg" in namespace "gc-5869"
  Feb 12 19:58:40.172: INFO: Deleting pod "simpletest.rc-n9pjq" in namespace "gc-5869"
  Feb 12 19:58:40.183: INFO: Deleting pod "simpletest.rc-nfhkj" in namespace "gc-5869"
  Feb 12 19:58:40.200: INFO: Deleting pod "simpletest.rc-npqp7" in namespace "gc-5869"
  Feb 12 19:58:40.213: INFO: Deleting pod "simpletest.rc-nxv76" in namespace "gc-5869"
  Feb 12 19:58:40.268: INFO: Deleting pod "simpletest.rc-pd87v" in namespace "gc-5869"
  Feb 12 19:58:40.311: INFO: Deleting pod "simpletest.rc-pl97z" in namespace "gc-5869"
  Feb 12 19:58:40.326: INFO: Deleting pod "simpletest.rc-q7vsr" in namespace "gc-5869"
  Feb 12 19:58:40.343: INFO: Deleting pod "simpletest.rc-qlvv2" in namespace "gc-5869"
  E0212 19:58:40.366102      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:58:40.367: INFO: Deleting pod "simpletest.rc-qqrz8" in namespace "gc-5869"
  Feb 12 19:58:40.415: INFO: Deleting pod "simpletest.rc-qttdf" in namespace "gc-5869"
  Feb 12 19:58:40.494: INFO: Deleting pod "simpletest.rc-qv4tc" in namespace "gc-5869"
  Feb 12 19:58:40.516: INFO: Deleting pod "simpletest.rc-r9ndw" in namespace "gc-5869"
  Feb 12 19:58:40.561: INFO: Deleting pod "simpletest.rc-rrsrc" in namespace "gc-5869"
  Feb 12 19:58:40.610: INFO: Deleting pod "simpletest.rc-t485k" in namespace "gc-5869"
  Feb 12 19:58:40.667: INFO: Deleting pod "simpletest.rc-t75h4" in namespace "gc-5869"
  Feb 12 19:58:40.719: INFO: Deleting pod "simpletest.rc-tf55h" in namespace "gc-5869"
  Feb 12 19:58:40.766: INFO: Deleting pod "simpletest.rc-tncf8" in namespace "gc-5869"
  Feb 12 19:58:40.813: INFO: Deleting pod "simpletest.rc-tx984" in namespace "gc-5869"
  Feb 12 19:58:40.869: INFO: Deleting pod "simpletest.rc-v56pn" in namespace "gc-5869"
  Feb 12 19:58:40.919: INFO: Deleting pod "simpletest.rc-vlsrs" in namespace "gc-5869"
  Feb 12 19:58:40.969: INFO: Deleting pod "simpletest.rc-vt9hd" in namespace "gc-5869"
  Feb 12 19:58:41.015: INFO: Deleting pod "simpletest.rc-vwqkh" in namespace "gc-5869"
  Feb 12 19:58:41.074: INFO: Deleting pod "simpletest.rc-vz2tg" in namespace "gc-5869"
  Feb 12 19:58:41.117: INFO: Deleting pod "simpletest.rc-w5q5t" in namespace "gc-5869"
  Feb 12 19:58:41.175: INFO: Deleting pod "simpletest.rc-w8hkg" in namespace "gc-5869"
  Feb 12 19:58:41.218: INFO: Deleting pod "simpletest.rc-w8kdl" in namespace "gc-5869"
  Feb 12 19:58:41.271: INFO: Deleting pod "simpletest.rc-wncrq" in namespace "gc-5869"
  Feb 12 19:58:41.312: INFO: Deleting pod "simpletest.rc-x65rg" in namespace "gc-5869"
  Feb 12 19:58:41.365: INFO: Deleting pod "simpletest.rc-xjsqr" in namespace "gc-5869"
  E0212 19:58:41.366602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:58:41.431: INFO: Deleting pod "simpletest.rc-xrxwg" in namespace "gc-5869"
  Feb 12 19:58:41.464: INFO: Deleting pod "simpletest.rc-xsmm7" in namespace "gc-5869"
  Feb 12 19:58:41.534: INFO: Deleting pod "simpletest.rc-xt5vv" in namespace "gc-5869"
  Feb 12 19:58:41.562: INFO: Deleting pod "simpletest.rc-xwkgh" in namespace "gc-5869"
  Feb 12 19:58:41.622: INFO: Deleting pod "simpletest.rc-xwl54" in namespace "gc-5869"
  Feb 12 19:58:41.665: INFO: Deleting pod "simpletest.rc-z88fk" in namespace "gc-5869"
  Feb 12 19:58:41.718: INFO: Deleting pod "simpletest.rc-zgcrh" in namespace "gc-5869"
  Feb 12 19:58:41.764: INFO: Deleting pod "simpletest.rc-ztkzp" in namespace "gc-5869"
  Feb 12 19:58:41.840: INFO: Deleting pod "simpletest.rc-zz7x8" in namespace "gc-5869"
  Feb 12 19:58:41.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5869" for this suite. @ 02/12/24 19:58:41.905
• [43.761 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 02/12/24 19:58:41.961
  Feb 12 19:58:41.961: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename runtimeclass @ 02/12/24 19:58:41.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:58:41.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:58:41.99
  STEP: getting /apis @ 02/12/24 19:58:41.994
  STEP: getting /apis/node.k8s.io @ 02/12/24 19:58:41.999
  STEP: getting /apis/node.k8s.io/v1 @ 02/12/24 19:58:42
  STEP: creating @ 02/12/24 19:58:42.002
  STEP: watching @ 02/12/24 19:58:42.027
  Feb 12 19:58:42.027: INFO: starting watch
  STEP: getting @ 02/12/24 19:58:42.037
  STEP: listing @ 02/12/24 19:58:42.04
  STEP: patching @ 02/12/24 19:58:42.043
  STEP: updating @ 02/12/24 19:58:42.052
  Feb 12 19:58:42.058: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 02/12/24 19:58:42.058
  STEP: deleting a collection @ 02/12/24 19:58:42.071
  Feb 12 19:58:42.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4658" for this suite. @ 02/12/24 19:58:42.093
• [0.141 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 02/12/24 19:58:42.103
  Feb 12 19:58:42.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 19:58:42.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:58:42.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:58:42.179
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 19:58:42.182
  E0212 19:58:42.377108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:43.377854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:44.378847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:45.379049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 19:58:46.216
  Feb 12 19:58:46.220: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-84043fdf-3227-4074-ab62-473b9bb97081 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 19:58:46.236
  Feb 12 19:58:46.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1734" for this suite. @ 02/12/24 19:58:46.255
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 02/12/24 19:58:46.263
  Feb 12 19:58:46.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 19:58:46.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:58:46.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:58:46.283
  STEP: creating service nodeport-test with type=NodePort in namespace services-9480 @ 02/12/24 19:58:46.286
  STEP: creating replication controller nodeport-test in namespace services-9480 @ 02/12/24 19:58:46.302
  I0212 19:58:46.310845      20 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-9480, replica count: 2
  E0212 19:58:46.379731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:47.380739      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:48.380912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 19:58:49.361893      20 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 19:58:49.361: INFO: Creating new exec pod
  E0212 19:58:49.380929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:50.381095      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:51.381103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:52.381847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:58:52.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-9480 exec execpod4vz2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Feb 12 19:58:52.482: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Feb 12 19:58:52.482: INFO: stdout: ""
  E0212 19:58:53.381937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:58:53.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-9480 exec execpod4vz2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Feb 12 19:58:53.474: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Feb 12 19:58:53.474: INFO: stdout: "nodeport-test-h6g9h"
  Feb 12 19:58:53.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-9480 exec execpod4vz2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.63 80'
  Feb 12 19:58:53.567: INFO: stderr: "+ nc -v -t -w 2 10.152.183.63 80\nConnection to 10.152.183.63 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Feb 12 19:58:53.567: INFO: stdout: ""
  E0212 19:58:54.382037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 19:58:54.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-9480 exec execpod4vz2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.63 80'
  Feb 12 19:58:54.572: INFO: stderr: "+ nc -v -t -w 2 10.152.183.63 80\n+ echo hostName\nConnection to 10.152.183.63 80 port [tcp/http] succeeded!\n"
  Feb 12 19:58:54.572: INFO: stdout: "nodeport-test-h6g9h"
  Feb 12 19:58:54.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-9480 exec execpod4vz2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.5.108 31802'
  Feb 12 19:58:54.660: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.5.108 31802\nConnection to 172.31.5.108 31802 port [tcp/*] succeeded!\n"
  Feb 12 19:58:54.660: INFO: stdout: "nodeport-test-7nf5t"
  Feb 12 19:58:54.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-9480 exec execpod4vz2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.91.42 31802'
  Feb 12 19:58:54.753: INFO: stderr: "+ nc -v -t -w 2 172.31.91.42 31802\n+ echo hostName\nConnection to 172.31.91.42 31802 port [tcp/*] succeeded!\n"
  Feb 12 19:58:54.753: INFO: stdout: "nodeport-test-7nf5t"
  Feb 12 19:58:54.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9480" for this suite. @ 02/12/24 19:58:54.758
• [8.503 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 02/12/24 19:58:54.766
  Feb 12 19:58:54.766: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 19:58:54.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:58:54.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:58:54.786
  STEP: creating a secret @ 02/12/24 19:58:54.789
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 02/12/24 19:58:54.795
  STEP: patching the secret @ 02/12/24 19:58:54.799
  STEP: deleting the secret using a LabelSelector @ 02/12/24 19:58:54.809
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 02/12/24 19:58:54.818
  Feb 12 19:58:54.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1371" for this suite. @ 02/12/24 19:58:54.825
• [0.065 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 02/12/24 19:58:54.832
  Feb 12 19:58:54.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename cronjob @ 02/12/24 19:58:54.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 19:58:54.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 19:58:54.851
  STEP: Creating a ReplaceConcurrent cronjob @ 02/12/24 19:58:54.854
  STEP: Ensuring a job is scheduled @ 02/12/24 19:58:54.862
  E0212 19:58:55.383047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:56.383115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:57.383202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:58.383508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:58:59.384527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:00.384784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 02/12/24 19:59:00.869
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 02/12/24 19:59:00.872
  STEP: Ensuring the job is replaced with a new one @ 02/12/24 19:59:00.876
  E0212 19:59:01.385716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:02.385834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:03.385960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:04.386936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:05.387053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:06.387126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:07.387244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:08.387598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:09.388521      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:10.388615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:11.388683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:12.389363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:13.389480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:14.389918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:15.390030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:16.390106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:17.390932      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:18.391071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:19.392034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:20.392166      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:21.392288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:22.393311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:23.393924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:24.394110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:25.394218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:26.394983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:27.395451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:28.395758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:29.396711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:30.396919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:31.397952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:32.398014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:33.398648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:34.398799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:35.398896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:36.398976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:37.399072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:38.399633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:39.399818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:40.400025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:41.400556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:42.400785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:43.401340      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:44.401445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:45.402354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:46.402468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:47.403375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:48.403663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:49.404024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:50.404902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:51.405231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:52.405813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:53.406598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:54.406712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:55.406798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:56.407016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:57.407654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:58.408112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 19:59:59.408865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:00.409098      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 02/12/24 20:00:00.882
  Feb 12 20:00:00.890: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4226" for this suite. @ 02/12/24 20:00:00.894
• [66.073 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 02/12/24 20:00:00.904
  Feb 12 20:00:00.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename chunking @ 02/12/24 20:00:00.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:00:00.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:00:00.926
  STEP: creating a large number of resources @ 02/12/24 20:00:00.929
  E0212 20:00:01.409845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:02.410333      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:03.410702      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:04.411677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:05.411774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:06.412106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:07.412651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:08.412754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:09.413591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:10.413837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:11.414724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:12.414805      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:13.415746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:14.415895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:15.416466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:16.416665      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:17.417011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:18.417710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 02/12/24 20:00:18.611
  Feb 12 20:00:18.662: INFO: Retrieved 40/40 results with rv 28414 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 02/12/24 20:00:18.662
  E0212 20:00:19.417884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:20.418921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:21.419010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:22.420084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:23.420986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:24.421788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:25.421846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:26.422896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:27.423712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:28.423939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:29.424152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:30.424248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:31.424363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:32.424452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:33.424977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:34.425056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:35.425901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:36.425981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:37.427084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:38.427289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:00:38.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:00:39.427393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:40.427603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:41.427837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:42.428033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:43.428955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:44.429121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:45.429357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:46.429569      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:47.429725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:48.430057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:49.430886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:50.430973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:51.431183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:52.431375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:53.431868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:54.432134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:55.432437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:56.432659      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:57.432869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:00:58.433553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:00:58.667: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:00:59.433663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:00.433831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:01.434890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:02.435728      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:03.435986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:04.436199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:05.436306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:06.436473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:07.436665      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:08.437143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:09.437421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:10.437610      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:11.437811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:12.437875      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:13.438146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:14.438240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:15.438996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:16.439206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:17.439408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:18.440058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:01:18.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:01:19.440240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:20.440437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:21.440534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:22.440757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:23.441091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:24.441289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:25.441513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:26.441733      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:27.441825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:28.441929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:29.442016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:30.442110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:31.442973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:32.443078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:33.444137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:34.444333      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:35.444434      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:36.445154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:37.445246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:38.445524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:01:38.667: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:01:39.445626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:40.445820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:41.445905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:42.446008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:43.446988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:44.447080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:45.447837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:46.447984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:47.448173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:48.448442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:49.448558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:50.449107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:51.449214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:52.449427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:53.449808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:54.449909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:55.450891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:56.451132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:57.451616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:01:58.451956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:01:58.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:01:59.452129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:00.452233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:01.453141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:02.453366      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:03.453625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:04.453832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:05.453912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:06.454890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:07.455942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:08.456546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:09.456656      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:10.456752      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:11.456819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:12.457048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:13.458135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:14.458231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:15.459022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:16.459225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:17.459631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:18.460198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:02:18.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:02:19.460806      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:20.460923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:21.461098      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:22.461199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:23.461428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:24.461647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:25.461827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:26.461932      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:27.462050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:28.462671      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:29.462863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:30.463091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:31.463283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:32.463477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:33.463775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:34.463886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:35.464084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:36.464277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:37.464478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:38.464692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:02:38.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:02:39.465468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:40.465667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:41.465845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:42.465924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:43.465969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:44.466888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:45.467150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:46.467458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:47.467642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:48.468643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:49.468751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:50.469566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:51.470394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:52.470952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:53.471065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:54.471305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:55.471398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:56.471571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:57.471769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:02:58.471985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:02:58.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:02:59.473136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:00.473242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:01.473524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:02.473755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:03.474097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:04.474193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:05.474302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:06.474410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:07.474463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:08.474690      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:09.474879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:10.474974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:11.475633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:12.475731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:13.476003      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:14.476195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:15.476293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:16.476685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:17.476771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:18.477173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:03:18.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:03:19.477827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:20.477930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:21.478923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:22.479023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:23.480014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:24.480120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:25.480343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:26.480518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:27.481241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:28.481900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:29.482900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:30.483164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:31.483379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:32.483571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:33.483872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:34.484039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:35.484525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:36.484652      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:37.484730      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:38.485161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:03:38.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:03:39.485395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:40.485476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:41.485637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:42.485823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:43.485928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:44.486891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:45.486992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:46.487188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:47.487480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:48.487813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:49.488034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:50.488170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:51.488348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:52.488467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:53.489430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:54.489534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:55.490208      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:56.490298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:57.490878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:03:58.490963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:03:58.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:03:59.491790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:00.491978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:01.492996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:02.493305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:03.493718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:04.493890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:05.493968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:06.494085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:07.494968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:08.495351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:09.495512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:10.495628      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:11.495937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:12.496851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:13.496973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:14.497159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:15.497267      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:16.497501      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:17.498147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:18.498696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:04:18.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:04:19.498783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:20.499019      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:21.499211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:22.499403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:23.499697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:24.499893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:25.500161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:26.500342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:27.500511      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:28.500934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:29.501477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:30.501589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:31.502192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:32.502275      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:33.502721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:34.503076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:35.503463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:36.503660      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:37.504210      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:38.504646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:04:38.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:04:39.504997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:40.505193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:41.505830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:42.505926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:43.505998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:44.506130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:45.506255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:46.507262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:47.507606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:48.508051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:49.508145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:50.508333      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:51.508551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:52.508730      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:53.509044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:54.509149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:55.509396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:56.509525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:57.509641      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:04:58.510033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:04:58.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:04:59.510941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:00.511160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:01.511364      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:02.511471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:03.511878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:04.512351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:05.512456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:06.512684      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:07.513428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:08.513771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:09.513838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:10.513929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:11.514035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:12.514126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:13.514185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:14.514258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:15.514900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:16.514997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:17.515808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:18.516219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:05:18.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:05:19.517029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:20.517779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:21.517897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:22.517987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:23.519082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:24.519300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:25.519980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:26.519658      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:27.519863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:28.520308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:29.520492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:30.520682      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:31.520881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:32.521078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:33.522077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:34.522880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:35.523071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:36.523263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:37.523375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:38.523715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:05:38.668: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:05:39.523834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:40.523935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:41.524797      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:42.524900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:43.525002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:44.525098      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:45.525315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:46.526345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:47.526439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:48.526942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:49.527050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:50.527253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:51.527366      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:52.527579      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:53.527687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:54.527878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:55.528096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:56.528206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:57.528402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:05:58.528859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:05:58.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:05:59.529516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:00.529618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:01.529817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:02.529861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:03.529951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:04.530924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:05.531166      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:06.531388      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:07.531481      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:08.531995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:09.532193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:10.532386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:11.532575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:12.532676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:13.533088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:14.533279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:15.533476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:16.533543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:17.533763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:18.534129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:06:18.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:06:19.534939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:20.535116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:21.535784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:22.536202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:23.537068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:24.537185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:25.537881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:26.537828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:27.537920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:28.538971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:29.539155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:30.539458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:31.539567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:32.539717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:33.540048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:34.540138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:35.540240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:36.540439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:37.540664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:38.540711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:06:38.667: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:06:39.540744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:40.540939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:41.541123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:42.541243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:43.541630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:44.541826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:45.542898      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:46.543087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:47.543183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:48.543877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:49.543979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:50.544175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:51.544360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:52.544463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:53.544558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:54.545556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:55.545670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:56.545827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:57.546876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:06:58.547358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:06:58.669: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjg0MTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0212 20:06:59.548097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:00.548281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:01.548741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:02.548893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:03.549030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:04.549134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:05.549341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:06.549542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:07.549759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:08.550096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:09.550186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:10.551142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:11.551219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:12.551414      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:13.551784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:14.551881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:15.552084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:16.552300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:17.552479      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:18.552842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:18.667: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  Feb 12 20:07:18.667: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 02/12/24 20:07:18.667
  STEP: retrieving all remaining pages @ 02/12/24 20:07:18.672
  Feb 12 20:07:18.677: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  Feb 12 20:07:18.681: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  Feb 12 20:07:18.686: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  Feb 12 20:07:18.690: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  Feb 12 20:07:18.694: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  Feb 12 20:07:18.699: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  Feb 12 20:07:18.704: INFO: Retrieved 40/40 results with rv 29231 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjkyMzEsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  Feb 12 20:07:18.708: INFO: Retrieved 40/40 results with rv 29231 and continue 
  Feb 12 20:07:18.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-7754" for this suite. @ 02/12/24 20:07:18.712
• [437.816 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 02/12/24 20:07:18.72
  Feb 12 20:07:18.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename csi-storageclass @ 02/12/24 20:07:18.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:18.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:18.742
  STEP: Creating a StorageClass @ 02/12/24 20:07:18.746
  STEP: Get StorageClass "e2e-br49n" @ 02/12/24 20:07:18.752
  STEP: Patching the StorageClass "e2e-br49n" @ 02/12/24 20:07:18.756
  STEP: Delete StorageClass "e2e-br49n" @ 02/12/24 20:07:18.761
  STEP: Confirm deletion of StorageClass "e2e-br49n" @ 02/12/24 20:07:18.769
  STEP: Create a replacement StorageClass @ 02/12/24 20:07:18.772
  STEP: Updating StorageClass "e2e-v2-4tz8l" @ 02/12/24 20:07:18.779
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-4tz8l=updated" @ 02/12/24 20:07:18.787
  STEP: Deleting StorageClass "e2e-v2-4tz8l" via DeleteCollection @ 02/12/24 20:07:18.791
  STEP: Confirm deletion of StorageClass "e2e-v2-4tz8l" @ 02/12/24 20:07:18.8
  Feb 12 20:07:18.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-1887" for this suite. @ 02/12/24 20:07:18.807
• [0.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 02/12/24 20:07:18.815
  Feb 12 20:07:18.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:07:18.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:18.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:18.834
  STEP: Counting existing ResourceQuota @ 02/12/24 20:07:18.837
  E0212 20:07:19.553483      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:20.553843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:21.554944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:22.555452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:23.555847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 20:07:23.842
  STEP: Ensuring resource quota status is calculated @ 02/12/24 20:07:23.847
  E0212 20:07:24.556688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:25.557363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:25.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3646" for this suite. @ 02/12/24 20:07:25.857
• [7.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 02/12/24 20:07:25.865
  Feb 12 20:07:25.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/12/24 20:07:25.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:25.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:25.889
  Feb 12 20:07:25.892: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:07:26.558106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:26.917: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2634" for this suite. @ 02/12/24 20:07:26.922
• [1.067 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 02/12/24 20:07:26.932
  Feb 12 20:07:26.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename security-context @ 02/12/24 20:07:26.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:26.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:26.953
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 02/12/24 20:07:26.957
  E0212 20:07:27.558196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:28.558657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:29.558762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:30.558970      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:07:30.983
  Feb 12 20:07:30.987: INFO: Trying to get logs from node ip-172-31-5-108 pod security-context-f4e89e94-1057-4fd7-a48d-41cb567f2b0c container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:07:31.005
  Feb 12 20:07:31.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-1828" for this suite. @ 02/12/24 20:07:31.024
• [4.100 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 02/12/24 20:07:31.033
  Feb 12 20:07:31.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:07:31.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:31.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:31.055
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:07:31.061
  E0212 20:07:31.559327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:32.559416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:07:33.081
  Feb 12 20:07:33.085: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-0cb105ac-60e2-4c5c-ae2c-036a5b2583aa container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:07:33.092
  Feb 12 20:07:33.109: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3397" for this suite. @ 02/12/24 20:07:33.112
• [2.087 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 02/12/24 20:07:33.12
  Feb 12 20:07:33.120: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubelet-test @ 02/12/24 20:07:33.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:33.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:33.142
  STEP: Waiting for pod completion @ 02/12/24 20:07:33.155
  E0212 20:07:33.560419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:34.560506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:35.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-786" for this suite. @ 02/12/24 20:07:35.178
• [2.067 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 02/12/24 20:07:35.188
  Feb 12 20:07:35.188: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:07:35.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:07:35.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:07:35.209
  STEP: Creating pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380 @ 02/12/24 20:07:35.213
  E0212 20:07:35.561256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:36.561393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 20:07:37.232
  Feb 12 20:07:37.236: INFO: Initial restart count of pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 is 0
  Feb 12 20:07:37.240: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:37.561474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:38.561882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:39.246: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:39.562399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:40.562546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:41.252: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:41.562529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:42.562632      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:43.257: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:43.563076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:44.563952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:45.263: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:45.564657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:46.564899      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:47.268: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:47.565332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:48.565807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:49.274: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:49.565860      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:50.565953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:51.281: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:51.566250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:52.566928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:53.287: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:53.567580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:54.567887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:55.293: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:55.568510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:56.568736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:57.299: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:57.568863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:07:58.569883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:07:59.304: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:07:59.570536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:00.570640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:01.309: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:01.571268      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:02.571369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:03.314: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:03.572353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:04.572573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:05.319: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:05.573630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:06.573878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:07.324: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:07.573988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:08.574900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:09.331: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:09.575526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:10.575704      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:11.336: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:11.576762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:12.576957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:13.342: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:13.577754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:14.577870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:15.347: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:15.578914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:16.579022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:17.353: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:17.579470      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:18.579768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:19.358: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:19.580486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:20.580701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:21.364: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:21.581807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:22.581865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:23.370: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:23.582213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:24.583064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:25.375: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  E0212 20:08:25.583911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:26.584111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:08:27.381: INFO: Get pod busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 in namespace container-probe-5380
  Feb 12 20:08:27.381: INFO: Restart count of pod container-probe-5380/busybox-5a69655a-3d27-4e48-994e-4902ba7ad000 is now 1 (50.144290584s elapsed)
  STEP: deleting the pod @ 02/12/24 20:08:27.381
  Feb 12 20:08:27.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5380" for this suite. @ 02/12/24 20:08:27.398
• [52.217 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 02/12/24 20:08:27.405
  Feb 12 20:08:27.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:08:27.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:08:27.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:08:27.426
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:08:27.429
  E0212 20:08:27.584576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:28.584717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:29.585201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:30.585303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:08:31.455
  Feb 12 20:08:31.459: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-2043588d-2521-402a-8727-a3085b8f04de container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:08:31.467
  Feb 12 20:08:31.486: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2556" for this suite. @ 02/12/24 20:08:31.489
• [4.092 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 02/12/24 20:08:31.497
  Feb 12 20:08:31.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:08:31.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:08:31.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:08:31.517
  STEP: Creating configMap with name projected-configmap-test-volume-map-6403bca6-a47f-4553-af38-d91ea807cd79 @ 02/12/24 20:08:31.519
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:08:31.524
  E0212 20:08:31.585406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:32.585501      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:33.585942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:34.586920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:08:35.551
  Feb 12 20:08:35.554: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-configmaps-b32fb23e-6811-417f-a0a3-c6a6fce67005 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:08:35.563
  Feb 12 20:08:35.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1410" for this suite. @ 02/12/24 20:08:35.586
  E0212 20:08:35.587004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.095 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 02/12/24 20:08:35.593
  Feb 12 20:08:35.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename discovery @ 02/12/24 20:08:35.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:08:35.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:08:35.614
  STEP: Setting up server cert @ 02/12/24 20:08:35.618
  STEP: Requesting APIResourceList from "/api/v1" @ 02/12/24 20:08:35.841
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 02/12/24 20:08:35.843
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 02/12/24 20:08:35.844
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 02/12/24 20:08:35.846
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 02/12/24 20:08:35.847
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 02/12/24 20:08:35.848
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 02/12/24 20:08:35.849
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 02/12/24 20:08:35.851
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 02/12/24 20:08:35.852
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 02/12/24 20:08:35.853
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 02/12/24 20:08:35.854
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 02/12/24 20:08:35.856
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 02/12/24 20:08:35.857
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 02/12/24 20:08:35.858
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 02/12/24 20:08:35.859
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 02/12/24 20:08:35.86
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 02/12/24 20:08:35.862
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 02/12/24 20:08:35.863
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 02/12/24 20:08:35.864
  Feb 12 20:08:35.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-7280" for this suite. @ 02/12/24 20:08:35.87
• [0.285 seconds]
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 02/12/24 20:08:35.877
  Feb 12 20:08:35.877: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:08:35.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:08:35.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:08:35.899
  STEP: Creating configMap with name configmap-test-upd-e70977fb-5082-4bb2-8cb3-1e9a759d27aa @ 02/12/24 20:08:35.907
  STEP: Creating the pod @ 02/12/24 20:08:35.912
  E0212 20:08:36.588066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:37.588347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-e70977fb-5082-4bb2-8cb3-1e9a759d27aa @ 02/12/24 20:08:37.94
  STEP: waiting to observe update in volume @ 02/12/24 20:08:37.946
  E0212 20:08:38.588399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:39.588694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:40.589793      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:41.589958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:42.590873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:43.590971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:44.591904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:45.592054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:46.592231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:47.592375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:48.592790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:49.593447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:50.594175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:51.594265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:52.594883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:53.594981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:54.595239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:55.595691      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:56.595820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:57.596103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:58.596791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:08:59.596902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:00.597018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:01.597107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:02.597218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:03.597673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:04.597848      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:05.598002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:06.598103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:07.598206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:08.598305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:09.598995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:10.599815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:11.600027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:12.600119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:13.601150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:14.601246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:15.601345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:16.601433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:17.601630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:18.602596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:19.602690      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:20.603431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:21.603531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:22.603628      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:23.603914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:24.604901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:25.605103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:26.605267      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:27.605592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:28.606419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:29.606907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:30.607645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:31.607850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:32.607983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:33.608100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:34.608223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:35.608525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:36.609223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:37.609428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:38.609476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:39.610084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:40.610901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:41.611113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:42.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9155" for this suite. @ 02/12/24 20:09:42.274
• [66.406 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 02/12/24 20:09:42.283
  Feb 12 20:09:42.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:09:42.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:09:42.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:09:42.305
  STEP: Creating pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184 @ 02/12/24 20:09:42.308
  E0212 20:09:42.611211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:43.611608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 20:09:44.328
  Feb 12 20:09:44.331: INFO: Initial restart count of pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 is 0
  Feb 12 20:09:44.336: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:44.611981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:45.612078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:46.342: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:46.612576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:47.612676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:48.347: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:48.613292      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:49.613492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:50.353: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:50.613764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:51.613923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:52.359: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:52.614606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:53.614753      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:54.364: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:54.615704      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:55.615762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:56.369: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:56.616100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:57.616302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:09:58.375: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:09:58.616750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:09:59.616942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:00.380: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:00.617635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:01.617866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:02.386: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:02.618620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:03.618863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:04.391: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:04.619355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:05.619448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:06.396: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:06.620016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:07.620103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:08.403: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:08.620209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:09.620305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:10.408: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:10.621168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:11.621255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:12.413: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:12.622195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:13.622597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:14.419: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:14.623546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:15.623595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:16.423: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:16.624087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:17.624166      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:18.429: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:18.624841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:19.625852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:20.435: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:20.626405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:21.626464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:22.440: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:22.627516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:23.627626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:24.446: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:24.628702      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:25.628884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:26.451: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:26.629210      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:27.629291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:28.457: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:28.629959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:29.631016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:30.463: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:30.631055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:31.631427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:32.468: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:32.632259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:33.632485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:34.474: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:34.633236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:35.633337      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:36.479: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:36.633954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:37.634924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:38.485: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:38.635842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:39.635950      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:40.491: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:40.636374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:41.636492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:42.495: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:42.637070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:43.637168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:44.501: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:44.638049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:45.638147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:46.508: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  E0212 20:10:46.638473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:47.638554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:48.514: INFO: Get pod test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 in namespace container-probe-184
  Feb 12 20:10:48.514: INFO: Restart count of pod container-probe-184/test-grpc-57f93b73-fe57-4d6e-a38f-67f5473774e1 is now 1 (1m4.182444322s elapsed)
  STEP: deleting the pod @ 02/12/24 20:10:48.514
  Feb 12 20:10:48.527: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-184" for this suite. @ 02/12/24 20:10:48.53
• [66.257 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 02/12/24 20:10:48.541
  Feb 12 20:10:48.541: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir-wrapper @ 02/12/24 20:10:48.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:10:48.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:10:48.561
  E0212 20:10:48.638944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:49.639046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 02/12/24 20:10:50.597
  STEP: Cleaning up the configmap @ 02/12/24 20:10:50.607
  STEP: Cleaning up the pod @ 02/12/24 20:10:50.613
  Feb 12 20:10:50.626: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-2746" for this suite. @ 02/12/24 20:10:50.63
• [2.098 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:270
  E0212 20:10:50.639361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a kubernetes client @ 02/12/24 20:10:50.639
  Feb 12 20:10:50.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename apf @ 02/12/24 20:10:50.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:10:50.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:10:50.662
  STEP: getting /apis @ 02/12/24 20:10:50.665
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 02/12/24 20:10:50.668
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 02/12/24 20:10:50.67
  STEP: creating @ 02/12/24 20:10:50.671
  STEP: getting @ 02/12/24 20:10:50.687
  STEP: listing @ 02/12/24 20:10:50.694
  STEP: watching @ 02/12/24 20:10:50.698
  Feb 12 20:10:50.698: INFO: starting watch
  STEP: patching @ 02/12/24 20:10:50.7
  STEP: updating @ 02/12/24 20:10:50.706
  Feb 12 20:10:50.716: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 02/12/24 20:10:50.716
  STEP: patching /status @ 02/12/24 20:10:50.72
  STEP: updating /status @ 02/12/24 20:10:50.725
  STEP: deleting @ 02/12/24 20:10:50.758
  STEP: deleting a collection @ 02/12/24 20:10:50.774
  Feb 12 20:10:50.796: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-2621" for this suite. @ 02/12/24 20:10:50.801
• [0.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 02/12/24 20:10:50.809
  Feb 12 20:10:50.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 20:10:50.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:10:50.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:10:50.83
  Feb 12 20:10:50.835: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2082" for this suite. @ 02/12/24 20:10:50.839
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 02/12/24 20:10:50.846
  Feb 12 20:10:50.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 20:10:50.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:10:50.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:10:50.867
  STEP: creating service in namespace services-102 @ 02/12/24 20:10:50.87
  STEP: creating service affinity-clusterip-transition in namespace services-102 @ 02/12/24 20:10:50.87
  STEP: creating replication controller affinity-clusterip-transition in namespace services-102 @ 02/12/24 20:10:50.883
  I0212 20:10:50.889944      20 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-102, replica count: 3
  E0212 20:10:51.639873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:52.640138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:53.640705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 20:10:53.941341      20 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 20:10:53.949: INFO: Creating new exec pod
  E0212 20:10:54.640842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:55.640932      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:56.641079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:56.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-102 exec execpod-affinityxqzvg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Feb 12 20:10:57.073: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Feb 12 20:10:57.074: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:10:57.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-102 exec execpod-affinityxqzvg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.41 80'
  Feb 12 20:10:57.176: INFO: stderr: "+ nc -v -t -w 2 10.152.183.41 80\nConnection to 10.152.183.41 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Feb 12 20:10:57.176: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:10:57.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-102 exec execpod-affinityxqzvg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.41:80/ ; done'
  Feb 12 20:10:57.333: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n"
  Feb 12 20:10:57.333: INFO: stdout: "\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-tmtmb\naffinity-clusterip-transition-gt4tv\naffinity-clusterip-transition-gt4tv\naffinity-clusterip-transition-tmtmb\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-tmtmb\naffinity-clusterip-transition-gt4tv\naffinity-clusterip-transition-tmtmb\naffinity-clusterip-transition-gt4tv\naffinity-clusterip-transition-gt4tv\naffinity-clusterip-transition-tmtmb\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5"
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-tmtmb
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-gt4tv
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-gt4tv
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-tmtmb
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-tmtmb
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-gt4tv
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-tmtmb
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-gt4tv
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-gt4tv
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-tmtmb
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.333: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-102 exec execpod-affinityxqzvg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.41:80/ ; done'
  Feb 12 20:10:57.501: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.41:80/\n"
  Feb 12 20:10:57.501: INFO: stdout: "\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5\naffinity-clusterip-transition-vzmv5"
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Received response from host: affinity-clusterip-transition-vzmv5
  Feb 12 20:10:57.501: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-102, will wait for the garbage collector to delete the pods @ 02/12/24 20:10:57.514
  Feb 12 20:10:57.577: INFO: Deleting ReplicationController affinity-clusterip-transition took: 7.828414ms
  E0212 20:10:57.641608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:10:57.677: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.30054ms
  E0212 20:10:58.642237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:10:59.642876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:00.642928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:11:00.901: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-102" for this suite. @ 02/12/24 20:11:00.906
• [10.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 02/12/24 20:11:00.916
  Feb 12 20:11:00.916: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:11:00.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:11:00.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:11:00.936
  STEP: Creating configMap with name configmap-test-volume-map-3214cb77-6471-4ff4-9185-195f6212be75 @ 02/12/24 20:11:00.94
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:11:00.946
  E0212 20:11:01.643101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:02.643412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:03.644355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:04.644457      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:11:04.974
  Feb 12 20:11:04.979: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-2a529b9c-2bb5-42da-9ec8-05f425f00c09 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:11:04.986
  Feb 12 20:11:05.002: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2190" for this suite. @ 02/12/24 20:11:05.007
• [4.098 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 02/12/24 20:11:05.015
  Feb 12 20:11:05.015: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 20:11:05.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:11:05.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:11:05.037
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:11:05.04
  E0212 20:11:05.645299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:06.645661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:07.646367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:08.646954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:11:09.064
  Feb 12 20:11:09.067: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-91e58b42-73b8-4209-95d6-7634c31abb79 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:11:09.075
  Feb 12 20:11:09.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8028" for this suite. @ 02/12/24 20:11:09.099
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 02/12/24 20:11:09.108
  Feb 12 20:11:09.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-pred @ 02/12/24 20:11:09.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:11:09.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:11:09.128
  Feb 12 20:11:09.131: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb 12 20:11:09.139: INFO: Waiting for terminating namespaces to be deleted...
  Feb 12 20:11:09.143: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-42-94 before test
  Feb 12 20:11:09.150: INFO: nginx-ingress-controller-kubernetes-worker-4n7x6 from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:22 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: calico-node-nknc4 from kube-system started at 2024-02-12 18:57:51 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: coredns-bddfd76d7-hpmdx from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container coredns ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: kube-state-metrics-78c475f58b-mmvpb from kube-system started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container kube-state-metrics ready: true, restart count 4
  Feb 12 20:11:09.150: INFO: metrics-server-v0.6.3-69d7fbfdf8-q42bs from kube-system started at 2024-02-12 18:46:29 +0000 UTC (2 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container metrics-server ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: dashboard-metrics-scraper-5dd7cb5fc-94q8l from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: kubernetes-dashboard-7b899cb9d9-kxlk9 from kubernetes-dashboard started at 2024-02-12 18:46:29 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container kubernetes-dashboard ready: true, restart count 6
  Feb 12 20:11:09.150: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-hxjsb from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 20:11:09.150: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 20:11:09.150: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-5-108 before test
  Feb 12 20:11:09.156: INFO: nginx-ingress-controller-kubernetes-worker-srk6p from ingress-nginx-kubernetes-worker started at 2024-02-12 19:35:06 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.156: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 20:11:09.156: INFO: calico-node-tcvrl from kube-system started at 2024-02-12 18:59:18 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.156: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 20:11:09.156: INFO: sonobuoy from sonobuoy started at 2024-02-12 19:00:55 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.156: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb 12 20:11:09.156: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-dq5wt from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 20:11:09.156: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 20:11:09.156: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb 12 20:11:09.156: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-91-42 before test
  Feb 12 20:11:09.162: INFO: nginx-ingress-controller-kubernetes-worker-89brg from ingress-nginx-kubernetes-worker started at 2024-02-12 18:49:34 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.162: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Feb 12 20:11:09.162: INFO: calico-node-5zt4h from kube-system started at 2024-02-12 18:57:41 +0000 UTC (1 container statuses recorded)
  Feb 12 20:11:09.162: INFO: 	Container calico-node ready: true, restart count 0
  Feb 12 20:11:09.162: INFO: sonobuoy-e2e-job-6d99262b73344895 from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 20:11:09.162: INFO: 	Container e2e ready: true, restart count 0
  Feb 12 20:11:09.162: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 20:11:09.162: INFO: sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-pcznp from sonobuoy started at 2024-02-12 19:00:57 +0000 UTC (2 container statuses recorded)
  Feb 12 20:11:09.162: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb 12 20:11:09.162: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 02/12/24 20:11:09.162
  E0212 20:11:09.647051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:10.647148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 02/12/24 20:11:11.189
  STEP: Trying to apply a random label on the found node. @ 02/12/24 20:11:11.201
  STEP: verifying the node has the label kubernetes.io/e2e-0afc0408-5fdb-4e87-99fa-ec6bf83a73b2 42 @ 02/12/24 20:11:11.209
  STEP: Trying to relaunch the pod, now with labels. @ 02/12/24 20:11:11.213
  E0212 20:11:11.647193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:12.647909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-0afc0408-5fdb-4e87-99fa-ec6bf83a73b2 off the node ip-172-31-5-108 @ 02/12/24 20:11:13.235
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-0afc0408-5fdb-4e87-99fa-ec6bf83a73b2 @ 02/12/24 20:11:13.246
  Feb 12 20:11:13.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8483" for this suite. @ 02/12/24 20:11:13.256
• [4.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 02/12/24 20:11:13.264
  Feb 12 20:11:13.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:11:13.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:11:13.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:11:13.285
  STEP: Creating configMap with name cm-test-opt-del-7f2d598d-4e8d-41d3-92c7-356312be3222 @ 02/12/24 20:11:13.291
  STEP: Creating configMap with name cm-test-opt-upd-ce6c768b-5f03-4a9d-b523-a9645ab7521c @ 02/12/24 20:11:13.296
  STEP: Creating the pod @ 02/12/24 20:11:13.299
  E0212 20:11:13.648604      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:14.648701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-7f2d598d-4e8d-41d3-92c7-356312be3222 @ 02/12/24 20:11:15.344
  STEP: Updating configmap cm-test-opt-upd-ce6c768b-5f03-4a9d-b523-a9645ab7521c @ 02/12/24 20:11:15.353
  STEP: Creating configMap with name cm-test-opt-create-6b2ed660-4bb1-48a4-a964-a1a21fb6da81 @ 02/12/24 20:11:15.357
  STEP: waiting to observe update in volume @ 02/12/24 20:11:15.362
  E0212 20:11:15.649381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:16.649627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:17.649853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:18.649934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:19.650715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:20.650926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:21.651407      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:22.651498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:23.652126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:24.652217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:25.652561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:26.652456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:27.652520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:28.653717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:29.654447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:30.654593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:31.654676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:32.654750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:33.655234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:34.655572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:35.655825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:36.656073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:37.656830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:38.657809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:39.658738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:40.658858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:41.659692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:42.659790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:43.660690      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:44.660907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:45.661011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:46.661124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:47.662101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:48.662592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:49.662949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:50.663148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:51.664081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:52.664137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:53.664647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:54.664823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:55.665491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:56.665606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:57.666587      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:58.666716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:11:59.666770      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:00.667005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:01.667404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:02.667588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:03.668433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:04.668637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:05.669496      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:06.669938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:07.670550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:08.670758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:09.670926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:10.671059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:11.671790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:12.671990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:13.672232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:14.672397      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:15.672485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:16.672723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:17.673736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:18.674153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:19.674908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:20.675186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:21.675285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:22.675351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:23.675718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:24.676033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:25.676245      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:26.676331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:27.676373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:12:27.739: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1482" for this suite. @ 02/12/24 20:12:27.743
• [74.488 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 02/12/24 20:12:27.752
  Feb 12 20:12:27.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pod-network-test @ 02/12/24 20:12:27.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:12:27.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:12:27.773
  STEP: Performing setup for networking test in namespace pod-network-test-4593 @ 02/12/24 20:12:27.776
  STEP: creating a selector @ 02/12/24 20:12:27.776
  STEP: Creating the service pods in kubernetes @ 02/12/24 20:12:27.776
  Feb 12 20:12:27.776: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0212 20:12:28.677065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:29.677143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:30.677852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:31.678918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:32.679019      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:33.679094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:34.679212      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:35.679327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:36.679415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:37.679530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:38.680070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:39.680277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/12/24 20:12:39.866
  E0212 20:12:40.680371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:41.680489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:12:41.886: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Feb 12 20:12:41.886: INFO: Breadth first check of 192.168.169.87 on host 172.31.42.94...
  Feb 12 20:12:41.890: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.218:9080/dial?request=hostname&protocol=http&host=192.168.169.87&port=8083&tries=1'] Namespace:pod-network-test-4593 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:12:41.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:12:41.891: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:12:41.891: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4593/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.150.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.169.87%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb 12 20:12:41.947: INFO: Waiting for responses: map[]
  Feb 12 20:12:41.947: INFO: reached 192.168.169.87 after 0/1 tries
  Feb 12 20:12:41.947: INFO: Breadth first check of 192.168.150.215 on host 172.31.5.108...
  Feb 12 20:12:41.951: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.218:9080/dial?request=hostname&protocol=http&host=192.168.150.215&port=8083&tries=1'] Namespace:pod-network-test-4593 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:12:41.951: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:12:41.952: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:12:41.952: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4593/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.150.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.150.215%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb 12 20:12:42.004: INFO: Waiting for responses: map[]
  Feb 12 20:12:42.004: INFO: reached 192.168.150.215 after 0/1 tries
  Feb 12 20:12:42.004: INFO: Breadth first check of 192.168.71.248 on host 172.31.91.42...
  Feb 12 20:12:42.010: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.218:9080/dial?request=hostname&protocol=http&host=192.168.71.248&port=8083&tries=1'] Namespace:pod-network-test-4593 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:12:42.010: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:12:42.011: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:12:42.011: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4593/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.150.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.71.248%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb 12 20:12:42.058: INFO: Waiting for responses: map[]
  Feb 12 20:12:42.058: INFO: reached 192.168.71.248 after 0/1 tries
  Feb 12 20:12:42.058: INFO: Going to retry 0 out of 3 pods....
  Feb 12 20:12:42.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4593" for this suite. @ 02/12/24 20:12:42.063
• [14.321 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 02/12/24 20:12:42.073
  Feb 12 20:12:42.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename daemonsets @ 02/12/24 20:12:42.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:12:42.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:12:42.095
  STEP: Creating simple DaemonSet "daemon-set" @ 02/12/24 20:12:42.117
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/12/24 20:12:42.124
  Feb 12 20:12:42.129: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:12:42.130: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:12:42.133: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb 12 20:12:42.133: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 20:12:42.681280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:12:43.131: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:12:43.131: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:12:43.135: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb 12 20:12:43.135: INFO: Node ip-172-31-5-108 is running 0 daemon pod, expected 1
  E0212 20:12:43.682257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:12:44.130: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:12:44.130: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:12:44.135: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Feb 12 20:12:44.135: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 02/12/24 20:12:44.139
  STEP: DeleteCollection of the DaemonSets @ 02/12/24 20:12:44.145
  STEP: Verify that ReplicaSets have been deleted @ 02/12/24 20:12:44.156
  Feb 12 20:12:44.167: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31116"},"items":null}

  Feb 12 20:12:44.172: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31119"},"items":[{"metadata":{"name":"daemon-set-2g82g","generateName":"daemon-set-","namespace":"daemonsets-2753","uid":"8b7546da-0b99-4a2a-aa9a-dc34a24cfe25","resourceVersion":"31107","creationTimestamp":"2024-02-12T20:12:42Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4831ce5-e371-4c97-ae17-f11e029a2727","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-02-12T20:12:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4831ce5-e371-4c97-ae17-f11e029a2727\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-02-12T20:12:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.169.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rq9dd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rq9dd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-42-94","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-42-94"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"}],"hostIP":"172.31.42.94","hostIPs":[{"ip":"172.31.42.94"}],"podIP":"192.168.169.88","podIPs":[{"ip":"192.168.169.88"}],"startTime":"2024-02-12T20:12:42Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-02-12T20:12:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://547ca190177fef4ad747cb354c3c2755cd5ebf711193275b4c9d5bfebf18f53f","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-dctkv","generateName":"daemon-set-","namespace":"daemonsets-2753","uid":"65a81227-b4fb-480c-bcd7-cd744ff3ad99","resourceVersion":"31117","creationTimestamp":"2024-02-12T20:12:42Z","deletionTimestamp":"2024-02-12T20:13:14Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4831ce5-e371-4c97-ae17-f11e029a2727","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-02-12T20:12:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4831ce5-e371-4c97-ae17-f11e029a2727\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-02-12T20:12:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.219\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-zvtr2","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-zvtr2","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-5-108","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-5-108"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:43Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"}],"hostIP":"172.31.5.108","hostIPs":[{"ip":"172.31.5.108"}],"podIP":"192.168.150.219","podIPs":[{"ip":"192.168.150.219"}],"startTime":"2024-02-12T20:12:42Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-02-12T20:12:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://5b6543a72a7dadf341005936a2b30f582277e08a43d9cd5b63a6378d8dc13670","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qvxh2","generateName":"daemon-set-","namespace":"daemonsets-2753","uid":"373f7703-5de6-4c04-aab4-2fa1d0f9246b","resourceVersion":"31118","creationTimestamp":"2024-02-12T20:12:42Z","deletionTimestamp":"2024-02-12T20:13:14Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4831ce5-e371-4c97-ae17-f11e029a2727","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-02-12T20:12:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4831ce5-e371-4c97-ae17-f11e029a2727\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-02-12T20:12:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.251\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-pmz4j","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-pmz4j","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-91-42","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-91-42"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:43Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-12T20:12:42Z"}],"hostIP":"172.31.91.42","hostIPs":[{"ip":"172.31.91.42"}],"podIP":"192.168.71.251","podIPs":[{"ip":"192.168.71.251"}],"startTime":"2024-02-12T20:12:42Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-02-12T20:12:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://06d9b1511acbb3f84e6230afd0b88b7314aacb073d59bd937793f3d390a30686","started":true}],"qosClass":"BestEffort"}}]}

  Feb 12 20:12:44.196: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2753" for this suite. @ 02/12/24 20:12:44.2
• [2.136 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 02/12/24 20:12:44.209
  Feb 12 20:12:44.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:12:44.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:12:44.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:12:44.227
  STEP: Creating secret with name projected-secret-test-31c33d7a-f833-4037-a71c-b3e7715e1cc8 @ 02/12/24 20:12:44.231
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:12:44.236
  E0212 20:12:44.685433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:45.685497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:46.686058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:47.686916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:12:48.262
  Feb 12 20:12:48.266: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-projected-secrets-a38456b1-6791-4fd0-8ac2-ed0655a5b703 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:12:48.283
  Feb 12 20:12:48.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-522" for this suite. @ 02/12/24 20:12:48.304
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 02/12/24 20:12:48.313
  Feb 12 20:12:48.313: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-webhook @ 02/12/24 20:12:48.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:12:48.332
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:12:48.335
  STEP: Setting up server cert @ 02/12/24 20:12:48.338
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 02/12/24 20:12:48.542
  STEP: Deploying the custom resource conversion webhook pod @ 02/12/24 20:12:48.55
  STEP: Wait for the deployment to be ready @ 02/12/24 20:12:48.563
  Feb 12 20:12:48.572: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0212 20:12:48.687779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:49.688044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:12:50.585
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:12:50.598
  E0212 20:12:50.688155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:12:51.599: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Feb 12 20:12:51.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:12:51.688494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:52.688956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:53.689288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 02/12/24 20:12:54.166
  STEP: v2 custom resource should be converted @ 02/12/24 20:12:54.171
  E0212 20:12:54.689314      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:12:54.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1928" for this suite. @ 02/12/24 20:12:54.738
• [6.432 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 02/12/24 20:12:54.746
  Feb 12 20:12:54.746: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:12:54.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:12:54.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:12:54.766
  STEP: Creating a ResourceQuota @ 02/12/24 20:12:54.769
  STEP: Getting a ResourceQuota @ 02/12/24 20:12:54.773
  STEP: Updating a ResourceQuota @ 02/12/24 20:12:54.778
  STEP: Verifying a ResourceQuota was modified @ 02/12/24 20:12:54.783
  STEP: Deleting a ResourceQuota @ 02/12/24 20:12:54.787
  STEP: Verifying the deleted ResourceQuota @ 02/12/24 20:12:54.794
  Feb 12 20:12:54.797: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-177" for this suite. @ 02/12/24 20:12:54.801
• [0.064 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 02/12/24 20:12:54.81
  Feb 12 20:12:54.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename subpath @ 02/12/24 20:12:54.811
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:12:54.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:12:54.829
  STEP: Setting up data @ 02/12/24 20:12:54.832
  STEP: Creating pod pod-subpath-test-secret-4d5q @ 02/12/24 20:12:54.842
  STEP: Creating a pod to test atomic-volume-subpath @ 02/12/24 20:12:54.842
  E0212 20:12:55.690367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:56.690439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:57.690542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:58.690812      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:12:59.691344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:00.691454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:01.691546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:02.692323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:03.692871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:04.692995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:05.693114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:06.693199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:07.693329      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:08.693916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:09.694903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:10.695259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:11.695364      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:12.695382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:13.695777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:14.696063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:15.696983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:16.697071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:17.697520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:18.697847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:13:18.921
  Feb 12 20:13:18.926: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-subpath-test-secret-4d5q container test-container-subpath-secret-4d5q: <nil>
  STEP: delete the pod @ 02/12/24 20:13:18.94
  STEP: Deleting pod pod-subpath-test-secret-4d5q @ 02/12/24 20:13:18.956
  Feb 12 20:13:18.956: INFO: Deleting pod "pod-subpath-test-secret-4d5q" in namespace "subpath-5083"
  Feb 12 20:13:18.960: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5083" for this suite. @ 02/12/24 20:13:18.965
• [24.162 seconds]
------------------------------
S
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 02/12/24 20:13:18.973
  Feb 12 20:13:18.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pv @ 02/12/24 20:13:18.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:18.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:18.995
  STEP: Creating initial PV and PVC @ 02/12/24 20:13:18.999
  Feb 12 20:13:18.999: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-1943" @ 02/12/24 20:13:19.013
  STEP: Listing PVCs in namespace "pv-1943" @ 02/12/24 20:13:19.018
  STEP: Reading "pvc-ms6gm" Status @ 02/12/24 20:13:19.022
  STEP: Reading "pv-1943-kzl94" Status @ 02/12/24 20:13:19.026
  STEP: Patching "pvc-ms6gm" Status @ 02/12/24 20:13:19.031
  STEP: Patching "pv-1943-kzl94" Status @ 02/12/24 20:13:19.04
  STEP: Updating "pvc-ms6gm" Status @ 02/12/24 20:13:19.07
  STEP: Updating "pv-1943-kzl94" Status @ 02/12/24 20:13:19.08
  Feb 12 20:13:19.089: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Feb 12 20:13:19.089: INFO: Deleting PersistentVolumeClaim "pvc-ms6gm"
  Feb 12 20:13:19.096: INFO: Deleting PersistentVolume "pv-1943-kzl94"
  Feb 12 20:13:19.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-1943" for this suite. @ 02/12/24 20:13:19.107
• [0.141 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 02/12/24 20:13:19.114
  Feb 12 20:13:19.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 02/12/24 20:13:19.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:19.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:19.137
  STEP: Setting up the test @ 02/12/24 20:13:19.14
  STEP: Creating hostNetwork=false pod @ 02/12/24 20:13:19.14
  E0212 20:13:19.698793      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:20.699091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 02/12/24 20:13:21.163
  E0212 20:13:21.699920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:22.700194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 02/12/24 20:13:23.185
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 02/12/24 20:13:23.185
  Feb 12 20:13:23.185: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.185: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.186: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.186: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb 12 20:13:23.238: INFO: Exec stderr: ""
  Feb 12 20:13:23.238: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.239: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.239: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.239: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb 12 20:13:23.294: INFO: Exec stderr: ""
  Feb 12 20:13:23.294: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.294: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.295: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.295: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb 12 20:13:23.342: INFO: Exec stderr: ""
  Feb 12 20:13:23.342: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.342: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.342: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.342: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb 12 20:13:23.390: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 02/12/24 20:13:23.39
  Feb 12 20:13:23.390: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.390: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.390: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Feb 12 20:13:23.439: INFO: Exec stderr: ""
  Feb 12 20:13:23.439: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.439: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.439: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.439: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Feb 12 20:13:23.486: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 02/12/24 20:13:23.486
  Feb 12 20:13:23.486: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.486: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.486: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb 12 20:13:23.542: INFO: Exec stderr: ""
  Feb 12 20:13:23.542: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.542: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.542: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb 12 20:13:23.585: INFO: Exec stderr: ""
  Feb 12 20:13:23.585: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.586: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.586: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb 12 20:13:23.638: INFO: Exec stderr: ""
  Feb 12 20:13:23.638: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4426 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:13:23.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:13:23.638: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:13:23.638: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4426/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb 12 20:13:23.686: INFO: Exec stderr: ""
  Feb 12 20:13:23.686: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-4426" for this suite. @ 02/12/24 20:13:23.69
• [4.584 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS  E0212 20:13:23.701211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
SSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 02/12/24 20:13:23.702
  Feb 12 20:13:23.702: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename security-context-test @ 02/12/24 20:13:23.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:23.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:23.757
  E0212 20:13:24.701849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:25.702228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:13:25.806: INFO: Got logs for pod "busybox-privileged-false-ef179717-89ef-472e-8a3b-a9b1e4f352b1": "ip: RTNETLINK answers: Operation not permitted\n"
  Feb 12 20:13:25.806: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-170" for this suite. @ 02/12/24 20:13:25.811
• [2.133 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 02/12/24 20:13:25.834
  Feb 12 20:13:25.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:13:25.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:25.854
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:25.857
  Feb 12 20:13:25.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-776" for this suite. @ 02/12/24 20:13:25.906
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 02/12/24 20:13:25.913
  Feb 12 20:13:25.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename job @ 02/12/24 20:13:25.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:25.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:25.934
  STEP: Creating a job @ 02/12/24 20:13:25.937
  STEP: Ensure pods equal to parallelism count is attached to the job @ 02/12/24 20:13:25.943
  E0212 20:13:26.702057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:27.702178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 02/12/24 20:13:27.949
  STEP: updating /status @ 02/12/24 20:13:27.958
  STEP: get /status @ 02/12/24 20:13:27.966
  Feb 12 20:13:27.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1690" for this suite. @ 02/12/24 20:13:27.976
• [2.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 02/12/24 20:13:27.983
  Feb 12 20:13:27.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 20:13:27.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:28.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:28.005
  STEP: creating the pod @ 02/12/24 20:13:28.008
  STEP: submitting the pod to kubernetes @ 02/12/24 20:13:28.008
  W0212 20:13:28.018387      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0212 20:13:28.702930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:29.703170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 02/12/24 20:13:30.032
  STEP: updating the pod @ 02/12/24 20:13:30.037
  Feb 12 20:13:30.549: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c0a9245a-8e0a-459e-9603-e79431ecfa94"
  E0212 20:13:30.703274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:31.704176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:32.704963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:33.705051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:13:34.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5144" for this suite. @ 02/12/24 20:13:34.57
• [6.594 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 02/12/24 20:13:34.577
  Feb 12 20:13:34.577: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:13:34.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:34.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:34.6
  STEP: creating a ConfigMap @ 02/12/24 20:13:34.603
  STEP: fetching the ConfigMap @ 02/12/24 20:13:34.607
  STEP: patching the ConfigMap @ 02/12/24 20:13:34.611
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 02/12/24 20:13:34.616
  STEP: deleting the ConfigMap by collection with a label selector @ 02/12/24 20:13:34.619
  STEP: listing all ConfigMaps in test namespace @ 02/12/24 20:13:34.628
  Feb 12 20:13:34.632: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7632" for this suite. @ 02/12/24 20:13:34.635
• [0.064 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 02/12/24 20:13:34.642
  Feb 12 20:13:34.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename cronjob @ 02/12/24 20:13:34.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:13:34.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:13:34.661
  STEP: Creating a suspended cronjob @ 02/12/24 20:13:34.664
  STEP: Ensuring no jobs are scheduled @ 02/12/24 20:13:34.67
  E0212 20:13:34.705088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:35.705194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:36.705231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:37.706181      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:38.706866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:39.706964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:40.707800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:41.708391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:42.709084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:43.709213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:44.709463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:45.709567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:46.709747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:47.709847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:48.710704      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:49.710904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:50.711161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:51.711445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:52.711540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:53.712576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:54.713223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:55.713860      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:56.714144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:57.714247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:58.715250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:13:59.715355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:00.716124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:01.716215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:02.717184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:03.717770      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:04.718348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:05.718895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:06.718983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:07.719227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:08.719381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:09.719543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:10.720304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:11.720492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:12.721029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:13.721125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:14.721952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:15.723016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:16.723908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:17.724923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:18.725905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:19.726000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:20.726306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:21.726395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:22.726653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:23.726808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:24.727636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:25.727729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:26.728405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:27.728599      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:28.729605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:29.729835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:30.730239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:31.730891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:32.731343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:33.731442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:34.732151      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:35.732230      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:36.733241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:37.733313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:38.733872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:39.733969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:40.734740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:41.734840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:42.735155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:43.735716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:44.736491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:45.736593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:46.737497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:47.737764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:48.738256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:49.738352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:50.738826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:51.739011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:52.739524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:53.739788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:54.740786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:55.741577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:56.742216      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:57.742331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:58.742369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:14:59.742560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:00.742939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:01.743063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:02.743585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:03.743911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:04.744667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:05.744745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:06.745675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:07.745824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:08.746134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:09.746222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:10.746759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:11.746840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:12.747391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:13.747451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:14.748449      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:15.749496      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:16.750472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:17.750575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:18.751271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:19.751465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:20.751583      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:21.751800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:22.752487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:23.752842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:24.753849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:25.754077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:26.754707      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:27.754726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:28.754899      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:29.754983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:30.755476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:31.756249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:32.757165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:33.757740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:34.758588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:35.758901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:36.760000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:37.760130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:38.760670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:39.760913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:40.761075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:41.761278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:42.761344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:43.761801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:44.761974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:45.762076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:46.762929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:47.763134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:48.763858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:49.763978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:50.764404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:51.764490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:52.765223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:53.765320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:54.765989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:55.766877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:56.767454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:57.767550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:58.768243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:15:59.768416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:00.769134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:01.769437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:02.770410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:03.770887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:04.771692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:05.772516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:06.773460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:07.773568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:08.773676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:09.773949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:10.774679      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:11.775714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:12.775973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:13.776157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:14.776741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:15.776843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:16.776928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:17.777142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:18.777354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:19.777593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:20.777810      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:21.777973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:22.778241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:23.779294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:24.779409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:25.779500      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:26.780404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:27.781119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:28.781244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:29.781493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:30.782142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:31.782236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:32.782727      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:33.783661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:34.784192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:35.784899      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:36.785918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:37.786012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:38.786060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:39.787084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:40.787867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:41.788073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:42.788385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:43.789006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:44.789573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:45.789869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:46.790921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:47.791112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:48.791833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:49.791923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:50.792856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:51.792956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:52.793844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:53.794892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:54.795538      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:55.795634      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:56.795945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:57.796105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:58.796572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:16:59.796799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:00.796861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:01.797048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:02.797638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:03.797823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:04.798498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:05.798596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:06.799299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:07.799915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:08.800870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:09.801012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:10.801817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:11.804809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:12.805644      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:13.805813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:14.806158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:15.806256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:16.806904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:17.807055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:18.807258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:19.807452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:20.808305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:21.809864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:22.810925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:23.811158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:24.811474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:25.811762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:26.812739      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:27.812749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:28.813792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:29.813855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:30.813952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:31.816678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:32.817340      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:33.817435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:34.817852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:35.817988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:36.818445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:37.818544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:38.819395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:39.819597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:40.820590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:41.822040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:42.822131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:43.822726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:44.822782      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:45.822966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:46.823031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:47.823107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:48.823956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:49.824036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:50.824963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:51.825916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:52.826831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:53.826923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:54.827238      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:55.827277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:56.827765      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:57.828342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:58.829250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:17:59.829465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:00.829514      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:01.829907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:02.830846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:03.830929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:04.831036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:05.831154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:06.831619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:07.831717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:08.831949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:09.832225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:10.833121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:11.833529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:12.833645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:13.833893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:14.834911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:15.835008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:16.835395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:17.835482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:18.836515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:19.836853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:20.837856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:21.838719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:22.838837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:23.839031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:24.839820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:25.839904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:26.840588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:27.841619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:28.842423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:29.842930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:30.843938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:31.845029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:32.845814      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:33.845853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 02/12/24 20:18:34.68
  STEP: Removing cronjob @ 02/12/24 20:18:34.684
  Feb 12 20:18:34.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2549" for this suite. @ 02/12/24 20:18:34.696
• [300.063 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 02/12/24 20:18:34.705
  Feb 12 20:18:34.705: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 20:18:34.706
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:18:34.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:18:34.728
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:18:34.731
  E0212 20:18:34.846512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:35.846599      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:36.847049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:37.847157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:18:38.754
  Feb 12 20:18:38.759: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-d51b57cd-9361-47a9-8695-1d380693afba container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:18:38.776
  Feb 12 20:18:38.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4482" for this suite. @ 02/12/24 20:18:38.797
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 02/12/24 20:18:38.804
  Feb 12 20:18:38.804: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-preemption @ 02/12/24 20:18:38.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:18:38.825
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:18:38.828
  Feb 12 20:18:38.846: INFO: Waiting up to 1m0s for all nodes to be ready
  E0212 20:18:38.847925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:39.848064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:40.848678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:41.849817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:42.850353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:43.850506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:44.851332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:45.851614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:46.851614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:47.851905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:48.851912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:49.852057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:50.852215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:51.852553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:52.852591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:53.852740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:54.853053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:55.853288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:56.853461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:57.853837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:58.854158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:18:59.855090      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:00.855416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:01.857862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:02.858187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:03.858322      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:04.859194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:05.859361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:06.860332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:07.860532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:08.861061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:09.861161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:10.861475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:11.861619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:12.862174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:13.862323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:14.862999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:15.864130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:16.864095      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:17.864202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:18.864260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:19.865150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:20.865450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:21.865756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:22.866315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:23.866445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:24.867276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:25.867692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:26.867941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:27.868040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:28.868113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:29.868293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:30.868718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:31.868963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:32.869300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:33.869596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:34.870058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:35.870932      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:36.871202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:37.872199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:19:38.853: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 02/12/24 20:19:38.857
  Feb 12 20:19:38.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-preemption-path @ 02/12/24 20:19:38.858
  E0212 20:19:38.872678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:19:38.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:19:38.881
  STEP: Finding an available node @ 02/12/24 20:19:38.884
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 02/12/24 20:19:38.884
  E0212 20:19:39.872989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:40.873726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 02/12/24 20:19:40.908
  Feb 12 20:19:40.919: INFO: found a healthy node: ip-172-31-5-108
  E0212 20:19:41.873893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:42.874520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:43.875110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:44.875965      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:45.876032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:46.876239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:19:46.980: INFO: pods created so far: [1 1 1]
  Feb 12 20:19:46.980: INFO: length of pods created so far: 3
  E0212 20:19:47.876748      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:48.877572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:19:48.994: INFO: pods created so far: [2 2 1]
  E0212 20:19:49.878149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:50.879062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:51.879382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:52.879515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:53.879636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:54.879694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:55.879835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:19:56.068: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4470" for this suite. @ 02/12/24 20:19:56.072
  Feb 12 20:19:56.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2001" for this suite. @ 02/12/24 20:19:56.083
• [77.286 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 02/12/24 20:19:56.09
  Feb 12 20:19:56.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:19:56.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:19:56.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:19:56.111
  STEP: Creating configMap with name projected-configmap-test-volume-81f9340f-8bb0-483d-94fe-cc0ea83b5686 @ 02/12/24 20:19:56.114
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:19:56.118
  E0212 20:19:56.880697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:57.880991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:58.882017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:19:59.882921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:20:00.143
  Feb 12 20:20:00.148: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-projected-configmaps-9f8df60e-627f-48a3-8cd1-02b6fc1526e6 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:20:00.168
  Feb 12 20:20:00.184: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3664" for this suite. @ 02/12/24 20:20:00.189
• [4.108 seconds]
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 02/12/24 20:20:00.198
  Feb 12 20:20:00.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 20:20:00.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:00.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:00.22
  STEP: fetching services @ 02/12/24 20:20:00.223
  Feb 12 20:20:00.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7525" for this suite. @ 02/12/24 20:20:00.231
• [0.041 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 02/12/24 20:20:00.239
  Feb 12 20:20:00.239: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename ingress @ 02/12/24 20:20:00.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:00.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:00.26
  STEP: getting /apis @ 02/12/24 20:20:00.263
  STEP: getting /apis/networking.k8s.io @ 02/12/24 20:20:00.268
  STEP: getting /apis/networking.k8s.iov1 @ 02/12/24 20:20:00.269
  STEP: creating @ 02/12/24 20:20:00.271
  STEP: getting @ 02/12/24 20:20:00.292
  STEP: listing @ 02/12/24 20:20:00.296
  STEP: watching @ 02/12/24 20:20:00.301
  Feb 12 20:20:00.301: INFO: starting watch
  STEP: cluster-wide listing @ 02/12/24 20:20:00.302
  STEP: cluster-wide watching @ 02/12/24 20:20:00.306
  Feb 12 20:20:00.306: INFO: starting watch
  STEP: patching @ 02/12/24 20:20:00.308
  STEP: updating @ 02/12/24 20:20:00.314
  Feb 12 20:20:00.325: INFO: waiting for watch events with expected annotations
  Feb 12 20:20:00.325: INFO: saw patched and updated annotations
  STEP: patching /status @ 02/12/24 20:20:00.325
  STEP: updating /status @ 02/12/24 20:20:00.332
  STEP: get /status @ 02/12/24 20:20:00.344
  STEP: deleting @ 02/12/24 20:20:00.348
  STEP: deleting a collection @ 02/12/24 20:20:00.372
  Feb 12 20:20:00.392: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7083" for this suite. @ 02/12/24 20:20:00.398
• [0.167 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 02/12/24 20:20:00.407
  Feb 12 20:20:00.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:20:00.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:00.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:00.428
  STEP: Setting up server cert @ 02/12/24 20:20:00.457
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:20:00.677
  STEP: Deploying the webhook pod @ 02/12/24 20:20:00.688
  STEP: Wait for the deployment to be ready @ 02/12/24 20:20:00.702
  Feb 12 20:20:00.710: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:20:00.883458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:01.883574      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:20:02.722
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:20:02.735
  E0212 20:20:02.883914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:20:03.735: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 02/12/24 20:20:03.744
  STEP: create a namespace for the webhook @ 02/12/24 20:20:03.758
  STEP: create a configmap should be unconditionally rejected by the webhook @ 02/12/24 20:20:03.776
  Feb 12 20:20:03.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6412" for this suite. @ 02/12/24 20:20:03.838
  STEP: Destroying namespace "webhook-markers-3988" for this suite. @ 02/12/24 20:20:03.847
  STEP: Destroying namespace "fail-closed-namespace-5533" for this suite. @ 02/12/24 20:20:03.854
• [3.454 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 02/12/24 20:20:03.861
  Feb 12 20:20:03.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/12/24 20:20:03.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:03.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:03.882
  E0212 20:20:03.883887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: fetching the /apis discovery document @ 02/12/24 20:20:03.885
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 02/12/24 20:20:03.886
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 02/12/24 20:20:03.886
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 02/12/24 20:20:03.886
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 02/12/24 20:20:03.887
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 02/12/24 20:20:03.887
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 02/12/24 20:20:03.889
  Feb 12 20:20:03.889: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9960" for this suite. @ 02/12/24 20:20:03.892
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 02/12/24 20:20:03.9
  Feb 12 20:20:03.900: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 20:20:03.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:03.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:03.922
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6382.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6382.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 02/12/24 20:20:03.925
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6382.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6382.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 02/12/24 20:20:03.925
  STEP: creating a pod to probe /etc/hosts @ 02/12/24 20:20:03.925
  STEP: submitting the pod to kubernetes @ 02/12/24 20:20:03.925
  E0212 20:20:04.884324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:05.884552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/12/24 20:20:05.943
  STEP: looking for the results for each expected name from probers @ 02/12/24 20:20:05.947
  Feb 12 20:20:05.968: INFO: DNS probes using dns-6382/dns-test-998c99ba-dc91-45ec-a16b-3892b369b827 succeeded

  STEP: deleting the pod @ 02/12/24 20:20:05.969
  Feb 12 20:20:05.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6382" for this suite. @ 02/12/24 20:20:05.985
• [2.094 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 02/12/24 20:20:05.994
  Feb 12 20:20:05.994: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-runtime @ 02/12/24 20:20:05.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:06.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:06.014
  STEP: create the container @ 02/12/24 20:20:06.017
  W0212 20:20:06.026231      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 02/12/24 20:20:06.026
  E0212 20:20:06.884890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:07.885063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:08.885815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/12/24 20:20:09.046
  STEP: the container should be terminated @ 02/12/24 20:20:09.051
  STEP: the termination message should be set @ 02/12/24 20:20:09.051
  Feb 12 20:20:09.051: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 02/12/24 20:20:09.051
  Feb 12 20:20:09.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2789" for this suite. @ 02/12/24 20:20:09.074
• [3.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 02/12/24 20:20:09.081
  Feb 12 20:20:09.081: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:20:09.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:09.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:09.109
  STEP: Creating configMap with name projected-configmap-test-volume-d34d8a97-a7f8-418b-a960-1f6216750ccc @ 02/12/24 20:20:09.112
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:20:09.116
  E0212 20:20:09.885859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:10.885991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:11.886933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:12.887054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:20:13.138
  Feb 12 20:20:13.141: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-configmaps-ad803c0c-40c3-4942-aacb-8fc187d80672 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:20:13.154
  Feb 12 20:20:13.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7578" for this suite. @ 02/12/24 20:20:13.177
• [4.104 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 02/12/24 20:20:13.184
  Feb 12 20:20:13.184: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:20:13.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:13.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:13.204
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 02/12/24 20:20:13.207
  E0212 20:20:13.887963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:14.888168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:15.888443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:16.888654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:20:17.231
  Feb 12 20:20:17.236: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-acbec7ba-6fed-428c-8072-07ee6952ae06 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:20:17.244
  Feb 12 20:20:17.261: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7807" for this suite. @ 02/12/24 20:20:17.264
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 02/12/24 20:20:17.273
  Feb 12 20:20:17.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:20:17.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:17.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:17.294
  STEP: creating secret secrets-943/secret-test-9bec4708-d2d9-4328-a992-ad9ddd403ebe @ 02/12/24 20:20:17.297
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:20:17.301
  E0212 20:20:17.888864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:18.888963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:19.889066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:20.889172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:20:21.324
  Feb 12 20:20:21.329: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-62359ff7-b15e-4188-8842-4ab7d4ac41e0 container env-test: <nil>
  STEP: delete the pod @ 02/12/24 20:20:21.337
  Feb 12 20:20:21.355: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-943" for this suite. @ 02/12/24 20:20:21.359
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 02/12/24 20:20:21.369
  Feb 12 20:20:21.369: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 20:20:21.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:21.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:21.392
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/12/24 20:20:21.395
  Feb 12 20:20:21.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-5206 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Feb 12 20:20:21.445: INFO: stderr: ""
  Feb 12 20:20:21.445: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 02/12/24 20:20:21.445
  Feb 12 20:20:21.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-5206 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  Feb 12 20:20:21.496: INFO: stderr: ""
  Feb 12 20:20:21.496: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/12/24 20:20:21.496
  Feb 12 20:20:21.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-5206 delete pods e2e-test-httpd-pod'
  E0212 20:20:21.889657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:22.889956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:20:23.220: INFO: stderr: ""
  Feb 12 20:20:23.220: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Feb 12 20:20:23.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5206" for this suite. @ 02/12/24 20:20:23.224
• [1.863 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 02/12/24 20:20:23.232
  Feb 12 20:20:23.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename endpointslice @ 02/12/24 20:20:23.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:23.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:23.258
  E0212 20:20:23.890058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:24.890156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:25.890931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:26.891159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:20:27.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-342" for this suite. @ 02/12/24 20:20:27.319
• [4.096 seconds]
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 02/12/24 20:20:27.328
  Feb 12 20:20:27.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 20:20:27.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:27.348
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:27.351
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 02/12/24 20:20:27.354
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 02/12/24 20:20:27.354
  STEP: creating a pod to probe DNS @ 02/12/24 20:20:27.354
  STEP: submitting the pod to kubernetes @ 02/12/24 20:20:27.354
  E0212 20:20:27.891284      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:28.891416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/12/24 20:20:29.377
  STEP: looking for the results for each expected name from probers @ 02/12/24 20:20:29.381
  Feb 12 20:20:29.401: INFO: DNS probes using dns-2692/dns-test-9d63b1f5-60c7-4918-adca-7c637483b509 succeeded

  STEP: deleting the pod @ 02/12/24 20:20:29.401
  Feb 12 20:20:29.414: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2692" for this suite. @ 02/12/24 20:20:29.417
• [2.095 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 02/12/24 20:20:29.424
  Feb 12 20:20:29.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 20:20:29.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:29.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:29.445
  Feb 12 20:20:29.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:20:29.892039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:30.892438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:31.892506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:20:32.544: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2816" for this suite. @ 02/12/24 20:20:32.548
• [3.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 02/12/24 20:20:32.559
  Feb 12 20:20:32.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:20:32.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:32.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:32.596
  STEP: Creating a ResourceQuota with terminating scope @ 02/12/24 20:20:32.599
  STEP: Ensuring ResourceQuota status is calculated @ 02/12/24 20:20:32.606
  E0212 20:20:32.892641      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:33.892917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 02/12/24 20:20:34.61
  STEP: Ensuring ResourceQuota status is calculated @ 02/12/24 20:20:34.615
  E0212 20:20:34.893008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:35.893096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 02/12/24 20:20:36.621
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 02/12/24 20:20:36.635
  E0212 20:20:36.893785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:37.893877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 02/12/24 20:20:38.641
  E0212 20:20:38.894575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:39.894669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/12/24 20:20:40.647
  STEP: Ensuring resource quota status released the pod usage @ 02/12/24 20:20:40.659
  E0212 20:20:40.895320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:41.895383      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 02/12/24 20:20:42.664
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 02/12/24 20:20:42.676
  E0212 20:20:42.896219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:43.896335      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 02/12/24 20:20:44.681
  E0212 20:20:44.897145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:45.897361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/12/24 20:20:46.686
  STEP: Ensuring resource quota status released the pod usage @ 02/12/24 20:20:46.697
  E0212 20:20:46.898106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:47.898217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:20:48.704: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4638" for this suite. @ 02/12/24 20:20:48.715
• [16.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 02/12/24 20:20:48.724
  Feb 12 20:20:48.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename subjectreview @ 02/12/24 20:20:48.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:48.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:48.747
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-7364" @ 02/12/24 20:20:48.75
  Feb 12 20:20:48.755: INFO: saUsername: "system:serviceaccount:subjectreview-7364:e2e"
  Feb 12 20:20:48.755: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-7364"}
  Feb 12 20:20:48.755: INFO: saUID: "bad9a8e1-df50-41bf-adad-df1a05a0b4fc"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-7364:e2e" @ 02/12/24 20:20:48.755
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-7364:e2e" @ 02/12/24 20:20:48.755
  Feb 12 20:20:48.757: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-7364:e2e" api 'list' configmaps in "subjectreview-7364" namespace @ 02/12/24 20:20:48.757
  Feb 12 20:20:48.758: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-7364:e2e" @ 02/12/24 20:20:48.758
  Feb 12 20:20:48.760: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Feb 12 20:20:48.760: INFO: LocalSubjectAccessReview has been verified
  Feb 12 20:20:48.760: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-7364" for this suite. @ 02/12/24 20:20:48.764
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 02/12/24 20:20:48.771
  Feb 12 20:20:48.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename watch @ 02/12/24 20:20:48.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:48.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:48.792
  STEP: creating a watch on configmaps with a certain label @ 02/12/24 20:20:48.795
  STEP: creating a new configmap @ 02/12/24 20:20:48.796
  STEP: modifying the configmap once @ 02/12/24 20:20:48.802
  STEP: changing the label value of the configmap @ 02/12/24 20:20:48.811
  STEP: Expecting to observe a delete notification for the watched object @ 02/12/24 20:20:48.819
  Feb 12 20:20:48.819: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3715  6c190837-9e45-4714-9815-ecf555207362 33396 0 2024-02-12 20:20:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-12 20:20:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:20:48.819: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3715  6c190837-9e45-4714-9815-ecf555207362 33397 0 2024-02-12 20:20:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-12 20:20:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:20:48.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3715  6c190837-9e45-4714-9815-ecf555207362 33398 0 2024-02-12 20:20:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-12 20:20:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 02/12/24 20:20:48.82
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 02/12/24 20:20:48.827
  E0212 20:20:48.898788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:49.898863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:50.898992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:51.899332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:52.899478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:53.899706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:54.899888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:55.899971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:56.900101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:20:57.900319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 02/12/24 20:20:58.827
  STEP: modifying the configmap a third time @ 02/12/24 20:20:58.839
  STEP: deleting the configmap @ 02/12/24 20:20:58.847
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 02/12/24 20:20:58.853
  Feb 12 20:20:58.853: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3715  6c190837-9e45-4714-9815-ecf555207362 33439 0 2024-02-12 20:20:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-12 20:20:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:20:58.853: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3715  6c190837-9e45-4714-9815-ecf555207362 33440 0 2024-02-12 20:20:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-12 20:20:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:20:58.853: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3715  6c190837-9e45-4714-9815-ecf555207362 33441 0 2024-02-12 20:20:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-12 20:20:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:20:58.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3715" for this suite. @ 02/12/24 20:20:58.858
• [10.096 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 02/12/24 20:20:58.866
  Feb 12 20:20:58.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-preemption @ 02/12/24 20:20:58.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:20:58.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:20:58.894
  E0212 20:20:58.900525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:20:58.911: INFO: Waiting up to 1m0s for all nodes to be ready
  E0212 20:20:59.900628      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:00.900903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:01.901017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:02.901100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:03.902157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:04.902262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:05.902936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:06.903168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:07.903266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:08.903927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:09.904061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:10.904539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:11.904638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:12.904738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:13.905013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:14.905070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:15.905201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:16.905646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:17.905853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:18.906900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:19.907033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:20.907189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:21.907516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:22.907608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:23.907710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:24.908010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:25.908135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:26.908339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:27.908558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:28.908635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:29.908687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:30.909021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:31.909125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:32.909249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:33.910233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:34.910325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:35.910431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:36.910505      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:37.910636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:38.911244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:39.911357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:40.911355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:41.911625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:42.911661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:43.911989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:44.912338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:45.912502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:46.913146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:47.913355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:48.914113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:49.915149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:50.915816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:51.915976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:52.915930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:53.916168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:54.916146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:55.916295      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:56.916299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:21:57.916541      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:21:58.916: INFO: Waiting for terminating namespaces to be deleted...
  E0212 20:21:58.917071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a kubernetes client @ 02/12/24 20:21:58.92
  Feb 12 20:21:58.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sched-preemption-path @ 02/12/24 20:21:58.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:21:58.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:21:58.942
  Feb 12 20:21:58.962: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Feb 12 20:21:58.967: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Feb 12 20:21:59.053: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-8726" for this suite. @ 02/12/24 20:21:59.058
  Feb 12 20:21:59.066: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-540" for this suite. @ 02/12/24 20:21:59.071
• [60.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 02/12/24 20:21:59.079
  Feb 12 20:21:59.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 20:21:59.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:21:59.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:21:59.1
  STEP: creating a Pod with a static label @ 02/12/24 20:21:59.11
  STEP: watching for Pod to be ready @ 02/12/24 20:21:59.12
  Feb 12 20:21:59.122: INFO: observed Pod pod-test in namespace pods-5077 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Feb 12 20:21:59.125: INFO: observed Pod pod-test in namespace pods-5077 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC  }]
  Feb 12 20:21:59.153: INFO: observed Pod pod-test in namespace pods-5077 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC  }]
  E0212 20:21:59.917207      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:00.352: INFO: Found Pod pod-test in namespace pods-5077 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:22:00 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:22:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:22:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-12 20:21:59 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 02/12/24 20:22:00.357
  STEP: getting the Pod and ensuring that it's patched @ 02/12/24 20:22:00.366
  STEP: replacing the Pod's status Ready condition to False @ 02/12/24 20:22:00.369
  STEP: check the Pod again to ensure its Ready conditions are False @ 02/12/24 20:22:00.381
  STEP: deleting the Pod via a Collection with a LabelSelector @ 02/12/24 20:22:00.381
  STEP: watching for the Pod to be deleted @ 02/12/24 20:22:00.396
  Feb 12 20:22:00.398: INFO: observed event type MODIFIED
  E0212 20:22:00.917907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:01.918922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:02.361: INFO: observed event type MODIFIED
  Feb 12 20:22:02.520: INFO: observed event type MODIFIED
  E0212 20:22:02.919321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:03.364: INFO: observed event type MODIFIED
  Feb 12 20:22:03.383: INFO: observed event type MODIFIED
  Feb 12 20:22:03.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5077" for this suite. @ 02/12/24 20:22:03.394
• [4.323 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 02/12/24 20:22:03.402
  Feb 12 20:22:03.402: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:22:03.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:03.445
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:03.452
  STEP: Setting up server cert @ 02/12/24 20:22:03.478
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:22:03.704
  STEP: Deploying the webhook pod @ 02/12/24 20:22:03.714
  STEP: Wait for the deployment to be ready @ 02/12/24 20:22:03.727
  Feb 12 20:22:03.737: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:22:03.919379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:04.919452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:22:05.75
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:22:05.759
  E0212 20:22:05.920186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:06.760: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 02/12/24 20:22:06.832
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/12/24 20:22:06.864
  STEP: Deleting the collection of validation webhooks @ 02/12/24 20:22:06.891
  E0212 20:22:06.920601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/12/24 20:22:06.944
  Feb 12 20:22:06.999: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9629" for this suite. @ 02/12/24 20:22:07.006
  STEP: Destroying namespace "webhook-markers-1275" for this suite. @ 02/12/24 20:22:07.015
• [3.619 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 02/12/24 20:22:07.021
  Feb 12 20:22:07.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:22:07.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:07.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:07.041
  STEP: Setting up server cert @ 02/12/24 20:22:07.065
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:22:07.482
  STEP: Deploying the webhook pod @ 02/12/24 20:22:07.489
  STEP: Wait for the deployment to be ready @ 02/12/24 20:22:07.503
  Feb 12 20:22:07.514: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:22:07.920739      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:08.920836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:22:09.526
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:22:09.536
  E0212 20:22:09.920922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:10.536: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 20:22:10.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:22:10.921827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3560-crds.webhook.example.com via the AdmissionRegistration API @ 02/12/24 20:22:11.06
  STEP: Creating a custom resource that should be mutated by the webhook @ 02/12/24 20:22:11.075
  E0212 20:22:11.922916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:12.923133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:13.672: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1120" for this suite. @ 02/12/24 20:22:13.678
  STEP: Destroying namespace "webhook-markers-1283" for this suite. @ 02/12/24 20:22:13.685
• [6.671 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 02/12/24 20:22:13.693
  Feb 12 20:22:13.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replication-controller @ 02/12/24 20:22:13.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:13.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:13.717
  STEP: Creating ReplicationController "e2e-rc-jtbsg" @ 02/12/24 20:22:13.721
  Feb 12 20:22:13.728: INFO: Get Replication Controller "e2e-rc-jtbsg" to confirm replicas
  E0212 20:22:13.923670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:14.728: INFO: Get Replication Controller "e2e-rc-jtbsg" to confirm replicas
  Feb 12 20:22:14.733: INFO: Found 1 replicas for "e2e-rc-jtbsg" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-jtbsg" @ 02/12/24 20:22:14.733
  STEP: Updating a scale subresource @ 02/12/24 20:22:14.736
  STEP: Verifying replicas where modified for replication controller "e2e-rc-jtbsg" @ 02/12/24 20:22:14.743
  Feb 12 20:22:14.743: INFO: Get Replication Controller "e2e-rc-jtbsg" to confirm replicas
  E0212 20:22:14.924046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:15.743: INFO: Get Replication Controller "e2e-rc-jtbsg" to confirm replicas
  Feb 12 20:22:15.747: INFO: Found 2 replicas for "e2e-rc-jtbsg" replication controller
  Feb 12 20:22:15.747: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9072" for this suite. @ 02/12/24 20:22:15.751
• [2.066 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 02/12/24 20:22:15.758
  Feb 12 20:22:15.758: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 20:22:15.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:15.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:15.779
  E0212 20:22:15.924945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:16.925553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 02/12/24 20:22:17.805
  Feb 12 20:22:17.805: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6866 pod-service-account-2fb262fd-b911-4d78-8489-cd42c132c981 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 02/12/24 20:22:17.904
  Feb 12 20:22:17.904: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6866 pod-service-account-2fb262fd-b911-4d78-8489-cd42c132c981 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  E0212 20:22:17.926190      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 02/12/24 20:22:18
  Feb 12 20:22:18.000: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6866 pod-service-account-2fb262fd-b911-4d78-8489-cd42c132c981 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Feb 12 20:22:18.089: INFO: Got root ca configmap in namespace "svcaccounts-6866"
  Feb 12 20:22:18.092: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6866" for this suite. @ 02/12/24 20:22:18.095
• [2.344 seconds]
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 02/12/24 20:22:18.103
  Feb 12 20:22:18.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename init-container @ 02/12/24 20:22:18.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:18.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:18.124
  STEP: creating the pod @ 02/12/24 20:22:18.127
  Feb 12 20:22:18.127: INFO: PodSpec: initContainers in spec.initContainers
  E0212 20:22:18.926302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:19.926578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:20.926670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:21.926776      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:22.400: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7600" for this suite. @ 02/12/24 20:22:22.405
• [4.309 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 02/12/24 20:22:22.412
  Feb 12 20:22:22.412: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 20:22:22.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:22.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:22.433
  STEP: Creating a test headless service @ 02/12/24 20:22:22.436
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9082.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9082.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 02/12/24 20:22:22.442
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9082.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9082.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 02/12/24 20:22:22.443
  STEP: creating a pod to probe DNS @ 02/12/24 20:22:22.443
  STEP: submitting the pod to kubernetes @ 02/12/24 20:22:22.443
  E0212 20:22:22.927579      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:23.928576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/12/24 20:22:24.466
  STEP: looking for the results for each expected name from probers @ 02/12/24 20:22:24.47
  Feb 12 20:22:24.491: INFO: DNS probes using dns-9082/dns-test-d5b1b352-01fb-4946-a230-cc8b71aa288a succeeded

  STEP: deleting the pod @ 02/12/24 20:22:24.491
  STEP: deleting the test headless service @ 02/12/24 20:22:24.507
  Feb 12 20:22:24.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9082" for this suite. @ 02/12/24 20:22:24.527
• [2.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 02/12/24 20:22:24.536
  Feb 12 20:22:24.536: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:22:24.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:24.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:24.56
  STEP: Creating the pod @ 02/12/24 20:22:24.563
  E0212 20:22:24.928678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:25.928872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:26.928998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:27.110: INFO: Successfully updated pod "annotationupdatef12b38dc-aed8-42a0-a1ae-7c8c3d4a9ea8"
  E0212 20:22:27.929876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:28.930911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:29.931022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:30.931128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:31.138: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-909" for this suite. @ 02/12/24 20:22:31.143
• [6.615 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 02/12/24 20:22:31.152
  Feb 12 20:22:31.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 20:22:31.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:31.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:31.175
  STEP: creating service endpoint-test2 in namespace services-6965 @ 02/12/24 20:22:31.178
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6965 to expose endpoints map[] @ 02/12/24 20:22:31.19
  Feb 12 20:22:31.193: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0212 20:22:31.932093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:32.206: INFO: successfully validated that service endpoint-test2 in namespace services-6965 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-6965 @ 02/12/24 20:22:32.206
  E0212 20:22:32.933085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:33.933278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6965 to expose endpoints map[pod1:[80]] @ 02/12/24 20:22:34.232
  Feb 12 20:22:34.249: INFO: successfully validated that service endpoint-test2 in namespace services-6965 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 02/12/24 20:22:34.249
  Feb 12 20:22:34.249: INFO: Creating new exec pod
  E0212 20:22:34.933763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:35.933868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:36.934761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:37.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6965 exec execpodzvjck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Feb 12 20:22:37.376: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Feb 12 20:22:37.376: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:22:37.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6965 exec execpodzvjck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.244 80'
  Feb 12 20:22:37.470: INFO: stderr: "+ nc -v -t -w 2 10.152.183.244 80\n+ echo hostName\nConnection to 10.152.183.244 80 port [tcp/http] succeeded!\n"
  Feb 12 20:22:37.470: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-6965 @ 02/12/24 20:22:37.47
  E0212 20:22:37.935403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:38.935507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6965 to expose endpoints map[pod1:[80] pod2:[80]] @ 02/12/24 20:22:39.489
  Feb 12 20:22:39.507: INFO: successfully validated that service endpoint-test2 in namespace services-6965 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 02/12/24 20:22:39.507
  E0212 20:22:39.936249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:40.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6965 exec execpodzvjck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Feb 12 20:22:40.607: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Feb 12 20:22:40.607: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:22:40.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6965 exec execpodzvjck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.244 80'
  Feb 12 20:22:40.697: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.244 80\nConnection to 10.152.183.244 80 port [tcp/http] succeeded!\n"
  Feb 12 20:22:40.697: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-6965 @ 02/12/24 20:22:40.697
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6965 to expose endpoints map[pod2:[80]] @ 02/12/24 20:22:40.71
  E0212 20:22:40.937007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:41.734: INFO: successfully validated that service endpoint-test2 in namespace services-6965 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 02/12/24 20:22:41.734
  E0212 20:22:41.938004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:42.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6965 exec execpodzvjck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Feb 12 20:22:42.835: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Feb 12 20:22:42.835: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:22:42.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-6965 exec execpodzvjck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.244 80'
  Feb 12 20:22:42.931: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 10.152.183.244 80\nConnection to 10.152.183.244 80 port [tcp/http] succeeded!\n"
  Feb 12 20:22:42.931: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-6965 @ 02/12/24 20:22:42.931
  E0212 20:22:42.938699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6965 to expose endpoints map[] @ 02/12/24 20:22:42.952
  Feb 12 20:22:42.961: INFO: successfully validated that service endpoint-test2 in namespace services-6965 exposes endpoints map[]
  Feb 12 20:22:42.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6965" for this suite. @ 02/12/24 20:22:42.984
• [11.840 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 02/12/24 20:22:42.992
  Feb 12 20:22:42.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 20:22:42.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:43.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:43.017
  STEP: create the rc @ 02/12/24 20:22:43.026
  W0212 20:22:43.032766      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0212 20:22:43.938836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:44.939043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:45.939436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:46.944436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:47.945500      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:48.945933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 02/12/24 20:22:49.047
  STEP: wait for the rc to be deleted @ 02/12/24 20:22:49.055
  E0212 20:22:49.946926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:50.068: INFO: 80 pods remaining
  Feb 12 20:22:50.068: INFO: 80 pods has nil DeletionTimestamp
  Feb 12 20:22:50.068: INFO: 
  E0212 20:22:50.947093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:51.069: INFO: 71 pods remaining
  Feb 12 20:22:51.069: INFO: 70 pods has nil DeletionTimestamp
  Feb 12 20:22:51.069: INFO: 
  E0212 20:22:51.953873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:52.078: INFO: 60 pods remaining
  Feb 12 20:22:52.078: INFO: 60 pods has nil DeletionTimestamp
  Feb 12 20:22:52.078: INFO: 
  E0212 20:22:52.953908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:53.075: INFO: 40 pods remaining
  Feb 12 20:22:53.075: INFO: 40 pods has nil DeletionTimestamp
  Feb 12 20:22:53.075: INFO: 
  E0212 20:22:53.954593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:54.067: INFO: 31 pods remaining
  Feb 12 20:22:54.067: INFO: 30 pods has nil DeletionTimestamp
  Feb 12 20:22:54.067: INFO: 
  E0212 20:22:54.954712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:55.064: INFO: 20 pods remaining
  Feb 12 20:22:55.064: INFO: 20 pods has nil DeletionTimestamp
  Feb 12 20:22:55.064: INFO: 
  E0212 20:22:55.954853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/12/24 20:22:56.066
  W0212 20:22:56.072470      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb 12 20:22:56.072: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb 12 20:22:56.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7930" for this suite. @ 02/12/24 20:22:56.078
• [13.095 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 02/12/24 20:22:56.087
  Feb 12 20:22:56.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 20:22:56.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:22:56.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:22:56.114
  Feb 12 20:22:56.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:22:56.954910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 02/12/24 20:22:57.425
  Feb 12 20:22:57.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 create -f -'
  E0212 20:22:57.955442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:22:58.955528      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:59.495: INFO: stderr: ""
  Feb 12 20:22:59.496: INFO: stdout: "e2e-test-crd-publish-openapi-3689-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Feb 12 20:22:59.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 delete e2e-test-crd-publish-openapi-3689-crds test-foo'
  Feb 12 20:22:59.557: INFO: stderr: ""
  Feb 12 20:22:59.557: INFO: stdout: "e2e-test-crd-publish-openapi-3689-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Feb 12 20:22:59.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 apply -f -'
  Feb 12 20:22:59.614: INFO: stderr: ""
  Feb 12 20:22:59.614: INFO: stdout: "e2e-test-crd-publish-openapi-3689-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Feb 12 20:22:59.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 delete e2e-test-crd-publish-openapi-3689-crds test-foo'
  Feb 12 20:22:59.666: INFO: stderr: ""
  Feb 12 20:22:59.666: INFO: stdout: "e2e-test-crd-publish-openapi-3689-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 02/12/24 20:22:59.666
  Feb 12 20:22:59.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 create -f -'
  Feb 12 20:22:59.710: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 02/12/24 20:22:59.71
  Feb 12 20:22:59.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 create -f -'
  Feb 12 20:22:59.754: INFO: rc: 1
  Feb 12 20:22:59.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 apply -f -'
  Feb 12 20:22:59.805: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 02/12/24 20:22:59.805
  Feb 12 20:22:59.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 create -f -'
  Feb 12 20:22:59.850: INFO: rc: 1
  Feb 12 20:22:59.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 --namespace=crd-publish-openapi-2254 apply -f -'
  Feb 12 20:22:59.901: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 02/12/24 20:22:59.902
  Feb 12 20:22:59.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 explain e2e-test-crd-publish-openapi-3689-crds'
  Feb 12 20:22:59.944: INFO: stderr: ""
  Feb 12 20:22:59.944: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3689-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 02/12/24 20:22:59.944
  Feb 12 20:22:59.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 explain e2e-test-crd-publish-openapi-3689-crds.metadata'
  E0212 20:22:59.956286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:22:59.987: INFO: stderr: ""
  Feb 12 20:22:59.987: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3689-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Feb 12 20:22:59.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 explain e2e-test-crd-publish-openapi-3689-crds.spec'
  Feb 12 20:23:00.029: INFO: stderr: ""
  Feb 12 20:23:00.030: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3689-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Feb 12 20:23:00.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 explain e2e-test-crd-publish-openapi-3689-crds.spec.bars'
  Feb 12 20:23:00.073: INFO: stderr: ""
  Feb 12 20:23:00.073: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3689-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 02/12/24 20:23:00.073
  Feb 12 20:23:00.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-2254 explain e2e-test-crd-publish-openapi-3689-crds.spec.bars2'
  Feb 12 20:23:00.115: INFO: rc: 1
  E0212 20:23:00.956469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:23:01.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2254" for this suite. @ 02/12/24 20:23:01.416
• [5.336 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 02/12/24 20:23:01.423
  Feb 12 20:23:01.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-watch @ 02/12/24 20:23:01.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:23:01.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:23:01.449
  Feb 12 20:23:01.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:23:01.956584      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:02.956720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:03.956821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 02/12/24 20:23:04.007
  Feb 12 20:23:04.012: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-12T20:23:04Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-12T20:23:04Z]] name:name1 resourceVersion:36647 uid:d16fe7e6-2d7a-4db7-9bf4-dc52e2f09dcb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0212 20:23:04.956949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:05.957116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:06.957441      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:07.958491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:08.958578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:09.958777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:10.959037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:11.959133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:12.959382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:13.959967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 02/12/24 20:23:14.013
  Feb 12 20:23:14.019: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-12T20:23:14Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-12T20:23:14Z]] name:name2 resourceVersion:36689 uid:4b97c5df-c302-400b-af08-227181142d8b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0212 20:23:14.960062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:15.961136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:16.961244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:17.961821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:18.961944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:19.963021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:20.963137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:21.963535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:22.963612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:23.964058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 02/12/24 20:23:24.02
  Feb 12 20:23:24.028: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-12T20:23:04Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-12T20:23:24Z]] name:name1 resourceVersion:36709 uid:d16fe7e6-2d7a-4db7-9bf4-dc52e2f09dcb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0212 20:23:24.964689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:25.964789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:26.965654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:27.966439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:28.966697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:29.966988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:30.967174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:31.967261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:32.967510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:33.967715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 02/12/24 20:23:34.029
  Feb 12 20:23:34.036: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-12T20:23:14Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-12T20:23:34Z]] name:name2 resourceVersion:36730 uid:4b97c5df-c302-400b-af08-227181142d8b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0212 20:23:34.967816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:35.968836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:36.968930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:37.969233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:38.969518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:39.969755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:40.969825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:41.969897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:42.970917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:43.971084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 02/12/24 20:23:44.037
  Feb 12 20:23:44.046: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-12T20:23:04Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-12T20:23:24Z]] name:name1 resourceVersion:36750 uid:d16fe7e6-2d7a-4db7-9bf4-dc52e2f09dcb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0212 20:23:44.971266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:45.971311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:46.971411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:47.972458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:48.972574      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:49.972666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:50.972779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:51.972893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:52.973002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:53.973794      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 02/12/24 20:23:54.047
  Feb 12 20:23:54.056: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-12T20:23:14Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-12T20:23:34Z]] name:name2 resourceVersion:36770 uid:4b97c5df-c302-400b-af08-227181142d8b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0212 20:23:54.973937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:55.974004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:56.974109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:57.974447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:58.974554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:23:59.974636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:00.975605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:01.975734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:02.976009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:03.976834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:04.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-8100" for this suite. @ 02/12/24 20:24:04.577
• [63.163 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 02/12/24 20:24:04.586
  Feb 12 20:24:04.586: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:24:04.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:04.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:04.604
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 02/12/24 20:24:04.607
  E0212 20:24:04.976976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:05.977088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:06.977179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:07.977540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:24:08.629
  Feb 12 20:24:08.632: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-ef6d70ee-0b0b-4419-90a6-de3a4f7fa20e container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:24:08.648
  Feb 12 20:24:08.664: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7849" for this suite. @ 02/12/24 20:24:08.668
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 02/12/24 20:24:08.675
  Feb 12 20:24:08.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 20:24:08.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:08.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:08.696
  STEP: Creating a test headless service @ 02/12/24 20:24:08.698
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-93.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-93.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-93.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-93.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-93.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-93.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-93.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-93.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 229.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.229_udp@PTR;check="$$(dig +tcp +noall +answer +search 229.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.229_tcp@PTR;sleep 1; done
   @ 02/12/24 20:24:08.718
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-93.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-93.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-93.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-93.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-93.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-93.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-93.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-93.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-93.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 229.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.229_udp@PTR;check="$$(dig +tcp +noall +answer +search 229.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.229_tcp@PTR;sleep 1; done
   @ 02/12/24 20:24:08.719
  STEP: creating a pod to probe DNS @ 02/12/24 20:24:08.719
  STEP: submitting the pod to kubernetes @ 02/12/24 20:24:08.719
  E0212 20:24:08.978133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:09.978242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/12/24 20:24:10.747
  STEP: looking for the results for each expected name from probers @ 02/12/24 20:24:10.751
  Feb 12 20:24:10.755: INFO: Unable to read wheezy_udp@dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.760: INFO: Unable to read wheezy_tcp@dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.764: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.766: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.785: INFO: Unable to read jessie_udp@dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.788: INFO: Unable to read jessie_tcp@dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.792: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.796: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-93.svc.cluster.local from pod dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e: the server could not find the requested resource (get pods dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e)
  Feb 12 20:24:10.811: INFO: Lookups using dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e failed for: [wheezy_udp@dns-test-service.dns-93.svc.cluster.local wheezy_tcp@dns-test-service.dns-93.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-93.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-93.svc.cluster.local jessie_udp@dns-test-service.dns-93.svc.cluster.local jessie_tcp@dns-test-service.dns-93.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-93.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-93.svc.cluster.local]

  Feb 12 20:24:10.818: INFO: Pod client logs for webserver: 
  Feb 12 20:24:10.823: INFO: Pod client logs for querier: 
  Feb 12 20:24:10.829: INFO: Pod client logs for jessie-querier: 
  E0212 20:24:10.979004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:11.979351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:12.979408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:13.979503      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:14.979700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:15.805: INFO: DNS probes using dns-93/dns-test-52d4ce95-05d9-4bdd-b1ad-5f03bd16938e succeeded

  STEP: deleting the pod @ 02/12/24 20:24:15.806
  STEP: deleting the test service @ 02/12/24 20:24:15.822
  STEP: deleting the test headless service @ 02/12/24 20:24:15.847
  Feb 12 20:24:15.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-93" for this suite. @ 02/12/24 20:24:15.866
• [7.199 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 02/12/24 20:24:15.873
  Feb 12 20:24:15.873: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 20:24:15.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:15.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:15.895
  STEP: creating a replication controller @ 02/12/24 20:24:15.897
  Feb 12 20:24:15.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 create -f -'
  E0212 20:24:15.980132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:15.987: INFO: stderr: ""
  Feb 12 20:24:15.987: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/12/24 20:24:15.987
  Feb 12 20:24:15.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 20:24:16.034: INFO: stderr: ""
  Feb 12 20:24:16.034: INFO: stdout: "update-demo-nautilus-kd5c8 update-demo-nautilus-qjjj4 "
  Feb 12 20:24:16.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods update-demo-nautilus-kd5c8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 20:24:16.077: INFO: stderr: ""
  Feb 12 20:24:16.077: INFO: stdout: ""
  Feb 12 20:24:16.077: INFO: update-demo-nautilus-kd5c8 is created but not running
  E0212 20:24:16.980248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:17.980626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:18.980736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:19.980992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:20.981109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:21.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb 12 20:24:21.122: INFO: stderr: ""
  Feb 12 20:24:21.122: INFO: stdout: "update-demo-nautilus-kd5c8 update-demo-nautilus-qjjj4 "
  Feb 12 20:24:21.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods update-demo-nautilus-kd5c8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 20:24:21.165: INFO: stderr: ""
  Feb 12 20:24:21.165: INFO: stdout: "true"
  Feb 12 20:24:21.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods update-demo-nautilus-kd5c8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 20:24:21.209: INFO: stderr: ""
  Feb 12 20:24:21.209: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 20:24:21.209: INFO: validating pod update-demo-nautilus-kd5c8
  Feb 12 20:24:21.215: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 20:24:21.215: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 20:24:21.215: INFO: update-demo-nautilus-kd5c8 is verified up and running
  Feb 12 20:24:21.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods update-demo-nautilus-qjjj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb 12 20:24:21.257: INFO: stderr: ""
  Feb 12 20:24:21.257: INFO: stdout: "true"
  Feb 12 20:24:21.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods update-demo-nautilus-qjjj4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb 12 20:24:21.301: INFO: stderr: ""
  Feb 12 20:24:21.301: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb 12 20:24:21.301: INFO: validating pod update-demo-nautilus-qjjj4
  Feb 12 20:24:21.306: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb 12 20:24:21.306: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb 12 20:24:21.306: INFO: update-demo-nautilus-qjjj4 is verified up and running
  STEP: using delete to clean up resources @ 02/12/24 20:24:21.306
  Feb 12 20:24:21.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 delete --grace-period=0 --force -f -'
  Feb 12 20:24:21.356: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb 12 20:24:21.356: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Feb 12 20:24:21.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get rc,svc -l name=update-demo --no-headers'
  Feb 12 20:24:21.420: INFO: stderr: "No resources found in kubectl-1121 namespace.\n"
  Feb 12 20:24:21.420: INFO: stdout: ""
  Feb 12 20:24:21.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-1121 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Feb 12 20:24:21.480: INFO: stderr: ""
  Feb 12 20:24:21.480: INFO: stdout: ""
  Feb 12 20:24:21.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1121" for this suite. @ 02/12/24 20:24:21.484
• [5.618 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 02/12/24 20:24:21.491
  Feb 12 20:24:21.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 20:24:21.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:21.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:21.51
  STEP: Creating a test headless service @ 02/12/24 20:24:21.512
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6740 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6740;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6740 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6740;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6740.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6740.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6740.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6740.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6740.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6740.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6740.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6740.svc;check="$$(dig +notcp +noall +answer +search 233.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.233_udp@PTR;check="$$(dig +tcp +noall +answer +search 233.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.233_tcp@PTR;sleep 1; done
   @ 02/12/24 20:24:21.535
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6740 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6740;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6740 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6740;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6740.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6740.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6740.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6740.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6740.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6740.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6740.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6740.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6740.svc;check="$$(dig +notcp +noall +answer +search 233.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.233_udp@PTR;check="$$(dig +tcp +noall +answer +search 233.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.233_tcp@PTR;sleep 1; done
   @ 02/12/24 20:24:21.535
  STEP: creating a pod to probe DNS @ 02/12/24 20:24:21.535
  STEP: submitting the pod to kubernetes @ 02/12/24 20:24:21.535
  E0212 20:24:21.982189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:22.982964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/12/24 20:24:23.554
  STEP: looking for the results for each expected name from probers @ 02/12/24 20:24:23.557
  Feb 12 20:24:23.563: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.567: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.570: INFO: Unable to read wheezy_udp@dns-test-service.dns-6740 from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.574: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6740 from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.577: INFO: Unable to read wheezy_udp@dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.580: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.583: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.587: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.604: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.607: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.610: INFO: Unable to read jessie_udp@dns-test-service.dns-6740 from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.613: INFO: Unable to read jessie_tcp@dns-test-service.dns-6740 from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.617: INFO: Unable to read jessie_udp@dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.623: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.627: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6740.svc from pod dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c: the server could not find the requested resource (get pods dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c)
  Feb 12 20:24:23.641: INFO: Lookups using dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6740 wheezy_tcp@dns-test-service.dns-6740 wheezy_udp@dns-test-service.dns-6740.svc wheezy_tcp@dns-test-service.dns-6740.svc wheezy_udp@_http._tcp.dns-test-service.dns-6740.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6740.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6740 jessie_tcp@dns-test-service.dns-6740 jessie_udp@dns-test-service.dns-6740.svc jessie_tcp@dns-test-service.dns-6740.svc jessie_udp@_http._tcp.dns-test-service.dns-6740.svc jessie_tcp@_http._tcp.dns-test-service.dns-6740.svc]

  Feb 12 20:24:23.648: INFO: Pod client logs for webserver: 
  Feb 12 20:24:23.656: INFO: Pod client logs for querier: 
  Feb 12 20:24:23.660: INFO: Pod client logs for jessie-querier: 
  E0212 20:24:23.983444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:24.983532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:25.983738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:26.984053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:27.984445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:28.640: INFO: DNS probes using dns-6740/dns-test-7d1adcf0-0ae4-472f-ac5f-8be8012b259c succeeded

  STEP: deleting the pod @ 02/12/24 20:24:28.64
  STEP: deleting the test service @ 02/12/24 20:24:28.656
  STEP: deleting the test headless service @ 02/12/24 20:24:28.68
  Feb 12 20:24:28.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6740" for this suite. @ 02/12/24 20:24:28.704
• [7.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 02/12/24 20:24:28.711
  Feb 12 20:24:28.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 20:24:28.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:28.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:28.73
  STEP: create the deployment @ 02/12/24 20:24:28.733
  W0212 20:24:28.737809      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 02/12/24 20:24:28.738
  E0212 20:24:28.985028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 02/12/24 20:24:29.247
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 02/12/24 20:24:29.254
  STEP: Gathering metrics @ 02/12/24 20:24:29.771
  W0212 20:24:29.774984      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb 12 20:24:29.775: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb 12 20:24:29.775: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-797" for this suite. @ 02/12/24 20:24:29.777
• [1.073 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 02/12/24 20:24:29.784
  Feb 12 20:24:29.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir-wrapper @ 02/12/24 20:24:29.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:29.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:29.8
  STEP: Creating 50 configmaps @ 02/12/24 20:24:29.803
  E0212 20:24:29.985773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 02/12/24 20:24:30.039
  Feb 12 20:24:30.220: INFO: Pod name wrapped-volume-race-d0393824-448e-4cf3-a2f9-048a2ebf2eb9: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 02/12/24 20:24:30.22
  E0212 20:24:30.986775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:31.986986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 02/12/24 20:24:32.254
  Feb 12 20:24:32.268: INFO: Pod name wrapped-volume-race-95d26eee-56c0-4fc1-84dd-d68f0d3048d6: Found 0 pods out of 5
  E0212 20:24:32.987975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:33.988120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:34.988210      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:35.989087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:36.989278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:37.276: INFO: Pod name wrapped-volume-race-95d26eee-56c0-4fc1-84dd-d68f0d3048d6: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 02/12/24 20:24:37.276
  STEP: Creating RC which spawns configmap-volume pods @ 02/12/24 20:24:37.298
  Feb 12 20:24:37.315: INFO: Pod name wrapped-volume-race-c4b2f1bf-36c2-48db-8bb3-138da2b157a2: Found 0 pods out of 5
  E0212 20:24:37.997055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:38.997087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:39.997302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:40.997534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:41.997649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:42.324: INFO: Pod name wrapped-volume-race-c4b2f1bf-36c2-48db-8bb3-138da2b157a2: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 02/12/24 20:24:42.324
  STEP: deleting ReplicationController wrapped-volume-race-c4b2f1bf-36c2-48db-8bb3-138da2b157a2 in namespace emptydir-wrapper-2858, will wait for the garbage collector to delete the pods @ 02/12/24 20:24:42.341
  Feb 12 20:24:42.405: INFO: Deleting ReplicationController wrapped-volume-race-c4b2f1bf-36c2-48db-8bb3-138da2b157a2 took: 10.859712ms
  Feb 12 20:24:42.505: INFO: Terminating ReplicationController wrapped-volume-race-c4b2f1bf-36c2-48db-8bb3-138da2b157a2 pods took: 100.133851ms
  E0212 20:24:42.998151      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-95d26eee-56c0-4fc1-84dd-d68f0d3048d6 in namespace emptydir-wrapper-2858, will wait for the garbage collector to delete the pods @ 02/12/24 20:24:43.706
  Feb 12 20:24:43.768: INFO: Deleting ReplicationController wrapped-volume-race-95d26eee-56c0-4fc1-84dd-d68f0d3048d6 took: 8.630068ms
  Feb 12 20:24:43.869: INFO: Terminating ReplicationController wrapped-volume-race-95d26eee-56c0-4fc1-84dd-d68f0d3048d6 pods took: 100.589548ms
  E0212 20:24:43.998980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:44.999461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-d0393824-448e-4cf3-a2f9-048a2ebf2eb9 in namespace emptydir-wrapper-2858, will wait for the garbage collector to delete the pods @ 02/12/24 20:24:45.17
  Feb 12 20:24:45.233: INFO: Deleting ReplicationController wrapped-volume-race-d0393824-448e-4cf3-a2f9-048a2ebf2eb9 took: 9.445617ms
  Feb 12 20:24:45.334: INFO: Terminating ReplicationController wrapped-volume-race-d0393824-448e-4cf3-a2f9-048a2ebf2eb9 pods took: 100.762932ms
  E0212 20:24:46.000423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:47.000891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 02/12/24 20:24:47.035
  Feb 12 20:24:47.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-2858" for this suite. @ 02/12/24 20:24:47.349
• [17.572 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 02/12/24 20:24:47.356
  Feb 12 20:24:47.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:24:47.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:47.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:47.375
  STEP: Creating projection with secret that has name projected-secret-test-c33b0b39-d940-444c-811c-d3950b84513d @ 02/12/24 20:24:47.378
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:24:47.383
  E0212 20:24:48.001451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:49.001857      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:50.002923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:51.003035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:24:51.404
  Feb 12 20:24:51.409: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-secrets-16d44cc5-be32-46c6-a3b5-1e28211d2cb7 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:24:51.416
  Feb 12 20:24:51.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-583" for this suite. @ 02/12/24 20:24:51.438
• [4.088 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 02/12/24 20:24:51.445
  Feb 12 20:24:51.445: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename security-context-test @ 02/12/24 20:24:51.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:51.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:51.468
  E0212 20:24:52.003211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:53.003317      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:54.003408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:55.003536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:24:55.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2655" for this suite. @ 02/12/24 20:24:55.503
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 02/12/24 20:24:55.509
  Feb 12 20:24:55.509: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:24:55.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:55.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:55.528
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 02/12/24 20:24:55.531
  E0212 20:24:56.004157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:57.004519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:58.005578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:24:59.005833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:24:59.559
  Feb 12 20:24:59.562: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-57eefa3c-2b97-4220-bcb8-294460fe85f0 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:24:59.568
  Feb 12 20:24:59.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9371" for this suite. @ 02/12/24 20:24:59.588
• [4.088 seconds]
------------------------------
S
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 02/12/24 20:24:59.597
  Feb 12 20:24:59.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename events @ 02/12/24 20:24:59.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:59.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:59.616
  STEP: Create set of events @ 02/12/24 20:24:59.62
  Feb 12 20:24:59.624: INFO: created test-event-1
  Feb 12 20:24:59.628: INFO: created test-event-2
  Feb 12 20:24:59.634: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 02/12/24 20:24:59.634
  STEP: delete collection of events @ 02/12/24 20:24:59.637
  Feb 12 20:24:59.637: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 02/12/24 20:24:59.657
  Feb 12 20:24:59.657: INFO: requesting list of events to confirm quantity
  Feb 12 20:24:59.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7739" for this suite. @ 02/12/24 20:24:59.665
• [0.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 02/12/24 20:24:59.672
  Feb 12 20:24:59.672: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename prestop @ 02/12/24 20:24:59.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:24:59.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:24:59.691
  STEP: Creating server pod server in namespace prestop-8289 @ 02/12/24 20:24:59.694
  STEP: Waiting for pods to come up. @ 02/12/24 20:24:59.703
  E0212 20:25:00.006603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:01.006696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-8289 @ 02/12/24 20:25:01.719
  E0212 20:25:02.006825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:03.006986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 02/12/24 20:25:03.738
  E0212 20:25:04.007930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:05.008156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:06.008235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:07.008688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:08.009590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:25:08.751: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 02/12/24 20:25:08.752
  Feb 12 20:25:08.766: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-8289" for this suite. @ 02/12/24 20:25:08.771
• [9.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 02/12/24 20:25:08.78
  Feb 12 20:25:08.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 20:25:08.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:25:08.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:25:08.808
  Feb 12 20:25:08.840: INFO: created pod
  E0212 20:25:09.010502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:10.010783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:11.011248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:12.011341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:25:12.856
  E0212 20:25:13.011494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:14.011598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:15.011684      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:16.011959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:17.012087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:18.012647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:19.012763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:20.012982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:21.013056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:22.013217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:23.013409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:24.013786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:25.013835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:26.013940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:27.014902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:28.015223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:29.015317      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:30.016435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:31.016549      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:32.016651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:33.016754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:34.017111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:35.017229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:36.017410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:37.017633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:38.017963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:39.018897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:40.019084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:41.019279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:42.019376      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:25:42.856: INFO: polling logs
  Feb 12 20:25:42.865: INFO: Pod logs: 
  I0212 20:25:09.418959       1 log.go:194] OK: Got token
  I0212 20:25:09.419127       1 log.go:194] validating with in-cluster discovery
  I0212 20:25:09.419334       1 log.go:194] OK: got issuer https://kubernetes.default.svc
  I0212 20:25:09.419375       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-5622:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0004c47d0), NotBefore:(*jwt.NumericDate)(0xc0004c48b8), IssuedAt:(*jwt.NumericDate)(0xc0004c47e0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5622", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4ec97477-ae31-4212-a370-3c41f2a9e905"}}}
  I0212 20:25:09.426441       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0212 20:25:09.429823       1 log.go:194] OK: Validated signature on JWT
  I0212 20:25:09.429927       1 log.go:194] OK: Got valid claims from token!
  I0212 20:25:09.429949       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-5622:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0003b5bd8), NotBefore:(*jwt.NumericDate)(0xc0003b5c00), IssuedAt:(*jwt.NumericDate)(0xc0003b5be0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5622", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4ec97477-ae31-4212-a370-3c41f2a9e905"}}}

  Feb 12 20:25:42.865: INFO: completed pod
  Feb 12 20:25:42.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5622" for this suite. @ 02/12/24 20:25:42.878
• [34.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 02/12/24 20:25:42.886
  Feb 12 20:25:42.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:25:42.887
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:25:42.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:25:42.911
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 02/12/24 20:25:42.915
  E0212 20:25:43.019587      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:44.019612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:45.019946      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:46.020170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:25:46.942
  Feb 12 20:25:46.945: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-bf8ccd74-5637-4e6b-a581-8cc96461652a container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:25:46.951
  Feb 12 20:25:46.966: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9229" for this suite. @ 02/12/24 20:25:46.969
• [4.088 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 02/12/24 20:25:46.974
  Feb 12 20:25:46.974: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:25:46.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:25:46.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:25:46.994
  STEP: Creating secret with name secret-test-map-b56a6623-c119-49ad-9f7d-534971565a5f @ 02/12/24 20:25:46.996
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:25:46.999
  E0212 20:25:47.020634      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:48.021758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:49.022574      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:50.022755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:25:51.019
  E0212 20:25:51.022842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:25:51.022: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-f00d83fb-0dcb-4000-98b8-7fd75fbc07a5 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:25:51.03
  Feb 12 20:25:51.048: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1905" for this suite. @ 02/12/24 20:25:51.051
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 02/12/24 20:25:51.058
  Feb 12 20:25:51.058: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:25:51.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:25:51.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:25:51.075
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 02/12/24 20:25:51.078
  E0212 20:25:52.022979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:53.023179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:54.023540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:55.023626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:25:55.103
  Feb 12 20:25:55.106: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-fe0fc0f3-2816-4144-97d1-d8243560e7b1 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:25:55.114
  Feb 12 20:25:55.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8289" for this suite. @ 02/12/24 20:25:55.133
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 02/12/24 20:25:55.14
  Feb 12 20:25:55.140: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename dns @ 02/12/24 20:25:55.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:25:55.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:25:55.16
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 02/12/24 20:25:55.163
  Feb 12 20:25:55.171: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8142  37753530-0667-462b-9b4b-2efbdc0c5cb8 38189 0 2024-02-12 20:25:55 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-02-12 20:25:55 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mhr26,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mhr26,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0212 20:25:56.023724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:57.023959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 02/12/24 20:25:57.181
  Feb 12 20:25:57.181: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8142 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:25:57.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:25:57.181: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:25:57.181: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8142/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 02/12/24 20:25:57.245
  Feb 12 20:25:57.245: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8142 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:25:57.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:25:57.246: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:25:57.246: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8142/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb 12 20:25:57.309: INFO: Deleting pod test-dns-nameservers...
  Feb 12 20:25:57.321: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8142" for this suite. @ 02/12/24 20:25:57.327
• [2.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 02/12/24 20:25:57.333
  Feb 12 20:25:57.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 20:25:57.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:25:57.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:25:57.347
  STEP: set up a multi version CRD @ 02/12/24 20:25:57.394
  Feb 12 20:25:57.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:25:58.024202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:25:59.024886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:00.025473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 02/12/24 20:26:00.486
  STEP: check the unserved version gets removed @ 02/12/24 20:26:00.502
  E0212 20:26:01.026146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 02/12/24 20:26:01.358
  E0212 20:26:02.027035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:03.027488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:03.795: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6790" for this suite. @ 02/12/24 20:26:03.802
• [6.478 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 02/12/24 20:26:03.811
  Feb 12 20:26:03.811: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:26:03.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:03.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:03.831
  STEP: Creating secret with name secret-test-ad84c895-acfc-4278-88b8-1ea513763b97 @ 02/12/24 20:26:03.833
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:26:03.838
  E0212 20:26:04.028341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:05.028396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:06.028559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:07.029340      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:26:07.864
  Feb 12 20:26:07.867: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-c54d5447-06c4-4ddc-a912-c62b55fc93c4 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:26:07.88
  Feb 12 20:26:07.900: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9222" for this suite. @ 02/12/24 20:26:07.903
• [4.100 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 02/12/24 20:26:07.911
  Feb 12 20:26:07.911: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 20:26:07.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:07.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:07.929
  E0212 20:26:08.030161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:09.031055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:09.950: INFO: Deleting pod "var-expansion-2bd6a428-4787-46bc-983e-1be5b69fb64e" in namespace "var-expansion-1586"
  Feb 12 20:26:09.958: INFO: Wait up to 5m0s for pod "var-expansion-2bd6a428-4787-46bc-983e-1be5b69fb64e" to be fully deleted
  E0212 20:26:10.031204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:11.031396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:11.966: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1586" for this suite. @ 02/12/24 20:26:11.971
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 02/12/24 20:26:11.979
  Feb 12 20:26:11.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 20:26:11.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:11.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:11.998
  Feb 12 20:26:12.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 create -f -'
  E0212 20:26:12.031666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:12.085: INFO: stderr: ""
  Feb 12 20:26:12.085: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Feb 12 20:26:12.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 create -f -'
  Feb 12 20:26:12.175: INFO: stderr: ""
  Feb 12 20:26:12.175: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 02/12/24 20:26:12.175
  E0212 20:26:13.031785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:13.180: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 20:26:13.180: INFO: Found 1 / 1
  Feb 12 20:26:13.180: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Feb 12 20:26:13.184: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 20:26:13.184: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb 12 20:26:13.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 describe pod agnhost-primary-vmgvq'
  Feb 12 20:26:13.239: INFO: stderr: ""
  Feb 12 20:26:13.240: INFO: stdout: "Name:             agnhost-primary-vmgvq\nNamespace:        kubectl-6502\nPriority:         0\nService Account:  default\nNode:             ip-172-31-5-108/172.31.5.108\nStart Time:       Mon, 12 Feb 2024 20:26:12 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.150.230\nIPs:\n  IP:           192.168.150.230\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://41aceef8187046ed23a0f5472ce19c2be20e8b397e04f199c33fe3525d8958bb\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.45\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 12 Feb 2024 20:26:12 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nbvvz (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-nbvvz:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-6502/agnhost-primary-vmgvq to ip-172-31-5-108\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.45\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Feb 12 20:26:13.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 describe rc agnhost-primary'
  Feb 12 20:26:13.295: INFO: stderr: ""
  Feb 12 20:26:13.295: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6502\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-vmgvq\n"
  Feb 12 20:26:13.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 describe service agnhost-primary'
  Feb 12 20:26:13.350: INFO: stderr: ""
  Feb 12 20:26:13.350: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-6502\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.93\nIPs:               10.152.183.93\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.150.230:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Feb 12 20:26:13.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 describe node ip-172-31-35-5'
  Feb 12 20:26:13.417: INFO: stderr: ""
  Feb 12 20:26:13.417: INFO: stdout: "Name:               ip-172-31-35-5\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    juju-charm=kubernetes-control-plane\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-35-5\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 12 Feb 2024 18:42:11 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-35-5\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 12 Feb 2024 20:26:05 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 12 Feb 2024 18:57:45 +0000   Mon, 12 Feb 2024 18:57:45 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 12 Feb 2024 20:23:12 +0000   Mon, 12 Feb 2024 18:42:11 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 12 Feb 2024 20:23:12 +0000   Mon, 12 Feb 2024 18:42:11 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 12 Feb 2024 20:23:12 +0000   Mon, 12 Feb 2024 18:42:11 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 12 Feb 2024 20:23:12 +0000   Mon, 12 Feb 2024 18:44:00 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.35.5\n  Hostname:    ip-172-31-35-5\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7962276Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7859876Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2aef69a5eee8c6d837e7d6ae6297a0\n  System UUID:                ec2aef69-a5ee-e8c6-d837-e7d6ae6297a0\n  Boot ID:                    072ff85d-eb5c-4a63-a77b-9135cb5e8e07\n  Kernel Version:             6.2.0-1018-aws\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.29.1\n  Kube-Proxy Version:         v1.29.1\nNon-terminated Pods:          (2 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-8nf5c                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         88m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-d6f2c9e5492640bc-bzp89    0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  Feb 12 20:26:13.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-6502 describe namespace kubectl-6502'
  Feb 12 20:26:13.471: INFO: stderr: ""
  Feb 12 20:26:13.471: INFO: stdout: "Name:         kubectl-6502\nLabels:       e2e-framework=kubectl\n              e2e-run=9bdb97e6-94a2-4de6-b7ef-44e96ca695dc\n              kubernetes.io/metadata.name=kubectl-6502\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Feb 12 20:26:13.471: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6502" for this suite. @ 02/12/24 20:26:13.476
• [1.504 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 02/12/24 20:26:13.484
  Feb 12 20:26:13.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 20:26:13.485
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:13.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:13.504
  STEP: Creating service test in namespace statefulset-1310 @ 02/12/24 20:26:13.506
  Feb 12 20:26:13.526: INFO: Found 0 stateful pods, waiting for 1
  E0212 20:26:14.032263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:15.032468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:16.032558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:17.032760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:18.033280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:19.033873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:20.034900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:21.035642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:22.035829      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:23.036842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:23.526: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 02/12/24 20:26:23.534
  W0212 20:26:23.544042      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Feb 12 20:26:23.554: INFO: Found 1 stateful pods, waiting for 2
  E0212 20:26:24.037115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:25.037216      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:26.037289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:27.037385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:28.037600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:29.037827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:30.038882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:31.039060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:32.039266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:33.039461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:33.555: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb 12 20:26:33.555: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 02/12/24 20:26:33.561
  STEP: Delete all of the StatefulSets @ 02/12/24 20:26:33.565
  STEP: Verify that StatefulSets have been deleted @ 02/12/24 20:26:33.575
  Feb 12 20:26:33.580: INFO: Deleting all statefulset in ns statefulset-1310
  Feb 12 20:26:33.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1310" for this suite. @ 02/12/24 20:26:33.605
• [20.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 02/12/24 20:26:33.613
  Feb 12 20:26:33.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename podtemplate @ 02/12/24 20:26:33.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:33.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:33.634
  STEP: Create a pod template @ 02/12/24 20:26:33.637
  STEP: Replace a pod template @ 02/12/24 20:26:33.647
  Feb 12 20:26:33.657: INFO: Found updated podtemplate annotation: "true"

  Feb 12 20:26:33.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8770" for this suite. @ 02/12/24 20:26:33.661
• [0.055 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 02/12/24 20:26:33.668
  Feb 12 20:26:33.668: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:26:33.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:33.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:33.691
  STEP: Creating secret with name secret-test-0d84f438-99ea-4937-8c2b-3f4d2f1fd806 @ 02/12/24 20:26:33.694
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:26:33.7
  E0212 20:26:34.039592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:35.039695      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:36.040394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:37.040603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:26:37.723
  Feb 12 20:26:37.726: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-eb2cc245-0d07-46a3-a85b-4be2b4326e1e container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:26:37.734
  Feb 12 20:26:37.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2957" for this suite. @ 02/12/24 20:26:37.754
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 02/12/24 20:26:37.763
  Feb 12 20:26:37.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replication-controller @ 02/12/24 20:26:37.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:37.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:37.785
  STEP: Creating replication controller my-hostname-basic-37d0a9c3-0b44-4268-bfba-4ee905866172 @ 02/12/24 20:26:37.788
  Feb 12 20:26:37.798: INFO: Pod name my-hostname-basic-37d0a9c3-0b44-4268-bfba-4ee905866172: Found 0 pods out of 1
  E0212 20:26:38.040735      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:39.040838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:40.040951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:41.041025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:42.041143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:42.806: INFO: Pod name my-hostname-basic-37d0a9c3-0b44-4268-bfba-4ee905866172: Found 1 pods out of 1
  Feb 12 20:26:42.806: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-37d0a9c3-0b44-4268-bfba-4ee905866172" are running
  Feb 12 20:26:42.810: INFO: Pod "my-hostname-basic-37d0a9c3-0b44-4268-bfba-4ee905866172-b52nl" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:26:39 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:26:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:26:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:26:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:26:37 +0000 UTC Reason: Message:}])
  Feb 12 20:26:42.810: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 02/12/24 20:26:42.81
  Feb 12 20:26:42.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6368" for this suite. @ 02/12/24 20:26:42.824
• [5.068 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 02/12/24 20:26:42.831
  Feb 12 20:26:42.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:26:42.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:42.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:42.852
  STEP: Setting up server cert @ 02/12/24 20:26:42.875
  E0212 20:26:43.041811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:26:43.237
  STEP: Deploying the webhook pod @ 02/12/24 20:26:43.246
  STEP: Wait for the deployment to be ready @ 02/12/24 20:26:43.259
  Feb 12 20:26:43.267: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:26:44.041938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:45.042036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:26:45.278
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:26:45.287
  E0212 20:26:46.042135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:26:46.287: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 02/12/24 20:26:46.365
  STEP: Creating a configMap that should be mutated @ 02/12/24 20:26:46.377
  STEP: Deleting the collection of validation webhooks @ 02/12/24 20:26:46.405
  STEP: Creating a configMap that should not be mutated @ 02/12/24 20:26:46.459
  Feb 12 20:26:46.512: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-227" for this suite. @ 02/12/24 20:26:46.516
  STEP: Destroying namespace "webhook-markers-8778" for this suite. @ 02/12/24 20:26:46.528
• [3.703 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 02/12/24 20:26:46.534
  Feb 12 20:26:46.534: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 20:26:46.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:46.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:46.555
  STEP: create the deployment @ 02/12/24 20:26:46.558
  W0212 20:26:46.562901      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 02/12/24 20:26:46.563
  E0212 20:26:47.044767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 02/12/24 20:26:47.069
  STEP: wait for all rs to be garbage collected @ 02/12/24 20:26:47.076
  STEP: expected 0 rs, got 1 rs @ 02/12/24 20:26:47.087
  STEP: expected 0 pods, got 2 pods @ 02/12/24 20:26:47.091
  STEP: Gathering metrics @ 02/12/24 20:26:47.587
  W0212 20:26:47.592877      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb 12 20:26:47.592: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb 12 20:26:47.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7889" for this suite. @ 02/12/24 20:26:47.597
• [1.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 02/12/24 20:26:47.606
  Feb 12 20:26:47.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename subpath @ 02/12/24 20:26:47.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:26:47.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:26:47.623
  STEP: Setting up data @ 02/12/24 20:26:47.627
  STEP: Creating pod pod-subpath-test-downwardapi-6xst @ 02/12/24 20:26:47.638
  STEP: Creating a pod to test atomic-volume-subpath @ 02/12/24 20:26:47.638
  E0212 20:26:48.045120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:49.045156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:50.045247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:51.045420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:52.045596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:53.045854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:54.045950      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:55.046045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:56.046591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:57.046777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:58.046955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:26:59.047218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:00.048066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:01.048262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:02.048986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:03.049066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:04.049538      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:05.049616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:06.049905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:07.049996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:08.050527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:09.050915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:10.051420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:11.051506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:27:11.717
  Feb 12 20:27:11.721: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-subpath-test-downwardapi-6xst container test-container-subpath-downwardapi-6xst: <nil>
  STEP: delete the pod @ 02/12/24 20:27:11.727
  STEP: Deleting pod pod-subpath-test-downwardapi-6xst @ 02/12/24 20:27:11.745
  Feb 12 20:27:11.745: INFO: Deleting pod "pod-subpath-test-downwardapi-6xst" in namespace "subpath-2226"
  Feb 12 20:27:11.747: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2226" for this suite. @ 02/12/24 20:27:11.751
• [24.150 seconds]
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 02/12/24 20:27:11.757
  Feb 12 20:27:11.757: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pv @ 02/12/24 20:27:11.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:11.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:11.776
  STEP: Creating initial PV and PVC @ 02/12/24 20:27:11.78
  Feb 12 20:27:11.780: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-1947" @ 02/12/24 20:27:11.793
  STEP: Listing PVCs in namespace "pv-1947" @ 02/12/24 20:27:11.796
  STEP: Patching the PV "pv-1947-mz55h" @ 02/12/24 20:27:11.799
  STEP: Patching the PVC "pvc-zfsbp" @ 02/12/24 20:27:11.817
  STEP: Getting PV "pv-1947-mz55h" @ 02/12/24 20:27:11.827
  STEP: Getting PVC "pvc-zfsbp" @ 02/12/24 20:27:11.847
  STEP: Deleting PVC "pvc-zfsbp" @ 02/12/24 20:27:11.851
  STEP: Confirm deletion of PVC "pvc-zfsbp" @ 02/12/24 20:27:11.857
  E0212 20:27:12.051999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:13.052076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-1947-mz55h" @ 02/12/24 20:27:13.867
  STEP: Confirm deletion of PV "pv-1947-mz55h" @ 02/12/24 20:27:13.875
  E0212 20:27:14.052311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:15.052396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 02/12/24 20:27:15.885
  Feb 12 20:27:15.885: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-1947-d9m6r" @ 02/12/24 20:27:15.897
  STEP: Updating the PVC "pvc-9gxnv" @ 02/12/24 20:27:15.906
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-9gxnv=updated" @ 02/12/24 20:27:15.915
  STEP: Deleting PVC "pvc-9gxnv" via DeleteCollection @ 02/12/24 20:27:15.917
  STEP: Confirm deletion of PVC "pvc-9gxnv" @ 02/12/24 20:27:15.927
  E0212 20:27:16.052618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:17.052743      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-1947-d9m6r" via DeleteCollection @ 02/12/24 20:27:17.935
  STEP: Confirm deletion of PV "pv-1947-d9m6r" @ 02/12/24 20:27:17.947
  E0212 20:27:18.053494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:19.053854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:19.956: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Feb 12 20:27:19.956: INFO: Deleting PersistentVolumeClaim "pvc-9gxnv"
  Feb 12 20:27:19.959: INFO: Deleting PersistentVolume "pv-1947-d9m6r"
  Feb 12 20:27:19.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-1947" for this suite. @ 02/12/24 20:27:19.966
• [8.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 02/12/24 20:27:19.973
  Feb 12 20:27:19.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 20:27:19.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:19.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:19.992
  STEP: creating the pod @ 02/12/24 20:27:19.995
  STEP: setting up watch @ 02/12/24 20:27:19.995
  E0212 20:27:20.054365      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: submitting the pod to kubernetes @ 02/12/24 20:27:20.099
  STEP: verifying the pod is in kubernetes @ 02/12/24 20:27:20.107
  STEP: verifying pod creation was observed @ 02/12/24 20:27:20.111
  E0212 20:27:21.054996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:22.055090      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 02/12/24 20:27:22.124
  STEP: verifying pod deletion was observed @ 02/12/24 20:27:22.133
  E0212 20:27:23.055799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:23.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4240" for this suite. @ 02/12/24 20:27:23.302
• [3.336 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 02/12/24 20:27:23.308
  Feb 12 20:27:23.309: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename lease-test @ 02/12/24 20:27:23.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:23.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:23.327
  Feb 12 20:27:23.391: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-5679" for this suite. @ 02/12/24 20:27:23.395
• [0.092 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 02/12/24 20:27:23.401
  Feb 12 20:27:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 20:27:23.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:23.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:23.42
  Feb 12 20:27:23.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:27:24.056194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:25.056430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0212 20:27:25.965449      20 warnings.go:70] unknown field "alpha"
  W0212 20:27:25.965469      20 warnings.go:70] unknown field "beta"
  W0212 20:27:25.965473      20 warnings.go:70] unknown field "delta"
  W0212 20:27:25.965476      20 warnings.go:70] unknown field "epsilon"
  W0212 20:27:25.965479      20 warnings.go:70] unknown field "gamma"
  E0212 20:27:26.056470      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:26.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6274" for this suite. @ 02/12/24 20:27:26.513
• [3.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 02/12/24 20:27:26.523
  Feb 12 20:27:26.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:27:26.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:26.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:26.545
  STEP: Creating Pod @ 02/12/24 20:27:26.548
  E0212 20:27:27.056553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:28.056960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 02/12/24 20:27:28.568
  Feb 12 20:27:28.568: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3759 PodName:pod-sharedvolume-5ce0e9e5-8ff5-40eb-9232-2e3adb3ed1de ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:27:28.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:27:28.569: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:27:28.569: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-3759/pods/pod-sharedvolume-5ce0e9e5-8ff5-40eb-9232-2e3adb3ed1de/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Feb 12 20:27:28.632: INFO: Exec stderr: ""
  Feb 12 20:27:28.632: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3759" for this suite. @ 02/12/24 20:27:28.636
• [2.119 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 02/12/24 20:27:28.642
  Feb 12 20:27:28.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 20:27:28.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:28.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:28.662
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 02/12/24 20:27:28.665
  Feb 12 20:27:28.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:27:29.057797      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:29.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:27:30.058503      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:31.058977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:32.059375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:33.060300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:34.060396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:34.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7327" for this suite. @ 02/12/24 20:27:34.921
• [6.292 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 02/12/24 20:27:34.935
  Feb 12 20:27:34.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename field-validation @ 02/12/24 20:27:34.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:34.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:34.957
  Feb 12 20:27:34.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:27:35.060987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:36.061103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:37.061337      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0212 20:27:37.501704      20 warnings.go:70] unknown field "alpha"
  W0212 20:27:37.501727      20 warnings.go:70] unknown field "beta"
  W0212 20:27:37.501730      20 warnings.go:70] unknown field "delta"
  W0212 20:27:37.501734      20 warnings.go:70] unknown field "epsilon"
  W0212 20:27:37.501736      20 warnings.go:70] unknown field "gamma"
  Feb 12 20:27:38.051: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7576" for this suite. @ 02/12/24 20:27:38.056
  E0212 20:27:38.061324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
• [3.128 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 02/12/24 20:27:38.063
  Feb 12 20:27:38.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 20:27:38.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:38.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:38.083
  STEP: creating Agnhost RC @ 02/12/24 20:27:38.086
  Feb 12 20:27:38.086: INFO: namespace kubectl-8515
  Feb 12 20:27:38.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-8515 create -f -'
  Feb 12 20:27:38.170: INFO: stderr: ""
  Feb 12 20:27:38.170: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 02/12/24 20:27:38.17
  E0212 20:27:39.062276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:39.176: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 20:27:39.176: INFO: Found 0 / 1
  E0212 20:27:40.062923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:40.175: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 20:27:40.175: INFO: Found 1 / 1
  Feb 12 20:27:40.175: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Feb 12 20:27:40.180: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb 12 20:27:40.180: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb 12 20:27:40.180: INFO: wait on agnhost-primary startup in kubectl-8515 
  Feb 12 20:27:40.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-8515 logs agnhost-primary-wpxrh agnhost-primary'
  Feb 12 20:27:40.237: INFO: stderr: ""
  Feb 12 20:27:40.237: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 02/12/24 20:27:40.237
  Feb 12 20:27:40.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-8515 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Feb 12 20:27:40.302: INFO: stderr: ""
  Feb 12 20:27:40.302: INFO: stdout: "service/rm2 exposed\n"
  Feb 12 20:27:40.306: INFO: Service rm2 in namespace kubectl-8515 found.
  E0212 20:27:41.063120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:42.063217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 02/12/24 20:27:42.315
  Feb 12 20:27:42.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-8515 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Feb 12 20:27:42.371: INFO: stderr: ""
  Feb 12 20:27:42.371: INFO: stdout: "service/rm3 exposed\n"
  Feb 12 20:27:42.376: INFO: Service rm3 in namespace kubectl-8515 found.
  E0212 20:27:43.063562      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:44.063985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:27:44.386: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8515" for this suite. @ 02/12/24 20:27:44.39
• [6.334 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 02/12/24 20:27:44.397
  Feb 12 20:27:44.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pod-network-test @ 02/12/24 20:27:44.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:27:44.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:27:44.421
  STEP: Performing setup for networking test in namespace pod-network-test-3332 @ 02/12/24 20:27:44.423
  STEP: creating a selector @ 02/12/24 20:27:44.424
  STEP: Creating the service pods in kubernetes @ 02/12/24 20:27:44.424
  Feb 12 20:27:44.424: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0212 20:27:45.064559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:46.064942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:47.064957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:48.065531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:49.066205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:50.066302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:51.066420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:52.066662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:53.067583      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:54.067941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:55.068204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:56.068319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:57.069229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:58.069621      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:27:59.069921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:00.070956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:01.071304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:02.071518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:03.071592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:04.071771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:05.072086      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:06.072293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/12/24 20:28:06.539
  E0212 20:28:07.073135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:08.073204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:08.588: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Feb 12 20:28:08.588: INFO: Going to poll 192.168.169.78 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Feb 12 20:28:08.591: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.169.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3332 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:28:08.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:28:08.591: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:28:08.591: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3332/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.169.78+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0212 20:28:09.073589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:09.658: INFO: Found all 1 expected endpoints: [netserver-0]
  Feb 12 20:28:09.658: INFO: Going to poll 192.168.150.225 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Feb 12 20:28:09.663: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.150.225 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3332 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:28:09.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:28:09.664: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:28:09.664: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3332/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.150.225+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0212 20:28:10.074467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:10.716: INFO: Found all 1 expected endpoints: [netserver-1]
  Feb 12 20:28:10.716: INFO: Going to poll 192.168.71.231 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Feb 12 20:28:10.721: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.71.231 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3332 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:28:10.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:28:10.721: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:28:10.722: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3332/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.71.231+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0212 20:28:11.074909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:11.776: INFO: Found all 1 expected endpoints: [netserver-2]
  Feb 12 20:28:11.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3332" for this suite. @ 02/12/24 20:28:11.782
• [27.394 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 02/12/24 20:28:11.791
  Feb 12 20:28:11.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:28:11.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:28:11.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:28:11.823
  STEP: Creating the pod @ 02/12/24 20:28:11.832
  E0212 20:28:12.075287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:13.075378      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:14.075724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:14.380: INFO: Successfully updated pod "labelsupdate72756bc9-c1d2-4d5c-a105-65201862acf7"
  E0212 20:28:15.075945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:16.076042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:17.076149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:18.077179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:18.408: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2278" for this suite. @ 02/12/24 20:28:18.411
• [6.628 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 02/12/24 20:28:18.42
  Feb 12 20:28:18.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 20:28:18.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:28:18.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:28:18.441
  STEP: creating the pod @ 02/12/24 20:28:18.444
  STEP: waiting for pod running @ 02/12/24 20:28:18.453
  E0212 20:28:19.077362      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:20.077669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 02/12/24 20:28:20.464
  Feb 12 20:28:20.468: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4196 PodName:var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:28:20.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:28:20.469: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:28:20.469: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4196/pods/var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 02/12/24 20:28:20.523
  Feb 12 20:28:20.528: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4196 PodName:var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:28:20.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:28:20.528: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:28:20.528: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4196/pods/var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 02/12/24 20:28:20.579
  E0212 20:28:21.077913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:21.093: INFO: Successfully updated pod "var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5"
  STEP: waiting for annotated pod running @ 02/12/24 20:28:21.093
  STEP: deleting the pod gracefully @ 02/12/24 20:28:21.097
  Feb 12 20:28:21.097: INFO: Deleting pod "var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5" in namespace "var-expansion-4196"
  Feb 12 20:28:21.107: INFO: Wait up to 5m0s for pod "var-expansion-f66a339d-8b0f-4911-803b-1e3dadc5c7b5" to be fully deleted
  E0212 20:28:22.077987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:23.078111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:24.078911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:25.079018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:26.079115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:27.079914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:28.080603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:29.080796      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:30.080903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:31.081669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:32.081800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:33.081892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:34.081995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:35.082097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:36.082913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:37.082997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:38.083552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:39.083877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:40.084666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:41.085216      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:42.085318      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:43.086168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:44.086926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:45.087035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:46.087469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:47.087780      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:48.088547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:49.088643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:50.088789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:51.089729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:52.089796      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:53.089863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:53.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4196" for this suite. @ 02/12/24 20:28:53.206
• [34.793 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 02/12/24 20:28:53.213
  Feb 12 20:28:53.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename init-container @ 02/12/24 20:28:53.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:28:53.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:28:53.233
  STEP: creating the pod @ 02/12/24 20:28:53.236
  Feb 12 20:28:53.236: INFO: PodSpec: initContainers in spec.initContainers
  E0212 20:28:54.090921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:55.091072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:28:56.091978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:28:56.608: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-6767" for this suite. @ 02/12/24 20:28:56.612
• [3.406 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 02/12/24 20:28:56.619
  Feb 12 20:28:56.619: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename tables @ 02/12/24 20:28:56.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:28:56.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:28:56.637
  Feb 12 20:28:56.645: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-903" for this suite. @ 02/12/24 20:28:56.649
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 02/12/24 20:28:56.656
  Feb 12 20:28:56.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 20:28:56.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:28:56.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:28:56.679
  Feb 12 20:28:56.687: INFO: Got root ca configmap in namespace "svcaccounts-586"
  Feb 12 20:28:56.693: INFO: Deleted root ca configmap in namespace "svcaccounts-586"
  E0212 20:28:57.092355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 02/12/24 20:28:57.194
  Feb 12 20:28:57.199: INFO: Recreated root ca configmap in namespace "svcaccounts-586"
  Feb 12 20:28:57.205: INFO: Updated root ca configmap in namespace "svcaccounts-586"
  STEP: waiting for the root ca configmap reconciled @ 02/12/24 20:28:57.706
  Feb 12 20:28:57.710: INFO: Reconciled root ca configmap in namespace "svcaccounts-586"
  Feb 12 20:28:57.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-586" for this suite. @ 02/12/24 20:28:57.715
• [1.065 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 02/12/24 20:28:57.722
  Feb 12 20:28:57.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:28:57.722
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:28:57.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:28:57.743
  STEP: Setting up server cert @ 02/12/24 20:28:57.77
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:28:58.072
  STEP: Deploying the webhook pod @ 02/12/24 20:28:58.083
  E0212 20:28:58.093226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Wait for the deployment to be ready @ 02/12/24 20:28:58.096
  Feb 12 20:28:58.103: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:28:59.094219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:00.094300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:29:00.118
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:29:00.133
  E0212 20:29:01.094410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:01.133: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 02/12/24 20:29:01.144
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/12/24 20:29:01.144
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 02/12/24 20:29:01.161
  E0212 20:29:02.094487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 02/12/24 20:29:02.179
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/12/24 20:29:02.179
  E0212 20:29:03.094608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 02/12/24 20:29:03.209
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/12/24 20:29:03.209
  E0212 20:29:04.095274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:05.095532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:06.095635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:07.095701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:08.096252      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 02/12/24 20:29:08.244
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/12/24 20:29:08.244
  E0212 20:29:09.096302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:10.096399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:11.096469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:12.096656      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:13.096717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:13.333: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7483" for this suite. @ 02/12/24 20:29:13.336
  STEP: Destroying namespace "webhook-markers-7593" for this suite. @ 02/12/24 20:29:13.343
• [15.630 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 02/12/24 20:29:13.352
  Feb 12 20:29:13.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:29:13.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:29:13.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:29:13.372
  STEP: Creating pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918 @ 02/12/24 20:29:13.375
  E0212 20:29:14.097818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:15.097870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 20:29:15.395
  Feb 12 20:29:15.398: INFO: Initial restart count of pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e is 0
  Feb 12 20:29:15.403: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:16.097955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:17.098054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:17.409: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:18.098356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:19.098673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:19.415: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:20.098773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:21.098861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:21.420: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:22.098987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:23.099085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:23.427: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:24.100122      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:25.100375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:25.433: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:26.100609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:27.100729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:27.437: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:28.101427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:29.101571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:29.443: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:30.101732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:31.101951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:31.450: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:32.102838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:33.103652      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:33.455: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:34.103715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:35.103882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:35.459: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  Feb 12 20:29:35.459: INFO: Restart count of pod container-probe-4918/liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e is now 1 (20.061334472s elapsed)
  E0212 20:29:36.104746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:37.104834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:37.465: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:38.105806      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:39.105903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:39.471: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:40.106606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:41.107016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:41.477: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:42.108108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:43.108191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:43.484: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:44.108265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:45.108546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:45.489: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:46.109244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:47.109477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:47.494: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:48.109473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:49.109812      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:49.500: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:50.109951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:51.110896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:51.506: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:52.111038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:53.111148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:53.511: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:54.111271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:55.111510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:55.516: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  Feb 12 20:29:55.516: INFO: Restart count of pod container-probe-4918/liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e is now 2 (40.117784386s elapsed)
  E0212 20:29:56.112244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:57.112450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:57.522: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:29:58.112605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:29:59.112921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:29:59.528: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:00.113138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:01.113822      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:01.534: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:02.114834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:03.115027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:03.540: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:04.115271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:05.115951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:05.547: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:06.115988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:07.117203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:07.552: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:08.118088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:09.118576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:09.558: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:10.119763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:11.119866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:11.564: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:12.120255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:13.120451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:13.570: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:14.120744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:15.120882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:15.575: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  Feb 12 20:30:15.575: INFO: Restart count of pod container-probe-4918/liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e is now 3 (1m0.176473682s elapsed)
  E0212 20:30:16.121747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:17.121842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:17.580: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:18.122600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:19.123106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:19.584: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:20.123507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:21.124408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:21.590: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:22.125199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:23.125338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:23.596: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:24.126320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:25.126411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:25.601: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:26.126589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:27.127073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:27.606: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:28.127643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:29.127737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:29.612: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:30.128103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:31.128299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:31.617: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:32.128866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:33.129120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:33.623: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:34.129227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:35.129420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:35.628: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  Feb 12 20:30:35.628: INFO: Restart count of pod container-probe-4918/liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e is now 4 (1m20.229785147s elapsed)
  E0212 20:30:36.129828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:37.129912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:37.633: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:38.130402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:39.130498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:39.640: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:40.130843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:41.131028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:41.646: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:42.131400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:43.131567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:43.652: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:44.132480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:45.132567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:45.657: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:46.132666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:47.133068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:47.663: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:48.133719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:49.133821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:49.669: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:50.134367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:51.134706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:51.674: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:52.134946      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:53.135026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:53.680: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:54.135964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:55.136075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:55.685: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:56.136874      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:57.137062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:57.691: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:30:58.138143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:30:59.138942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:30:59.696: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:00.139902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:01.140042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:01.702: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:02.140192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:03.140386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:03.709: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:04.140878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:05.141100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:05.714: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:06.141804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:07.141845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:07.719: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:08.142554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:09.142909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:09.725: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:10.143041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:11.143222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:11.730: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:12.143707      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:13.144723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:13.735: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:14.145452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:15.145585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:15.741: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:16.145832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:17.145867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:17.747: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:18.146921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:19.147347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:19.753: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:20.147437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:21.148153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:21.757: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:22.148826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:23.148905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:23.763: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:24.149106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:25.149817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:25.769: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:26.150903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:27.151128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:27.774: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:28.151204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:29.151301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:29.780: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:30.152013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:31.152136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:31.786: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:32.152302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:33.152501      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:33.792: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:34.153448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:35.153710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:35.798: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  E0212 20:31:36.153809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:37.153846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:37.803: INFO: Get pod liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e in namespace container-probe-4918
  Feb 12 20:31:37.803: INFO: Restart count of pod container-probe-4918/liveness-cb2f8b61-22df-47d7-aaa5-42d02ff2348e is now 5 (2m22.405224084s elapsed)
  STEP: deleting the pod @ 02/12/24 20:31:37.804
  Feb 12 20:31:37.816: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4918" for this suite. @ 02/12/24 20:31:37.82
• [144.475 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 02/12/24 20:31:37.827
  Feb 12 20:31:37.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:31:37.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:31:37.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:31:37.85
  STEP: Creating a ResourceQuota @ 02/12/24 20:31:37.853
  STEP: Getting a ResourceQuota @ 02/12/24 20:31:37.859
  STEP: Listing all ResourceQuotas with LabelSelector @ 02/12/24 20:31:37.865
  STEP: Patching the ResourceQuota @ 02/12/24 20:31:37.868
  STEP: Deleting a Collection of ResourceQuotas @ 02/12/24 20:31:37.873
  STEP: Verifying the deleted ResourceQuota @ 02/12/24 20:31:37.882
  Feb 12 20:31:37.886: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8835" for this suite. @ 02/12/24 20:31:37.889
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 02/12/24 20:31:37.896
  Feb 12 20:31:37.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 20:31:37.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:31:37.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:31:37.919
  Feb 12 20:31:37.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:31:38.154799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 02/12/24 20:31:39.145
  Feb 12 20:31:39.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-3222 --namespace=crd-publish-openapi-3222 create -f -'
  E0212 20:31:39.154876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:39.215: INFO: stderr: ""
  Feb 12 20:31:39.215: INFO: stdout: "e2e-test-crd-publish-openapi-5751-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Feb 12 20:31:39.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-3222 --namespace=crd-publish-openapi-3222 delete e2e-test-crd-publish-openapi-5751-crds test-cr'
  Feb 12 20:31:39.273: INFO: stderr: ""
  Feb 12 20:31:39.273: INFO: stdout: "e2e-test-crd-publish-openapi-5751-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Feb 12 20:31:39.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-3222 --namespace=crd-publish-openapi-3222 apply -f -'
  Feb 12 20:31:39.330: INFO: stderr: ""
  Feb 12 20:31:39.330: INFO: stdout: "e2e-test-crd-publish-openapi-5751-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Feb 12 20:31:39.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-3222 --namespace=crd-publish-openapi-3222 delete e2e-test-crd-publish-openapi-5751-crds test-cr'
  Feb 12 20:31:39.382: INFO: stderr: ""
  Feb 12 20:31:39.382: INFO: stdout: "e2e-test-crd-publish-openapi-5751-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 02/12/24 20:31:39.382
  Feb 12 20:31:39.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-3222 explain e2e-test-crd-publish-openapi-5751-crds'
  Feb 12 20:31:39.425: INFO: stderr: ""
  Feb 12 20:31:39.425: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-5751-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0212 20:31:40.154933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:40.669: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3222" for this suite. @ 02/12/24 20:31:40.679
• [2.792 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 02/12/24 20:31:40.688
  Feb 12 20:31:40.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:31:40.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:31:40.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:31:40.708
  STEP: Counting existing ResourceQuota @ 02/12/24 20:31:40.711
  E0212 20:31:41.155242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:42.155490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:43.155984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:44.156764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:45.157476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 20:31:45.716
  STEP: Ensuring resource quota status is calculated @ 02/12/24 20:31:45.721
  E0212 20:31:46.157566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:47.157711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 02/12/24 20:31:47.727
  STEP: Ensuring ResourceQuota status captures the pod usage @ 02/12/24 20:31:47.745
  E0212 20:31:48.158451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:49.158580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 02/12/24 20:31:49.751
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 02/12/24 20:31:49.753
  STEP: Ensuring a pod cannot update its resource requirements @ 02/12/24 20:31:49.755
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 02/12/24 20:31:49.76
  E0212 20:31:50.158917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:51.159616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/12/24 20:31:51.767
  STEP: Ensuring resource quota status released the pod usage @ 02/12/24 20:31:51.778
  E0212 20:31:52.159756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:53.159859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:53.783: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3798" for this suite. @ 02/12/24 20:31:53.787
• [13.108 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 02/12/24 20:31:53.797
  Feb 12 20:31:53.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename ingressclass @ 02/12/24 20:31:53.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:31:53.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:31:53.818
  STEP: getting /apis @ 02/12/24 20:31:53.821
  STEP: getting /apis/networking.k8s.io @ 02/12/24 20:31:53.825
  STEP: getting /apis/networking.k8s.iov1 @ 02/12/24 20:31:53.826
  STEP: creating @ 02/12/24 20:31:53.827
  STEP: getting @ 02/12/24 20:31:53.843
  STEP: listing @ 02/12/24 20:31:53.846
  STEP: watching @ 02/12/24 20:31:53.851
  Feb 12 20:31:53.851: INFO: starting watch
  STEP: patching @ 02/12/24 20:31:53.852
  STEP: updating @ 02/12/24 20:31:53.857
  Feb 12 20:31:53.864: INFO: waiting for watch events with expected annotations
  Feb 12 20:31:53.864: INFO: saw patched and updated annotations
  STEP: deleting @ 02/12/24 20:31:53.864
  STEP: deleting a collection @ 02/12/24 20:31:53.878
  Feb 12 20:31:53.898: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-1842" for this suite. @ 02/12/24 20:31:53.902
• [0.114 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 02/12/24 20:31:53.911
  Feb 12 20:31:53.911: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replicaset @ 02/12/24 20:31:53.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:31:53.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:31:53.932
  STEP: Create a ReplicaSet @ 02/12/24 20:31:53.935
  STEP: Verify that the required pods have come up @ 02/12/24 20:31:53.94
  Feb 12 20:31:53.944: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0212 20:31:54.160734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:55.160850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:56.160937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:57.161129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:31:58.161763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:31:58.950: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 02/12/24 20:31:58.95
  Feb 12 20:31:58.954: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 02/12/24 20:31:58.954
  STEP: DeleteCollection of the ReplicaSets @ 02/12/24 20:31:58.958
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 02/12/24 20:31:58.966
  Feb 12 20:31:58.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4535" for this suite. @ 02/12/24 20:31:58.976
• [5.079 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 02/12/24 20:31:58.99
  Feb 12 20:31:58.990: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename statefulset @ 02/12/24 20:31:58.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:31:59.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:31:59.02
  STEP: Creating service test in namespace statefulset-4338 @ 02/12/24 20:31:59.024
  STEP: Creating statefulset ss in namespace statefulset-4338 @ 02/12/24 20:31:59.034
  Feb 12 20:31:59.045: INFO: Found 0 stateful pods, waiting for 1
  E0212 20:31:59.165256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:00.165703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:01.165875      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:02.166934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:03.167033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:04.167319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:05.167382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:06.167596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:07.167720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:08.167910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:09.049: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 02/12/24 20:32:09.058
  STEP: Getting /status @ 02/12/24 20:32:09.069
  Feb 12 20:32:09.074: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 02/12/24 20:32:09.074
  Feb 12 20:32:09.084: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 02/12/24 20:32:09.084
  Feb 12 20:32:09.085: INFO: Observed &StatefulSet event: ADDED
  Feb 12 20:32:09.085: INFO: Found Statefulset ss in namespace statefulset-4338 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb 12 20:32:09.085: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 02/12/24 20:32:09.085
  Feb 12 20:32:09.085: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Feb 12 20:32:09.093: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 02/12/24 20:32:09.093
  Feb 12 20:32:09.095: INFO: Observed &StatefulSet event: ADDED
  Feb 12 20:32:09.095: INFO: Deleting all statefulset in ns statefulset-4338
  Feb 12 20:32:09.099: INFO: Scaling statefulset ss to 0
  E0212 20:32:09.168706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:10.168773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:11.168961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:12.169199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:13.169308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:14.169430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:15.169653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:16.169852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:17.170924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:18.171155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:19.115: INFO: Waiting for statefulset status.replicas updated to 0
  Feb 12 20:32:19.120: INFO: Deleting statefulset ss
  Feb 12 20:32:19.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4338" for this suite. @ 02/12/24 20:32:19.139
• [20.159 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 02/12/24 20:32:19.149
  Feb 12 20:32:19.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:32:19.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:32:19.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:32:19.17
  E0212 20:32:19.171174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:20.172175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:21.172297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:22.172712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:23.173274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:24.173761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:25.173757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:26.173862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:27.173885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:28.173948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:29.174713      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:30.174855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:31.174928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:32.175973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:33.177028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:34.177807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:35.177835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:36.177931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 02/12/24 20:32:36.179
  E0212 20:32:37.178936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:38.179820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:39.179810      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:40.179886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:41.180717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 20:32:41.182
  STEP: Ensuring resource quota status is calculated @ 02/12/24 20:32:41.189
  E0212 20:32:42.181081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:43.181185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 02/12/24 20:32:43.194
  STEP: Ensuring resource quota status captures configMap creation @ 02/12/24 20:32:43.205
  E0212 20:32:44.181289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:45.181679      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 02/12/24 20:32:45.211
  STEP: Ensuring resource quota status released usage @ 02/12/24 20:32:45.218
  E0212 20:32:46.182209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:47.183084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:47.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-673" for this suite. @ 02/12/24 20:32:47.23
• [28.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 02/12/24 20:32:47.237
  Feb 12 20:32:47.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 20:32:47.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:32:47.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:32:47.259
  STEP: Create set of pods @ 02/12/24 20:32:47.263
  Feb 12 20:32:47.272: INFO: created test-pod-1
  Feb 12 20:32:47.278: INFO: created test-pod-2
  Feb 12 20:32:47.288: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 02/12/24 20:32:47.288
  E0212 20:32:48.183694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:49.183859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 02/12/24 20:32:49.338
  Feb 12 20:32:49.343: INFO: Pod quantity 3 is different from expected quantity 0
  E0212 20:32:50.184037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:50.343: INFO: Pod quantity 2 is different from expected quantity 0
  E0212 20:32:51.184202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:51.344: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7688" for this suite. @ 02/12/24 20:32:51.348
• [4.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 02/12/24 20:32:51.358
  Feb 12 20:32:51.358: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 20:32:51.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:32:51.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:32:51.379
  STEP: creating service in namespace services-4266 @ 02/12/24 20:32:51.382
  STEP: creating service affinity-nodeport in namespace services-4266 @ 02/12/24 20:32:51.382
  STEP: creating replication controller affinity-nodeport in namespace services-4266 @ 02/12/24 20:32:51.399
  I0212 20:32:51.408823      20 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-4266, replica count: 3
  E0212 20:32:52.184689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:53.185445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:54.185838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 20:32:54.460358      20 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 20:32:54.474: INFO: Creating new exec pod
  E0212 20:32:55.186941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:56.187014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:32:57.187116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:57.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4266 exec execpod-affinitymd8ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Feb 12 20:32:57.603: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Feb 12 20:32:57.603: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:32:57.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4266 exec execpod-affinitymd8ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.47 80'
  Feb 12 20:32:57.702: INFO: stderr: "+ nc -v -t -w 2 10.152.183.47 80\n+ echo hostName\nConnection to 10.152.183.47 80 port [tcp/http] succeeded!\n"
  Feb 12 20:32:57.702: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:32:57.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4266 exec execpod-affinitymd8ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.42.94 31242'
  Feb 12 20:32:57.799: INFO: stderr: "+ nc -v -t -w 2 172.31.42.94 31242\n+ echo hostName\nConnection to 172.31.42.94 31242 port [tcp/*] succeeded!\n"
  Feb 12 20:32:57.799: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:32:57.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4266 exec execpod-affinitymd8ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.5.108 31242'
  Feb 12 20:32:57.897: INFO: stderr: "+ nc -v -t -w 2 172.31.5.108 31242\n+ echo hostName\nConnection to 172.31.5.108 31242 port [tcp/*] succeeded!\n"
  Feb 12 20:32:57.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb 12 20:32:57.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=services-4266 exec execpod-affinitymd8ct -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.42.94:31242/ ; done'
  Feb 12 20:32:58.086: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.42.94:31242/\n"
  Feb 12 20:32:58.086: INFO: stdout: "\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c\naffinity-nodeport-2sr9c"
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.086: INFO: Received response from host: affinity-nodeport-2sr9c
  Feb 12 20:32:58.087: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-4266, will wait for the garbage collector to delete the pods @ 02/12/24 20:32:58.104
  Feb 12 20:32:58.166: INFO: Deleting ReplicationController affinity-nodeport took: 7.514213ms
  E0212 20:32:58.187350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:32:58.267: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.819067ms
  E0212 20:32:59.188048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:00.189031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:01.189849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:33:01.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4266" for this suite. @ 02/12/24 20:33:01.404
• [10.054 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 02/12/24 20:33:01.411
  Feb 12 20:33:01.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename init-container @ 02/12/24 20:33:01.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:33:01.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:33:01.433
  STEP: creating the pod @ 02/12/24 20:33:01.436
  Feb 12 20:33:01.436: INFO: PodSpec: initContainers in spec.initContainers
  E0212 20:33:02.190838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:03.190870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:04.191401      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:05.191615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:06.191756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:07.192080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:08.192592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:09.192758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:10.192948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:11.193227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:12.193323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:13.193478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:14.193882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:15.194897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:16.195105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:17.195176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:18.195417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:19.195736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:20.195990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:21.196303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:22.196462      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:23.196646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:24.196772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:25.196929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:26.197132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:27.197289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:28.197450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:29.197838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:30.197879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:31.198193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:32.198921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:33.199143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:34.199237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:35.199392      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:36.199593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:37.199807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:38.200677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:39.200819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:40.200994      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:41.201092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:42.201299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:43.201491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:44.201818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:45.202994      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:33:45.966: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-225feb43-75d6-4459-9c35-6a89c78892df", GenerateName:"", Namespace:"init-container-5781", SelfLink:"", UID:"57c11542-15c0-416f-bdf4-74edef43361f", ResourceVersion:"40946", Generation:0, CreationTimestamp:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"436676310"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0007559f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 12, 20, 33, 45, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000755ae8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-m7nxn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc005635800), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-m7nxn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-m7nxn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-m7nxn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0029c9fd0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-5-108", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004351810), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003d78370)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003d78390)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003d78398), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003d7839c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0015be370), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 12, 20, 33, 2, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.5.108", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.5.108"}}, PodIP:"192.168.150.209", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.150.209"}}, StartTime:time.Date(2024, time.February, 12, 20, 33, 1, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0043518f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004351960)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://270156d908ec31e4d0c839f7027165f464c0240a69f8db3885cd596254062b8c", Started:(*bool)(0xc003d78afa), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc005635860), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003d78b2f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc005635840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc003d78a7f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Feb 12 20:33:45.966: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5781" for this suite. @ 02/12/24 20:33:45.971
• [44.568 seconds]
------------------------------
SSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 02/12/24 20:33:45.979
  Feb 12 20:33:45.980: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename conformance-tests @ 02/12/24 20:33:45.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:33:45.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:33:46
  STEP: Getting node addresses @ 02/12/24 20:33:46.004
  Feb 12 20:33:46.004: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Feb 12 20:33:46.009: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-401" for this suite. @ 02/12/24 20:33:46.013
• [0.042 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 02/12/24 20:33:46.022
  Feb 12 20:33:46.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 20:33:46.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:33:46.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:33:46.043
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:33:46.048
  E0212 20:33:46.203095      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:47.203382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:48.204083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:49.204189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:33:50.072
  Feb 12 20:33:50.077: INFO: Trying to get logs from node ip-172-31-91-42 pod downwardapi-volume-3aaebfcc-6b6e-4ac1-96a7-ee27d8f80f4c container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:33:50.093
  Feb 12 20:33:50.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6102" for this suite. @ 02/12/24 20:33:50.114
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 02/12/24 20:33:50.122
  Feb 12 20:33:50.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename endpointslicemirroring @ 02/12/24 20:33:50.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:33:50.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:33:50.169
  STEP: mirroring a new custom Endpoint @ 02/12/24 20:33:50.183
  Feb 12 20:33:50.192: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0212 20:33:50.204267      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:51.204561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 02/12/24 20:33:52.197
  E0212 20:33:52.204529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:33:52.208: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0212 20:33:53.204976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:54.205254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 02/12/24 20:33:54.214
  Feb 12 20:33:54.224: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0212 20:33:55.205835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:56.205960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:33:56.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-8696" for this suite. @ 02/12/24 20:33:56.233
• [6.118 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 02/12/24 20:33:56.241
  Feb 12 20:33:56.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:33:56.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:33:56.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:33:56.261
  STEP: Creating a ResourceQuota with best effort scope @ 02/12/24 20:33:56.265
  STEP: Ensuring ResourceQuota status is calculated @ 02/12/24 20:33:56.269
  E0212 20:33:57.206917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:33:58.207368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 02/12/24 20:33:58.276
  STEP: Ensuring ResourceQuota status is calculated @ 02/12/24 20:33:58.282
  E0212 20:33:59.207642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:00.207742      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 02/12/24 20:34:00.287
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 02/12/24 20:34:00.3
  E0212 20:34:01.207880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:02.208140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 02/12/24 20:34:02.306
  E0212 20:34:03.208311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:04.208443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/12/24 20:34:04.311
  STEP: Ensuring resource quota status released the pod usage @ 02/12/24 20:34:04.327
  E0212 20:34:05.208542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:06.208655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 02/12/24 20:34:06.332
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 02/12/24 20:34:06.343
  E0212 20:34:07.209305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:08.209774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 02/12/24 20:34:08.354
  E0212 20:34:09.209866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:10.209945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/12/24 20:34:10.359
  STEP: Ensuring resource quota status released the pod usage @ 02/12/24 20:34:10.373
  E0212 20:34:11.210070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:12.210980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:34:12.380: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5817" for this suite. @ 02/12/24 20:34:12.384
• [16.152 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 02/12/24 20:34:12.392
  Feb 12 20:34:12.392: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:34:12.393
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:12.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:12.418
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:34:12.421
  E0212 20:34:13.211040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:14.212041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:15.212237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:16.213156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:34:16.445
  Feb 12 20:34:16.450: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-4579db72-2bfd-4393-9d34-87abfc91624a container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:34:16.468
  Feb 12 20:34:16.486: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5123" for this suite. @ 02/12/24 20:34:16.49
• [4.107 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 02/12/24 20:34:16.499
  Feb 12 20:34:16.499: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename podtemplate @ 02/12/24 20:34:16.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:16.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:16.521
  STEP: Create set of pod templates @ 02/12/24 20:34:16.526
  Feb 12 20:34:16.531: INFO: created test-podtemplate-1
  Feb 12 20:34:16.536: INFO: created test-podtemplate-2
  Feb 12 20:34:16.543: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 02/12/24 20:34:16.543
  STEP: delete collection of pod templates @ 02/12/24 20:34:16.547
  Feb 12 20:34:16.547: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 02/12/24 20:34:16.569
  Feb 12 20:34:16.569: INFO: requesting list of pod templates to confirm quantity
  Feb 12 20:34:16.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6614" for this suite. @ 02/12/24 20:34:16.578
• [0.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 02/12/24 20:34:16.585
  Feb 12 20:34:16.585: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:34:16.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:16.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:16.607
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:34:16.61
  E0212 20:34:17.213999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:18.214638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:19.215422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:20.215517      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:34:20.635
  Feb 12 20:34:20.640: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-a5498706-258f-4b29-8b03-65a6cd5057f9 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:34:20.648
  Feb 12 20:34:20.666: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9051" for this suite. @ 02/12/24 20:34:20.67
• [4.093 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 02/12/24 20:34:20.678
  Feb 12 20:34:20.678: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:34:20.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:20.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:20.701
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 02/12/24 20:34:20.704
  E0212 20:34:21.215614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:22.215708      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:23.216093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:24.216328      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:34:24.725
  Feb 12 20:34:24.730: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-ba2fdfcb-30bc-4f33-8ab6-7719ad62c964 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:34:24.738
  Feb 12 20:34:24.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3094" for this suite. @ 02/12/24 20:34:24.758
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 02/12/24 20:34:24.769
  Feb 12 20:34:24.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 20:34:24.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:24.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:24.789
  STEP: Creating a pod to test substitution in volume subpath @ 02/12/24 20:34:24.792
  E0212 20:34:25.216427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:26.216456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:27.216511      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:28.216680      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:34:28.82
  Feb 12 20:34:28.825: INFO: Trying to get logs from node ip-172-31-5-108 pod var-expansion-c65ba0b6-2799-4237-8033-c63db7f51b56 container dapi-container: <nil>
  STEP: delete the pod @ 02/12/24 20:34:28.832
  Feb 12 20:34:28.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2165" for this suite. @ 02/12/24 20:34:28.852
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 02/12/24 20:34:28.86
  Feb 12 20:34:28.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:34:28.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:28.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:28.882
  STEP: Counting existing ResourceQuota @ 02/12/24 20:34:28.886
  E0212 20:34:29.217442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:30.217826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:31.217931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:32.218938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:33.219936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 20:34:33.89
  STEP: Ensuring resource quota status is calculated @ 02/12/24 20:34:33.897
  E0212 20:34:34.220754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:35.220892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 02/12/24 20:34:35.903
  STEP: Ensuring resource quota status captures replicaset creation @ 02/12/24 20:34:35.915
  E0212 20:34:36.221590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:37.221736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 02/12/24 20:34:37.92
  STEP: Ensuring resource quota status released usage @ 02/12/24 20:34:37.929
  E0212 20:34:38.221760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:39.221869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:34:39.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6334" for this suite. @ 02/12/24 20:34:39.939
• [11.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 02/12/24 20:34:39.947
  Feb 12 20:34:39.947: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename services @ 02/12/24 20:34:39.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:39.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:39.971
  STEP: creating an Endpoint @ 02/12/24 20:34:39.977
  STEP: waiting for available Endpoint @ 02/12/24 20:34:39.982
  STEP: listing all Endpoints @ 02/12/24 20:34:39.984
  STEP: updating the Endpoint @ 02/12/24 20:34:39.988
  STEP: fetching the Endpoint @ 02/12/24 20:34:39.995
  STEP: patching the Endpoint @ 02/12/24 20:34:40
  STEP: fetching the Endpoint @ 02/12/24 20:34:40.008
  STEP: deleting the Endpoint by Collection @ 02/12/24 20:34:40.011
  STEP: waiting for Endpoint deletion @ 02/12/24 20:34:40.021
  STEP: fetching the Endpoint @ 02/12/24 20:34:40.022
  Feb 12 20:34:40.026: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-822" for this suite. @ 02/12/24 20:34:40.031
• [0.092 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 02/12/24 20:34:40.04
  Feb 12 20:34:40.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename containers @ 02/12/24 20:34:40.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:40.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:40.071
  STEP: Creating a pod to test override all @ 02/12/24 20:34:40.074
  E0212 20:34:40.222920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:41.223018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:42.223951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:43.224043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:34:44.1
  Feb 12 20:34:44.103: INFO: Trying to get logs from node ip-172-31-5-108 pod client-containers-0ebbc3ba-7598-4a70-8303-81698a7b82ad container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:34:44.112
  Feb 12 20:34:44.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8660" for this suite. @ 02/12/24 20:34:44.135
• [4.103 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 02/12/24 20:34:44.143
  Feb 12 20:34:44.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubelet-test @ 02/12/24 20:34:44.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:44.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:44.166
  E0212 20:34:44.224798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:45.224910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:46.224993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:47.225085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:34:48.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9878" for this suite. @ 02/12/24 20:34:48.193
• [4.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 02/12/24 20:34:48.2
  Feb 12 20:34:48.200: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:34:48.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:48.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:48.221
  STEP: Creating configMap with name projected-configmap-test-volume-map-6bafbaae-ce68-41b6-8fe9-adc53d84eed2 @ 02/12/24 20:34:48.224
  E0212 20:34:48.225558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:34:48.232
  E0212 20:34:49.225843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:50.226919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:34:50.253
  Feb 12 20:34:50.257: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-configmaps-ba80a1d9-6e5e-449d-bde4-2cd4dc0de04f container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:34:50.264
  Feb 12 20:34:50.282: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3619" for this suite. @ 02/12/24 20:34:50.287
• [2.095 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 02/12/24 20:34:50.295
  Feb 12 20:34:50.295: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:34:50.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:34:50.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:34:50.319
  STEP: Counting existing ResourceQuota @ 02/12/24 20:34:50.322
  E0212 20:34:51.227214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:52.227383      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:53.227815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:54.228233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:55.228348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 20:34:55.326
  STEP: Ensuring resource quota status is calculated @ 02/12/24 20:34:55.333
  E0212 20:34:56.228591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:57.228712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 02/12/24 20:34:57.339
  STEP: Ensuring resource quota status captures replication controller creation @ 02/12/24 20:34:57.35
  E0212 20:34:58.228907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:34:59.229205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 02/12/24 20:34:59.357
  STEP: Ensuring resource quota status released usage @ 02/12/24 20:34:59.365
  E0212 20:35:00.229903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:01.229993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:01.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8082" for this suite. @ 02/12/24 20:35:01.376
• [11.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 02/12/24 20:35:01.386
  Feb 12 20:35:01.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 20:35:01.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:35:01.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:35:01.406
  Feb 12 20:35:01.409: INFO: Creating simple deployment test-new-deployment
  Feb 12 20:35:01.427: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0212 20:35:02.230112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:03.230205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 02/12/24 20:35:03.445
  STEP: updating a scale subresource @ 02/12/24 20:35:03.448
  STEP: verifying the deployment Spec.Replicas was modified @ 02/12/24 20:35:03.455
  STEP: Patch a scale subresource @ 02/12/24 20:35:03.459
  Feb 12 20:35:03.484: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4678",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "76b35380-5741-4427-9c45-f1273b9f6636",
      ResourceVersion: (string) (len=5) "41557",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843366901,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366901,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366901,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 20:35:03.488: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4678",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d3c944e-1e1c-460f-aa6c-eecb6d1fdb95",
      ResourceVersion: (string) (len=5) "41563",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843366901,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "76b35380-5741-4427-9c45-f1273b9f6636",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 36 62 33 35 33  38 30 2d 35 37 34 31 2d  |\"76b35380-5741-|
              00000120  34 34 32 37 2d 39 63 34  35 2d 66 31 32 37 33 62  |4427-9c45-f1273b|
              00000130  39 66 36 36 33 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9f6636\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 20:35:03.495: INFO: Pod "test-new-deployment-557759b7c7-mhhkv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-mhhkv",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4678",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "299906a4-eed9-4253-aadd-1621fb900e19",
      ResourceVersion: (string) (len=5) "41551",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843366901,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0d3c944e-1e1c-460f-aa6c-eecb6d1fdb95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366901,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 64  33 63 39 34 34 65 2d 31  |d\":\"0d3c944e-1|
              00000090  65 31 63 2d 34 36 30 66  2d 61 61 36 63 2d 65 65  |e1c-460f-aa6c-ee|
              000000a0  63 62 36 64 31 66 64 62  39 35 5c 22 7d 22 3a 7b  |cb6d1fdb95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  30 2e 32 34 37 5c 22 7d  |2.168.150.247\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mmp88",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mmp88",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366901,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366902,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366901,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.247",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.247"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843366901,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843366902,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5fdd8da0facb0c66b6e1a8dbf8b7025f2592af93521cdf67d137a7c89cba1c11",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 20:35:03.497: INFO: Pod "test-new-deployment-557759b7c7-ppchn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-ppchn",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4678",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "42cfb3d0-8e33-4a25-80eb-5edc7095019c",
      ResourceVersion: (string) (len=5) "41562",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843366903,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0d3c944e-1e1c-460f-aa6c-eecb6d1fdb95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 64  33 63 39 34 34 65 2d 31  |d\":\"0d3c944e-1|
              00000090  65 31 63 2d 34 36 30 66  2d 61 61 36 63 2d 65 65  |e1c-460f-aa6c-ee|
              000000a0  63 62 36 64 31 66 64 62  39 35 5c 22 7d 22 3a 7b  |cb6d1fdb95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cb5h2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cb5h2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843366903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 20:35:03.497: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4678" for this suite. @ 02/12/24 20:35:03.503
• [2.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 02/12/24 20:35:03.514
  Feb 12 20:35:03.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:35:03.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:35:03.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:35:03.564
  STEP: Creating pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675 @ 02/12/24 20:35:03.567
  E0212 20:35:04.230983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:05.231056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 20:35:05.586
  Feb 12 20:35:05.590: INFO: Initial restart count of pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 is 0
  Feb 12 20:35:05.594: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:06.232152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:07.232309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:07.599: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:08.232740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:09.232833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:09.604: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:10.232984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:11.233154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:11.608: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:12.233996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:13.234895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:13.615: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:14.235074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:15.235374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:15.621: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:16.236214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:17.236438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:17.627: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:18.236644      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:19.236738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:19.633: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:20.237365      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:21.237481      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:21.638: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:22.237897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:23.238919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:23.643: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:24.239353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:25.239506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:25.649: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:26.240140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:27.240252      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:27.654: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:28.240444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:29.240535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:29.660: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:30.241303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:31.241494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:31.666: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:32.241847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:33.241939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:33.671: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:34.242054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:35.242141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:35.677: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:36.242709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:37.242926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:37.682: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:38.243759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:39.243867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:39.687: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:40.244339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:41.244452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:41.693: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:42.244711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:43.244789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:43.698: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:44.245818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:45.245858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:45.703: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:46.246551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:47.246650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:47.709: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:48.246882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:49.246996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:49.714: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:50.247965      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:51.248063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:51.719: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:52.248867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:53.249082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:53.724: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:54.249184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:55.249397      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:55.730: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:56.250234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:57.250910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:57.734: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:35:58.251220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:35:59.251326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:35:59.740: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:00.251824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:01.252022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:01.745: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:02.253024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:03.253111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:03.749: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:04.253488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:05.253615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:05.755: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:06.253846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:07.253939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:07.760: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:08.254710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:09.254808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:09.765: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:10.254938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:11.255139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:11.771: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:12.255514      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:13.255617      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:13.775: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:14.256166      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:15.256338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:15.781: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:16.257071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:17.257197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:17.786: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:18.258029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:19.259006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:19.792: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:20.259450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:21.259649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:21.798: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:22.259757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:23.259825      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:23.803: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:24.259975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:25.260071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:25.809: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:26.260503      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:27.260650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:27.814: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:28.260746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:29.260843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:29.820: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:30.261850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:31.261947      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:31.827: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:32.262044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:33.262910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:33.832: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:34.263020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:35.263121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:35.838: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:36.263991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:37.264050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:37.843: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:38.264196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:39.264420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:39.850: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:40.264660      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:41.264722      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:41.857: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:42.265278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:43.265350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:43.862: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:44.266133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:45.266242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:45.868: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:46.266346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:47.266435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:47.873: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:48.266922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:49.267023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:49.878: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:50.267180      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:51.267242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:51.884: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:52.268065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:53.268164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:53.890: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:54.268878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:55.269076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:55.896: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:56.269190      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:57.269410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:57.901: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:36:58.269828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:36:59.269957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:36:59.907: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:00.270892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:01.270999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:01.913: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:02.271585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:03.271788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:03.918: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:04.272164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:05.272331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:05.924: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:06.273051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:07.273226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:07.931: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:08.273382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:09.273631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:09.935: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:10.274356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:11.274564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:11.941: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:12.275401      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:13.275497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:13.947: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:14.276214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:15.276391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:15.952: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:16.277070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:17.277635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:17.959: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:18.278611      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:19.278746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:19.965: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:20.279553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:21.279701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:21.969: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:22.279738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:23.279896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:23.975: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:24.280887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:25.281005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:25.980: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:26.281478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:27.281729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:27.986: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:28.281821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:29.281999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:29.993: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:30.282508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:31.282943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:31.998: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:32.283037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:33.283236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:34.004: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:34.283763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:35.284571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:36.009: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:36.285487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:37.285581      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:38.014: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:38.285818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:39.285914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:40.020: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:40.286618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:41.286724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:42.025: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:42.287625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:43.287751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:44.030: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:44.288242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:45.288357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:46.035: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:46.288779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:47.289566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:48.045: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:48.290581      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:49.291013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:50.051: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:50.291831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:51.292065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:52.055: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:52.293103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:53.293198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:54.061: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:54.293403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:55.293505      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:56.068: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:56.293749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:57.293831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:37:58.074: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:37:58.294865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:37:59.295165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:00.078: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:00.295193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:01.295277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:02.084: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:02.295466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:03.296485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:04.089: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:04.296571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:05.296704      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:06.094: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:06.297403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:07.297529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:08.099: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:08.298319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:09.298413      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:10.105: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:10.298919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:11.299014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:12.110: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:12.299308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:13.299522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:14.115: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:14.299738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:15.299925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:16.121: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:16.300469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:17.300649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:18.125: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:18.301139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:19.301872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:20.132: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:20.302791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:21.302832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:22.137: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:22.303272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:23.303514      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:24.143: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:24.304004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:25.304783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:26.150: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:26.305662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:27.305828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:28.156: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:28.306477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:29.306592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:30.160: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:30.307232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:31.307330      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:32.166: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:32.308112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:33.308354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:34.173: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:34.309278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:35.309645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:36.179: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:36.310451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:37.310551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:38.184: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:38.310724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:39.311485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:40.190: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:40.311835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:41.312635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:42.195: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:42.313256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:43.313383      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:44.201: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:44.314377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:45.314471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:46.206: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:46.315181      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:47.315479      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:48.212: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:48.316173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:49.316268      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:50.217: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:50.316782      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:51.316873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:52.223: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:52.317467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:53.318445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:54.229: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:54.319384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:55.319635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:56.234: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:56.319742      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:57.319961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:38:58.240: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:38:58.320163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:38:59.321369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:00.245: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:39:00.322110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:01.322200      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:02.252: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:39:02.322458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:03.322550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:04.258: INFO: Get pod test-webserver-d4942cf3-639e-4054-8115-2258a2955e21 in namespace container-probe-7675
  E0212 20:39:04.323260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:05.323640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/12/24 20:39:06.258
  Feb 12 20:39:06.271: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7675" for this suite. @ 02/12/24 20:39:06.276
• [242.769 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 02/12/24 20:39:06.284
  Feb 12 20:39:06.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/12/24 20:39:06.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:06.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:06.317
  Feb 12 20:39:06.320: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:39:06.324424      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:06.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3254" for this suite. @ 02/12/24 20:39:06.868
• [0.592 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 02/12/24 20:39:06.876
  Feb 12 20:39:06.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-runtime @ 02/12/24 20:39:06.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:06.896
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:06.898
  STEP: create the container @ 02/12/24 20:39:06.901
  W0212 20:39:06.912389      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 02/12/24 20:39:06.912
  E0212 20:39:07.324570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:08.324643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:09.325190      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/12/24 20:39:09.935
  STEP: the container should be terminated @ 02/12/24 20:39:09.939
  STEP: the termination message should be set @ 02/12/24 20:39:09.939
  Feb 12 20:39:09.939: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 02/12/24 20:39:09.939
  Feb 12 20:39:09.955: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7703" for this suite. @ 02/12/24 20:39:09.959
• [3.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 02/12/24 20:39:09.968
  Feb 12 20:39:09.968: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename podtemplate @ 02/12/24 20:39:09.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:09.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:09.99
  Feb 12 20:39:10.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6750" for this suite. @ 02/12/24 20:39:10.03
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 02/12/24 20:39:10.039
  Feb 12 20:39:10.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:39:10.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:10.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:10.061
  STEP: Creating secret with name secret-test-25931e17-fce1-4437-8d8c-c8785ad722c4 @ 02/12/24 20:39:10.088
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:39:10.093
  E0212 20:39:10.325294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:11.326124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:12.326540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:13.326843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:39:14.118
  Feb 12 20:39:14.122: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-362aa7ee-1798-4e9c-b68d-b1c99f775b80 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:39:14.133
  Feb 12 20:39:14.150: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7144" for this suite. @ 02/12/24 20:39:14.155
  STEP: Destroying namespace "secret-namespace-5988" for this suite. @ 02/12/24 20:39:14.163
• [4.131 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 02/12/24 20:39:14.17
  Feb 12 20:39:14.170: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:39:14.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:14.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:14.19
  STEP: Creating projection with secret that has name projected-secret-test-map-f1f7eca2-1227-4bc4-9018-919e8d447f75 @ 02/12/24 20:39:14.193
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:39:14.197
  E0212 20:39:14.327103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:15.327303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:16.327930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:17.328251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:39:18.221
  Feb 12 20:39:18.225: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-projected-secrets-f82c9cf0-6630-42e1-ba90-104880cf6e08 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:39:18.236
  Feb 12 20:39:18.253: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5257" for this suite. @ 02/12/24 20:39:18.257
• [4.095 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 02/12/24 20:39:18.266
  Feb 12 20:39:18.266: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 20:39:18.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:18.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:18.285
  Feb 12 20:39:18.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:39:18.328410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:19.328718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 02/12/24 20:39:19.514
  Feb 12 20:39:19.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-516 --namespace=crd-publish-openapi-516 create -f -'
  E0212 20:39:20.328961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:21.329999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:21.583: INFO: stderr: ""
  Feb 12 20:39:21.583: INFO: stdout: "e2e-test-crd-publish-openapi-7794-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Feb 12 20:39:21.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-516 --namespace=crd-publish-openapi-516 delete e2e-test-crd-publish-openapi-7794-crds test-cr'
  Feb 12 20:39:21.634: INFO: stderr: ""
  Feb 12 20:39:21.634: INFO: stdout: "e2e-test-crd-publish-openapi-7794-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Feb 12 20:39:21.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-516 --namespace=crd-publish-openapi-516 apply -f -'
  Feb 12 20:39:21.688: INFO: stderr: ""
  Feb 12 20:39:21.688: INFO: stdout: "e2e-test-crd-publish-openapi-7794-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Feb 12 20:39:21.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-516 --namespace=crd-publish-openapi-516 delete e2e-test-crd-publish-openapi-7794-crds test-cr'
  Feb 12 20:39:21.739: INFO: stderr: ""
  Feb 12 20:39:21.739: INFO: stdout: "e2e-test-crd-publish-openapi-7794-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 02/12/24 20:39:21.739
  Feb 12 20:39:21.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=crd-publish-openapi-516 explain e2e-test-crd-publish-openapi-7794-crds'
  Feb 12 20:39:21.785: INFO: stderr: ""
  Feb 12 20:39:21.785: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-7794-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0212 20:39:22.330320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:22.991: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-516" for this suite. @ 02/12/24 20:39:22.999
• [4.741 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 02/12/24 20:39:23.007
  Feb 12 20:39:23.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:39:23.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:23.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:23.032
  STEP: Creating a pod to test emptydir volume type on node default medium @ 02/12/24 20:39:23.035
  E0212 20:39:23.330724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:24.330843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:25.331518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:26.331725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:39:27.061
  Feb 12 20:39:27.065: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-bf94e7bd-d31e-4189-a5c0-43ca72f62be0 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:39:27.073
  Feb 12 20:39:27.087: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7425" for this suite. @ 02/12/24 20:39:27.092
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 02/12/24 20:39:27.099
  Feb 12 20:39:27.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename downward-api @ 02/12/24 20:39:27.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:27.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:27.12
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:39:27.123
  E0212 20:39:27.332527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:28.332792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:29.333227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:30.333356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:39:31.151
  Feb 12 20:39:31.155: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-1042eebf-d9c3-4133-ae94-b3873f36f04d container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:39:31.163
  Feb 12 20:39:31.180: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2295" for this suite. @ 02/12/24 20:39:31.185
• [4.095 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 02/12/24 20:39:31.193
  Feb 12 20:39:31.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 20:39:31.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:31.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:31.222
  STEP: Creating a pod to test service account token:  @ 02/12/24 20:39:31.228
  E0212 20:39:31.333992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:32.334085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:33.335041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:34.335157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:39:35.263
  Feb 12 20:39:35.267: INFO: Trying to get logs from node ip-172-31-5-108 pod test-pod-7bf3fada-0836-487d-ad5e-5b481277e0e4 container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:39:35.275
  Feb 12 20:39:35.291: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1935" for this suite. @ 02/12/24 20:39:35.296
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 02/12/24 20:39:35.303
  Feb 12 20:39:35.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename hostport @ 02/12/24 20:39:35.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:35.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:35.323
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 02/12/24 20:39:35.33
  E0212 20:39:35.336083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:36.336624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:37.336871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.42.94 on the node which pod1 resides and expect scheduled @ 02/12/24 20:39:37.348
  E0212 20:39:38.336988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:39.337059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:40.337826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:41.337860      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:42.338043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:43.338954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:44.339405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:45.339634      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:46.339778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:47.340509      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:48.341498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:49.341615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.42.94 but use UDP protocol on the node which pod2 resides @ 02/12/24 20:39:49.392
  E0212 20:39:50.341855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:51.342929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:52.343048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:53.343128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 02/12/24 20:39:53.428
  Feb 12 20:39:53.428: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.42.94 http://127.0.0.1:54323/hostname] Namespace:hostport-8910 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:39:53.428: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:39:53.429: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:39:53.429: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-8910/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.42.94+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.42.94, port: 54323 @ 02/12/24 20:39:53.485
  Feb 12 20:39:53.485: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.42.94:54323/hostname] Namespace:hostport-8910 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:39:53.485: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:39:53.485: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:39:53.486: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-8910/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.42.94%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.42.94, port: 54323 UDP @ 02/12/24 20:39:53.532
  Feb 12 20:39:53.532: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.42.94 54323] Namespace:hostport-8910 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:39:53.532: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:39:53.533: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:39:53.533: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-8910/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.42.94+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0212 20:39:54.344123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:55.344263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:56.344356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:57.344515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:39:58.344625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:58.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-8910" for this suite. @ 02/12/24 20:39:58.59
• [23.295 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 02/12/24 20:39:58.598
  Feb 12 20:39:58.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename events @ 02/12/24 20:39:58.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:58.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:58.62
  STEP: Create set of events @ 02/12/24 20:39:58.625
  STEP: get a list of Events with a label in the current namespace @ 02/12/24 20:39:58.643
  STEP: delete a list of events @ 02/12/24 20:39:58.646
  Feb 12 20:39:58.646: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 02/12/24 20:39:58.675
  Feb 12 20:39:58.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1700" for this suite. @ 02/12/24 20:39:58.682
• [0.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 02/12/24 20:39:58.69
  Feb 12 20:39:58.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename controllerrevisions @ 02/12/24 20:39:58.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:39:58.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:39:58.71
  STEP: Creating DaemonSet "e2e-p6v27-daemon-set" @ 02/12/24 20:39:58.733
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/12/24 20:39:58.738
  Feb 12 20:39:58.742: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:39:58.742: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:39:58.746: INFO: Number of nodes with available pods controlled by daemonset e2e-p6v27-daemon-set: 0
  Feb 12 20:39:58.746: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 20:39:59.344670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:39:59.743: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:39:59.743: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:39:59.747: INFO: Number of nodes with available pods controlled by daemonset e2e-p6v27-daemon-set: 1
  Feb 12 20:39:59.747: INFO: Node ip-172-31-42-94 is running 0 daemon pod, expected 1
  E0212 20:40:00.344845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:40:00.744: INFO: DaemonSet pods can't tolerate node ip-172-31-35-5 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:40:00.745: INFO: DaemonSet pods can't tolerate node ip-172-31-5-243 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Feb 12 20:40:00.748: INFO: Number of nodes with available pods controlled by daemonset e2e-p6v27-daemon-set: 3
  Feb 12 20:40:00.748: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-p6v27-daemon-set
  STEP: Confirm DaemonSet "e2e-p6v27-daemon-set" successfully created with "daemonset-name=e2e-p6v27-daemon-set" label @ 02/12/24 20:40:00.753
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-p6v27-daemon-set" @ 02/12/24 20:40:00.76
  Feb 12 20:40:00.764: INFO: Located ControllerRevision: "e2e-p6v27-daemon-set-6c7979ff9b"
  STEP: Patching ControllerRevision "e2e-p6v27-daemon-set-6c7979ff9b" @ 02/12/24 20:40:00.768
  Feb 12 20:40:00.776: INFO: e2e-p6v27-daemon-set-6c7979ff9b has been patched
  STEP: Create a new ControllerRevision @ 02/12/24 20:40:00.776
  Feb 12 20:40:00.781: INFO: Created ControllerRevision: e2e-p6v27-daemon-set-7f9556b878
  STEP: Confirm that there are two ControllerRevisions @ 02/12/24 20:40:00.781
  Feb 12 20:40:00.781: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb 12 20:40:00.784: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-p6v27-daemon-set-6c7979ff9b" @ 02/12/24 20:40:00.784
  STEP: Confirm that there is only one ControllerRevision @ 02/12/24 20:40:00.792
  Feb 12 20:40:00.792: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb 12 20:40:00.795: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-p6v27-daemon-set-7f9556b878" @ 02/12/24 20:40:00.799
  Feb 12 20:40:00.809: INFO: e2e-p6v27-daemon-set-7f9556b878 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 02/12/24 20:40:00.809
  W0212 20:40:00.814833      20 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 02/12/24 20:40:00.814
  Feb 12 20:40:00.814: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0212 20:40:01.344948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:40:01.817: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb 12 20:40:01.824: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-p6v27-daemon-set-7f9556b878=updated" @ 02/12/24 20:40:01.824
  STEP: Confirm that there is only one ControllerRevision @ 02/12/24 20:40:01.834
  Feb 12 20:40:01.834: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb 12 20:40:01.837: INFO: Found 1 ControllerRevisions
  Feb 12 20:40:01.841: INFO: ControllerRevision "e2e-p6v27-daemon-set-7c4b55b799" has revision 3
  STEP: Deleting DaemonSet "e2e-p6v27-daemon-set" @ 02/12/24 20:40:01.849
  STEP: deleting DaemonSet.extensions e2e-p6v27-daemon-set in namespace controllerrevisions-7284, will wait for the garbage collector to delete the pods @ 02/12/24 20:40:01.85
  Feb 12 20:40:01.913: INFO: Deleting DaemonSet.extensions e2e-p6v27-daemon-set took: 8.864299ms
  Feb 12 20:40:02.013: INFO: Terminating DaemonSet.extensions e2e-p6v27-daemon-set pods took: 100.575466ms
  E0212 20:40:02.345302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:03.345427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:40:03.718: INFO: Number of nodes with available pods controlled by daemonset e2e-p6v27-daemon-set: 0
  Feb 12 20:40:03.718: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-p6v27-daemon-set
  Feb 12 20:40:03.722: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"42695"},"items":null}

  Feb 12 20:40:03.724: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"42696"},"items":null}

  Feb 12 20:40:03.739: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-7284" for this suite. @ 02/12/24 20:40:03.742
• [5.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 02/12/24 20:40:03.75
  Feb 12 20:40:03.750: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename svcaccounts @ 02/12/24 20:40:03.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:40:03.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:40:03.771
  STEP: creating a ServiceAccount @ 02/12/24 20:40:03.774
  STEP: watching for the ServiceAccount to be added @ 02/12/24 20:40:03.786
  STEP: patching the ServiceAccount @ 02/12/24 20:40:03.791
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 02/12/24 20:40:03.797
  STEP: deleting the ServiceAccount @ 02/12/24 20:40:03.802
  Feb 12 20:40:03.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8196" for this suite. @ 02/12/24 20:40:03.823
• [0.079 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 02/12/24 20:40:03.83
  Feb 12 20:40:03.830: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:40:03.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:40:03.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:40:03.854
  E0212 20:40:04.346109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:05.346231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:06.346977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:07.347783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:08.348832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:09.349812      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:10.350680      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:11.351578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:12.352165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:13.352944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:14.353027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:15.353076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:16.353973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:17.354089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:18.354937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:19.355930      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:20.356675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:21.356781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:22.356878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:23.357632      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:24.357866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:25.357954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:26.358762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:27.359905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:28.360011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:29.361081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:30.361342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:31.361868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:32.362903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:33.363836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:34.364282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:35.364786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:36.365398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:37.366265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:38.366902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:39.367145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:40.367264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:41.367815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:42.368043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:43.368131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:44.368613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:45.369191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:46.369336      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:47.369428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:48.369631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:49.369767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:50.370592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:51.370919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:52.371661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:53.372346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:54.373205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:55.373788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:56.374675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:57.374740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:58.374807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:40:59.375628      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:00.376132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:01.376701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:02.377313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:03.377897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:41:03.871: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9036" for this suite. @ 02/12/24 20:41:03.875
• [60.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 02/12/24 20:41:03.885
  Feb 12 20:41:03.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:41:03.886
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:03.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:03.911
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 02/12/24 20:41:03.914
  E0212 20:41:04.377974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:05.381882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:06.382653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:07.383036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:41:07.941
  Feb 12 20:41:07.946: INFO: Trying to get logs from node ip-172-31-91-42 pod pod-71dc0491-f98b-4bfa-b50d-d598ebdf02c2 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:41:07.964
  Feb 12 20:41:07.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1591" for this suite. @ 02/12/24 20:41:07.985
• [4.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 02/12/24 20:41:07.993
  Feb 12 20:41:07.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename kubectl @ 02/12/24 20:41:07.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:08.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:08.014
  STEP: validating api versions @ 02/12/24 20:41:08.017
  Feb 12 20:41:08.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3167951924 --namespace=kubectl-3164 api-versions'
  Feb 12 20:41:08.059: INFO: stderr: ""
  Feb 12 20:41:08.059: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Feb 12 20:41:08.059: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3164" for this suite. @ 02/12/24 20:41:08.063
• [0.078 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 02/12/24 20:41:08.071
  Feb 12 20:41:08.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 20:41:08.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:08.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:08.095
  Feb 12 20:41:08.111: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0212 20:41:08.383655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:09.383942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:10.384094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:11.384185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:12.384295      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:41:13.116: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/12/24 20:41:13.116
  Feb 12 20:41:13.116: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 02/12/24 20:41:13.127
  Feb 12 20:41:13.141: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8745",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2bb04cbe-6137-46d5-acec-40c38667c3b8",
      ResourceVersion: (string) (len=5) "43014",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367273,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367273,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 20:41:13.145: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Feb 12 20:41:13.145: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Feb 12 20:41:13.145: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8745",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e0e194cb-19d4-4483-bfea-f38a067ca877",
      ResourceVersion: (string) (len=5) "43018",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "2bb04cbe-6137-46d5-acec-40c38667c3b8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367269,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367273,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 32 62 62 30 34 63 62  |"uid\":\"2bb04cb|
              00000040  65 2d 36 31 33 37 2d 34  36 64 35 2d 61 63 65 63  |e-6137-46d5-acec|
              00000050  2d 34 30 63 33 38 36 36  37 63 33 62 38 5c 22 7d  |-40c38667c3b8\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 20:41:13.149: INFO: Pod "test-cleanup-controller-jg6z8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-jg6z8",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-8745",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d541c8d5-28be-4f1a-9710-2be856309abd",
      ResourceVersion: (string) (len=5) "42994",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "e0e194cb-19d4-4483-bfea-f38a067ca877",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  65 30 65 31 39 34 63 62  |uid\":\"e0e194cb|
              00000080  2d 31 39 64 34 2d 34 34  38 33 2d 62 66 65 61 2d  |-19d4-4483-bfea-|
              00000090  66 33 38 61 30 36 37 63  61 38 37 37 5c 22 7d 22  |f38a067ca877\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367269,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 37 31  2e 32 34 39 5c 22 7d 22  |2.168.71.249\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lgdcd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lgdcd",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-91-42",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367269,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367269,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367269,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.91.42",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.91.42"
        }
      },
      PodIP: (string) (len=14) "192.168.71.249",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.71.249"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843367268,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://73c2a300e09fbf162bc9bbe74a3ddcaf7542b07d65deef8012d66938499152b7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 20:41:13.151: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8745" for this suite. @ 02/12/24 20:41:13.155
• [5.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 02/12/24 20:41:13.168
  Feb 12 20:41:13.168: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:41:13.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:13.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:13.19
  STEP: Creating secret with name secret-test-map-1ef063cb-46c1-4a77-bae9-27e4c82007b1 @ 02/12/24 20:41:13.193
  STEP: Creating a pod to test consume secrets @ 02/12/24 20:41:13.198
  E0212 20:41:13.385043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:14.385856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:15.385958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:16.386045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:41:17.221
  Feb 12 20:41:17.225: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-secrets-5c32e98b-1b70-490c-82f2-9c3e74794298 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:41:17.238
  Feb 12 20:41:17.258: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1556" for this suite. @ 02/12/24 20:41:17.261
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 02/12/24 20:41:17.269
  Feb 12 20:41:17.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:41:17.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:17.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:17.29
  STEP: Creating configMap with name configmap-test-volume-9a8ff811-c65d-48ea-9711-3578f6b862fd @ 02/12/24 20:41:17.293
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:41:17.299
  E0212 20:41:17.386802      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:18.387763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:19.388619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:20.389636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:41:21.324
  Feb 12 20:41:21.328: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-2963bf8c-d05d-4e9f-8e8b-b44c86fc109b container configmap-volume-test: <nil>
  STEP: delete the pod @ 02/12/24 20:41:21.335
  Feb 12 20:41:21.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2989" for this suite. @ 02/12/24 20:41:21.356
• [4.093 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 02/12/24 20:41:21.362
  Feb 12 20:41:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename subpath @ 02/12/24 20:41:21.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:21.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:21.383
  STEP: Setting up data @ 02/12/24 20:41:21.386
  E0212 20:41:21.389893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating pod pod-subpath-test-configmap-g4lt @ 02/12/24 20:41:21.396
  STEP: Creating a pod to test atomic-volume-subpath @ 02/12/24 20:41:21.396
  E0212 20:41:22.390237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:23.390893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:24.391022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:25.391172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:26.391266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:27.391543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:28.392531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:29.393052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:30.393169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:31.393291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:32.393618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:33.393835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:34.393996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:35.394097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:36.394263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:37.394927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:38.395835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:39.395934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:40.396038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:41.396125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:42.396231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:43.396526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:44.396618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:45.396833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:41:45.479
  Feb 12 20:41:45.482: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-subpath-test-configmap-g4lt container test-container-subpath-configmap-g4lt: <nil>
  STEP: delete the pod @ 02/12/24 20:41:45.491
  STEP: Deleting pod pod-subpath-test-configmap-g4lt @ 02/12/24 20:41:45.511
  Feb 12 20:41:45.511: INFO: Deleting pod "pod-subpath-test-configmap-g4lt" in namespace "subpath-7035"
  Feb 12 20:41:45.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7035" for this suite. @ 02/12/24 20:41:45.518
• [24.164 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 02/12/24 20:41:45.526
  Feb 12 20:41:45.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename pods @ 02/12/24 20:41:45.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:45.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:45.547
  STEP: creating the pod @ 02/12/24 20:41:45.551
  STEP: submitting the pod to kubernetes @ 02/12/24 20:41:45.551
  STEP: verifying QOS class is set on the pod @ 02/12/24 20:41:45.559
  Feb 12 20:41:45.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-547" for this suite. @ 02/12/24 20:41:45.569
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 02/12/24 20:41:45.577
  Feb 12 20:41:45.577: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename disruption @ 02/12/24 20:41:45.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:45.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:45.597
  STEP: Creating a pdb that targets all three pods in a test replica set @ 02/12/24 20:41:45.6
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:41:45.605
  E0212 20:41:46.396877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:47.397243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 02/12/24 20:41:47.617
  STEP: Waiting for all pods to be running @ 02/12/24 20:41:47.617
  Feb 12 20:41:47.621: INFO: pods: 0 < 3
  E0212 20:41:48.397376      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:49.397427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 02/12/24 20:41:49.622
  STEP: Updating the pdb to allow a pod to be evicted @ 02/12/24 20:41:49.635
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:41:49.644
  E0212 20:41:50.397568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:51.397892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 02/12/24 20:41:51.649
  STEP: Waiting for all pods to be running @ 02/12/24 20:41:51.649
  STEP: Waiting for the pdb to observed all healthy pods @ 02/12/24 20:41:51.653
  STEP: Patching the pdb to disallow a pod to be evicted @ 02/12/24 20:41:51.681
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:41:51.693
  E0212 20:41:52.398890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:53.398919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 02/12/24 20:41:53.699
  STEP: locating a running pod @ 02/12/24 20:41:53.704
  STEP: Deleting the pdb to allow a pod to be evicted @ 02/12/24 20:41:53.716
  STEP: Waiting for the pdb to be deleted @ 02/12/24 20:41:53.723
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 02/12/24 20:41:53.727
  STEP: Waiting for all pods to be running @ 02/12/24 20:41:53.727
  Feb 12 20:41:53.748: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3303" for this suite. @ 02/12/24 20:41:53.752
• [8.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 02/12/24 20:41:53.761
  Feb 12 20:41:53.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename disruption @ 02/12/24 20:41:53.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:53.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:53.786
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:41:53.795
  E0212 20:41:54.399342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:55.399403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 02/12/24 20:41:55.827
  Feb 12 20:41:55.831: INFO: running pods: 0 < 3
  E0212 20:41:56.400188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:57.400430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:41:57.835: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9507" for this suite. @ 02/12/24 20:41:57.839
• [4.086 seconds]
------------------------------
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 02/12/24 20:41:57.847
  Feb 12 20:41:57.847: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename taint-multiple-pods @ 02/12/24 20:41:57.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:41:57.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:41:57.87
  Feb 12 20:41:57.873: INFO: Waiting up to 1m0s for all nodes to be ready
  E0212 20:41:58.401291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:41:59.401403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:00.401613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:01.401853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:02.401955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:03.402978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:04.403089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:05.403291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:06.403411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:07.403583      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:08.404346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:09.404487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:10.405106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:11.406046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:12.406755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:13.406983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:14.407202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:15.407390      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:16.407524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:17.407612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:18.408499      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:19.408615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:20.408710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:21.408787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:22.409032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:23.409975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:24.410107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:25.410169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:26.411079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:27.411995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:28.412463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:29.412745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:30.412849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:31.413271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:32.413504      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:33.413619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:34.413752      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:35.414146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:36.414566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:37.414654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:38.415316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:39.415713      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:40.415881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:41.415983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:42.416969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:43.417030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:44.417126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:45.417223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:46.417324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:47.418092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:48.418615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:49.418961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:50.419332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:51.419591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:52.419741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:53.419967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:54.420117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:55.420219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:56.420960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:57.421250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:42:57.873: INFO: Waiting for terminating namespaces to be deleted...
  Feb 12 20:42:57.879: INFO: Starting informer...
  STEP: Starting pods... @ 02/12/24 20:42:57.879
  Feb 12 20:42:58.101: INFO: Pod1 is running on ip-172-31-5-108. Tainting Node
  E0212 20:42:58.421942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:42:59.422548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:43:00.325: INFO: Pod2 is running on ip-172-31-5-108. Tainting Node
  STEP: Trying to apply a taint on the Node @ 02/12/24 20:43:00.326
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/12/24 20:43:00.335
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 02/12/24 20:43:00.339
  E0212 20:43:00.423429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:01.423916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:02.424017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:03.425016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:04.425115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:05.426048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:43:05.960: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0212 20:43:06.426230      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:07.426354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:08.426643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:09.427736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:10.428534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:11.428705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:12.428813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:13.429235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:14.429464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:15.430046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:16.430903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:17.431001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:18.431437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:19.431602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:20.431806      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:21.431896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:22.432082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:23.432984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:24.433162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:25.433817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:43:25.994: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/12/24 20:43:26.005
  Feb 12 20:43:26.010: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-39" for this suite. @ 02/12/24 20:43:26.014
• [88.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 02/12/24 20:43:26.026
  Feb 12 20:43:26.026: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename sysctl @ 02/12/24 20:43:26.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:43:26.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:43:26.053
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 02/12/24 20:43:26.057
  STEP: Watching for error events or started pod @ 02/12/24 20:43:26.064
  E0212 20:43:26.433871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:27.433974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 02/12/24 20:43:28.069
  E0212 20:43:28.434148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:29.434239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 02/12/24 20:43:30.084
  STEP: Getting logs from the pod @ 02/12/24 20:43:30.084
  STEP: Checking that the sysctl is actually updated @ 02/12/24 20:43:30.097
  Feb 12 20:43:30.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6925" for this suite. @ 02/12/24 20:43:30.101
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 02/12/24 20:43:30.11
  Feb 12 20:43:30.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename gc @ 02/12/24 20:43:30.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:43:30.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:43:30.13
  STEP: create the rc1 @ 02/12/24 20:43:30.136
  STEP: create the rc2 @ 02/12/24 20:43:30.141
  E0212 20:43:30.434563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:31.435816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:32.436248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:33.444044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:34.466168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:35.468594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 02/12/24 20:43:36.156
  E0212 20:43:36.468986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 02/12/24 20:43:36.6
  STEP: wait for the rc to be deleted @ 02/12/24 20:43:36.607
  E0212 20:43:37.471771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:38.472564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:39.473938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:40.473977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:41.474255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:43:41.620: INFO: 77 pods remaining
  Feb 12 20:43:41.621: INFO: 77 pods has nil DeletionTimestamp
  Feb 12 20:43:41.621: INFO: 
  E0212 20:43:42.474647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:43.475749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:44.475959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:45.476078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:46.476146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/12/24 20:43:46.622
  W0212 20:43:46.629399      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb 12 20:43:46.629: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb 12 20:43:46.630: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bbff" in namespace "gc-880"
  Feb 12 20:43:46.643: INFO: Deleting pod "simpletest-rc-to-be-deleted-2n6d9" in namespace "gc-880"
  Feb 12 20:43:46.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q8wq" in namespace "gc-880"
  Feb 12 20:43:46.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qzwd" in namespace "gc-880"
  Feb 12 20:43:46.679: INFO: Deleting pod "simpletest-rc-to-be-deleted-4sk9r" in namespace "gc-880"
  Feb 12 20:43:46.692: INFO: Deleting pod "simpletest-rc-to-be-deleted-4xqgf" in namespace "gc-880"
  Feb 12 20:43:46.706: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mjbn" in namespace "gc-880"
  Feb 12 20:43:46.718: INFO: Deleting pod "simpletest-rc-to-be-deleted-66m54" in namespace "gc-880"
  Feb 12 20:43:46.731: INFO: Deleting pod "simpletest-rc-to-be-deleted-6s2l5" in namespace "gc-880"
  Feb 12 20:43:46.742: INFO: Deleting pod "simpletest-rc-to-be-deleted-7549b" in namespace "gc-880"
  Feb 12 20:43:46.753: INFO: Deleting pod "simpletest-rc-to-be-deleted-75nzb" in namespace "gc-880"
  Feb 12 20:43:46.765: INFO: Deleting pod "simpletest-rc-to-be-deleted-77cgp" in namespace "gc-880"
  Feb 12 20:43:46.778: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mt4b" in namespace "gc-880"
  Feb 12 20:43:46.790: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qzsz" in namespace "gc-880"
  Feb 12 20:43:46.802: INFO: Deleting pod "simpletest-rc-to-be-deleted-7rw29" in namespace "gc-880"
  Feb 12 20:43:46.815: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rqsm" in namespace "gc-880"
  Feb 12 20:43:46.827: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tm8q" in namespace "gc-880"
  Feb 12 20:43:46.838: INFO: Deleting pod "simpletest-rc-to-be-deleted-99lmk" in namespace "gc-880"
  Feb 12 20:43:46.851: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jbhl" in namespace "gc-880"
  Feb 12 20:43:46.862: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ncwh" in namespace "gc-880"
  Feb 12 20:43:46.876: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rgjt" in namespace "gc-880"
  Feb 12 20:43:46.888: INFO: Deleting pod "simpletest-rc-to-be-deleted-9tnhx" in namespace "gc-880"
  Feb 12 20:43:46.903: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4d7c" in namespace "gc-880"
  Feb 12 20:43:46.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8qjn" in namespace "gc-880"
  Feb 12 20:43:46.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-bcggs" in namespace "gc-880"
  Feb 12 20:43:46.938: INFO: Deleting pod "simpletest-rc-to-be-deleted-btg9p" in namespace "gc-880"
  Feb 12 20:43:46.949: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjt6b" in namespace "gc-880"
  Feb 12 20:43:46.962: INFO: Deleting pod "simpletest-rc-to-be-deleted-cxdn2" in namespace "gc-880"
  Feb 12 20:43:46.975: INFO: Deleting pod "simpletest-rc-to-be-deleted-cxg5h" in namespace "gc-880"
  Feb 12 20:43:46.987: INFO: Deleting pod "simpletest-rc-to-be-deleted-d8vlf" in namespace "gc-880"
  Feb 12 20:43:46.999: INFO: Deleting pod "simpletest-rc-to-be-deleted-f849p" in namespace "gc-880"
  Feb 12 20:43:47.011: INFO: Deleting pod "simpletest-rc-to-be-deleted-fqsml" in namespace "gc-880"
  Feb 12 20:43:47.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-gb9jx" in namespace "gc-880"
  Feb 12 20:43:47.043: INFO: Deleting pod "simpletest-rc-to-be-deleted-gjvsd" in namespace "gc-880"
  Feb 12 20:43:47.055: INFO: Deleting pod "simpletest-rc-to-be-deleted-glkjd" in namespace "gc-880"
  Feb 12 20:43:47.067: INFO: Deleting pod "simpletest-rc-to-be-deleted-gx7tw" in namespace "gc-880"
  Feb 12 20:43:47.083: INFO: Deleting pod "simpletest-rc-to-be-deleted-gx9wl" in namespace "gc-880"
  Feb 12 20:43:47.098: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxkqk" in namespace "gc-880"
  Feb 12 20:43:47.112: INFO: Deleting pod "simpletest-rc-to-be-deleted-hbv27" in namespace "gc-880"
  Feb 12 20:43:47.131: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjnss" in namespace "gc-880"
  Feb 12 20:43:47.169: INFO: Deleting pod "simpletest-rc-to-be-deleted-jqfmj" in namespace "gc-880"
  Feb 12 20:43:47.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-jqx2l" in namespace "gc-880"
  Feb 12 20:43:47.197: INFO: Deleting pod "simpletest-rc-to-be-deleted-k2jnj" in namespace "gc-880"
  Feb 12 20:43:47.210: INFO: Deleting pod "simpletest-rc-to-be-deleted-khjb6" in namespace "gc-880"
  Feb 12 20:43:47.226: INFO: Deleting pod "simpletest-rc-to-be-deleted-ksccf" in namespace "gc-880"
  Feb 12 20:43:47.240: INFO: Deleting pod "simpletest-rc-to-be-deleted-kx9x2" in namespace "gc-880"
  Feb 12 20:43:47.253: INFO: Deleting pod "simpletest-rc-to-be-deleted-l2vks" in namespace "gc-880"
  Feb 12 20:43:47.269: INFO: Deleting pod "simpletest-rc-to-be-deleted-lhq8s" in namespace "gc-880"
  Feb 12 20:43:47.283: INFO: Deleting pod "simpletest-rc-to-be-deleted-lnxsn" in namespace "gc-880"
  Feb 12 20:43:47.298: INFO: Deleting pod "simpletest-rc-to-be-deleted-lrng6" in namespace "gc-880"
  Feb 12 20:43:47.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-880" for this suite. @ 02/12/24 20:43:47.319
• [17.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 02/12/24 20:43:47.328
  Feb 12 20:43:47.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 02/12/24 20:43:47.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:43:47.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:43:47.352
  STEP: creating a target pod @ 02/12/24 20:43:47.356
  E0212 20:43:47.477460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:48.481929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 02/12/24 20:43:49.377
  E0212 20:43:49.482428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:50.482518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 02/12/24 20:43:51.395
  Feb 12 20:43:51.395: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-7670 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb 12 20:43:51.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  Feb 12 20:43:51.395: INFO: ExecWithOptions: Clientset creation
  Feb 12 20:43:51.395: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-7670/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Feb 12 20:43:51.446: INFO: Exec stderr: ""
  Feb 12 20:43:51.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-7670" for this suite. @ 02/12/24 20:43:51.458
• [4.137 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 02/12/24 20:43:51.465
  Feb 12 20:43:51.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename projected @ 02/12/24 20:43:51.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:43:51.482
  E0212 20:43:51.483041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:43:51.485
  STEP: Creating a pod to test downward API volume plugin @ 02/12/24 20:43:51.488
  E0212 20:43:52.483223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:53.483638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:54.484534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:55.484850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:43:55.513
  Feb 12 20:43:55.517: INFO: Trying to get logs from node ip-172-31-5-108 pod downwardapi-volume-7fd255fa-89b6-48ce-8ccd-016914fb2181 container client-container: <nil>
  STEP: delete the pod @ 02/12/24 20:43:55.523
  Feb 12 20:43:55.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8985" for this suite. @ 02/12/24 20:43:55.544
• [4.086 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 02/12/24 20:43:55.552
  Feb 12 20:43:55.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename watch @ 02/12/24 20:43:55.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:43:55.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:43:55.58
  STEP: creating a watch on configmaps with label A @ 02/12/24 20:43:55.583
  STEP: creating a watch on configmaps with label B @ 02/12/24 20:43:55.584
  STEP: creating a watch on configmaps with label A or B @ 02/12/24 20:43:55.586
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 02/12/24 20:43:55.587
  Feb 12 20:43:55.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46421 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:43:55.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46421 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 02/12/24 20:43:55.591
  Feb 12 20:43:55.600: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46422 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:43:55.600: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46422 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 02/12/24 20:43:55.6
  Feb 12 20:43:55.608: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46423 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:43:55.608: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46423 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 02/12/24 20:43:55.608
  Feb 12 20:43:55.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46424 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:43:55.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3940  86129aa0-7384-4660-8487-7e5bb2821555 46424 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 02/12/24 20:43:55.614
  Feb 12 20:43:55.621: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3940  1d266413-bdac-48f7-89a4-615144fcc265 46425 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:43:55.621: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3940  1d266413-bdac-48f7-89a4-615144fcc265 46425 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0212 20:43:56.484958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:57.485025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:58.485359      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:43:59.485446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:00.485557      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:01.485669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:02.485849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:03.485961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:04.486049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:05.486886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 02/12/24 20:44:05.622
  Feb 12 20:44:05.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3940  1d266413-bdac-48f7-89a4-615144fcc265 46467 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:44:05.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3940  1d266413-bdac-48f7-89a4-615144fcc265 46467 0 2024-02-12 20:43:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-12 20:43:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0212 20:44:06.487239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:07.487350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:08.487841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:09.487914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:10.488091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:11.488353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:12.488537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:13.488612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:14.489645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:15.489819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:15.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3940" for this suite. @ 02/12/24 20:44:15.637
• [20.092 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 02/12/24 20:44:15.645
  Feb 12 20:44:15.645: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename job @ 02/12/24 20:44:15.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:15.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:15.666
  STEP: Creating a job @ 02/12/24 20:44:15.669
  STEP: Ensuring active pods == parallelism @ 02/12/24 20:44:15.676
  E0212 20:44:16.490332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:17.490509      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 02/12/24 20:44:17.681
  Feb 12 20:44:18.199: INFO: Successfully updated pod "adopt-release-kwbrp"
  STEP: Checking that the Job readopts the Pod @ 02/12/24 20:44:18.199
  E0212 20:44:18.490602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:19.490905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 02/12/24 20:44:20.209
  E0212 20:44:20.491013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:20.722: INFO: Successfully updated pod "adopt-release-kwbrp"
  STEP: Checking that the Job releases the Pod @ 02/12/24 20:44:20.722
  E0212 20:44:21.491595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:22.491823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:22.732: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3561" for this suite. @ 02/12/24 20:44:22.737
• [7.102 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 02/12/24 20:44:22.747
  Feb 12 20:44:22.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/12/24 20:44:22.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:22.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:22.766
  STEP: set up a multi version CRD @ 02/12/24 20:44:22.769
  Feb 12 20:44:22.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:44:23.492830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:24.493729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:25.494056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 02/12/24 20:44:25.886
  STEP: check the new version name is served @ 02/12/24 20:44:25.899
  E0212 20:44:26.494416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 02/12/24 20:44:26.656
  STEP: check the other version is not changed @ 02/12/24 20:44:27.278
  E0212 20:44:27.494911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:28.495602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:29.496369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:29.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2874" for this suite. @ 02/12/24 20:44:29.884
• [7.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 02/12/24 20:44:29.896
  Feb 12 20:44:29.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename watch @ 02/12/24 20:44:29.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:29.917
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:29.922
  STEP: creating a new configmap @ 02/12/24 20:44:29.925
  STEP: modifying the configmap once @ 02/12/24 20:44:29.935
  STEP: modifying the configmap a second time @ 02/12/24 20:44:29.946
  STEP: deleting the configmap @ 02/12/24 20:44:29.954
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 02/12/24 20:44:29.961
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 02/12/24 20:44:29.964
  Feb 12 20:44:29.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5304  c2ef195a-7252-417e-8e3c-a0d8fec97257 46655 0 2024-02-12 20:44:29 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-02-12 20:44:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:44:29.964: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5304  c2ef195a-7252-417e-8e3c-a0d8fec97257 46656 0 2024-02-12 20:44:29 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-02-12 20:44:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb 12 20:44:29.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5304" for this suite. @ 02/12/24 20:44:29.968
• [0.079 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 02/12/24 20:44:29.975
  Feb 12 20:44:29.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename secrets @ 02/12/24 20:44:29.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:29.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:29.996
  Feb 12 20:44:30.043: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-658" for this suite. @ 02/12/24 20:44:30.049
• [0.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 02/12/24 20:44:30.058
  Feb 12 20:44:30.058: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:44:30.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:30.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:30.079
  E0212 20:44:30.496426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:31.497418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:32.497500      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:33.497786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:34.497865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:35.498933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:36.499631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:37.500465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:38.501170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:39.501281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:40.502340      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:41.502445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:42.502974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:43.503062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:44.503553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:45.503715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:46.504614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:47.504835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:48.505493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:49.505648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:50.506033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:51.506275      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:52.158: INFO: Container started at 2024-02-12 20:44:30 +0000 UTC, pod became ready at 2024-02-12 20:44:50 +0000 UTC
  Feb 12 20:44:52.158: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2734" for this suite. @ 02/12/24 20:44:52.162
• [22.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 02/12/24 20:44:52.171
  Feb 12 20:44:52.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename runtimeclass @ 02/12/24 20:44:52.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:52.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:52.192
  E0212 20:44:52.506356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:53.506662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:54.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1777" for this suite. @ 02/12/24 20:44:54.231
• [2.067 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 02/12/24 20:44:54.238
  Feb 12 20:44:54.238: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename deployment @ 02/12/24 20:44:54.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:44:54.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:44:54.26
  Feb 12 20:44:54.272: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0212 20:44:54.506992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:55.507199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:56.507372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:57.507626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:44:58.508045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:44:59.276: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/12/24 20:44:59.277
  Feb 12 20:44:59.277: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0212 20:44:59.508230      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:00.508399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:01.282: INFO: Creating deployment "test-rollover-deployment"
  Feb 12 20:45:01.292: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0212 20:45:01.509133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:02.509219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:03.301: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Feb 12 20:45:03.307: INFO: Ensure that both replica sets have 1 created replica
  Feb 12 20:45:03.315: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Feb 12 20:45:03.328: INFO: Updating deployment test-rollover-deployment
  Feb 12 20:45:03.328: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0212 20:45:03.509564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:04.509682      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:05.338: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Feb 12 20:45:05.347: INFO: Make sure deployment "test-rollover-deployment" is complete
  Feb 12 20:45:05.355: INFO: all replica sets need to contain the pod-template-hash label
  Feb 12 20:45:05.355: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0212 20:45:05.510522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:06.510627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:07.364: INFO: all replica sets need to contain the pod-template-hash label
  Feb 12 20:45:07.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0212 20:45:07.510714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:08.511163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:09.366: INFO: all replica sets need to contain the pod-template-hash label
  Feb 12 20:45:09.366: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0212 20:45:09.511253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:10.511372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:11.364: INFO: all replica sets need to contain the pod-template-hash label
  Feb 12 20:45:11.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0212 20:45:11.512116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:12.512343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:13.365: INFO: all replica sets need to contain the pod-template-hash label
  Feb 12 20:45:13.365: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 12, 20, 45, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 12, 20, 45, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0212 20:45:13.512958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:14.513085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:15.364: INFO: 
  Feb 12 20:45:15.364: INFO: Ensure that both old replica sets have no replicas
  Feb 12 20:45:15.375: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4374",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f785db52-7b7f-48bd-9e41-9169877af4a0",
      ResourceVersion: (string) (len=5) "46928",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367501,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367514,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367501,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367501,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367514,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367501,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5d484bf7f9\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb 12 20:45:15.381: INFO: New ReplicaSet "test-rollover-deployment-5d484bf7f9" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4374",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0673a13e-9335-474c-8f21-d394101d84ee",
      ResourceVersion: (string) (len=5) "46918",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367503,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f785db52-7b7f-48bd-9e41-9169877af4a0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 37 38 35 64 62  35 32 2d 37 62 37 66 2d  |\"f785db52-7b7f-|
              00000120  34 38 62 64 2d 39 65 34  31 2d 39 31 36 39 38 37  |48bd-9e41-916987|
              00000130  37 61 66 34 61 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |7af4a0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367514,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 20:45:15.382: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Feb 12 20:45:15.382: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4374",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a18714d-d31a-45d9-a682-0bafb79dd30c",
      ResourceVersion: (string) (len=5) "46927",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367494,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f785db52-7b7f-48bd-9e41-9169877af4a0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367494,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367514,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  66 37 38 35 64 62 35 32  2d 37 62 37 66 2d 34 38  |f785db52-7b7f-48|
              000000c0  62 64 2d 39 65 34 31 2d  39 31 36 39 38 37 37 61  |bd-9e41-9169877a|
              000000d0  66 34 61 30 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |f4a0\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367514,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 20:45:15.383: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4374",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6aaa7442-09d1-4f7e-8885-7c4debf8f77f",
      ResourceVersion: (string) (len=5) "46876",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367501,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f785db52-7b7f-48bd-9e41-9169877af4a0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 37 38 35 64 62  35 32 2d 37 62 37 66 2d  |\"f785db52-7b7f-|
              00000120  34 38 62 64 2d 39 65 34  31 2d 39 31 36 39 38 37  |48bd-9e41-916987|
              00000130  37 61 66 34 61 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |7af4a0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb 12 20:45:15.388: INFO: Pod "test-rollover-deployment-5d484bf7f9-gw8ch" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5d484bf7f9-gw8ch",
      GenerateName: (string) (len=36) "test-rollover-deployment-5d484bf7f9-",
      Namespace: (string) (len=15) "deployment-4374",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "872565cc-9580-4c2b-9dfc-a13025e4caae",
      ResourceVersion: (string) (len=5) "46894",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367503,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
          UID: (types.UID) (len=36) "0673a13e-9335-474c-8f21-d394101d84ee",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 36  37 33 61 31 33 65 2d 39  |d\":\"0673a13e-9|
              00000090  33 33 35 2d 34 37 34 63  2d 38 66 32 31 2d 64 33  |335-474c-8f21-d3|
              000000a0  39 34 31 30 31 64 38 34  65 65 5c 22 7d 22 3a 7b  |94101d84ee\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367504,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  30 2e 32 34 31 5c 22 7d  |2.168.150.241\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fp6mb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fp6mb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-5-108",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367504,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367504,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367504,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63843367503,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.5.108",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.5.108"
        }
      },
      PodIP: (string) (len=15) "192.168.150.241",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.150.241"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63843367503,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63843367503,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://0f3765f57f375d8fef444baa58bc415f4eeef1e483f3fd056a0884eefd16d002",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb 12 20:45:15.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4374" for this suite. @ 02/12/24 20:45:15.395
• [21.164 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 02/12/24 20:45:15.402
  Feb 12 20:45:15.402: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:45:15.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:45:15.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:45:15.423
  STEP: Setting up server cert @ 02/12/24 20:45:15.448
  E0212 20:45:15.514098      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:45:15.744
  STEP: Deploying the webhook pod @ 02/12/24 20:45:15.753
  STEP: Wait for the deployment to be ready @ 02/12/24 20:45:15.767
  Feb 12 20:45:15.782: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:45:16.515304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:17.515421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:45:17.795
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:45:17.807
  E0212 20:45:18.515475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:18.808: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 02/12/24 20:45:18.817
  STEP: create a pod that should be updated by the webhook @ 02/12/24 20:45:18.832
  Feb 12 20:45:18.899: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-731" for this suite. @ 02/12/24 20:45:18.903
  STEP: Destroying namespace "webhook-markers-521" for this suite. @ 02/12/24 20:45:18.91
• [3.515 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 02/12/24 20:45:18.917
  Feb 12 20:45:18.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename replicaset @ 02/12/24 20:45:18.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:45:18.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:45:18.937
  Feb 12 20:45:18.940: INFO: Creating ReplicaSet my-hostname-basic-6d4a8090-bf56-4d9c-9544-6a6d0a7bb19a
  Feb 12 20:45:18.949: INFO: Pod name my-hostname-basic-6d4a8090-bf56-4d9c-9544-6a6d0a7bb19a: Found 0 pods out of 1
  E0212 20:45:19.515646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:20.515692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:21.515788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:22.515879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:23.516018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:23.953: INFO: Pod name my-hostname-basic-6d4a8090-bf56-4d9c-9544-6a6d0a7bb19a: Found 1 pods out of 1
  Feb 12 20:45:23.953: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6d4a8090-bf56-4d9c-9544-6a6d0a7bb19a" is running
  Feb 12 20:45:23.957: INFO: Pod "my-hostname-basic-6d4a8090-bf56-4d9c-9544-6a6d0a7bb19a-4hf48" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:45:19 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:45:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:45:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:45:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-12 20:45:18 +0000 UTC Reason: Message:}])
  Feb 12 20:45:23.957: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 02/12/24 20:45:23.957
  Feb 12 20:45:23.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3960" for this suite. @ 02/12/24 20:45:23.976
• [5.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 02/12/24 20:45:23.986
  Feb 12 20:45:23.986: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename namespaces @ 02/12/24 20:45:23.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:45:24.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:45:24.01
  STEP: creating a Namespace @ 02/12/24 20:45:24.013
  STEP: patching the Namespace @ 02/12/24 20:45:24.028
  STEP: get the Namespace and ensuring it has the label @ 02/12/24 20:45:24.035
  Feb 12 20:45:24.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6724" for this suite. @ 02/12/24 20:45:24.044
  STEP: Destroying namespace "nspatchtest-8f9d2c47-3079-4f03-be87-b0f88d3f06fd-1093" for this suite. @ 02/12/24 20:45:24.051
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 02/12/24 20:45:24.06
  Feb 12 20:45:24.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename container-probe @ 02/12/24 20:45:24.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:45:24.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:45:24.09
  STEP: Creating pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129 @ 02/12/24 20:45:24.093
  E0212 20:45:24.516458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:25.516570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/12/24 20:45:26.11
  Feb 12 20:45:26.113: INFO: Initial restart count of pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f is 0
  Feb 12 20:45:26.117: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:26.517422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:27.517712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:28.123: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:28.518381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:29.518992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:30.129: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:30.519902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:31.520142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:32.135: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:32.521153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:33.521706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:34.140: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:34.522313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:35.522927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:36.146: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:36.523513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:37.523700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:38.150: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:38.524621      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:39.524833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:40.156: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:40.525782      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:41.525861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:42.161: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:42.526308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:43.526613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:44.167: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:44.527424      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:45.527645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:46.172: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:46.527836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:47.528057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:48.178: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:48.529061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:49.529234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:50.183: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:50.529929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:51.530024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:52.189: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:52.530802      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:53.531032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:54.196: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:54.531544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:55.531701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:56.202: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:56.531730      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:57.531813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:45:58.206: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:45:58.532535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:45:59.532637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:00.213: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:00.533509      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:01.533639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:02.217: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:02.534215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:03.534669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:04.223: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:04.534731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:05.535042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:06.228: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:06.535123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:07.535298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:08.234: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:08.535801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:09.535895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:10.239: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:10.536251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:11.536371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:12.244: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:12.537169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:13.537502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:14.251: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:14.537725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:15.537852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:16.256: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:16.538427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:17.538649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:18.263: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:18.539623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:19.539958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:20.267: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:20.540081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:21.540399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:22.273: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:22.541394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:23.541578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:24.279: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:24.541826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:25.541864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:26.284: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:26.542873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:27.542960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:28.290: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:28.543078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:29.543203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:30.298: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:30.543482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:31.543513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:32.303: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:32.544239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:33.544734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:34.309: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:34.545282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:35.545406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:36.314: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:36.545488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:37.546276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:38.319: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:38.547037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:39.547221      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:40.325: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:40.547793      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:41.548011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:42.330: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:42.548497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:43.548686      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:44.336: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:44.549612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:45.549813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:46.341: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:46.550285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:47.550896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:48.347: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:48.551744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:49.552114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:50.353: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:50.552556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:51.553036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:52.358: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:52.553904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:53.553995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:54.363: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:54.554681      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:55.555074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:56.368: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:56.555115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:57.556135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:46:58.373: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:46:58.556633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:46:59.556809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:00.379: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:00.557526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:01.557736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:02.384: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:02.557831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:03.558107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:04.389: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:04.558199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:05.558883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:06.396: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:06.559633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:07.559822      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:08.401: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:08.560642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:09.560764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:10.407: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:10.561379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:11.561520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:12.412: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:12.561928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:13.562977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:14.417: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:14.563505      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:15.563771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:16.423: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:16.564461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:17.564551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:18.428: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:18.565311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:19.565515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:20.433: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:20.566051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:21.566147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:22.439: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:22.566265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:23.566735      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:24.445: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:24.567475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:25.568204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:26.450: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:26.569177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:27.569309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:28.456: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:28.569941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:29.570032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:30.462: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:30.570696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:31.570778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:32.468: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:32.571832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:33.572112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:34.473: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:34.572876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:35.573956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:36.478: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:36.574989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:37.575078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:38.483: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:38.576118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:39.576205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:40.489: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:40.576637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:41.576716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:42.494: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:42.577808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:43.578234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:44.499: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:44.578657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:45.578750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:46.505: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:46.578995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:47.579073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:48.511: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:48.580156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:49.580251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:50.516: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:50.580442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:51.580644      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:52.521: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:52.581147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:53.581816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:54.528: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:54.582317      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:55.582901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:56.534: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:56.583448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:57.583644      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:47:58.540: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:47:58.583727      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:47:59.583937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:00.545: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:00.584804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:01.584913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:02.551: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:02.585740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:03.586778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:04.558: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:04.587834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:05.588020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:06.563: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:06.588692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:07.588979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:08.569: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:08.589704      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:09.589818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:10.574: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:10.590872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:11.591062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:12.580: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:12.591120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:13.592141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:14.586: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:14.592606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:15.592767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:16.591: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:16.593443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:17.593660      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:18.594219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:18.597: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:19.594339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:20.594884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:20.603: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:21.594979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:22.595719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:22.608: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:23.595996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:24.596223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:24.614: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:25.596392      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:26.596516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:26.619: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:27.596915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:28.597073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:28.624: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:29.597186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:30.597466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:30.630: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:31.597943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:32.598885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:32.636: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:33.599756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:34.599969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:34.641: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:35.600089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:36.600270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:36.648: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:37.601079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:38.601710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:38.653: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:39.601811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:40.602902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:40.659: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:41.603540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:42.603722      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:42.665: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:43.604666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:44.604826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:44.671: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:45.605078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:46.605171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:46.676: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:47.605324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:48.605975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:48.682: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:49.606849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:50.607027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:50.687: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:51.607811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:52.608037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:52.693: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:53.608786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:54.609018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:54.699: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:55.609115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:56.609287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:56.705: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:57.609821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:48:58.610204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:48:58.710: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:48:59.610305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:00.610393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:00.715: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:01.610895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:02.610983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:02.721: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:03.611091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:04.611273      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:04.726: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:05.611377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:06.611553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:06.731: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:07.611675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:08.611714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:08.737: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:09.611824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:10.611916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:10.741: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:11.612005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:12.612183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:12.748: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:13.613157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:14.613360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:14.754: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:15.613979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:16.614042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:16.759: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:17.614155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:18.614264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:18.764: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:19.614892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:20.615747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:20.769: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:21.615799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:22.616007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:22.775: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:23.616754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:24.617570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:24.782: INFO: Get pod test-grpc-c978f857-7803-46f6-b5dd-530bcc3a946f in namespace container-probe-6129
  E0212 20:49:25.617816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:26.617921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/12/24 20:49:26.783
  Feb 12 20:49:26.797: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6129" for this suite. @ 02/12/24 20:49:26.803
• [242.751 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 02/12/24 20:49:26.811
  Feb 12 20:49:26.811: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:49:26.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:26.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:26.833
  STEP: Setting up server cert @ 02/12/24 20:49:26.858
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:49:27.214
  STEP: Deploying the webhook pod @ 02/12/24 20:49:27.222
  STEP: Wait for the deployment to be ready @ 02/12/24 20:49:27.237
  Feb 12 20:49:27.245: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:49:27.618536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:28.618913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:49:29.259
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:49:29.272
  E0212 20:49:29.619034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:30.272: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 20:49:30.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  E0212 20:49:30.619698      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 02/12/24 20:49:30.794
  STEP: Creating a custom resource that should be denied by the webhook @ 02/12/24 20:49:30.809
  E0212 20:49:31.620326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:32.620575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 02/12/24 20:49:32.826
  STEP: Updating the custom resource with disallowed data should be denied @ 02/12/24 20:49:32.833
  STEP: Deleting the custom resource should be denied @ 02/12/24 20:49:32.842
  STEP: Remove the offending key and value from the custom resource data @ 02/12/24 20:49:32.85
  STEP: Deleting the updated custom resource should be successful @ 02/12/24 20:49:32.863
  Feb 12 20:49:33.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4430" for this suite. @ 02/12/24 20:49:33.437
  STEP: Destroying namespace "webhook-markers-9225" for this suite. @ 02/12/24 20:49:33.444
• [6.642 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 02/12/24 20:49:33.453
  Feb 12 20:49:33.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename var-expansion @ 02/12/24 20:49:33.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:33.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:33.473
  E0212 20:49:33.621136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:34.621246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:35.493: INFO: Deleting pod "var-expansion-1dab9510-5796-4a92-91fa-47b33ed99e80" in namespace "var-expansion-1984"
  Feb 12 20:49:35.502: INFO: Wait up to 5m0s for pod "var-expansion-1dab9510-5796-4a92-91fa-47b33ed99e80" to be fully deleted
  E0212 20:49:35.622112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:36.623079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:37.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1984" for this suite. @ 02/12/24 20:49:37.515
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 02/12/24 20:49:37.523
  Feb 12 20:49:37.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:49:37.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:37.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:37.543
  STEP: Creating configMap with name configmap-test-volume-3825d314-4afb-4d36-a76c-79a229422c9e @ 02/12/24 20:49:37.546
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:49:37.55
  E0212 20:49:37.623838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:38.624297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:39.624617      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:40.624721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:49:41.574
  Feb 12 20:49:41.579: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-95b53ecc-0bde-42b6-ad48-7a6791504bbc container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:49:41.595
  Feb 12 20:49:41.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6653" for this suite. @ 02/12/24 20:49:41.615
• [4.100 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 02/12/24 20:49:41.623
  Feb 12 20:49:41.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename webhook @ 02/12/24 20:49:41.624
  E0212 20:49:41.625476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:41.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:41.643
  STEP: Setting up server cert @ 02/12/24 20:49:41.667
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/12/24 20:49:42.007
  STEP: Deploying the webhook pod @ 02/12/24 20:49:42.013
  STEP: Wait for the deployment to be ready @ 02/12/24 20:49:42.026
  Feb 12 20:49:42.036: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0212 20:49:42.626583      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:43.626885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/12/24 20:49:44.053
  STEP: Verifying the service has paired with the endpoint @ 02/12/24 20:49:44.064
  E0212 20:49:44.626988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:49:45.065: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb 12 20:49:45.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6219-crds.webhook.example.com via the AdmissionRegistration API @ 02/12/24 20:49:45.588
  STEP: Creating a custom resource while v1 is storage version @ 02/12/24 20:49:45.604
  E0212 20:49:45.628018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:46.628171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:47.628345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 02/12/24 20:49:47.638
  STEP: Patching the custom resource while v2 is storage version @ 02/12/24 20:49:47.658
  Feb 12 20:49:48.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9751" for this suite. @ 02/12/24 20:49:48.285
  STEP: Destroying namespace "webhook-markers-8195" for this suite. @ 02/12/24 20:49:48.292
• [6.677 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 02/12/24 20:49:48.306
  Feb 12 20:49:48.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:49:48.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:48.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:48.326
  STEP: Creating configMap with name configmap-test-volume-map-efe7356a-7fa5-4053-ba09-e2b107f7a085 @ 02/12/24 20:49:48.331
  STEP: Creating a pod to test consume configMaps @ 02/12/24 20:49:48.336
  E0212 20:49:48.628639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:49.628831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:49:50.354
  Feb 12 20:49:50.358: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-configmaps-d745bf68-82e0-4356-9ac8-1486074c320e container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:49:50.367
  Feb 12 20:49:50.380: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4861" for this suite. @ 02/12/24 20:49:50.385
• [2.087 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 02/12/24 20:49:50.393
  Feb 12 20:49:50.393: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename emptydir @ 02/12/24 20:49:50.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:50.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:50.415
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 02/12/24 20:49:50.418
  E0212 20:49:50.629520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:51.629630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:52.629714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:53.629870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:49:54.443
  Feb 12 20:49:54.446: INFO: Trying to get logs from node ip-172-31-5-108 pod pod-44664700-467c-4506-9398-3681ee9cee31 container test-container: <nil>
  STEP: delete the pod @ 02/12/24 20:49:54.455
  Feb 12 20:49:54.474: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1878" for this suite. @ 02/12/24 20:49:54.479
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 02/12/24 20:49:54.486
  Feb 12 20:49:54.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename disruption @ 02/12/24 20:49:54.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:54.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:54.508
  STEP: Creating a kubernetes client @ 02/12/24 20:49:54.513
  Feb 12 20:49:54.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename disruption-2 @ 02/12/24 20:49:54.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:54.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:54.551
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:49:54.561
  E0212 20:49:54.630862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:49:55.630986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:49:56.572
  STEP: Waiting for the pdb to be processed @ 02/12/24 20:49:56.583
  STEP: listing a collection of PDBs across all namespaces @ 02/12/24 20:49:56.588
  STEP: listing a collection of PDBs in namespace disruption-9625 @ 02/12/24 20:49:56.592
  STEP: deleting a collection of PDBs @ 02/12/24 20:49:56.595
  STEP: Waiting for the PDB collection to be deleted @ 02/12/24 20:49:56.609
  Feb 12 20:49:56.612: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-4260" for this suite. @ 02/12/24 20:49:56.616
  Feb 12 20:49:56.625: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9625" for this suite. @ 02/12/24 20:49:56.629
  E0212 20:49:56.631476      20 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.150 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 02/12/24 20:49:56.637
  Feb 12 20:49:56.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename proxy @ 02/12/24 20:49:56.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:49:56.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:49:56.658
  STEP: starting an echo server on multiple ports @ 02/12/24 20:49:56.673
  STEP: creating replication controller proxy-service-n6nqz in namespace proxy-8873 @ 02/12/24 20:49:56.673
  I0212 20:49:56.682854      20 runners.go:197] Created replication controller with name: proxy-service-n6nqz, namespace: proxy-8873, replica count: 1
  E0212 20:49:57.632286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 20:49:57.733636      20 runners.go:197] proxy-service-n6nqz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0212 20:49:58.632943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 20:49:58.734264      20 runners.go:197] proxy-service-n6nqz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0212 20:49:59.633922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0212 20:49:59.735218      20 runners.go:197] proxy-service-n6nqz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb 12 20:49:59.740: INFO: setup took 3.078870615s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 02/12/24 20:49:59.74
  Feb 12 20:49:59.747: INFO: (0) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.780501ms)
  Feb 12 20:49:59.748: INFO: (0) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 7.322132ms)
  Feb 12 20:49:59.748: INFO: (0) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 7.254449ms)
  Feb 12 20:49:59.748: INFO: (0) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.28401ms)
  Feb 12 20:49:59.751: INFO: (0) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 10.389749ms)
  Feb 12 20:49:59.751: INFO: (0) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 10.607735ms)
  Feb 12 20:49:59.751: INFO: (0) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 10.787176ms)
  Feb 12 20:49:59.752: INFO: (0) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 11.094649ms)
  Feb 12 20:49:59.752: INFO: (0) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 10.860971ms)
  Feb 12 20:49:59.753: INFO: (0) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 12.269548ms)
  Feb 12 20:49:59.753: INFO: (0) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 12.725758ms)
  Feb 12 20:49:59.753: INFO: (0) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 12.649004ms)
  Feb 12 20:49:59.754: INFO: (0) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 13.378905ms)
  Feb 12 20:49:59.754: INFO: (0) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 13.52504ms)
  Feb 12 20:49:59.755: INFO: (0) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 14.203274ms)
  Feb 12 20:49:59.755: INFO: (0) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 14.373945ms)
  Feb 12 20:49:59.760: INFO: (1) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 4.731882ms)
  Feb 12 20:49:59.760: INFO: (1) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.117199ms)
  Feb 12 20:49:59.761: INFO: (1) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 5.405644ms)
  Feb 12 20:49:59.761: INFO: (1) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 5.400914ms)
  Feb 12 20:49:59.762: INFO: (1) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 6.749542ms)
  Feb 12 20:49:59.762: INFO: (1) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.955487ms)
  Feb 12 20:49:59.762: INFO: (1) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.029102ms)
  Feb 12 20:49:59.763: INFO: (1) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 7.03614ms)
  Feb 12 20:49:59.763: INFO: (1) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 7.397836ms)
  Feb 12 20:49:59.763: INFO: (1) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.605821ms)
  Feb 12 20:49:59.763: INFO: (1) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 7.775532ms)
  Feb 12 20:49:59.763: INFO: (1) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 7.818827ms)
  Feb 12 20:49:59.764: INFO: (1) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 8.638413ms)
  Feb 12 20:49:59.764: INFO: (1) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 8.476004ms)
  Feb 12 20:49:59.766: INFO: (1) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 10.157639ms)
  Feb 12 20:49:59.766: INFO: (1) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 10.323425ms)
  Feb 12 20:49:59.771: INFO: (2) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 5.522591ms)
  Feb 12 20:49:59.772: INFO: (2) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.124589ms)
  Feb 12 20:49:59.772: INFO: (2) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.344884ms)
  Feb 12 20:49:59.772: INFO: (2) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.506436ms)
  Feb 12 20:49:59.772: INFO: (2) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 5.750809ms)
  Feb 12 20:49:59.776: INFO: (2) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 10.024042ms)
  Feb 12 20:49:59.776: INFO: (2) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 10.270091ms)
  Feb 12 20:49:59.776: INFO: (2) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 10.499668ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 10.601196ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 10.477842ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 10.727732ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 10.785094ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 11.353348ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 11.116323ms)
  Feb 12 20:49:59.777: INFO: (2) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 11.101995ms)
  Feb 12 20:49:59.778: INFO: (2) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 11.187695ms)
  Feb 12 20:49:59.784: INFO: (3) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.975802ms)
  Feb 12 20:49:59.784: INFO: (3) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.184716ms)
  Feb 12 20:49:59.784: INFO: (3) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.62921ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.247767ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.56401ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 7.061439ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.509715ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.635348ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 6.893772ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.136182ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 7.143902ms)
  Feb 12 20:49:59.785: INFO: (3) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.45434ms)
  Feb 12 20:49:59.786: INFO: (3) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.745877ms)
  Feb 12 20:49:59.786: INFO: (3) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.59757ms)
  Feb 12 20:49:59.786: INFO: (3) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.062726ms)
  Feb 12 20:49:59.787: INFO: (3) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.293619ms)
  Feb 12 20:49:59.791: INFO: (4) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 4.392445ms)
  Feb 12 20:49:59.791: INFO: (4) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 4.787288ms)
  Feb 12 20:49:59.792: INFO: (4) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.087304ms)
  Feb 12 20:49:59.792: INFO: (4) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.571248ms)
  Feb 12 20:49:59.792: INFO: (4) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.411224ms)
  Feb 12 20:49:59.793: INFO: (4) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.113209ms)
  Feb 12 20:49:59.793: INFO: (4) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 6.2004ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.824142ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 6.907039ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 6.789461ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 7.158801ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.156003ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.183578ms)
  Feb 12 20:49:59.794: INFO: (4) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 7.215911ms)
  Feb 12 20:49:59.796: INFO: (4) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 8.937518ms)
  Feb 12 20:49:59.796: INFO: (4) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 9.16705ms)
  Feb 12 20:49:59.800: INFO: (5) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 3.589342ms)
  Feb 12 20:49:59.801: INFO: (5) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 4.82865ms)
  Feb 12 20:49:59.801: INFO: (5) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 4.993167ms)
  Feb 12 20:49:59.801: INFO: (5) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 5.259644ms)
  Feb 12 20:49:59.802: INFO: (5) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.658253ms)
  Feb 12 20:49:59.802: INFO: (5) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 6.140427ms)
  Feb 12 20:49:59.802: INFO: (5) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.171427ms)
  Feb 12 20:49:59.803: INFO: (5) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 6.246532ms)
  Feb 12 20:49:59.803: INFO: (5) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.262574ms)
  Feb 12 20:49:59.803: INFO: (5) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.519798ms)
  Feb 12 20:49:59.803: INFO: (5) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 6.697438ms)
  Feb 12 20:49:59.803: INFO: (5) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.176463ms)
  Feb 12 20:49:59.804: INFO: (5) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.549308ms)
  Feb 12 20:49:59.804: INFO: (5) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 7.767547ms)
  Feb 12 20:49:59.804: INFO: (5) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.120756ms)
  Feb 12 20:49:59.804: INFO: (5) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.19219ms)
  Feb 12 20:49:59.810: INFO: (6) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 4.970596ms)
  Feb 12 20:49:59.810: INFO: (6) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.484251ms)
  Feb 12 20:49:59.811: INFO: (6) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.169489ms)
  Feb 12 20:49:59.811: INFO: (6) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.36621ms)
  Feb 12 20:49:59.811: INFO: (6) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.145963ms)
  Feb 12 20:49:59.811: INFO: (6) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.216304ms)
  Feb 12 20:49:59.811: INFO: (6) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 6.6441ms)
  Feb 12 20:49:59.812: INFO: (6) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 7.189701ms)
  Feb 12 20:49:59.812: INFO: (6) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.143729ms)
  Feb 12 20:49:59.812: INFO: (6) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.475034ms)
  Feb 12 20:49:59.812: INFO: (6) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.88209ms)
  Feb 12 20:49:59.813: INFO: (6) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 8.018079ms)
  Feb 12 20:49:59.813: INFO: (6) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 7.933423ms)
  Feb 12 20:49:59.813: INFO: (6) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 7.988643ms)
  Feb 12 20:49:59.813: INFO: (6) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 8.474295ms)
  Feb 12 20:49:59.815: INFO: (6) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 9.98554ms)
  Feb 12 20:49:59.820: INFO: (7) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.147023ms)
  Feb 12 20:49:59.820: INFO: (7) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.495739ms)
  Feb 12 20:49:59.820: INFO: (7) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 5.46248ms)
  Feb 12 20:49:59.821: INFO: (7) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 6.302196ms)
  Feb 12 20:49:59.821: INFO: (7) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.099006ms)
  Feb 12 20:49:59.821: INFO: (7) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 6.467364ms)
  Feb 12 20:49:59.822: INFO: (7) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.834492ms)
  Feb 12 20:49:59.822: INFO: (7) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.189055ms)
  Feb 12 20:49:59.822: INFO: (7) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 7.275514ms)
  Feb 12 20:49:59.822: INFO: (7) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.446539ms)
  Feb 12 20:49:59.822: INFO: (7) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 7.454632ms)
  Feb 12 20:49:59.823: INFO: (7) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 7.576764ms)
  Feb 12 20:49:59.823: INFO: (7) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.729382ms)
  Feb 12 20:49:59.823: INFO: (7) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.923261ms)
  Feb 12 20:49:59.825: INFO: (7) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 9.920166ms)
  Feb 12 20:49:59.825: INFO: (7) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 10.3551ms)
  Feb 12 20:49:59.829: INFO: (8) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 3.936362ms)
  Feb 12 20:49:59.831: INFO: (8) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.928571ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.997184ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.175753ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 6.146449ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 6.301659ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.403183ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.305847ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 6.655378ms)
  Feb 12 20:49:59.832: INFO: (8) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 6.977494ms)
  Feb 12 20:49:59.833: INFO: (8) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.291666ms)
  Feb 12 20:49:59.833: INFO: (8) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.640937ms)
  Feb 12 20:49:59.833: INFO: (8) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 7.901226ms)
  Feb 12 20:49:59.833: INFO: (8) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.852378ms)
  Feb 12 20:49:59.833: INFO: (8) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.948992ms)
  Feb 12 20:49:59.834: INFO: (8) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.423725ms)
  Feb 12 20:49:59.839: INFO: (9) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 4.843895ms)
  Feb 12 20:49:59.839: INFO: (9) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.610049ms)
  Feb 12 20:49:59.840: INFO: (9) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 5.886423ms)
  Feb 12 20:49:59.840: INFO: (9) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.887398ms)
  Feb 12 20:49:59.840: INFO: (9) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.944459ms)
  Feb 12 20:49:59.840: INFO: (9) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.348973ms)
  Feb 12 20:49:59.840: INFO: (9) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.277351ms)
  Feb 12 20:49:59.841: INFO: (9) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 6.801634ms)
  Feb 12 20:49:59.841: INFO: (9) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.874954ms)
  Feb 12 20:49:59.841: INFO: (9) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 7.374026ms)
  Feb 12 20:49:59.841: INFO: (9) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.449043ms)
  Feb 12 20:49:59.842: INFO: (9) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 7.953596ms)
  Feb 12 20:49:59.842: INFO: (9) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.022674ms)
  Feb 12 20:49:59.842: INFO: (9) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 8.299078ms)
  Feb 12 20:49:59.842: INFO: (9) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 8.44723ms)
  Feb 12 20:49:59.843: INFO: (9) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 9.070464ms)
  Feb 12 20:49:59.847: INFO: (10) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 3.598693ms)
  Feb 12 20:49:59.848: INFO: (10) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 4.993538ms)
  Feb 12 20:49:59.848: INFO: (10) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.072447ms)
  Feb 12 20:49:59.849: INFO: (10) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.39608ms)
  Feb 12 20:49:59.849: INFO: (10) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.425554ms)
  Feb 12 20:49:59.850: INFO: (10) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.218565ms)
  Feb 12 20:49:59.850: INFO: (10) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.050827ms)
  Feb 12 20:49:59.850: INFO: (10) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.237239ms)
  Feb 12 20:49:59.850: INFO: (10) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 6.521955ms)
  Feb 12 20:49:59.851: INFO: (10) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.100986ms)
  Feb 12 20:49:59.851: INFO: (10) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.794165ms)
  Feb 12 20:49:59.851: INFO: (10) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.880769ms)
  Feb 12 20:49:59.851: INFO: (10) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.040265ms)
  Feb 12 20:49:59.851: INFO: (10) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 7.878272ms)
  Feb 12 20:49:59.852: INFO: (10) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 8.973882ms)
  Feb 12 20:49:59.853: INFO: (10) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 9.380313ms)
  Feb 12 20:49:59.857: INFO: (11) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 3.788407ms)
  Feb 12 20:49:59.857: INFO: (11) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 4.304751ms)
  Feb 12 20:49:59.858: INFO: (11) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.701586ms)
  Feb 12 20:49:59.859: INFO: (11) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.616329ms)
  Feb 12 20:49:59.859: INFO: (11) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 5.540003ms)
  Feb 12 20:49:59.859: INFO: (11) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.906665ms)
  Feb 12 20:49:59.859: INFO: (11) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.857875ms)
  Feb 12 20:49:59.860: INFO: (11) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.730805ms)
  Feb 12 20:49:59.860: INFO: (11) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.717684ms)
  Feb 12 20:49:59.860: INFO: (11) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.852612ms)
  Feb 12 20:49:59.860: INFO: (11) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 7.120459ms)
  Feb 12 20:49:59.860: INFO: (11) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.244509ms)
  Feb 12 20:49:59.860: INFO: (11) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 7.292347ms)
  Feb 12 20:49:59.861: INFO: (11) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.53662ms)
  Feb 12 20:49:59.861: INFO: (11) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.753775ms)
  Feb 12 20:49:59.861: INFO: (11) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.377796ms)
  Feb 12 20:49:59.866: INFO: (12) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 4.187944ms)
  Feb 12 20:49:59.866: INFO: (12) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 4.131756ms)
  Feb 12 20:49:59.867: INFO: (12) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 5.284923ms)
  Feb 12 20:49:59.867: INFO: (12) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.257254ms)
  Feb 12 20:49:59.867: INFO: (12) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.9317ms)
  Feb 12 20:49:59.868: INFO: (12) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.069112ms)
  Feb 12 20:49:59.868: INFO: (12) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 6.245516ms)
  Feb 12 20:49:59.868: INFO: (12) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.333777ms)
  Feb 12 20:49:59.868: INFO: (12) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.175185ms)
  Feb 12 20:49:59.868: INFO: (12) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.293352ms)
  Feb 12 20:49:59.868: INFO: (12) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 6.889587ms)
  Feb 12 20:49:59.869: INFO: (12) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.569185ms)
  Feb 12 20:49:59.869: INFO: (12) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.832914ms)
  Feb 12 20:49:59.870: INFO: (12) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.342915ms)
  Feb 12 20:49:59.870: INFO: (12) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.754439ms)
  Feb 12 20:49:59.871: INFO: (12) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 9.33367ms)
  Feb 12 20:49:59.875: INFO: (13) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 4.029586ms)
  Feb 12 20:49:59.875: INFO: (13) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 4.211356ms)
  Feb 12 20:49:59.876: INFO: (13) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.280355ms)
  Feb 12 20:49:59.876: INFO: (13) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.303077ms)
  Feb 12 20:49:59.877: INFO: (13) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.663563ms)
  Feb 12 20:49:59.877: INFO: (13) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 6.127831ms)
  Feb 12 20:49:59.878: INFO: (13) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 6.299614ms)
  Feb 12 20:49:59.878: INFO: (13) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 6.647836ms)
  Feb 12 20:49:59.878: INFO: (13) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.385667ms)
  Feb 12 20:49:59.878: INFO: (13) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 7.121404ms)
  Feb 12 20:49:59.879: INFO: (13) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 7.248685ms)
  Feb 12 20:49:59.879: INFO: (13) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 7.256074ms)
  Feb 12 20:49:59.879: INFO: (13) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 7.40473ms)
  Feb 12 20:49:59.880: INFO: (13) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.303106ms)
  Feb 12 20:49:59.880: INFO: (13) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 9.013323ms)
  Feb 12 20:49:59.881: INFO: (13) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 9.406235ms)
  Feb 12 20:49:59.885: INFO: (14) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 4.052559ms)
  Feb 12 20:49:59.885: INFO: (14) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 4.452682ms)
  Feb 12 20:49:59.885: INFO: (14) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 4.640675ms)
  Feb 12 20:49:59.886: INFO: (14) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 4.876042ms)
  Feb 12 20:49:59.886: INFO: (14) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.55272ms)
  Feb 12 20:49:59.887: INFO: (14) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 5.931678ms)
  Feb 12 20:49:59.887: INFO: (14) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.283127ms)
  Feb 12 20:49:59.887: INFO: (14) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 6.483768ms)
  Feb 12 20:49:59.888: INFO: (14) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.83318ms)
  Feb 12 20:49:59.888: INFO: (14) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.163415ms)
  Feb 12 20:49:59.888: INFO: (14) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 7.2685ms)
  Feb 12 20:49:59.888: INFO: (14) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 7.205536ms)
  Feb 12 20:49:59.889: INFO: (14) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.89566ms)
  Feb 12 20:49:59.890: INFO: (14) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 8.554478ms)
  Feb 12 20:49:59.890: INFO: (14) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.706228ms)
  Feb 12 20:49:59.890: INFO: (14) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 8.872191ms)
  Feb 12 20:49:59.895: INFO: (15) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 5.118607ms)
  Feb 12 20:49:59.895: INFO: (15) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 4.949737ms)
  Feb 12 20:49:59.895: INFO: (15) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.314182ms)
  Feb 12 20:49:59.895: INFO: (15) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.447474ms)
  Feb 12 20:49:59.896: INFO: (15) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.060075ms)
  Feb 12 20:49:59.896: INFO: (15) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.007897ms)
  Feb 12 20:49:59.896: INFO: (15) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.292406ms)
  Feb 12 20:49:59.897: INFO: (15) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.82443ms)
  Feb 12 20:49:59.897: INFO: (15) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.35415ms)
  Feb 12 20:49:59.897: INFO: (15) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.43136ms)
  Feb 12 20:49:59.898: INFO: (15) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 7.987645ms)
  Feb 12 20:49:59.898: INFO: (15) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 7.961716ms)
  Feb 12 20:49:59.898: INFO: (15) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.945893ms)
  Feb 12 20:49:59.898: INFO: (15) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 8.125209ms)
  Feb 12 20:49:59.899: INFO: (15) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 9.526824ms)
  Feb 12 20:49:59.899: INFO: (15) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 9.416841ms)
  Feb 12 20:49:59.904: INFO: (16) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 4.217166ms)
  Feb 12 20:49:59.905: INFO: (16) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 5.29242ms)
  Feb 12 20:49:59.905: INFO: (16) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 5.256072ms)
  Feb 12 20:49:59.905: INFO: (16) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.855677ms)
  Feb 12 20:49:59.906: INFO: (16) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 5.897807ms)
  Feb 12 20:49:59.906: INFO: (16) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.092731ms)
  Feb 12 20:49:59.906: INFO: (16) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 6.572444ms)
  Feb 12 20:49:59.907: INFO: (16) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 6.818918ms)
  Feb 12 20:49:59.907: INFO: (16) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.853527ms)
  Feb 12 20:49:59.907: INFO: (16) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.899104ms)
  Feb 12 20:49:59.907: INFO: (16) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 7.140435ms)
  Feb 12 20:49:59.907: INFO: (16) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.302548ms)
  Feb 12 20:49:59.908: INFO: (16) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.928688ms)
  Feb 12 20:49:59.908: INFO: (16) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.142458ms)
  Feb 12 20:49:59.908: INFO: (16) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.677423ms)
  Feb 12 20:49:59.908: INFO: (16) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 8.514787ms)
  Feb 12 20:49:59.912: INFO: (17) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 3.999518ms)
  Feb 12 20:49:59.913: INFO: (17) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 4.652346ms)
  Feb 12 20:49:59.914: INFO: (17) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.585666ms)
  Feb 12 20:49:59.914: INFO: (17) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 5.514949ms)
  Feb 12 20:49:59.914: INFO: (17) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.627159ms)
  Feb 12 20:49:59.915: INFO: (17) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.266136ms)
  Feb 12 20:49:59.915: INFO: (17) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 6.56212ms)
  Feb 12 20:49:59.915: INFO: (17) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 6.849731ms)
  Feb 12 20:49:59.916: INFO: (17) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 7.007556ms)
  Feb 12 20:49:59.916: INFO: (17) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 7.129121ms)
  Feb 12 20:49:59.916: INFO: (17) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.308827ms)
  Feb 12 20:49:59.916: INFO: (17) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.354223ms)
  Feb 12 20:49:59.916: INFO: (17) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.52551ms)
  Feb 12 20:49:59.917: INFO: (17) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.268653ms)
  Feb 12 20:49:59.917: INFO: (17) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 8.585974ms)
  Feb 12 20:49:59.917: INFO: (17) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 8.62423ms)
  Feb 12 20:49:59.922: INFO: (18) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 5.016115ms)
  Feb 12 20:49:59.923: INFO: (18) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 5.354906ms)
  Feb 12 20:49:59.923: INFO: (18) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.469772ms)
  Feb 12 20:49:59.923: INFO: (18) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.044648ms)
  Feb 12 20:49:59.924: INFO: (18) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.802444ms)
  Feb 12 20:49:59.924: INFO: (18) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.897238ms)
  Feb 12 20:49:59.924: INFO: (18) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 7.03329ms)
  Feb 12 20:49:59.924: INFO: (18) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 7.011461ms)
  Feb 12 20:49:59.924: INFO: (18) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 6.968335ms)
  Feb 12 20:49:59.925: INFO: (18) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 7.27138ms)
  Feb 12 20:49:59.925: INFO: (18) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 7.417836ms)
  Feb 12 20:49:59.925: INFO: (18) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 7.70318ms)
  Feb 12 20:49:59.925: INFO: (18) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 7.919025ms)
  Feb 12 20:49:59.926: INFO: (18) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.432566ms)
  Feb 12 20:49:59.926: INFO: (18) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 9.049646ms)
  Feb 12 20:49:59.927: INFO: (18) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 9.9244ms)
  Feb 12 20:49:59.932: INFO: (19) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 4.518616ms)
  Feb 12 20:49:59.933: INFO: (19) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:443/proxy/tlsrewritem... (200; 5.630694ms)
  Feb 12 20:49:59.933: INFO: (19) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:460/proxy/: tls baz (200; 5.708521ms)
  Feb 12 20:49:59.933: INFO: (19) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">test<... (200; 5.937489ms)
  Feb 12 20:49:59.933: INFO: (19) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:1080/proxy/rewriteme">... (200; 5.977662ms)
  Feb 12 20:49:59.934: INFO: (19) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname2/proxy/: bar (200; 6.397249ms)
  Feb 12 20:49:59.934: INFO: (19) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:162/proxy/: bar (200; 6.08872ms)
  Feb 12 20:49:59.934: INFO: (19) /api/v1/namespaces/proxy-8873/pods/http:proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 6.652031ms)
  Feb 12 20:49:59.934: INFO: (19) /api/v1/namespaces/proxy-8873/pods/https:proxy-service-n6nqz-q7b8h:462/proxy/: tls qux (200; 6.677078ms)
  Feb 12 20:49:59.935: INFO: (19) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/: <a href="/api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h/proxy/rewriteme">test</a> (200; 6.903581ms)
  Feb 12 20:49:59.935: INFO: (19) /api/v1/namespaces/proxy-8873/pods/proxy-service-n6nqz-q7b8h:160/proxy/: foo (200; 7.100114ms)
  Feb 12 20:49:59.935: INFO: (19) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname1/proxy/: foo (200; 7.735927ms)
  Feb 12 20:49:59.936: INFO: (19) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname2/proxy/: tls qux (200; 8.191579ms)
  Feb 12 20:49:59.936: INFO: (19) /api/v1/namespaces/proxy-8873/services/proxy-service-n6nqz:portname1/proxy/: foo (200; 8.409932ms)
  Feb 12 20:49:59.936: INFO: (19) /api/v1/namespaces/proxy-8873/services/https:proxy-service-n6nqz:tlsportname1/proxy/: tls baz (200; 8.69669ms)
  Feb 12 20:49:59.937: INFO: (19) /api/v1/namespaces/proxy-8873/services/http:proxy-service-n6nqz:portname2/proxy/: bar (200; 9.074101ms)
  STEP: deleting ReplicationController proxy-service-n6nqz in namespace proxy-8873, will wait for the garbage collector to delete the pods @ 02/12/24 20:49:59.937
  Feb 12 20:50:00.000: INFO: Deleting ReplicationController proxy-service-n6nqz took: 8.49079ms
  Feb 12 20:50:00.101: INFO: Terminating ReplicationController proxy-service-n6nqz pods took: 100.886603ms
  E0212 20:50:00.634635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:01.635135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:50:02.101: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-8873" for this suite. @ 02/12/24 20:50:02.106
• [5.477 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 02/12/24 20:50:02.114
  Feb 12 20:50:02.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename resourcequota @ 02/12/24 20:50:02.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:50:02.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:50:02.135
  STEP: Counting existing ResourceQuota @ 02/12/24 20:50:02.139
  E0212 20:50:02.635622      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:03.636626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:04.637554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:05.637856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:06.637941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/12/24 20:50:07.144
  STEP: Ensuring resource quota status is calculated @ 02/12/24 20:50:07.15
  E0212 20:50:07.638888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:08.639949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 02/12/24 20:50:09.156
  STEP: Creating a NodePort Service @ 02/12/24 20:50:09.173
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 02/12/24 20:50:09.194
  STEP: Ensuring resource quota status captures service creation @ 02/12/24 20:50:09.218
  E0212 20:50:09.640594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:10.640814      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 02/12/24 20:50:11.223
  STEP: Ensuring resource quota status released usage @ 02/12/24 20:50:11.261
  E0212 20:50:11.641605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:12.641861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb 12 20:50:13.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5803" for this suite. @ 02/12/24 20:50:13.272
• [11.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 02/12/24 20:50:13.28
  Feb 12 20:50:13.280: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename configmap @ 02/12/24 20:50:13.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:50:13.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:50:13.301
  STEP: Creating configMap that has name configmap-test-emptyKey-156960f3-b64e-435a-b64b-ccca55d582c2 @ 02/12/24 20:50:13.304
  Feb 12 20:50:13.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2494" for this suite. @ 02/12/24 20:50:13.31
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 02/12/24 20:50:13.317
  Feb 12 20:50:13.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename runtimeclass @ 02/12/24 20:50:13.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:50:13.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:50:13.337
  Feb 12 20:50:13.348: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-102" for this suite. @ 02/12/24 20:50:13.352
• [0.041 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 02/12/24 20:50:13.358
  Feb 12 20:50:13.358: INFO: >>> kubeConfig: /tmp/kubeconfig-3167951924
  STEP: Building a namespace api object, basename containers @ 02/12/24 20:50:13.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/12/24 20:50:13.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/12/24 20:50:13.38
  STEP: Creating a pod to test override command @ 02/12/24 20:50:13.383
  E0212 20:50:13.642929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:14.643031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:15.643999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0212 20:50:16.644101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/12/24 20:50:17.409
  Feb 12 20:50:17.413: INFO: Trying to get logs from node ip-172-31-5-108 pod client-containers-48bc7f73-a566-4f87-9e5c-d02328b2721e container agnhost-container: <nil>
  STEP: delete the pod @ 02/12/24 20:50:17.421
  Feb 12 20:50:17.437: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2580" for this suite. @ 02/12/24 20:50:17.442
• [4.092 seconds]
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Feb 12 20:50:17.452: INFO: Running AfterSuite actions on node 1
  Feb 12 20:50:17.452: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.032 seconds]
------------------------------

Ran 388 of 7407 Specs in 6548.850 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 1h49m9.580597298s
Test Suite Passed
