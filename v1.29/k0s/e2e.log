  I0207 13:37:27.242997      23 e2e.go:117] Starting e2e run "6f38753a-a54c-471f-9df2-0d69bb9619d8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1707313046 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Feb  7 13:37:27.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:37:27.462: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Feb  7 13:38:21.841: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Feb  7 13:38:21.844: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
  Feb  7 13:38:21.844: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Feb  7 13:38:21.844: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-router' (0 seconds elapsed)
  Feb  7 13:38:21.844: INFO: e2e test version: v1.29.1
  Feb  7 13:38:21.845: INFO: kube-apiserver version: v1.29.1+k0s
  Feb  7 13:38:21.845: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:38:21.848: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [54.387 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 02/07/24 13:38:21.995
  Feb  7 13:38:21.995: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 13:38:21.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:38:22.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:38:22.011
  STEP: Creating configMap with name configmap-test-volume-map-02eebc0f-3f62-408f-bbbe-d0eeb532f983 @ 02/07/24 13:38:22.014
  STEP: Creating a pod to test consume configMaps @ 02/07/24 13:38:22.018
  STEP: Saw pod success @ 02/07/24 13:38:30.038
  Feb  7 13:38:30.040: INFO: Trying to get logs from node worker-0 pod pod-configmaps-86ddef57-72f0-44ca-99ee-4ce1d687316e container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 13:38:30.054
  Feb  7 13:38:30.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4959" for this suite. @ 02/07/24 13:38:30.067
• [8.076 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 02/07/24 13:38:30.072
  Feb  7 13:38:30.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename taint-multiple-pods @ 02/07/24 13:38:30.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:38:30.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:38:30.083
  Feb  7 13:38:30.086: INFO: Waiting up to 1m0s for all nodes to be ready
  Feb  7 13:39:30.086: INFO: Waiting for terminating namespaces to be deleted...
  Feb  7 13:39:30.089: INFO: Starting informer...
  STEP: Starting pods... @ 02/07/24 13:39:30.089
  Feb  7 13:39:30.300: INFO: Pod1 is running on worker-0. Tainting Node
  Feb  7 13:39:32.517: INFO: Pod2 is running on worker-0. Tainting Node
  STEP: Trying to apply a taint on the Node @ 02/07/24 13:39:32.517
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/07/24 13:39:32.525
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 02/07/24 13:39:32.527
  Feb  7 13:39:38.229: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  Feb  7 13:39:58.270: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/07/24 13:39:58.278
  Feb  7 13:39:58.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-7504" for this suite. @ 02/07/24 13:39:58.283
• [88.214 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 02/07/24 13:39:58.287
  Feb  7 13:39:58.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename endpointslice @ 02/07/24 13:39:58.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:39:58.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:39:58.303
  STEP: getting /apis @ 02/07/24 13:39:58.305
  STEP: getting /apis/discovery.k8s.io @ 02/07/24 13:39:58.309
  STEP: getting /apis/discovery.k8s.iov1 @ 02/07/24 13:39:58.31
  STEP: creating @ 02/07/24 13:39:58.311
  STEP: getting @ 02/07/24 13:39:58.321
  STEP: listing @ 02/07/24 13:39:58.323
  STEP: watching @ 02/07/24 13:39:58.325
  Feb  7 13:39:58.325: INFO: starting watch
  STEP: cluster-wide listing @ 02/07/24 13:39:58.326
  STEP: cluster-wide watching @ 02/07/24 13:39:58.328
  Feb  7 13:39:58.328: INFO: starting watch
  STEP: patching @ 02/07/24 13:39:58.328
  STEP: updating @ 02/07/24 13:39:58.332
  Feb  7 13:39:58.337: INFO: waiting for watch events with expected annotations
  Feb  7 13:39:58.337: INFO: saw patched and updated annotations
  STEP: deleting @ 02/07/24 13:39:58.337
  STEP: deleting a collection @ 02/07/24 13:39:58.343
  Feb  7 13:39:58.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3822" for this suite. @ 02/07/24 13:39:58.353
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 02/07/24 13:39:58.359
  Feb  7 13:39:58.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 13:39:58.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:39:58.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:39:58.37
  STEP: Setting up server cert @ 02/07/24 13:39:58.384
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 13:39:58.938
  STEP: Deploying the webhook pod @ 02/07/24 13:39:58.942
  STEP: Wait for the deployment to be ready @ 02/07/24 13:39:58.95
  Feb  7 13:39:58.955: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/07/24 13:40:00.963
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 13:40:00.972
  Feb  7 13:40:01.972: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb  7 13:40:01.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-685-crds.webhook.example.com via the AdmissionRegistration API @ 02/07/24 13:40:02.485
  STEP: Creating a custom resource that should be mutated by the webhook @ 02/07/24 13:40:02.501
  Feb  7 13:40:05.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1109" for this suite. @ 02/07/24 13:40:05.072
  STEP: Destroying namespace "webhook-markers-5779" for this suite. @ 02/07/24 13:40:05.075
• [6.720 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 02/07/24 13:40:05.079
  Feb  7 13:40:05.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 13:40:05.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:05.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:05.092
  Feb  7 13:40:05.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 02/07/24 13:40:06.443
  Feb  7 13:40:06.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-253 --namespace=crd-publish-openapi-253 create -f -'
  Feb  7 13:40:08.530: INFO: stderr: ""
  Feb  7 13:40:08.530: INFO: stdout: "e2e-test-crd-publish-openapi-4389-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Feb  7 13:40:08.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-253 --namespace=crd-publish-openapi-253 delete e2e-test-crd-publish-openapi-4389-crds test-cr'
  Feb  7 13:40:08.593: INFO: stderr: ""
  Feb  7 13:40:08.593: INFO: stdout: "e2e-test-crd-publish-openapi-4389-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Feb  7 13:40:08.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-253 --namespace=crd-publish-openapi-253 apply -f -'
  Feb  7 13:40:08.660: INFO: stderr: ""
  Feb  7 13:40:08.660: INFO: stdout: "e2e-test-crd-publish-openapi-4389-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Feb  7 13:40:08.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-253 --namespace=crd-publish-openapi-253 delete e2e-test-crd-publish-openapi-4389-crds test-cr'
  Feb  7 13:40:08.720: INFO: stderr: ""
  Feb  7 13:40:08.720: INFO: stdout: "e2e-test-crd-publish-openapi-4389-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 02/07/24 13:40:08.72
  Feb  7 13:40:08.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-253 explain e2e-test-crd-publish-openapi-4389-crds'
  Feb  7 13:40:08.779: INFO: stderr: ""
  Feb  7 13:40:08.779: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-4389-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Feb  7 13:40:10.024: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-253" for this suite. @ 02/07/24 13:40:10.031
• [4.957 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 02/07/24 13:40:10.036
  Feb  7 13:40:10.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 13:40:10.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:10.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:10.048
  STEP: Setting up server cert @ 02/07/24 13:40:10.063
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 13:40:10.588
  STEP: Deploying the webhook pod @ 02/07/24 13:40:10.593
  STEP: Wait for the deployment to be ready @ 02/07/24 13:40:10.601
  Feb  7 13:40:10.615: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/07/24 13:40:12.622
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 13:40:12.632
  Feb  7 13:40:13.632: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 02/07/24 13:40:13.636
  STEP: create a pod that should be updated by the webhook @ 02/07/24 13:40:13.652
  Feb  7 13:40:13.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8048" for this suite. @ 02/07/24 13:40:13.7
  STEP: Destroying namespace "webhook-markers-3433" for this suite. @ 02/07/24 13:40:13.705
• [3.673 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 02/07/24 13:40:13.711
  Feb  7 13:40:13.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubelet-test @ 02/07/24 13:40:13.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:13.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:13.733
  STEP: Waiting for pod completion @ 02/07/24 13:40:13.741
  Feb  7 13:40:17.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3189" for this suite. @ 02/07/24 13:40:17.764
• [4.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 02/07/24 13:40:17.769
  Feb  7 13:40:17.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 13:40:17.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:17.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:17.781
  STEP: Creating projection with secret that has name secret-emptykey-test-02d4265b-d4b2-4f6a-b71a-cea43f43dd36 @ 02/07/24 13:40:17.783
  Feb  7 13:40:17.785: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2491" for this suite. @ 02/07/24 13:40:17.787
• [0.023 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 02/07/24 13:40:17.792
  Feb  7 13:40:17.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/07/24 13:40:17.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:17.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:17.804
  Feb  7 13:40:17.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:40:23.954: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3023" for this suite. @ 02/07/24 13:40:23.956
• [6.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 02/07/24 13:40:23.962
  Feb  7 13:40:23.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir-wrapper @ 02/07/24 13:40:23.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:23.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:23.974
  STEP: Cleaning up the secret @ 02/07/24 13:40:25.996
  STEP: Cleaning up the configmap @ 02/07/24 13:40:26
  STEP: Cleaning up the pod @ 02/07/24 13:40:26.003
  Feb  7 13:40:26.010: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-7085" for this suite. @ 02/07/24 13:40:26.013
• [2.055 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 02/07/24 13:40:26.016
  Feb  7 13:40:26.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 13:40:26.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:26.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:26.027
  STEP: Creating simple DaemonSet "daemon-set" @ 02/07/24 13:40:26.041
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/07/24 13:40:26.044
  Feb  7 13:40:26.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:40:26.049: INFO: Node worker-0 is running 0 daemon pod, expected 1
  Feb  7 13:40:27.050: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:40:27.050: INFO: Node worker-0 is running 0 daemon pod, expected 1
  Feb  7 13:40:28.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:40:28.049: INFO: Node worker-0 is running 0 daemon pod, expected 1
  Feb  7 13:40:29.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:40:29.051: INFO: Node worker-0 is running 0 daemon pod, expected 1
  Feb  7 13:40:30.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:40:30.049: INFO: Node worker-0 is running 0 daemon pod, expected 1
  Feb  7 13:40:31.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 13:40:31.049: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 02/07/24 13:40:31.051
  Feb  7 13:40:31.055: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 02/07/24 13:40:31.055
  Feb  7 13:40:31.061: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 02/07/24 13:40:31.061
  Feb  7 13:40:31.063: INFO: Observed &DaemonSet event: ADDED
  Feb  7 13:40:31.063: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.063: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.063: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.064: INFO: Found daemon set daemon-set in namespace daemonsets-7108 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb  7 13:40:31.064: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 02/07/24 13:40:31.064
  STEP: watching for the daemon set status to be patched @ 02/07/24 13:40:31.07
  Feb  7 13:40:31.072: INFO: Observed &DaemonSet event: ADDED
  Feb  7 13:40:31.072: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.072: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.072: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.072: INFO: Observed daemon set daemon-set in namespace daemonsets-7108 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb  7 13:40:31.072: INFO: Observed &DaemonSet event: MODIFIED
  Feb  7 13:40:31.072: INFO: Found daemon set daemon-set in namespace daemonsets-7108 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Feb  7 13:40:31.072: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 02/07/24 13:40:31.075
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7108, will wait for the garbage collector to delete the pods @ 02/07/24 13:40:31.075
  Feb  7 13:40:31.132: INFO: Deleting DaemonSet.extensions daemon-set took: 3.716615ms
  Feb  7 13:40:31.232: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.610057ms
  Feb  7 13:40:35.435: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:40:35.435: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb  7 13:40:35.437: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1698"},"items":null}

  Feb  7 13:40:35.439: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1698"},"items":null}

  Feb  7 13:40:35.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7108" for this suite. @ 02/07/24 13:40:35.447
• [9.435 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 02/07/24 13:40:35.452
  Feb  7 13:40:35.452: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 13:40:35.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:35.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:35.464
  STEP: Creating the pod @ 02/07/24 13:40:35.467
  Feb  7 13:40:37.994: INFO: Successfully updated pod "annotationupdateba5d6e86-f33b-4a86-972d-fb3dc816cf65"
  Feb  7 13:40:40.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9678" for this suite. @ 02/07/24 13:40:40.008
• [4.560 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 02/07/24 13:40:40.012
  Feb  7 13:40:40.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 13:40:40.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:40.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:40.023
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7809 @ 02/07/24 13:40:40.025
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 02/07/24 13:40:40.036
  STEP: creating service externalsvc in namespace services-7809 @ 02/07/24 13:40:40.036
  STEP: creating replication controller externalsvc in namespace services-7809 @ 02/07/24 13:40:40.05
  I0207 13:40:40.055451      23 runners.go:197] Created replication controller with name: externalsvc, namespace: services-7809, replica count: 2
  I0207 13:40:43.105853      23 runners.go:197] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0207 13:40:46.108289      23 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 02/07/24 13:40:46.11
  Feb  7 13:40:46.120: INFO: Creating new exec pod
  Feb  7 13:40:48.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-7809 exec execpodzghfq -- /bin/sh -x -c nslookup clusterip-service.services-7809.svc.cluster.local'
  Feb  7 13:40:48.272: INFO: stderr: "+ nslookup clusterip-service.services-7809.svc.cluster.local\n"
  Feb  7 13:40:48.272: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-7809.svc.cluster.local\tcanonical name = externalsvc.services-7809.svc.cluster.local.\nName:\texternalsvc.services-7809.svc.cluster.local\nAddress: 10.102.224.109\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-7809, will wait for the garbage collector to delete the pods @ 02/07/24 13:40:48.272
  Feb  7 13:40:48.328: INFO: Deleting ReplicationController externalsvc took: 3.557076ms
  Feb  7 13:40:48.429: INFO: Terminating ReplicationController externalsvc pods took: 100.762897ms
  Feb  7 13:40:52.747: INFO: Cleaning up the ClusterIP to ExternalName test service
  Feb  7 13:40:52.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7809" for this suite. @ 02/07/24 13:40:52.756
• [12.748 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 02/07/24 13:40:52.76
  Feb  7 13:40:52.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 13:40:52.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:52.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:52.773
  STEP: Creating secret with name s-test-opt-del-699e99bf-cb9e-4118-9806-97320224ea5b @ 02/07/24 13:40:52.777
  STEP: Creating secret with name s-test-opt-upd-d55ae6d0-7cd7-4b67-a829-c853ee76ad7d @ 02/07/24 13:40:52.78
  STEP: Creating the pod @ 02/07/24 13:40:52.783
  STEP: Deleting secret s-test-opt-del-699e99bf-cb9e-4118-9806-97320224ea5b @ 02/07/24 13:40:54.81
  STEP: Updating secret s-test-opt-upd-d55ae6d0-7cd7-4b67-a829-c853ee76ad7d @ 02/07/24 13:40:54.815
  STEP: Creating secret with name s-test-opt-create-fd37d582-0ff1-4c9b-af03-c3c22268bf82 @ 02/07/24 13:40:54.818
  STEP: waiting to observe update in volume @ 02/07/24 13:40:54.821
  Feb  7 13:40:58.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-732" for this suite. @ 02/07/24 13:40:58.849
• [6.092 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 02/07/24 13:40:58.852
  Feb  7 13:40:58.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename containers @ 02/07/24 13:40:58.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:40:58.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:40:58.864
  STEP: Creating a pod to test override all @ 02/07/24 13:40:58.866
  STEP: Saw pod success @ 02/07/24 13:41:02.88
  Feb  7 13:41:02.882: INFO: Trying to get logs from node worker-1 pod client-containers-f271542f-de72-4c0d-b0b5-74ad3c01e324 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 13:41:02.895
  Feb  7 13:41:02.905: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7849" for this suite. @ 02/07/24 13:41:02.908
• [4.059 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 02/07/24 13:41:02.912
  Feb  7 13:41:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 13:41:02.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:02.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:02.924
  STEP: Creating configMap with name configmap-test-volume-map-6b43aef3-02ff-4964-931e-332adf29c32b @ 02/07/24 13:41:02.926
  STEP: Creating a pod to test consume configMaps @ 02/07/24 13:41:02.929
  STEP: Saw pod success @ 02/07/24 13:41:06.944
  Feb  7 13:41:06.946: INFO: Trying to get logs from node worker-1 pod pod-configmaps-dfe469f7-bb80-468f-b131-eca103f62124 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 13:41:06.951
  Feb  7 13:41:06.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2958" for this suite. @ 02/07/24 13:41:06.964
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 02/07/24 13:41:06.968
  Feb  7 13:41:06.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 13:41:06.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:06.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:06.981
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 13:41:06.983
  STEP: Saw pod success @ 02/07/24 13:41:10.997
  Feb  7 13:41:11.000: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-bdeaab0c-33f2-4cb5-912c-be78845c29ee container client-container: <nil>
  STEP: delete the pod @ 02/07/24 13:41:11.004
  Feb  7 13:41:11.014: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6870" for this suite. @ 02/07/24 13:41:11.017
• [4.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 02/07/24 13:41:11.021
  Feb  7 13:41:11.021: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 13:41:11.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:11.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:11.034
  STEP: creating secret secrets-8035/secret-test-876a39c8-7644-4842-a6ae-b4104bbf7e93 @ 02/07/24 13:41:11.037
  STEP: Creating a pod to test consume secrets @ 02/07/24 13:41:11.04
  STEP: Saw pod success @ 02/07/24 13:41:15.054
  Feb  7 13:41:15.056: INFO: Trying to get logs from node worker-0 pod pod-configmaps-ff075d27-61c1-4166-9678-c63aa0b57bd1 container env-test: <nil>
  STEP: delete the pod @ 02/07/24 13:41:15.063
  Feb  7 13:41:15.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8035" for this suite. @ 02/07/24 13:41:15.075
• [4.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 02/07/24 13:41:15.079
  Feb  7 13:41:15.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pod-network-test @ 02/07/24 13:41:15.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:15.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:15.091
  STEP: Performing setup for networking test in namespace pod-network-test-4138 @ 02/07/24 13:41:15.094
  STEP: creating a selector @ 02/07/24 13:41:15.094
  STEP: Creating the service pods in kubernetes @ 02/07/24 13:41:15.094
  Feb  7 13:41:15.094: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 02/07/24 13:41:27.137
  Feb  7 13:41:29.149: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Feb  7 13:41:29.149: INFO: Breadth first check of 10.244.1.20 on host 10.0.60.182...
  Feb  7 13:41:29.151: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.21:9080/dial?request=hostname&protocol=udp&host=10.244.1.20&port=8081&tries=1'] Namespace:pod-network-test-4138 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 13:41:29.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:41:29.151: INFO: ExecWithOptions: Clientset creation
  Feb  7 13:41:29.151: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4138/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.21%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.20%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb  7 13:41:29.213: INFO: Waiting for responses: map[]
  Feb  7 13:41:29.213: INFO: reached 10.244.1.20 after 0/1 tries
  Feb  7 13:41:29.213: INFO: Breadth first check of 10.244.0.11 on host 10.0.58.191...
  Feb  7 13:41:29.215: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.21:9080/dial?request=hostname&protocol=udp&host=10.244.0.11&port=8081&tries=1'] Namespace:pod-network-test-4138 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 13:41:29.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:41:29.216: INFO: ExecWithOptions: Clientset creation
  Feb  7 13:41:29.216: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4138/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.21%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.11%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb  7 13:41:29.280: INFO: Waiting for responses: map[]
  Feb  7 13:41:29.280: INFO: reached 10.244.0.11 after 0/1 tries
  Feb  7 13:41:29.280: INFO: Going to retry 0 out of 2 pods....
  Feb  7 13:41:29.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4138" for this suite. @ 02/07/24 13:41:29.283
• [14.207 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 02/07/24 13:41:29.287
  Feb  7 13:41:29.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 13:41:29.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:29.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:29.299
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 13:41:29.302
  STEP: Saw pod success @ 02/07/24 13:41:33.317
  Feb  7 13:41:33.319: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-aebf9f59-a32c-45f1-b54e-d611ec310d7e container client-container: <nil>
  STEP: delete the pod @ 02/07/24 13:41:33.324
  Feb  7 13:41:33.334: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5325" for this suite. @ 02/07/24 13:41:33.336
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 02/07/24 13:41:33.34
  Feb  7 13:41:33.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-pred @ 02/07/24 13:41:33.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:33.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:33.356
  Feb  7 13:41:33.358: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb  7 13:41:33.366: INFO: Waiting for terminating namespaces to be deleted...
  Feb  7 13:41:33.368: INFO: 
  Logging pods the apiserver thinks is on node worker-0 before test
  Feb  7 13:41:33.372: INFO: coredns-555d98c87b-f64d9 from kube-system started at 2024-02-07 13:40:05 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: konnectivity-agent-x99jt from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: kube-proxy-l28q5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: kube-router-wfgm8 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: netserver-0 from pod-network-test-4138 started at 2024-02-07 13:41:15 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container webserver ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: test-container-pod from pod-network-test-4138 started at 2024-02-07 13:41:27 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container webserver ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: sonobuoy from sonobuoy started at 2024-02-07 13:37:03 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-2wkv5 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 13:41:33.372: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb  7 13:41:33.372: INFO: 
  Logging pods the apiserver thinks is on node worker-1 before test
  Feb  7 13:41:33.376: INFO: coredns-555d98c87b-f8t6j from kube-system started at 2024-02-07 13:37:51 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: konnectivity-agent-bt2h5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: kube-proxy-qvgjm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: kube-router-mqgnm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: metrics-server-7556957bb7-6kv5t from kube-system started at 2024-02-07 13:36:50 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container metrics-server ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: netserver-1 from pod-network-test-4138 started at 2024-02-07 13:41:15 +0000 UTC (1 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container webserver ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: sonobuoy-e2e-job-fedf139ced3a4f30 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container e2e ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-rq8vf from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 13:41:33.376: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 13:41:33.376: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node worker-0 @ 02/07/24 13:41:33.386
  STEP: verifying the node has the label node worker-1 @ 02/07/24 13:41:33.395
  Feb  7 13:41:33.401: INFO: Pod coredns-555d98c87b-f64d9 requesting resource cpu=100m on Node worker-0
  Feb  7 13:41:33.401: INFO: Pod coredns-555d98c87b-f8t6j requesting resource cpu=100m on Node worker-1
  Feb  7 13:41:33.401: INFO: Pod konnectivity-agent-bt2h5 requesting resource cpu=0m on Node worker-1
  Feb  7 13:41:33.401: INFO: Pod konnectivity-agent-x99jt requesting resource cpu=0m on Node worker-0
  Feb  7 13:41:33.401: INFO: Pod kube-proxy-l28q5 requesting resource cpu=0m on Node worker-0
  Feb  7 13:41:33.402: INFO: Pod kube-proxy-qvgjm requesting resource cpu=0m on Node worker-1
  Feb  7 13:41:33.402: INFO: Pod kube-router-mqgnm requesting resource cpu=250m on Node worker-1
  Feb  7 13:41:33.402: INFO: Pod kube-router-wfgm8 requesting resource cpu=250m on Node worker-0
  Feb  7 13:41:33.402: INFO: Pod metrics-server-7556957bb7-6kv5t requesting resource cpu=10m on Node worker-1
  Feb  7 13:41:33.402: INFO: Pod netserver-0 requesting resource cpu=0m on Node worker-0
  Feb  7 13:41:33.402: INFO: Pod netserver-1 requesting resource cpu=0m on Node worker-1
  Feb  7 13:41:33.402: INFO: Pod test-container-pod requesting resource cpu=0m on Node worker-0
  Feb  7 13:41:33.402: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker-0
  Feb  7 13:41:33.402: INFO: Pod sonobuoy-e2e-job-fedf139ced3a4f30 requesting resource cpu=0m on Node worker-1
  Feb  7 13:41:33.402: INFO: Pod sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-2wkv5 requesting resource cpu=0m on Node worker-0
  Feb  7 13:41:33.402: INFO: Pod sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-rq8vf requesting resource cpu=0m on Node worker-1
  STEP: Starting Pods to consume most of the cluster CPU. @ 02/07/24 13:41:33.403
  Feb  7 13:41:33.403: INFO: Creating a pod which consumes cpu=2555m on Node worker-0
  Feb  7 13:41:33.409: INFO: Creating a pod which consumes cpu=2548m on Node worker-1
  STEP: Creating another pod that requires unavailable amount of CPU. @ 02/07/24 13:41:35.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-72d23c64-36d8-4458-869f-d25b845dc055.17b19865062ce5c2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6821/filler-pod-72d23c64-36d8-4458-869f-d25b845dc055 to worker-0] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-72d23c64-36d8-4458-869f-d25b845dc055.17b198651fe64568], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-72d23c64-36d8-4458-869f-d25b845dc055.17b19865215f5cc0], Reason = [Created], Message = [Created container filler-pod-72d23c64-36d8-4458-869f-d25b845dc055] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-72d23c64-36d8-4458-869f-d25b845dc055.17b1986525fd66c0], Reason = [Started], Message = [Started container filler-pod-72d23c64-36d8-4458-869f-d25b845dc055] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a7e269dc-e537-4659-9b94-979af9464a49.17b19865069f1edc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6821/filler-pod-a7e269dc-e537-4659-9b94-979af9464a49 to worker-1] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a7e269dc-e537-4659-9b94-979af9464a49.17b1986520848c51], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a7e269dc-e537-4659-9b94-979af9464a49.17b1986521dda1f2], Reason = [Created], Message = [Created container filler-pod-a7e269dc-e537-4659-9b94-979af9464a49] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a7e269dc-e537-4659-9b94-979af9464a49.17b19865260f4498], Reason = [Started], Message = [Started container filler-pod-a7e269dc-e537-4659-9b94-979af9464a49] @ 02/07/24 13:41:35.43
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17b198657eb7c6d0], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 02/07/24 13:41:35.438
  STEP: removing the label node off the node worker-0 @ 02/07/24 13:41:36.438
  STEP: verifying the node doesn't have the label node @ 02/07/24 13:41:36.449
  STEP: removing the label node off the node worker-1 @ 02/07/24 13:41:36.452
  STEP: verifying the node doesn't have the label node @ 02/07/24 13:41:36.459
  Feb  7 13:41:36.462: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6821" for this suite. @ 02/07/24 13:41:36.464
• [3.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 02/07/24 13:41:36.468
  Feb  7 13:41:36.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 13:41:36.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:36.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:36.482
  STEP: Creating service test in namespace statefulset-5511 @ 02/07/24 13:41:36.485
  STEP: Looking for a node to schedule stateful set and pod @ 02/07/24 13:41:36.489
  STEP: Creating pod with conflicting port in namespace statefulset-5511 @ 02/07/24 13:41:36.492
  STEP: Waiting until pod test-pod will start running in namespace statefulset-5511 @ 02/07/24 13:41:36.499
  STEP: Creating statefulset with conflicting port in namespace statefulset-5511 @ 02/07/24 13:41:38.505
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5511 @ 02/07/24 13:41:38.51
  Feb  7 13:41:38.524: INFO: Observed stateful pod in namespace: statefulset-5511, name: ss-0, uid: 9d14764b-967c-44c6-a0d0-62ac319caed7, status phase: Pending. Waiting for statefulset controller to delete.
  Feb  7 13:41:38.535: INFO: Observed stateful pod in namespace: statefulset-5511, name: ss-0, uid: 9d14764b-967c-44c6-a0d0-62ac319caed7, status phase: Failed. Waiting for statefulset controller to delete.
  Feb  7 13:41:38.542: INFO: Observed stateful pod in namespace: statefulset-5511, name: ss-0, uid: 9d14764b-967c-44c6-a0d0-62ac319caed7, status phase: Failed. Waiting for statefulset controller to delete.
  Feb  7 13:41:38.545: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5511
  STEP: Removing pod with conflicting port in namespace statefulset-5511 @ 02/07/24 13:41:38.546
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5511 and will be in running state @ 02/07/24 13:41:38.556
  Feb  7 13:41:40.563: INFO: Deleting all statefulset in ns statefulset-5511
  Feb  7 13:41:40.565: INFO: Scaling statefulset ss to 0
  Feb  7 13:41:50.576: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 13:41:50.578: INFO: Deleting statefulset ss
  Feb  7 13:41:50.586: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5511" for this suite. @ 02/07/24 13:41:50.589
• [14.125 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 02/07/24 13:41:50.594
  Feb  7 13:41:50.594: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 13:41:50.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:50.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:50.607
  STEP: Starting the proxy @ 02/07/24 13:41:50.609
  Feb  7 13:41:50.610: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2457 proxy --unix-socket=/tmp/kubectl-proxy-unix2071709071/test'
  STEP: retrieving proxy /api/ output @ 02/07/24 13:41:50.656
  Feb  7 13:41:50.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2457" for this suite. @ 02/07/24 13:41:50.659
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 02/07/24 13:41:50.663
  Feb  7 13:41:50.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename endpointslice @ 02/07/24 13:41:50.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:50.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:50.676
  Feb  7 13:41:52.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4674" for this suite. @ 02/07/24 13:41:52.719
• [2.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 02/07/24 13:41:52.724
  Feb  7 13:41:52.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename endpointslice @ 02/07/24 13:41:52.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:52.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:52.735
  Feb  7 13:41:52.743: INFO: Endpoints addresses: [10.0.41.2] , ports: [6443]
  Feb  7 13:41:52.743: INFO: EndpointSlices addresses: [10.0.41.2] , ports: [6443]
  Feb  7 13:41:52.743: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8163" for this suite. @ 02/07/24 13:41:52.745
• [0.026 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 02/07/24 13:41:52.751
  Feb  7 13:41:52.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 13:41:52.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:52.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:52.763
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 02/07/24 13:41:52.765
  Feb  7 13:41:52.770: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5629  5c5151b7-c268-497c-836b-fe02ddb809af 2384 0 2024-02-07 13:41:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-02-07 13:41:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtbf6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtbf6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 02/07/24 13:41:54.775
  Feb  7 13:41:54.775: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5629 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 13:41:54.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:41:54.775: INFO: ExecWithOptions: Clientset creation
  Feb  7 13:41:54.775: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-5629/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 02/07/24 13:41:54.852
  Feb  7 13:41:54.852: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5629 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 13:41:54.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:41:54.853: INFO: ExecWithOptions: Clientset creation
  Feb  7 13:41:54.853: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-5629/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb  7 13:41:54.923: INFO: Deleting pod test-dns-nameservers...
  Feb  7 13:41:54.932: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5629" for this suite. @ 02/07/24 13:41:54.934
• [2.188 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 02/07/24 13:41:54.939
  Feb  7 13:41:54.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 13:41:54.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:54.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:54.953
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 02/07/24 13:41:54.955
  STEP: Saw pod success @ 02/07/24 13:41:58.969
  Feb  7 13:41:58.971: INFO: Trying to get logs from node worker-0 pod pod-88f58623-6d2e-4c30-8fa0-0e88e8538a38 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 13:41:58.977
  Feb  7 13:41:58.987: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6395" for this suite. @ 02/07/24 13:41:58.99
• [4.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 02/07/24 13:41:58.995
  Feb  7 13:41:58.995: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 13:41:58.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:41:59.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:41:59.011
  STEP: Creating simple DaemonSet "daemon-set" @ 02/07/24 13:41:59.023
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/07/24 13:41:59.03
  Feb  7 13:41:59.035: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 13:41:59.035: INFO: Node worker-0 is running 0 daemon pod, expected 1
  Feb  7 13:42:00.035: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 13:42:00.035: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 02/07/24 13:42:00.037
  STEP: DeleteCollection of the DaemonSets @ 02/07/24 13:42:00.04
  STEP: Verify that ReplicaSets have been deleted @ 02/07/24 13:42:00.044
  Feb  7 13:42:00.054: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2497"},"items":null}

  Feb  7 13:42:00.058: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2497"},"items":[{"metadata":{"name":"daemon-set-4zvq9","generateName":"daemon-set-","namespace":"daemonsets-8097","uid":"6be65166-d157-408a-bb82-e965a5e2e9c5","resourceVersion":"2496","creationTimestamp":"2024-02-07T13:41:59Z","deletionTimestamp":"2024-02-07T13:42:30Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d5b89555-8507-4bf9-b011-f075db724465","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-02-07T13:41:59Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5b89555-8507-4bf9-b011-f075db724465\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-02-07T13:41:59Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xjws9","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xjws9","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"worker-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["worker-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"}],"hostIP":"10.0.60.182","hostIPs":[{"ip":"10.0.60.182"}],"podIP":"10.244.1.26","podIPs":[{"ip":"10.244.1.26"}],"startTime":"2024-02-07T13:41:59Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-02-07T13:41:59Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://cd0db5aac23ee9a6df5218537a836a9f66523b1057b007336d1e51d6e88c0e2c","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-hvndl","generateName":"daemon-set-","namespace":"daemonsets-8097","uid":"43a0532f-7b5b-4bbb-ad95-4ed2e47e3493","resourceVersion":"2497","creationTimestamp":"2024-02-07T13:41:59Z","deletionTimestamp":"2024-02-07T13:42:30Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d5b89555-8507-4bf9-b011-f075db724465","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-02-07T13:41:59Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5b89555-8507-4bf9-b011-f075db724465\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-02-07T13:41:59Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hx4zj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hx4zj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"worker-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["worker-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-02-07T13:41:59Z"}],"hostIP":"10.0.58.191","hostIPs":[{"ip":"10.0.58.191"}],"podIP":"10.244.0.15","podIPs":[{"ip":"10.244.0.15"}],"startTime":"2024-02-07T13:41:59Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-02-07T13:41:59Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://88d7fb9e80cbafd0a1bc2de3086525452efe8cb87c356c853ab3f12380c9a346","started":true}],"qosClass":"BestEffort"}}]}

  Feb  7 13:42:00.066: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8097" for this suite. @ 02/07/24 13:42:00.068
• [1.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 02/07/24 13:42:00.072
  Feb  7 13:42:00.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename subpath @ 02/07/24 13:42:00.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:42:00.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:42:00.084
  STEP: Setting up data @ 02/07/24 13:42:00.086
  STEP: Creating pod pod-subpath-test-configmap-fbsq @ 02/07/24 13:42:00.092
  STEP: Creating a pod to test atomic-volume-subpath @ 02/07/24 13:42:00.092
  STEP: Saw pod success @ 02/07/24 13:42:24.14
  Feb  7 13:42:24.143: INFO: Trying to get logs from node worker-0 pod pod-subpath-test-configmap-fbsq container test-container-subpath-configmap-fbsq: <nil>
  STEP: delete the pod @ 02/07/24 13:42:24.149
  STEP: Deleting pod pod-subpath-test-configmap-fbsq @ 02/07/24 13:42:24.159
  Feb  7 13:42:24.159: INFO: Deleting pod "pod-subpath-test-configmap-fbsq" in namespace "subpath-6084"
  Feb  7 13:42:24.161: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6084" for this suite. @ 02/07/24 13:42:24.164
• [24.095 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 02/07/24 13:42:24.168
  Feb  7 13:42:24.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 13:42:24.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:42:24.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:42:24.184
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 13:42:24.186
  STEP: Saw pod success @ 02/07/24 13:42:28.202
  Feb  7 13:42:28.204: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-85560745-21f2-46bc-bd8f-3f6af9e78f5c container client-container: <nil>
  STEP: delete the pod @ 02/07/24 13:42:28.208
  Feb  7 13:42:28.221: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5559" for this suite. @ 02/07/24 13:42:28.224
• [4.060 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 02/07/24 13:42:28.229
  Feb  7 13:42:28.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 13:42:28.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:42:28.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:42:28.241
  STEP: Creating a test headless service @ 02/07/24 13:42:28.243
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2805 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2805;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2805 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2805;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2805.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2805.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2805.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2805.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2805.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2805.svc;check="$$(dig +notcp +noall +answer +search 70.162.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.162.70_udp@PTR;check="$$(dig +tcp +noall +answer +search 70.162.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.162.70_tcp@PTR;sleep 1; done
   @ 02/07/24 13:42:28.264
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2805 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2805;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2805 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2805;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2805.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2805.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2805.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2805.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2805.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2805.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2805.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2805.svc;check="$$(dig +notcp +noall +answer +search 70.162.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.162.70_udp@PTR;check="$$(dig +tcp +noall +answer +search 70.162.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.162.70_tcp@PTR;sleep 1; done
   @ 02/07/24 13:42:28.264
  STEP: creating a pod to probe DNS @ 02/07/24 13:42:28.264
  STEP: submitting the pod to kubernetes @ 02/07/24 13:42:28.264
  STEP: retrieving the pod @ 02/07/24 13:42:36.287
  STEP: looking for the results for each expected name from probers @ 02/07/24 13:42:36.289
  Feb  7 13:42:36.295: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.298: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.301: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.304: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.307: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.309: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.312: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.315: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.330: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.333: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.336: INFO: Unable to read jessie_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.338: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.341: INFO: Unable to read jessie_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.344: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.347: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.349: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:36.360: INFO: Lookups using dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2805 wheezy_tcp@dns-test-service.dns-2805 wheezy_udp@dns-test-service.dns-2805.svc wheezy_tcp@dns-test-service.dns-2805.svc wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2805 jessie_tcp@dns-test-service.dns-2805 jessie_udp@dns-test-service.dns-2805.svc jessie_tcp@dns-test-service.dns-2805.svc jessie_udp@_http._tcp.dns-test-service.dns-2805.svc jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc]

  Feb  7 13:42:36.364: INFO: Pod client logs for webserver: 
  Feb  7 13:42:36.369: INFO: Pod client logs for querier: 
  Feb  7 13:42:36.373: INFO: Pod client logs for jessie-querier: 
  Feb  7 13:42:41.296: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.299: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.305: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.308: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.311: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.313: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.316: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.330: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.333: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.336: INFO: Unable to read jessie_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.339: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.341: INFO: Unable to read jessie_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.344: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.347: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.350: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:41.361: INFO: Lookups using dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2805 wheezy_tcp@dns-test-service.dns-2805 wheezy_udp@dns-test-service.dns-2805.svc wheezy_tcp@dns-test-service.dns-2805.svc wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2805 jessie_tcp@dns-test-service.dns-2805 jessie_udp@dns-test-service.dns-2805.svc jessie_tcp@dns-test-service.dns-2805.svc jessie_udp@_http._tcp.dns-test-service.dns-2805.svc jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc]

  Feb  7 13:42:41.366: INFO: Pod client logs for webserver: 
  Feb  7 13:42:41.370: INFO: Pod client logs for querier: 
  Feb  7 13:42:41.374: INFO: Pod client logs for jessie-querier: 
  Feb  7 13:42:46.296: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.299: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.305: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.307: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.310: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.313: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.315: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.329: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.332: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.335: INFO: Unable to read jessie_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.340: INFO: Unable to read jessie_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.343: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.346: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.349: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:46.360: INFO: Lookups using dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2805 wheezy_tcp@dns-test-service.dns-2805 wheezy_udp@dns-test-service.dns-2805.svc wheezy_tcp@dns-test-service.dns-2805.svc wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2805 jessie_tcp@dns-test-service.dns-2805 jessie_udp@dns-test-service.dns-2805.svc jessie_tcp@dns-test-service.dns-2805.svc jessie_udp@_http._tcp.dns-test-service.dns-2805.svc jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc]

  Feb  7 13:42:46.364: INFO: Pod client logs for webserver: 
  Feb  7 13:42:46.369: INFO: Pod client logs for querier: 
  Feb  7 13:42:46.373: INFO: Pod client logs for jessie-querier: 
  Feb  7 13:42:51.296: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.299: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.305: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.307: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.310: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.313: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.316: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.329: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.332: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.334: INFO: Unable to read jessie_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.340: INFO: Unable to read jessie_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.343: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.346: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.349: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:51.360: INFO: Lookups using dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2805 wheezy_tcp@dns-test-service.dns-2805 wheezy_udp@dns-test-service.dns-2805.svc wheezy_tcp@dns-test-service.dns-2805.svc wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2805 jessie_tcp@dns-test-service.dns-2805 jessie_udp@dns-test-service.dns-2805.svc jessie_tcp@dns-test-service.dns-2805.svc jessie_udp@_http._tcp.dns-test-service.dns-2805.svc jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc]

  Feb  7 13:42:51.364: INFO: Pod client logs for webserver: 
  Feb  7 13:42:51.369: INFO: Pod client logs for querier: 
  Feb  7 13:42:51.373: INFO: Pod client logs for jessie-querier: 
  Feb  7 13:42:56.297: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.300: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.303: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.306: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.308: INFO: Unable to read wheezy_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.311: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.314: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.317: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.331: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.333: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.336: INFO: Unable to read jessie_udp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.339: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805 from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.342: INFO: Unable to read jessie_udp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.344: INFO: Unable to read jessie_tcp@dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.347: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.350: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc from pod dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634: the server could not find the requested resource (get pods dns-test-29653829-fe08-46fb-b067-50dfab0bd634)
  Feb  7 13:42:56.361: INFO: Lookups using dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2805 wheezy_tcp@dns-test-service.dns-2805 wheezy_udp@dns-test-service.dns-2805.svc wheezy_tcp@dns-test-service.dns-2805.svc wheezy_udp@_http._tcp.dns-test-service.dns-2805.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2805.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2805 jessie_tcp@dns-test-service.dns-2805 jessie_udp@dns-test-service.dns-2805.svc jessie_tcp@dns-test-service.dns-2805.svc jessie_udp@_http._tcp.dns-test-service.dns-2805.svc jessie_tcp@_http._tcp.dns-test-service.dns-2805.svc]

  Feb  7 13:42:56.366: INFO: Pod client logs for webserver: 
  Feb  7 13:42:56.370: INFO: Pod client logs for querier: 
  Feb  7 13:42:56.374: INFO: Pod client logs for jessie-querier: 
  Feb  7 13:43:01.359: INFO: DNS probes using dns-2805/dns-test-29653829-fe08-46fb-b067-50dfab0bd634 succeeded

  STEP: deleting the pod @ 02/07/24 13:43:01.359
  STEP: deleting the test service @ 02/07/24 13:43:01.371
  STEP: deleting the test headless service @ 02/07/24 13:43:01.388
  Feb  7 13:43:01.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2805" for this suite. @ 02/07/24 13:43:01.397
• [33.171 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 02/07/24 13:43:01.401
  Feb  7 13:43:01.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename init-container @ 02/07/24 13:43:01.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:01.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:01.412
  STEP: creating the pod @ 02/07/24 13:43:01.415
  Feb  7 13:43:01.415: INFO: PodSpec: initContainers in spec.initContainers
  Feb  7 13:43:08.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7033" for this suite. @ 02/07/24 13:43:08.868
• [7.470 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 02/07/24 13:43:08.872
  Feb  7 13:43:08.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 13:43:08.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:08.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:08.883
  STEP: Creating a pod to test downward api env vars @ 02/07/24 13:43:08.886
  STEP: Saw pod success @ 02/07/24 13:43:10.896
  Feb  7 13:43:10.899: INFO: Trying to get logs from node worker-0 pod downward-api-50471d2c-0459-465e-a681-5ffd3da8387b container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 13:43:10.905
  Feb  7 13:43:10.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8754" for this suite. @ 02/07/24 13:43:10.917
• [2.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 02/07/24 13:43:10.921
  Feb  7 13:43:10.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 13:43:10.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:10.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:10.933
  STEP: creating a replication controller @ 02/07/24 13:43:10.936
  Feb  7 13:43:10.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 create -f -'
  Feb  7 13:43:11.074: INFO: stderr: ""
  Feb  7 13:43:11.074: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/07/24 13:43:11.074
  Feb  7 13:43:11.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 13:43:11.142: INFO: stderr: ""
  Feb  7 13:43:11.142: INFO: stdout: "update-demo-nautilus-slb6w update-demo-nautilus-vjg7q "
  Feb  7 13:43:11.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods update-demo-nautilus-slb6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 13:43:11.203: INFO: stderr: ""
  Feb  7 13:43:11.203: INFO: stdout: ""
  Feb  7 13:43:11.203: INFO: update-demo-nautilus-slb6w is created but not running
  Feb  7 13:43:16.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 13:43:16.263: INFO: stderr: ""
  Feb  7 13:43:16.263: INFO: stdout: "update-demo-nautilus-slb6w update-demo-nautilus-vjg7q "
  Feb  7 13:43:16.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods update-demo-nautilus-slb6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 13:43:16.321: INFO: stderr: ""
  Feb  7 13:43:16.321: INFO: stdout: "true"
  Feb  7 13:43:16.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods update-demo-nautilus-slb6w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 13:43:16.380: INFO: stderr: ""
  Feb  7 13:43:16.380: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 13:43:16.380: INFO: validating pod update-demo-nautilus-slb6w
  Feb  7 13:43:16.385: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 13:43:16.385: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 13:43:16.385: INFO: update-demo-nautilus-slb6w is verified up and running
  Feb  7 13:43:16.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods update-demo-nautilus-vjg7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 13:43:16.442: INFO: stderr: ""
  Feb  7 13:43:16.442: INFO: stdout: "true"
  Feb  7 13:43:16.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods update-demo-nautilus-vjg7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 13:43:16.498: INFO: stderr: ""
  Feb  7 13:43:16.498: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 13:43:16.498: INFO: validating pod update-demo-nautilus-vjg7q
  Feb  7 13:43:16.503: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 13:43:16.503: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 13:43:16.503: INFO: update-demo-nautilus-vjg7q is verified up and running
  STEP: using delete to clean up resources @ 02/07/24 13:43:16.503
  Feb  7 13:43:16.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 delete --grace-period=0 --force -f -'
  Feb  7 13:43:16.561: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:16.561: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Feb  7 13:43:16.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get rc,svc -l name=update-demo --no-headers'
  Feb  7 13:43:16.623: INFO: stderr: "No resources found in kubectl-1125 namespace.\n"
  Feb  7 13:43:16.623: INFO: stdout: ""
  Feb  7 13:43:16.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-1125 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Feb  7 13:43:16.681: INFO: stderr: ""
  Feb  7 13:43:16.681: INFO: stdout: ""
  Feb  7 13:43:16.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1125" for this suite. @ 02/07/24 13:43:16.684
• [5.766 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 02/07/24 13:43:16.688
  Feb  7 13:43:16.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename tables @ 02/07/24 13:43:16.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:16.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:16.701
  Feb  7 13:43:16.706: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-7128" for this suite. @ 02/07/24 13:43:16.708
• [0.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 02/07/24 13:43:16.712
  Feb  7 13:43:16.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 13:43:16.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:16.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:16.724
  STEP: creating all guestbook components @ 02/07/24 13:43:16.726
  Feb  7 13:43:16.726: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Feb  7 13:43:16.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 create -f -'
  Feb  7 13:43:16.867: INFO: stderr: ""
  Feb  7 13:43:16.867: INFO: stdout: "service/agnhost-replica created\n"
  Feb  7 13:43:16.867: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Feb  7 13:43:16.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 create -f -'
  Feb  7 13:43:17.032: INFO: stderr: ""
  Feb  7 13:43:17.032: INFO: stdout: "service/agnhost-primary created\n"
  Feb  7 13:43:17.032: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Feb  7 13:43:17.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 create -f -'
  Feb  7 13:43:17.183: INFO: stderr: ""
  Feb  7 13:43:17.183: INFO: stdout: "service/frontend created\n"
  Feb  7 13:43:17.183: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Feb  7 13:43:17.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 create -f -'
  Feb  7 13:43:17.299: INFO: stderr: ""
  Feb  7 13:43:17.299: INFO: stdout: "deployment.apps/frontend created\n"
  Feb  7 13:43:17.299: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Feb  7 13:43:17.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 create -f -'
  Feb  7 13:43:17.393: INFO: stderr: ""
  Feb  7 13:43:17.393: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Feb  7 13:43:17.393: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Feb  7 13:43:17.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 create -f -'
  Feb  7 13:43:17.491: INFO: stderr: ""
  Feb  7 13:43:17.491: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 02/07/24 13:43:17.491
  Feb  7 13:43:17.491: INFO: Waiting for all frontend pods to be Running.
  Feb  7 13:43:22.542: INFO: Waiting for frontend to serve content.
  Feb  7 13:43:22.552: INFO: Trying to add a new entry to the guestbook.
  Feb  7 13:43:22.560: INFO: Verifying that added entry can be retrieved.
  Feb  7 13:43:22.565: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
  STEP: using delete to clean up resources @ 02/07/24 13:43:27.574
  Feb  7 13:43:27.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 delete --grace-period=0 --force -f -'
  Feb  7 13:43:27.642: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:27.642: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 02/07/24 13:43:27.642
  Feb  7 13:43:27.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 delete --grace-period=0 --force -f -'
  Feb  7 13:43:27.710: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:27.710: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 02/07/24 13:43:27.711
  Feb  7 13:43:27.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 delete --grace-period=0 --force -f -'
  Feb  7 13:43:27.780: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:27.780: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 02/07/24 13:43:27.78
  Feb  7 13:43:27.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 delete --grace-period=0 --force -f -'
  Feb  7 13:43:27.839: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:27.839: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 02/07/24 13:43:27.839
  Feb  7 13:43:27.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 delete --grace-period=0 --force -f -'
  Feb  7 13:43:27.910: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:27.910: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 02/07/24 13:43:27.91
  Feb  7 13:43:27.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7085 delete --grace-period=0 --force -f -'
  Feb  7 13:43:27.995: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 13:43:27.995: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Feb  7 13:43:27.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7085" for this suite. @ 02/07/24 13:43:27.998
• [11.293 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 02/07/24 13:43:28.006
  Feb  7 13:43:28.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 13:43:28.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:28.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:28.018
  STEP: creating a Deployment @ 02/07/24 13:43:28.023
  Feb  7 13:43:28.024: INFO: Creating simple deployment test-deployment-t8q69
  Feb  7 13:43:28.037: INFO: deployment "test-deployment-t8q69" doesn't have the required revision set
  STEP: Getting /status @ 02/07/24 13:43:30.045
  Feb  7 13:43:30.048: INFO: Deployment test-deployment-t8q69 has Conditions: [{Available True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-t8q69-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 02/07/24 13:43:30.048
  Feb  7 13:43:30.053: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 13, 43, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 13, 43, 28, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 13, 43, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 13, 43, 28, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-t8q69-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 02/07/24 13:43:30.053
  Feb  7 13:43:30.055: INFO: Observed &Deployment event: ADDED
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-t8q69-5d576bd769"}
  Feb  7 13:43:30.055: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-t8q69-5d576bd769"}
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb  7 13:43:30.055: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-t8q69-5d576bd769" is progressing.}
  Feb  7 13:43:30.055: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb  7 13:43:30.055: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-t8q69-5d576bd769" has successfully progressed.}
  Feb  7 13:43:30.056: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.056: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb  7 13:43:30.056: INFO: Observed Deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-t8q69-5d576bd769" has successfully progressed.}
  Feb  7 13:43:30.056: INFO: Found Deployment test-deployment-t8q69 in namespace deployment-5969 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 13:43:30.056: INFO: Deployment test-deployment-t8q69 has an updated status
  STEP: patching the Statefulset Status @ 02/07/24 13:43:30.056
  Feb  7 13:43:30.056: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Feb  7 13:43:30.063: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 02/07/24 13:43:30.063
  Feb  7 13:43:30.065: INFO: Observed &Deployment event: ADDED
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-t8q69-5d576bd769"}
  Feb  7 13:43:30.065: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-t8q69-5d576bd769"}
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb  7 13:43:30.065: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-t8q69-5d576bd769" is progressing.}
  Feb  7 13:43:30.065: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb  7 13:43:30.065: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-t8q69-5d576bd769" has successfully progressed.}
  Feb  7 13:43:30.065: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.066: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Feb  7 13:43:30.066: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-02-07 13:43:28 +0000 UTC 2024-02-07 13:43:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-t8q69-5d576bd769" has successfully progressed.}
  Feb  7 13:43:30.066: INFO: Observed deployment test-deployment-t8q69 in namespace deployment-5969 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 13:43:30.066: INFO: Observed &Deployment event: MODIFIED
  Feb  7 13:43:30.066: INFO: Found deployment test-deployment-t8q69 in namespace deployment-5969 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Feb  7 13:43:30.066: INFO: Deployment test-deployment-t8q69 has a patched status
  Feb  7 13:43:30.068: INFO: Deployment "test-deployment-t8q69":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-t8q69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "64b5dd81-3b91-45ed-8101-140eb46a0a61",
      ResourceVersion: (string) (len=4) "3151",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842910208,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-t8q69-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 13:43:30.072: INFO: New ReplicaSet "test-deployment-t8q69-5d576bd769" of Deployment "test-deployment-t8q69":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-t8q69-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0a5d5cc0-ff98-4b3e-89ff-bf849f2191df",
      ResourceVersion: (string) (len=4) "3136",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842910208,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-t8q69",
          UID: (types.UID) (len=36) "64b5dd81-3b91-45ed-8101-140eb46a0a61",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 36 34 62  |k:{\"uid\":\"64b|
              00000120  35 64 64 38 31 2d 33 62  39 31 2d 34 35 65 64 2d  |5dd81-3b91-45ed-|
              00000130  38 31 30 31 2d 31 34 30  65 62 34 36 61 30 61 36  |8101-140eb46a0a6|
              00000140  31 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |1\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 13:43:30.077: INFO: Pod "test-deployment-t8q69-5d576bd769-vg2bf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-t8q69-5d576bd769-vg2bf",
      GenerateName: (string) (len=33) "test-deployment-t8q69-5d576bd769-",
      Namespace: (string) (len=15) "deployment-5969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eb159992-f45c-4920-b866-191a80199338",
      ResourceVersion: (string) (len=4) "3135",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842910208,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-t8q69-5d576bd769",
          UID: (types.UID) (len=36) "0a5d5cc0-ff98-4b3e-89ff-bf849f2191df",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 30 61 35 64 35 63 63  30 2d 66 66 39 38 2d 34  |"0a5d5cc0-ff98-4|
              000000a0  62 33 65 2d 38 39 66 66  2d 62 66 38 34 39 66 32  |b3e-89ff-bf849f2|
              000000b0  31 39 31 64 66 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |191df\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 33  36 5c 22 7d 22 3a 7b 22  |.244.1.36\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dlsms",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dlsms",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842910208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=11) "10.244.1.36",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.36"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842910208,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842910208,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://02fd1442abf2a040e2eadc548df38a0311be8e5a6cea13702713638dbd250f4d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 13:43:30.080: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5969" for this suite. @ 02/07/24 13:43:30.082
• [2.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 02/07/24 13:43:30.086
  Feb  7 13:43:30.086: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-preemption @ 02/07/24 13:43:30.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:43:30.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:43:30.098
  Feb  7 13:43:30.109: INFO: Waiting up to 1m0s for all nodes to be ready
  Feb  7 13:44:30.112: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 02/07/24 13:44:30.114
  Feb  7 13:44:30.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-preemption-path @ 02/07/24 13:44:30.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:44:30.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:44:30.127
  Feb  7 13:44:30.139: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Feb  7 13:44:30.142: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Feb  7 13:44:30.181: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-3525" for this suite. @ 02/07/24 13:44:30.184
  Feb  7 13:44:30.187: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7340" for this suite. @ 02/07/24 13:44:30.189
• [60.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 02/07/24 13:44:30.194
  Feb  7 13:44:30.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl-logs @ 02/07/24 13:44:30.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:44:30.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:44:30.206
  STEP: creating an pod @ 02/07/24 13:44:30.208
  Feb  7 13:44:30.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Feb  7 13:44:30.276: INFO: stderr: ""
  Feb  7 13:44:30.276: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 02/07/24 13:44:30.276
  Feb  7 13:44:30.277: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  Feb  7 13:44:32.281: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 02/07/24 13:44:32.282
  Feb  7 13:44:32.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 logs logs-generator logs-generator'
  Feb  7 13:44:32.347: INFO: stderr: ""
  Feb  7 13:44:32.347: INFO: stdout: "I0207 13:44:30.801766       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/sdwv 363\nI0207 13:44:31.002161       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/xgqs 265\nI0207 13:44:31.202472       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/qqc7 563\nI0207 13:44:31.402792       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/d76m 369\nI0207 13:44:31.602112       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/2dj 454\nI0207 13:44:31.802423       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/8p8 416\nI0207 13:44:32.002762       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/dp6b 583\nI0207 13:44:32.202075       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/n52 538\n"
  STEP: limiting log lines @ 02/07/24 13:44:32.347
  Feb  7 13:44:32.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 logs logs-generator logs-generator --tail=1'
  Feb  7 13:44:32.412: INFO: stderr: ""
  Feb  7 13:44:32.412: INFO: stdout: "I0207 13:44:32.402398       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/hkkv 366\n"
  Feb  7 13:44:32.412: INFO: got output "I0207 13:44:32.402398       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/hkkv 366\n"
  STEP: limiting log bytes @ 02/07/24 13:44:32.412
  Feb  7 13:44:32.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 logs logs-generator logs-generator --limit-bytes=1'
  Feb  7 13:44:32.474: INFO: stderr: ""
  Feb  7 13:44:32.474: INFO: stdout: "I"
  Feb  7 13:44:32.474: INFO: got output "I"
  STEP: exposing timestamps @ 02/07/24 13:44:32.474
  Feb  7 13:44:32.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 logs logs-generator logs-generator --tail=1 --timestamps'
  Feb  7 13:44:32.535: INFO: stderr: ""
  Feb  7 13:44:32.535: INFO: stdout: "2024-02-07T13:44:32.402500751Z I0207 13:44:32.402398       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/hkkv 366\n"
  Feb  7 13:44:32.535: INFO: got output "2024-02-07T13:44:32.402500751Z I0207 13:44:32.402398       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/hkkv 366\n"
  STEP: restricting to a time range @ 02/07/24 13:44:32.535
  Feb  7 13:44:35.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 logs logs-generator logs-generator --since=1s'
  Feb  7 13:44:35.101: INFO: stderr: ""
  Feb  7 13:44:35.101: INFO: stdout: "I0207 13:44:34.202131       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/qpdp 386\nI0207 13:44:34.402425       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/wcft 538\nI0207 13:44:34.602776       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/vr4 347\nI0207 13:44:34.802098       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/qgs 492\nI0207 13:44:35.002435       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/chwj 582\n"
  Feb  7 13:44:35.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 logs logs-generator logs-generator --since=24h'
  Feb  7 13:44:35.165: INFO: stderr: ""
  Feb  7 13:44:35.165: INFO: stdout: "I0207 13:44:30.801766       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/sdwv 363\nI0207 13:44:31.002161       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/xgqs 265\nI0207 13:44:31.202472       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/qqc7 563\nI0207 13:44:31.402792       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/d76m 369\nI0207 13:44:31.602112       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/2dj 454\nI0207 13:44:31.802423       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/8p8 416\nI0207 13:44:32.002762       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/dp6b 583\nI0207 13:44:32.202075       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/n52 538\nI0207 13:44:32.402398       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/hkkv 366\nI0207 13:44:32.602716       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/4r6v 248\nI0207 13:44:32.801973       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/qv6 303\nI0207 13:44:33.002290       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/5tx 328\nI0207 13:44:33.202617       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/8fc 410\nI0207 13:44:33.401887       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/5tns 506\nI0207 13:44:33.602208       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/wpx 428\nI0207 13:44:33.802541       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/57r 490\nI0207 13:44:34.001812       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/568 502\nI0207 13:44:34.202131       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/qpdp 386\nI0207 13:44:34.402425       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/wcft 538\nI0207 13:44:34.602776       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/vr4 347\nI0207 13:44:34.802098       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/qgs 492\nI0207 13:44:35.002435       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/chwj 582\n"
  Feb  7 13:44:35.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-logs-3318 delete pod logs-generator'
  Feb  7 13:44:35.947: INFO: stderr: ""
  Feb  7 13:44:35.947: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Feb  7 13:44:35.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-3318" for this suite. @ 02/07/24 13:44:35.95
• [5.760 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 02/07/24 13:44:35.954
  Feb  7 13:44:35.954: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename disruption @ 02/07/24 13:44:35.955
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:44:35.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:44:35.966
  STEP: creating the pdb @ 02/07/24 13:44:35.968
  STEP: Waiting for the pdb to be processed @ 02/07/24 13:44:35.971
  STEP: updating the pdb @ 02/07/24 13:44:37.973
  STEP: Waiting for the pdb to be processed @ 02/07/24 13:44:37.979
  STEP: patching the pdb @ 02/07/24 13:44:39.983
  STEP: Waiting for the pdb to be processed @ 02/07/24 13:44:39.988
  STEP: Waiting for the pdb to be deleted @ 02/07/24 13:44:41.995
  Feb  7 13:44:41.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7541" for this suite. @ 02/07/24 13:44:41.999
• [6.048 seconds]
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 02/07/24 13:44:42.003
  Feb  7 13:44:42.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 13:44:42.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:44:42.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:44:42.016
  STEP: Creating configMap with name cm-test-opt-del-fb27c751-02a3-41a5-8686-a8e1ce6a4de4 @ 02/07/24 13:44:42.021
  STEP: Creating configMap with name cm-test-opt-upd-34b8d2ff-b070-4178-935c-f4be57faedc0 @ 02/07/24 13:44:42.024
  STEP: Creating the pod @ 02/07/24 13:44:42.027
  STEP: Deleting configmap cm-test-opt-del-fb27c751-02a3-41a5-8686-a8e1ce6a4de4 @ 02/07/24 13:44:44.055
  STEP: Updating configmap cm-test-opt-upd-34b8d2ff-b070-4178-935c-f4be57faedc0 @ 02/07/24 13:44:44.058
  STEP: Creating configMap with name cm-test-opt-create-e1eed476-7c6a-43cc-a8c2-affb68b44eca @ 02/07/24 13:44:44.062
  STEP: waiting to observe update in volume @ 02/07/24 13:44:44.065
  Feb  7 13:46:04.368: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4098" for this suite. @ 02/07/24 13:46:04.371
• [82.372 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 02/07/24 13:46:04.375
  Feb  7 13:46:04.375: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 13:46:04.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:04.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:04.388
  Feb  7 13:46:04.414: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5054" for this suite. @ 02/07/24 13:46:04.416
• [0.047 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 02/07/24 13:46:04.423
  Feb  7 13:46:04.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename runtimeclass @ 02/07/24 13:46:04.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:04.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:04.434
  STEP: Deleting RuntimeClass runtimeclass-8986-delete-me @ 02/07/24 13:46:04.44
  STEP: Waiting for the RuntimeClass to disappear @ 02/07/24 13:46:04.443
  Feb  7 13:46:04.449: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8986" for this suite. @ 02/07/24 13:46:04.451
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 02/07/24 13:46:04.456
  Feb  7 13:46:04.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename runtimeclass @ 02/07/24 13:46:04.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:04.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:04.468
  Feb  7 13:46:06.490: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-633" for this suite. @ 02/07/24 13:46:06.493
• [2.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 02/07/24 13:46:06.497
  Feb  7 13:46:06.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/07/24 13:46:06.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:06.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:06.509
  Feb  7 13:46:06.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:46:07.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2532" for this suite. @ 02/07/24 13:46:07.041
• [0.547 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 02/07/24 13:46:07.045
  Feb  7 13:46:07.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 13:46:07.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:07.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:07.06
  STEP: Creating a pod to test substitution in container's command @ 02/07/24 13:46:07.063
  STEP: Saw pod success @ 02/07/24 13:46:11.076
  Feb  7 13:46:11.078: INFO: Trying to get logs from node worker-1 pod var-expansion-917b5cc0-d660-473f-9b42-290da9d393c5 container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 13:46:11.095
  Feb  7 13:46:11.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1698" for this suite. @ 02/07/24 13:46:11.106
• [4.064 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 02/07/24 13:46:11.11
  Feb  7 13:46:11.110: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 13:46:11.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:11.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:11.121
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 02/07/24 13:46:11.123
  STEP: Saw pod success @ 02/07/24 13:46:15.141
  Feb  7 13:46:15.143: INFO: Trying to get logs from node worker-0 pod pod-c522921e-7f0e-4ea9-9277-c16fcac1d046 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 13:46:15.147
  Feb  7 13:46:15.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2823" for this suite. @ 02/07/24 13:46:15.159
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 02/07/24 13:46:15.164
  Feb  7 13:46:15.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename containers @ 02/07/24 13:46:15.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:15.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:15.177
  Feb  7 13:46:17.195: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1195" for this suite. @ 02/07/24 13:46:17.198
• [2.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 02/07/24 13:46:17.202
  Feb  7 13:46:17.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replication-controller @ 02/07/24 13:46:17.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:17.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:17.215
  Feb  7 13:46:17.217: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 02/07/24 13:46:18.225
  STEP: Checking rc "condition-test" has the desired failure condition set @ 02/07/24 13:46:18.231
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 02/07/24 13:46:19.235
  Feb  7 13:46:19.241: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 02/07/24 13:46:19.241
  Feb  7 13:46:20.247: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4530" for this suite. @ 02/07/24 13:46:20.249
• [3.056 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 02/07/24 13:46:20.259
  Feb  7 13:46:20.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename cronjob @ 02/07/24 13:46:20.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:46:20.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:46:20.271
  STEP: Creating a ReplaceConcurrent cronjob @ 02/07/24 13:46:20.274
  STEP: Ensuring a job is scheduled @ 02/07/24 13:46:20.28
  STEP: Ensuring exactly one is scheduled @ 02/07/24 13:47:00.283
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 02/07/24 13:47:00.284
  STEP: Ensuring the job is replaced with a new one @ 02/07/24 13:47:00.286
  STEP: Removing cronjob @ 02/07/24 13:48:00.291
  Feb  7 13:48:00.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8591" for this suite. @ 02/07/24 13:48:00.296
• [100.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 02/07/24 13:48:00.302
  Feb  7 13:48:00.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename cronjob @ 02/07/24 13:48:00.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:48:00.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:48:00.322
  STEP: Creating a ForbidConcurrent cronjob @ 02/07/24 13:48:00.325
  STEP: Ensuring a job is scheduled @ 02/07/24 13:48:00.328
  STEP: Ensuring exactly one is scheduled @ 02/07/24 13:49:00.331
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 02/07/24 13:49:00.333
  STEP: Ensuring no more jobs are scheduled @ 02/07/24 13:49:00.335
  STEP: Removing cronjob @ 02/07/24 13:54:00.34
  Feb  7 13:54:00.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1183" for this suite. @ 02/07/24 13:54:00.348
• [360.051 seconds]
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 02/07/24 13:54:00.353
  Feb  7 13:54:00.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubelet-test @ 02/07/24 13:54:00.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:00.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:00.37
  Feb  7 13:54:02.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5046" for this suite. @ 02/07/24 13:54:02.404
• [2.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 02/07/24 13:54:02.408
  Feb  7 13:54:02.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename csiinlinevolumes @ 02/07/24 13:54:02.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:02.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:02.42
  STEP: creating @ 02/07/24 13:54:02.422
  STEP: getting @ 02/07/24 13:54:02.437
  STEP: listing in namespace @ 02/07/24 13:54:02.439
  STEP: patching @ 02/07/24 13:54:02.441
  STEP: deleting @ 02/07/24 13:54:02.446
  Feb  7 13:54:02.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5340" for this suite. @ 02/07/24 13:54:02.456
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 02/07/24 13:54:02.461
  Feb  7 13:54:02.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replication-controller @ 02/07/24 13:54:02.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:02.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:02.472
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 02/07/24 13:54:02.474
  STEP: When a replication controller with a matching selector is created @ 02/07/24 13:54:04.486
  STEP: Then the orphan pod is adopted @ 02/07/24 13:54:04.49
  Feb  7 13:54:05.494: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8913" for this suite. @ 02/07/24 13:54:05.496
• [3.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 02/07/24 13:54:05.5
  Feb  7 13:54:05.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/07/24 13:54:05.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:05.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:05.513
  Feb  7 13:54:05.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 13:54:06.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4905" for this suite. @ 02/07/24 13:54:06.534
• [1.040 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 02/07/24 13:54:06.541
  Feb  7 13:54:06.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 13:54:06.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:06.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:06.555
  Feb  7 13:54:06.558: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  W0207 13:54:09.094087      23 warnings.go:70] unknown field "alpha"
  W0207 13:54:09.094110      23 warnings.go:70] unknown field "beta"
  W0207 13:54:09.094116      23 warnings.go:70] unknown field "delta"
  W0207 13:54:09.094122      23 warnings.go:70] unknown field "epsilon"
  W0207 13:54:09.094128      23 warnings.go:70] unknown field "gamma"
  Feb  7 13:54:09.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2375" for this suite. @ 02/07/24 13:54:09.621
• [3.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 02/07/24 13:54:09.626
  Feb  7 13:54:09.626: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 13:54:09.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:09.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:09.637
  STEP: apply creating a deployment @ 02/07/24 13:54:09.64
  Feb  7 13:54:09.648: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6185" for this suite. @ 02/07/24 13:54:09.651
• [0.030 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 02/07/24 13:54:09.656
  Feb  7 13:54:09.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename podtemplate @ 02/07/24 13:54:09.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:09.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:09.666
  Feb  7 13:54:09.688: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9525" for this suite. @ 02/07/24 13:54:09.69
• [0.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 02/07/24 13:54:09.694
  Feb  7 13:54:09.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 13:54:09.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:09.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:09.705
  Feb  7 13:54:09.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5630" for this suite. @ 02/07/24 13:54:09.712
• [0.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 02/07/24 13:54:09.716
  Feb  7 13:54:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 13:54:09.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:09.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:09.731
  STEP: Creating the pod @ 02/07/24 13:54:09.733
  Feb  7 13:54:12.261: INFO: Successfully updated pod "labelsupdate2df80306-1ac1-453b-b341-f6427bcea5a0"
  Feb  7 13:54:14.274: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-222" for this suite. @ 02/07/24 13:54:14.276
• [4.565 seconds]
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 02/07/24 13:54:14.281
  Feb  7 13:54:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svc-latency @ 02/07/24 13:54:14.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:14.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:14.293
  Feb  7 13:54:14.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-4121 @ 02/07/24 13:54:14.296
  I0207 13:54:14.302072      23 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4121, replica count: 1
  I0207 13:54:15.353362      23 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 13:54:15.463: INFO: Created: latency-svc-9glxv
  Feb  7 13:54:15.467: INFO: Got endpoints: latency-svc-9glxv [13.261516ms]
  Feb  7 13:54:15.479: INFO: Created: latency-svc-xp5xn
  Feb  7 13:54:15.490: INFO: Got endpoints: latency-svc-xp5xn [22.655608ms]
  Feb  7 13:54:15.496: INFO: Created: latency-svc-hvzfr
  Feb  7 13:54:15.503: INFO: Got endpoints: latency-svc-hvzfr [35.512206ms]
  Feb  7 13:54:15.504: INFO: Created: latency-svc-9gghz
  Feb  7 13:54:15.510: INFO: Got endpoints: latency-svc-9gghz [42.238316ms]
  Feb  7 13:54:15.513: INFO: Created: latency-svc-2tj54
  Feb  7 13:54:15.516: INFO: Got endpoints: latency-svc-2tj54 [47.944919ms]
  Feb  7 13:54:15.518: INFO: Created: latency-svc-797zz
  Feb  7 13:54:15.522: INFO: Got endpoints: latency-svc-797zz [53.555837ms]
  Feb  7 13:54:15.531: INFO: Created: latency-svc-zb8lt
  Feb  7 13:54:15.537: INFO: Got endpoints: latency-svc-zb8lt [68.079959ms]
  Feb  7 13:54:15.540: INFO: Created: latency-svc-ww8b7
  Feb  7 13:54:15.544: INFO: Got endpoints: latency-svc-ww8b7 [75.741019ms]
  Feb  7 13:54:15.547: INFO: Created: latency-svc-p74mq
  Feb  7 13:54:15.552: INFO: Got endpoints: latency-svc-p74mq [83.938693ms]
  Feb  7 13:54:15.554: INFO: Created: latency-svc-6mxzt
  Feb  7 13:54:15.566: INFO: Got endpoints: latency-svc-6mxzt [96.650851ms]
  Feb  7 13:54:15.567: INFO: Created: latency-svc-gs7r2
  Feb  7 13:54:15.576: INFO: Got endpoints: latency-svc-gs7r2 [106.928023ms]
  Feb  7 13:54:15.578: INFO: Created: latency-svc-ddnwz
  Feb  7 13:54:15.584: INFO: Got endpoints: latency-svc-ddnwz [114.732683ms]
  Feb  7 13:54:15.593: INFO: Created: latency-svc-twpz7
  Feb  7 13:54:15.600: INFO: Got endpoints: latency-svc-twpz7 [130.328699ms]
  Feb  7 13:54:15.610: INFO: Created: latency-svc-np2dm
  Feb  7 13:54:15.612: INFO: Got endpoints: latency-svc-np2dm [142.788409ms]
  Feb  7 13:54:15.620: INFO: Created: latency-svc-vw89k
  Feb  7 13:54:15.636: INFO: Got endpoints: latency-svc-vw89k [166.543366ms]
  Feb  7 13:54:15.639: INFO: Created: latency-svc-57x7t
  Feb  7 13:54:15.646: INFO: Got endpoints: latency-svc-57x7t [176.263532ms]
  Feb  7 13:54:15.649: INFO: Created: latency-svc-9wrxs
  Feb  7 13:54:15.655: INFO: Got endpoints: latency-svc-9wrxs [165.023578ms]
  Feb  7 13:54:15.659: INFO: Created: latency-svc-lb9v9
  Feb  7 13:54:15.665: INFO: Got endpoints: latency-svc-lb9v9 [161.608112ms]
  Feb  7 13:54:15.667: INFO: Created: latency-svc-h4wp2
  Feb  7 13:54:15.672: INFO: Got endpoints: latency-svc-h4wp2 [162.33114ms]
  Feb  7 13:54:15.683: INFO: Created: latency-svc-42hd6
  Feb  7 13:54:15.687: INFO: Got endpoints: latency-svc-42hd6 [170.386608ms]
  Feb  7 13:54:15.690: INFO: Created: latency-svc-95c9f
  Feb  7 13:54:15.693: INFO: Got endpoints: latency-svc-95c9f [171.186504ms]
  Feb  7 13:54:15.696: INFO: Created: latency-svc-h58f4
  Feb  7 13:54:15.699: INFO: Got endpoints: latency-svc-h58f4 [162.510295ms]
  Feb  7 13:54:15.703: INFO: Created: latency-svc-zpdgx
  Feb  7 13:54:15.706: INFO: Got endpoints: latency-svc-zpdgx [161.430824ms]
  Feb  7 13:54:15.718: INFO: Created: latency-svc-7rzxj
  Feb  7 13:54:15.720: INFO: Got endpoints: latency-svc-7rzxj [168.237127ms]
  Feb  7 13:54:15.721: INFO: Created: latency-svc-j99wr
  Feb  7 13:54:15.730: INFO: Got endpoints: latency-svc-j99wr [164.393076ms]
  Feb  7 13:54:15.732: INFO: Created: latency-svc-85mpd
  Feb  7 13:54:15.738: INFO: Got endpoints: latency-svc-85mpd [162.136199ms]
  Feb  7 13:54:15.742: INFO: Created: latency-svc-x6q6w
  Feb  7 13:54:15.754: INFO: Got endpoints: latency-svc-x6q6w [170.292935ms]
  Feb  7 13:54:15.755: INFO: Created: latency-svc-zvgtz
  Feb  7 13:54:15.762: INFO: Got endpoints: latency-svc-zvgtz [162.148484ms]
  Feb  7 13:54:15.762: INFO: Created: latency-svc-87kcl
  Feb  7 13:54:15.768: INFO: Got endpoints: latency-svc-87kcl [156.247913ms]
  Feb  7 13:54:15.774: INFO: Created: latency-svc-l5k8w
  Feb  7 13:54:15.780: INFO: Got endpoints: latency-svc-l5k8w [144.382602ms]
  Feb  7 13:54:15.782: INFO: Created: latency-svc-swgj9
  Feb  7 13:54:15.785: INFO: Got endpoints: latency-svc-swgj9 [139.430732ms]
  Feb  7 13:54:15.796: INFO: Created: latency-svc-xzdw5
  Feb  7 13:54:15.799: INFO: Got endpoints: latency-svc-xzdw5 [143.326761ms]
  Feb  7 13:54:15.805: INFO: Created: latency-svc-tnplz
  Feb  7 13:54:15.812: INFO: Got endpoints: latency-svc-tnplz [146.751613ms]
  Feb  7 13:54:15.815: INFO: Created: latency-svc-crpw5
  Feb  7 13:54:15.819: INFO: Got endpoints: latency-svc-crpw5 [146.983187ms]
  Feb  7 13:54:15.825: INFO: Created: latency-svc-vk7qk
  Feb  7 13:54:15.835: INFO: Got endpoints: latency-svc-vk7qk [147.760419ms]
  Feb  7 13:54:15.837: INFO: Created: latency-svc-w2ftq
  Feb  7 13:54:15.840: INFO: Got endpoints: latency-svc-w2ftq [146.893013ms]
  Feb  7 13:54:15.846: INFO: Created: latency-svc-dmndz
  Feb  7 13:54:15.849: INFO: Got endpoints: latency-svc-dmndz [149.362233ms]
  Feb  7 13:54:15.854: INFO: Created: latency-svc-gg2g5
  Feb  7 13:54:15.862: INFO: Created: latency-svc-z92dr
  Feb  7 13:54:15.871: INFO: Got endpoints: latency-svc-gg2g5 [165.47864ms]
  Feb  7 13:54:15.878: INFO: Created: latency-svc-mvgtk
  Feb  7 13:54:15.887: INFO: Created: latency-svc-5qbg5
  Feb  7 13:54:15.894: INFO: Created: latency-svc-pftgx
  Feb  7 13:54:15.902: INFO: Created: latency-svc-5hkpg
  Feb  7 13:54:15.913: INFO: Created: latency-svc-n8vdk
  Feb  7 13:54:15.916: INFO: Got endpoints: latency-svc-z92dr [195.798617ms]
  Feb  7 13:54:15.925: INFO: Created: latency-svc-lrllf
  Feb  7 13:54:15.930: INFO: Created: latency-svc-5zpkv
  Feb  7 13:54:15.937: INFO: Created: latency-svc-n9jhx
  Feb  7 13:54:15.947: INFO: Created: latency-svc-b9gnl
  Feb  7 13:54:15.953: INFO: Created: latency-svc-g64tt
  Feb  7 13:54:15.960: INFO: Created: latency-svc-zt96f
  Feb  7 13:54:15.967: INFO: Created: latency-svc-2s6jb
  Feb  7 13:54:15.968: INFO: Got endpoints: latency-svc-mvgtk [238.399682ms]
  Feb  7 13:54:15.978: INFO: Created: latency-svc-9g9mv
  Feb  7 13:54:15.984: INFO: Created: latency-svc-866c4
  Feb  7 13:54:16.004: INFO: Created: latency-svc-54m4g
  Feb  7 13:54:16.011: INFO: Created: latency-svc-8tspf
  Feb  7 13:54:16.018: INFO: Got endpoints: latency-svc-5qbg5 [279.497075ms]
  Feb  7 13:54:16.027: INFO: Created: latency-svc-6jmzw
  Feb  7 13:54:16.067: INFO: Got endpoints: latency-svc-pftgx [312.423736ms]
  Feb  7 13:54:16.077: INFO: Created: latency-svc-zlf8n
  Feb  7 13:54:16.117: INFO: Got endpoints: latency-svc-5hkpg [354.95086ms]
  Feb  7 13:54:16.128: INFO: Created: latency-svc-4dq9c
  Feb  7 13:54:16.168: INFO: Got endpoints: latency-svc-n8vdk [399.565595ms]
  Feb  7 13:54:16.181: INFO: Created: latency-svc-lpb5h
  Feb  7 13:54:16.217: INFO: Got endpoints: latency-svc-lrllf [437.092905ms]
  Feb  7 13:54:16.227: INFO: Created: latency-svc-m94qb
  Feb  7 13:54:16.267: INFO: Got endpoints: latency-svc-5zpkv [482.088905ms]
  Feb  7 13:54:16.278: INFO: Created: latency-svc-wlh75
  Feb  7 13:54:16.322: INFO: Got endpoints: latency-svc-n9jhx [523.223208ms]
  Feb  7 13:54:16.332: INFO: Created: latency-svc-szjns
  Feb  7 13:54:16.367: INFO: Got endpoints: latency-svc-b9gnl [555.541952ms]
  Feb  7 13:54:16.381: INFO: Created: latency-svc-vx2h4
  Feb  7 13:54:16.418: INFO: Got endpoints: latency-svc-g64tt [598.47087ms]
  Feb  7 13:54:16.441: INFO: Created: latency-svc-558kh
  Feb  7 13:54:16.468: INFO: Got endpoints: latency-svc-zt96f [632.808014ms]
  Feb  7 13:54:16.477: INFO: Created: latency-svc-zt5vp
  Feb  7 13:54:16.518: INFO: Got endpoints: latency-svc-2s6jb [677.683588ms]
  Feb  7 13:54:16.528: INFO: Created: latency-svc-vmn7c
  Feb  7 13:54:16.567: INFO: Got endpoints: latency-svc-9g9mv [718.091303ms]
  Feb  7 13:54:16.581: INFO: Created: latency-svc-wm9dc
  Feb  7 13:54:16.617: INFO: Got endpoints: latency-svc-866c4 [745.082958ms]
  Feb  7 13:54:16.627: INFO: Created: latency-svc-nrffl
  Feb  7 13:54:16.667: INFO: Got endpoints: latency-svc-54m4g [750.853513ms]
  Feb  7 13:54:16.676: INFO: Created: latency-svc-tv492
  Feb  7 13:54:16.717: INFO: Got endpoints: latency-svc-8tspf [748.091741ms]
  Feb  7 13:54:16.725: INFO: Created: latency-svc-m64pf
  Feb  7 13:54:16.767: INFO: Got endpoints: latency-svc-6jmzw [748.932719ms]
  Feb  7 13:54:16.780: INFO: Created: latency-svc-zmhhj
  Feb  7 13:54:16.818: INFO: Got endpoints: latency-svc-zlf8n [751.328621ms]
  Feb  7 13:54:16.827: INFO: Created: latency-svc-vv9ct
  Feb  7 13:54:16.869: INFO: Got endpoints: latency-svc-4dq9c [751.902555ms]
  Feb  7 13:54:16.878: INFO: Created: latency-svc-c5pfj
  Feb  7 13:54:16.916: INFO: Got endpoints: latency-svc-lpb5h [748.370275ms]
  Feb  7 13:54:16.926: INFO: Created: latency-svc-n8xdz
  Feb  7 13:54:16.975: INFO: Got endpoints: latency-svc-m94qb [757.278752ms]
  Feb  7 13:54:16.990: INFO: Created: latency-svc-tlbh2
  Feb  7 13:54:17.019: INFO: Got endpoints: latency-svc-wlh75 [751.22414ms]
  Feb  7 13:54:17.029: INFO: Created: latency-svc-bwxgf
  Feb  7 13:54:17.066: INFO: Got endpoints: latency-svc-szjns [743.995678ms]
  Feb  7 13:54:17.080: INFO: Created: latency-svc-zfdfc
  Feb  7 13:54:17.117: INFO: Got endpoints: latency-svc-vx2h4 [749.520308ms]
  Feb  7 13:54:17.126: INFO: Created: latency-svc-spds4
  Feb  7 13:54:17.167: INFO: Got endpoints: latency-svc-558kh [748.70474ms]
  Feb  7 13:54:17.179: INFO: Created: latency-svc-jv5xh
  Feb  7 13:54:17.217: INFO: Got endpoints: latency-svc-zt5vp [748.936256ms]
  Feb  7 13:54:17.227: INFO: Created: latency-svc-29t5z
  Feb  7 13:54:17.267: INFO: Got endpoints: latency-svc-vmn7c [748.586274ms]
  Feb  7 13:54:17.276: INFO: Created: latency-svc-9lp9z
  Feb  7 13:54:17.319: INFO: Got endpoints: latency-svc-wm9dc [752.384606ms]
  Feb  7 13:54:17.329: INFO: Created: latency-svc-7wtmv
  Feb  7 13:54:17.367: INFO: Got endpoints: latency-svc-nrffl [750.01527ms]
  Feb  7 13:54:17.381: INFO: Created: latency-svc-bbbbl
  Feb  7 13:54:17.418: INFO: Got endpoints: latency-svc-tv492 [750.557261ms]
  Feb  7 13:54:17.427: INFO: Created: latency-svc-h28s8
  Feb  7 13:54:17.467: INFO: Got endpoints: latency-svc-m64pf [750.488706ms]
  Feb  7 13:54:17.476: INFO: Created: latency-svc-bcdh4
  Feb  7 13:54:17.517: INFO: Got endpoints: latency-svc-zmhhj [749.955344ms]
  Feb  7 13:54:17.528: INFO: Created: latency-svc-vptwr
  Feb  7 13:54:17.567: INFO: Got endpoints: latency-svc-vv9ct [748.072446ms]
  Feb  7 13:54:17.579: INFO: Created: latency-svc-7wmlh
  Feb  7 13:54:17.616: INFO: Got endpoints: latency-svc-c5pfj [747.170269ms]
  Feb  7 13:54:17.625: INFO: Created: latency-svc-84v4s
  Feb  7 13:54:17.667: INFO: Got endpoints: latency-svc-n8xdz [750.495949ms]
  Feb  7 13:54:17.680: INFO: Created: latency-svc-jv4l7
  Feb  7 13:54:17.717: INFO: Got endpoints: latency-svc-tlbh2 [741.919543ms]
  Feb  7 13:54:17.725: INFO: Created: latency-svc-9mppw
  Feb  7 13:54:17.768: INFO: Got endpoints: latency-svc-bwxgf [749.633812ms]
  Feb  7 13:54:17.781: INFO: Created: latency-svc-lpdkh
  Feb  7 13:54:17.819: INFO: Got endpoints: latency-svc-zfdfc [752.850436ms]
  Feb  7 13:54:17.829: INFO: Created: latency-svc-hs227
  Feb  7 13:54:17.867: INFO: Got endpoints: latency-svc-spds4 [749.94544ms]
  Feb  7 13:54:17.876: INFO: Created: latency-svc-mm7g4
  Feb  7 13:54:17.917: INFO: Got endpoints: latency-svc-jv5xh [750.012216ms]
  Feb  7 13:54:17.933: INFO: Created: latency-svc-fpqkh
  Feb  7 13:54:17.967: INFO: Got endpoints: latency-svc-29t5z [750.574673ms]
  Feb  7 13:54:17.981: INFO: Created: latency-svc-94kz4
  Feb  7 13:54:18.017: INFO: Got endpoints: latency-svc-9lp9z [750.553838ms]
  Feb  7 13:54:18.027: INFO: Created: latency-svc-bq7ks
  Feb  7 13:54:18.068: INFO: Got endpoints: latency-svc-7wtmv [749.320292ms]
  Feb  7 13:54:18.078: INFO: Created: latency-svc-bqvxr
  Feb  7 13:54:18.118: INFO: Got endpoints: latency-svc-bbbbl [751.810683ms]
  Feb  7 13:54:18.140: INFO: Created: latency-svc-9lpvh
  Feb  7 13:54:18.166: INFO: Got endpoints: latency-svc-h28s8 [748.33593ms]
  Feb  7 13:54:18.180: INFO: Created: latency-svc-skfpl
  Feb  7 13:54:18.219: INFO: Got endpoints: latency-svc-bcdh4 [751.90531ms]
  Feb  7 13:54:18.228: INFO: Created: latency-svc-q57w4
  Feb  7 13:54:18.266: INFO: Got endpoints: latency-svc-vptwr [749.504587ms]
  Feb  7 13:54:18.277: INFO: Created: latency-svc-k5bsb
  Feb  7 13:54:18.317: INFO: Got endpoints: latency-svc-7wmlh [750.016438ms]
  Feb  7 13:54:18.326: INFO: Created: latency-svc-qjzgh
  Feb  7 13:54:18.366: INFO: Got endpoints: latency-svc-84v4s [750.307245ms]
  Feb  7 13:54:18.379: INFO: Created: latency-svc-xjfct
  Feb  7 13:54:18.419: INFO: Got endpoints: latency-svc-jv4l7 [751.36397ms]
  Feb  7 13:54:18.432: INFO: Created: latency-svc-twbfq
  Feb  7 13:54:18.469: INFO: Got endpoints: latency-svc-9mppw [752.675981ms]
  Feb  7 13:54:18.482: INFO: Created: latency-svc-6w6fv
  Feb  7 13:54:18.517: INFO: Got endpoints: latency-svc-lpdkh [748.901736ms]
  Feb  7 13:54:18.529: INFO: Created: latency-svc-q4fgk
  Feb  7 13:54:18.569: INFO: Got endpoints: latency-svc-hs227 [749.434316ms]
  Feb  7 13:54:18.578: INFO: Created: latency-svc-h44dr
  Feb  7 13:54:18.618: INFO: Got endpoints: latency-svc-mm7g4 [750.332942ms]
  Feb  7 13:54:18.627: INFO: Created: latency-svc-l55hh
  Feb  7 13:54:18.671: INFO: Got endpoints: latency-svc-fpqkh [754.459145ms]
  Feb  7 13:54:18.680: INFO: Created: latency-svc-d9pn5
  Feb  7 13:54:18.719: INFO: Got endpoints: latency-svc-94kz4 [750.928163ms]
  Feb  7 13:54:18.728: INFO: Created: latency-svc-l2t4v
  Feb  7 13:54:18.769: INFO: Got endpoints: latency-svc-bq7ks [751.330645ms]
  Feb  7 13:54:18.781: INFO: Created: latency-svc-zhscj
  Feb  7 13:54:18.817: INFO: Got endpoints: latency-svc-bqvxr [748.922359ms]
  Feb  7 13:54:18.826: INFO: Created: latency-svc-qbzw8
  Feb  7 13:54:18.869: INFO: Got endpoints: latency-svc-9lpvh [750.338816ms]
  Feb  7 13:54:18.885: INFO: Created: latency-svc-dst25
  Feb  7 13:54:18.917: INFO: Got endpoints: latency-svc-skfpl [750.178293ms]
  Feb  7 13:54:18.930: INFO: Created: latency-svc-dbpx9
  Feb  7 13:54:18.967: INFO: Got endpoints: latency-svc-q57w4 [748.033179ms]
  Feb  7 13:54:18.977: INFO: Created: latency-svc-qcfff
  Feb  7 13:54:19.018: INFO: Got endpoints: latency-svc-k5bsb [751.942298ms]
  Feb  7 13:54:19.032: INFO: Created: latency-svc-lzpnb
  Feb  7 13:54:19.067: INFO: Got endpoints: latency-svc-qjzgh [749.818724ms]
  Feb  7 13:54:19.076: INFO: Created: latency-svc-6brx9
  Feb  7 13:54:19.117: INFO: Got endpoints: latency-svc-xjfct [750.738641ms]
  Feb  7 13:54:19.131: INFO: Created: latency-svc-2x5jl
  Feb  7 13:54:19.167: INFO: Got endpoints: latency-svc-twbfq [748.219383ms]
  Feb  7 13:54:19.177: INFO: Created: latency-svc-k5kdk
  Feb  7 13:54:19.218: INFO: Got endpoints: latency-svc-6w6fv [748.434776ms]
  Feb  7 13:54:19.227: INFO: Created: latency-svc-5nt52
  Feb  7 13:54:19.267: INFO: Got endpoints: latency-svc-q4fgk [749.69873ms]
  Feb  7 13:54:19.278: INFO: Created: latency-svc-rzwqc
  Feb  7 13:54:19.317: INFO: Got endpoints: latency-svc-h44dr [748.704267ms]
  Feb  7 13:54:19.330: INFO: Created: latency-svc-29kvd
  Feb  7 13:54:19.368: INFO: Got endpoints: latency-svc-l55hh [750.354316ms]
  Feb  7 13:54:19.378: INFO: Created: latency-svc-nxgv7
  Feb  7 13:54:19.418: INFO: Got endpoints: latency-svc-d9pn5 [746.958838ms]
  Feb  7 13:54:19.428: INFO: Created: latency-svc-c684n
  Feb  7 13:54:19.470: INFO: Got endpoints: latency-svc-l2t4v [750.995883ms]
  Feb  7 13:54:19.478: INFO: Created: latency-svc-rmdsv
  Feb  7 13:54:19.521: INFO: Got endpoints: latency-svc-zhscj [752.374743ms]
  Feb  7 13:54:19.533: INFO: Created: latency-svc-rj8nj
  Feb  7 13:54:19.567: INFO: Got endpoints: latency-svc-qbzw8 [749.721064ms]
  Feb  7 13:54:19.578: INFO: Created: latency-svc-zfvpv
  Feb  7 13:54:19.616: INFO: Got endpoints: latency-svc-dst25 [747.148645ms]
  Feb  7 13:54:19.632: INFO: Created: latency-svc-t2fc5
  Feb  7 13:54:19.668: INFO: Got endpoints: latency-svc-dbpx9 [751.929484ms]
  Feb  7 13:54:19.677: INFO: Created: latency-svc-4fspj
  Feb  7 13:54:19.719: INFO: Got endpoints: latency-svc-qcfff [751.882719ms]
  Feb  7 13:54:19.736: INFO: Created: latency-svc-mfn66
  Feb  7 13:54:19.766: INFO: Got endpoints: latency-svc-lzpnb [747.861275ms]
  Feb  7 13:54:19.776: INFO: Created: latency-svc-5z6h5
  Feb  7 13:54:19.818: INFO: Got endpoints: latency-svc-6brx9 [751.402192ms]
  Feb  7 13:54:19.827: INFO: Created: latency-svc-mx44d
  Feb  7 13:54:19.867: INFO: Got endpoints: latency-svc-2x5jl [749.4219ms]
  Feb  7 13:54:19.879: INFO: Created: latency-svc-zlr4h
  Feb  7 13:54:19.917: INFO: Got endpoints: latency-svc-k5kdk [749.757469ms]
  Feb  7 13:54:19.929: INFO: Created: latency-svc-w6hrg
  Feb  7 13:54:19.968: INFO: Got endpoints: latency-svc-5nt52 [750.007515ms]
  Feb  7 13:54:19.979: INFO: Created: latency-svc-d9x7f
  Feb  7 13:54:20.017: INFO: Got endpoints: latency-svc-rzwqc [750.023717ms]
  Feb  7 13:54:20.027: INFO: Created: latency-svc-b8x7h
  Feb  7 13:54:20.067: INFO: Got endpoints: latency-svc-29kvd [749.5325ms]
  Feb  7 13:54:20.076: INFO: Created: latency-svc-rzf4z
  Feb  7 13:54:20.118: INFO: Got endpoints: latency-svc-nxgv7 [750.095222ms]
  Feb  7 13:54:20.130: INFO: Created: latency-svc-rzm76
  Feb  7 13:54:20.166: INFO: Got endpoints: latency-svc-c684n [748.078374ms]
  Feb  7 13:54:20.177: INFO: Created: latency-svc-q6z68
  Feb  7 13:54:20.217: INFO: Got endpoints: latency-svc-rmdsv [747.037103ms]
  Feb  7 13:54:20.226: INFO: Created: latency-svc-rnt2k
  Feb  7 13:54:20.270: INFO: Got endpoints: latency-svc-rj8nj [749.00724ms]
  Feb  7 13:54:20.278: INFO: Created: latency-svc-phj7k
  Feb  7 13:54:20.316: INFO: Got endpoints: latency-svc-zfvpv [748.926362ms]
  Feb  7 13:54:20.331: INFO: Created: latency-svc-vxbl9
  Feb  7 13:54:20.366: INFO: Got endpoints: latency-svc-t2fc5 [749.775806ms]
  Feb  7 13:54:20.385: INFO: Created: latency-svc-rmd9j
  Feb  7 13:54:20.419: INFO: Got endpoints: latency-svc-4fspj [750.347449ms]
  Feb  7 13:54:20.429: INFO: Created: latency-svc-wfgsg
  Feb  7 13:54:20.467: INFO: Got endpoints: latency-svc-mfn66 [748.065945ms]
  Feb  7 13:54:20.481: INFO: Created: latency-svc-l8fcj
  Feb  7 13:54:20.518: INFO: Got endpoints: latency-svc-5z6h5 [751.664028ms]
  Feb  7 13:54:20.528: INFO: Created: latency-svc-q258m
  Feb  7 13:54:20.566: INFO: Got endpoints: latency-svc-mx44d [748.117709ms]
  Feb  7 13:54:20.576: INFO: Created: latency-svc-s8x2p
  Feb  7 13:54:20.618: INFO: Got endpoints: latency-svc-zlr4h [751.065779ms]
  Feb  7 13:54:20.627: INFO: Created: latency-svc-p85rh
  Feb  7 13:54:20.667: INFO: Got endpoints: latency-svc-w6hrg [749.776992ms]
  Feb  7 13:54:20.681: INFO: Created: latency-svc-26825
  Feb  7 13:54:20.717: INFO: Got endpoints: latency-svc-d9x7f [749.128915ms]
  Feb  7 13:54:20.727: INFO: Created: latency-svc-wwh2w
  Feb  7 13:54:20.768: INFO: Got endpoints: latency-svc-b8x7h [751.001659ms]
  Feb  7 13:54:20.777: INFO: Created: latency-svc-jfssh
  Feb  7 13:54:20.816: INFO: Got endpoints: latency-svc-rzf4z [748.919859ms]
  Feb  7 13:54:20.826: INFO: Created: latency-svc-67zpd
  Feb  7 13:54:20.866: INFO: Got endpoints: latency-svc-rzm76 [748.143393ms]
  Feb  7 13:54:20.882: INFO: Created: latency-svc-c5qgl
  Feb  7 13:54:20.918: INFO: Got endpoints: latency-svc-q6z68 [751.346551ms]
  Feb  7 13:54:20.927: INFO: Created: latency-svc-xgkm2
  Feb  7 13:54:20.967: INFO: Got endpoints: latency-svc-rnt2k [750.39512ms]
  Feb  7 13:54:20.977: INFO: Created: latency-svc-4pv42
  Feb  7 13:54:21.017: INFO: Got endpoints: latency-svc-phj7k [746.646321ms]
  Feb  7 13:54:21.026: INFO: Created: latency-svc-8ldt5
  Feb  7 13:54:21.068: INFO: Got endpoints: latency-svc-vxbl9 [751.369368ms]
  Feb  7 13:54:21.081: INFO: Created: latency-svc-vx6nb
  Feb  7 13:54:21.121: INFO: Got endpoints: latency-svc-rmd9j [754.839633ms]
  Feb  7 13:54:21.129: INFO: Created: latency-svc-xz4j8
  Feb  7 13:54:21.167: INFO: Got endpoints: latency-svc-wfgsg [747.67115ms]
  Feb  7 13:54:21.176: INFO: Created: latency-svc-p8db7
  Feb  7 13:54:21.216: INFO: Got endpoints: latency-svc-l8fcj [748.987768ms]
  Feb  7 13:54:21.230: INFO: Created: latency-svc-jrpxf
  Feb  7 13:54:21.269: INFO: Got endpoints: latency-svc-q258m [750.558809ms]
  Feb  7 13:54:21.282: INFO: Created: latency-svc-4nwtd
  Feb  7 13:54:21.316: INFO: Got endpoints: latency-svc-s8x2p [750.050307ms]
  Feb  7 13:54:21.327: INFO: Created: latency-svc-b5ddz
  Feb  7 13:54:21.367: INFO: Got endpoints: latency-svc-p85rh [749.595224ms]
  Feb  7 13:54:21.376: INFO: Created: latency-svc-ggh5h
  Feb  7 13:54:21.418: INFO: Got endpoints: latency-svc-26825 [751.387658ms]
  Feb  7 13:54:21.427: INFO: Created: latency-svc-xvgkd
  Feb  7 13:54:21.466: INFO: Got endpoints: latency-svc-wwh2w [748.945989ms]
  Feb  7 13:54:21.481: INFO: Created: latency-svc-ftrhr
  Feb  7 13:54:21.517: INFO: Got endpoints: latency-svc-jfssh [748.942043ms]
  Feb  7 13:54:21.527: INFO: Created: latency-svc-kf6bv
  Feb  7 13:54:21.569: INFO: Got endpoints: latency-svc-67zpd [752.889904ms]
  Feb  7 13:54:21.579: INFO: Created: latency-svc-g8tsm
  Feb  7 13:54:21.619: INFO: Got endpoints: latency-svc-c5qgl [752.452754ms]
  Feb  7 13:54:21.629: INFO: Created: latency-svc-6ftz8
  Feb  7 13:54:21.667: INFO: Got endpoints: latency-svc-xgkm2 [749.063298ms]
  Feb  7 13:54:21.680: INFO: Created: latency-svc-8n2h7
  Feb  7 13:54:21.718: INFO: Got endpoints: latency-svc-4pv42 [750.920348ms]
  Feb  7 13:54:21.727: INFO: Created: latency-svc-znnkn
  Feb  7 13:54:21.766: INFO: Got endpoints: latency-svc-8ldt5 [749.07045ms]
  Feb  7 13:54:21.777: INFO: Created: latency-svc-mwz8t
  Feb  7 13:54:21.816: INFO: Got endpoints: latency-svc-vx6nb [748.543793ms]
  Feb  7 13:54:21.826: INFO: Created: latency-svc-d42f8
  Feb  7 13:54:21.870: INFO: Got endpoints: latency-svc-xz4j8 [749.561759ms]
  Feb  7 13:54:21.883: INFO: Created: latency-svc-7wmpn
  Feb  7 13:54:21.919: INFO: Got endpoints: latency-svc-p8db7 [752.219855ms]
  Feb  7 13:54:21.929: INFO: Created: latency-svc-lgp6p
  Feb  7 13:54:21.967: INFO: Got endpoints: latency-svc-jrpxf [751.022022ms]
  Feb  7 13:54:21.981: INFO: Created: latency-svc-9gczv
  Feb  7 13:54:22.021: INFO: Got endpoints: latency-svc-4nwtd [752.208038ms]
  Feb  7 13:54:22.029: INFO: Created: latency-svc-bcxq4
  Feb  7 13:54:22.068: INFO: Got endpoints: latency-svc-b5ddz [751.483048ms]
  Feb  7 13:54:22.084: INFO: Created: latency-svc-884rl
  Feb  7 13:54:22.117: INFO: Got endpoints: latency-svc-ggh5h [749.738105ms]
  Feb  7 13:54:22.126: INFO: Created: latency-svc-jfjj7
  Feb  7 13:54:22.168: INFO: Got endpoints: latency-svc-xvgkd [749.574091ms]
  Feb  7 13:54:22.177: INFO: Created: latency-svc-dkpvz
  Feb  7 13:54:22.218: INFO: Got endpoints: latency-svc-ftrhr [751.317522ms]
  Feb  7 13:54:22.227: INFO: Created: latency-svc-wjzxr
  Feb  7 13:54:22.267: INFO: Got endpoints: latency-svc-kf6bv [749.480598ms]
  Feb  7 13:54:22.277: INFO: Created: latency-svc-mvpwg
  Feb  7 13:54:22.318: INFO: Got endpoints: latency-svc-g8tsm [748.467483ms]
  Feb  7 13:54:22.327: INFO: Created: latency-svc-9xdmq
  Feb  7 13:54:22.367: INFO: Got endpoints: latency-svc-6ftz8 [747.791403ms]
  Feb  7 13:54:22.389: INFO: Created: latency-svc-rq8tv
  Feb  7 13:54:22.419: INFO: Got endpoints: latency-svc-8n2h7 [752.092604ms]
  Feb  7 13:54:22.428: INFO: Created: latency-svc-4tdl7
  Feb  7 13:54:22.468: INFO: Got endpoints: latency-svc-znnkn [750.156909ms]
  Feb  7 13:54:22.481: INFO: Created: latency-svc-7v8zv
  Feb  7 13:54:22.517: INFO: Got endpoints: latency-svc-mwz8t [750.720114ms]
  Feb  7 13:54:22.526: INFO: Created: latency-svc-pzlpl
  Feb  7 13:54:22.566: INFO: Got endpoints: latency-svc-d42f8 [750.163796ms]
  Feb  7 13:54:22.575: INFO: Created: latency-svc-494j2
  Feb  7 13:54:22.622: INFO: Got endpoints: latency-svc-7wmpn [751.247082ms]
  Feb  7 13:54:22.630: INFO: Created: latency-svc-vrt7b
  Feb  7 13:54:22.671: INFO: Got endpoints: latency-svc-lgp6p [752.514293ms]
  Feb  7 13:54:22.680: INFO: Created: latency-svc-t99nq
  Feb  7 13:54:22.720: INFO: Got endpoints: latency-svc-9gczv [752.569902ms]
  Feb  7 13:54:22.729: INFO: Created: latency-svc-5qtbq
  Feb  7 13:54:22.769: INFO: Got endpoints: latency-svc-bcxq4 [747.729878ms]
  Feb  7 13:54:22.777: INFO: Created: latency-svc-gv4qd
  Feb  7 13:54:22.817: INFO: Got endpoints: latency-svc-884rl [748.659691ms]
  Feb  7 13:54:22.830: INFO: Created: latency-svc-q5d2z
  Feb  7 13:54:22.867: INFO: Got endpoints: latency-svc-jfjj7 [749.919233ms]
  Feb  7 13:54:22.875: INFO: Created: latency-svc-dz6qb
  Feb  7 13:54:22.917: INFO: Got endpoints: latency-svc-dkpvz [749.792575ms]
  Feb  7 13:54:22.927: INFO: Created: latency-svc-xw5pj
  Feb  7 13:54:22.969: INFO: Got endpoints: latency-svc-wjzxr [751.121451ms]
  Feb  7 13:54:22.977: INFO: Created: latency-svc-m86w9
  Feb  7 13:54:23.018: INFO: Got endpoints: latency-svc-mvpwg [751.126033ms]
  Feb  7 13:54:23.032: INFO: Created: latency-svc-xjvx8
  Feb  7 13:54:23.069: INFO: Got endpoints: latency-svc-9xdmq [750.951862ms]
  Feb  7 13:54:23.079: INFO: Created: latency-svc-zhspq
  Feb  7 13:54:23.117: INFO: Got endpoints: latency-svc-rq8tv [750.643049ms]
  Feb  7 13:54:23.127: INFO: Created: latency-svc-2xmll
  Feb  7 13:54:23.167: INFO: Got endpoints: latency-svc-4tdl7 [748.008307ms]
  Feb  7 13:54:23.177: INFO: Created: latency-svc-mbn64
  Feb  7 13:54:23.217: INFO: Got endpoints: latency-svc-7v8zv [748.651749ms]
  Feb  7 13:54:23.230: INFO: Created: latency-svc-4rdxm
  Feb  7 13:54:23.269: INFO: Got endpoints: latency-svc-pzlpl [751.971058ms]
  Feb  7 13:54:23.278: INFO: Created: latency-svc-7w8ds
  Feb  7 13:54:23.318: INFO: Got endpoints: latency-svc-494j2 [751.083356ms]
  Feb  7 13:54:23.368: INFO: Got endpoints: latency-svc-vrt7b [746.272633ms]
  Feb  7 13:54:23.416: INFO: Got endpoints: latency-svc-t99nq [744.667826ms]
  Feb  7 13:54:23.468: INFO: Got endpoints: latency-svc-5qtbq [747.749157ms]
  Feb  7 13:54:23.520: INFO: Got endpoints: latency-svc-gv4qd [750.782179ms]
  Feb  7 13:54:23.567: INFO: Got endpoints: latency-svc-q5d2z [750.592154ms]
  Feb  7 13:54:23.617: INFO: Got endpoints: latency-svc-dz6qb [749.621074ms]
  Feb  7 13:54:23.668: INFO: Got endpoints: latency-svc-xw5pj [750.301431ms]
  Feb  7 13:54:23.716: INFO: Got endpoints: latency-svc-m86w9 [747.634811ms]
  Feb  7 13:54:23.767: INFO: Got endpoints: latency-svc-xjvx8 [749.378287ms]
  Feb  7 13:54:23.816: INFO: Got endpoints: latency-svc-zhspq [747.522535ms]
  Feb  7 13:54:23.867: INFO: Got endpoints: latency-svc-2xmll [749.592072ms]
  Feb  7 13:54:23.917: INFO: Got endpoints: latency-svc-mbn64 [749.471948ms]
  Feb  7 13:54:23.967: INFO: Got endpoints: latency-svc-4rdxm [749.569803ms]
  Feb  7 13:54:24.018: INFO: Got endpoints: latency-svc-7w8ds [748.924668ms]
  Feb  7 13:54:24.018: INFO: Latencies: [22.655608ms 35.512206ms 42.238316ms 47.944919ms 53.555837ms 68.079959ms 75.741019ms 83.938693ms 96.650851ms 106.928023ms 114.732683ms 130.328699ms 139.430732ms 142.788409ms 143.326761ms 144.382602ms 146.751613ms 146.893013ms 146.983187ms 147.760419ms 149.362233ms 156.247913ms 161.430824ms 161.608112ms 162.136199ms 162.148484ms 162.33114ms 162.510295ms 164.393076ms 165.023578ms 165.47864ms 166.543366ms 168.237127ms 170.292935ms 170.386608ms 171.186504ms 176.263532ms 195.798617ms 238.399682ms 279.497075ms 312.423736ms 354.95086ms 399.565595ms 437.092905ms 482.088905ms 523.223208ms 555.541952ms 598.47087ms 632.808014ms 677.683588ms 718.091303ms 741.919543ms 743.995678ms 744.667826ms 745.082958ms 746.272633ms 746.646321ms 746.958838ms 747.037103ms 747.148645ms 747.170269ms 747.522535ms 747.634811ms 747.67115ms 747.729878ms 747.749157ms 747.791403ms 747.861275ms 748.008307ms 748.033179ms 748.065945ms 748.072446ms 748.078374ms 748.091741ms 748.117709ms 748.143393ms 748.219383ms 748.33593ms 748.370275ms 748.434776ms 748.467483ms 748.543793ms 748.586274ms 748.651749ms 748.659691ms 748.704267ms 748.70474ms 748.901736ms 748.919859ms 748.922359ms 748.924668ms 748.926362ms 748.932719ms 748.936256ms 748.942043ms 748.945989ms 748.987768ms 749.00724ms 749.063298ms 749.07045ms 749.128915ms 749.320292ms 749.378287ms 749.4219ms 749.434316ms 749.471948ms 749.480598ms 749.504587ms 749.520308ms 749.5325ms 749.561759ms 749.569803ms 749.574091ms 749.592072ms 749.595224ms 749.621074ms 749.633812ms 749.69873ms 749.721064ms 749.738105ms 749.757469ms 749.775806ms 749.776992ms 749.792575ms 749.818724ms 749.919233ms 749.94544ms 749.955344ms 750.007515ms 750.012216ms 750.01527ms 750.016438ms 750.023717ms 750.050307ms 750.095222ms 750.156909ms 750.163796ms 750.178293ms 750.301431ms 750.307245ms 750.332942ms 750.338816ms 750.347449ms 750.354316ms 750.39512ms 750.488706ms 750.495949ms 750.553838ms 750.557261ms 750.558809ms 750.574673ms 750.592154ms 750.643049ms 750.720114ms 750.738641ms 750.782179ms 750.853513ms 750.920348ms 750.928163ms 750.951862ms 750.995883ms 751.001659ms 751.022022ms 751.065779ms 751.083356ms 751.121451ms 751.126033ms 751.22414ms 751.247082ms 751.317522ms 751.328621ms 751.330645ms 751.346551ms 751.36397ms 751.369368ms 751.387658ms 751.402192ms 751.483048ms 751.664028ms 751.810683ms 751.882719ms 751.902555ms 751.90531ms 751.929484ms 751.942298ms 751.971058ms 752.092604ms 752.208038ms 752.219855ms 752.374743ms 752.384606ms 752.452754ms 752.514293ms 752.569902ms 752.675981ms 752.850436ms 752.889904ms 754.459145ms 754.839633ms 757.278752ms]
  Feb  7 13:54:24.018: INFO: 50 %ile: 749.128915ms
  Feb  7 13:54:24.018: INFO: 90 %ile: 751.882719ms
  Feb  7 13:54:24.018: INFO: 99 %ile: 754.839633ms
  Feb  7 13:54:24.018: INFO: Total sample count: 200
  Feb  7 13:54:24.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-4121" for this suite. @ 02/07/24 13:54:24.022
• [9.745 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 02/07/24 13:54:24.027
  Feb  7 13:54:24.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename init-container @ 02/07/24 13:54:24.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:54:24.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:54:24.038
  STEP: creating the pod @ 02/07/24 13:54:24.04
  Feb  7 13:54:24.040: INFO: PodSpec: initContainers in spec.initContainers
  Feb  7 13:55:04.061: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f401272e-dff1-4907-9e9f-3d8ce2a0b39e", GenerateName:"", Namespace:"init-container-7237", SelfLink:"", UID:"16368867-d749-4cac-aa2d-b5fc7b2adcca", ResourceVersion:"6916", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"40959449"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e68bb8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 13, 55, 4, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e68be8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-z9wb9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003e79da0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-z9wb9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-z9wb9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-z9wb9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0020a18b0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0006464d0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020a1ac0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020a1b20)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0020a1b28), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0020a1b2c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000a79ea0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.60.182", HostIPs:[]v1.HostIP{v1.HostIP{IP:"10.0.60.182"}}, PodIP:"10.244.1.47", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.47"}}, StartTime:time.Date(2024, time.February, 7, 13, 54, 24, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000646620)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000646690)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://966d95d96a2b93d24fc733deaf307684ed2d329f62f3d1c470fdc96d9da3e010", Started:(*bool)(0xc0020a1dfa), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003e79e20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0020a1e8f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003e79e00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0020a1ddf), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Feb  7 13:55:04.061: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7237" for this suite. @ 02/07/24 13:55:04.064
• [40.040 seconds]
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 02/07/24 13:55:04.068
  Feb  7 13:55:04.068: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename runtimeclass @ 02/07/24 13:55:04.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:04.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:04.079
  STEP: getting /apis @ 02/07/24 13:55:04.081
  STEP: getting /apis/node.k8s.io @ 02/07/24 13:55:04.085
  STEP: getting /apis/node.k8s.io/v1 @ 02/07/24 13:55:04.086
  STEP: creating @ 02/07/24 13:55:04.087
  STEP: watching @ 02/07/24 13:55:04.097
  Feb  7 13:55:04.097: INFO: starting watch
  STEP: getting @ 02/07/24 13:55:04.101
  STEP: listing @ 02/07/24 13:55:04.103
  STEP: patching @ 02/07/24 13:55:04.105
  STEP: updating @ 02/07/24 13:55:04.108
  Feb  7 13:55:04.111: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 02/07/24 13:55:04.112
  STEP: deleting a collection @ 02/07/24 13:55:04.118
  Feb  7 13:55:04.142: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1150" for this suite. @ 02/07/24 13:55:04.145
• [0.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 02/07/24 13:55:04.151
  Feb  7 13:55:04.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubelet-test @ 02/07/24 13:55:04.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:04.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:04.166
  Feb  7 13:55:06.196: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2954" for this suite. @ 02/07/24 13:55:06.199
• [2.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 02/07/24 13:55:06.204
  Feb  7 13:55:06.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 13:55:06.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:06.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:06.217
  STEP: creating Agnhost RC @ 02/07/24 13:55:06.22
  Feb  7 13:55:06.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2826 create -f -'
  Feb  7 13:55:06.337: INFO: stderr: ""
  Feb  7 13:55:06.337: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 02/07/24 13:55:06.337
  Feb  7 13:55:07.340: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 13:55:07.340: INFO: Found 0 / 1
  Feb  7 13:55:08.341: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 13:55:08.341: INFO: Found 1 / 1
  Feb  7 13:55:08.341: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 02/07/24 13:55:08.341
  Feb  7 13:55:08.343: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 13:55:08.343: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb  7 13:55:08.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2826 patch pod agnhost-primary-2jkvz -p {"metadata":{"annotations":{"x":"y"}}}'
  Feb  7 13:55:08.406: INFO: stderr: ""
  Feb  7 13:55:08.406: INFO: stdout: "pod/agnhost-primary-2jkvz patched\n"
  STEP: checking annotations @ 02/07/24 13:55:08.406
  Feb  7 13:55:08.409: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 13:55:08.409: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb  7 13:55:08.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2826" for this suite. @ 02/07/24 13:55:08.411
• [2.212 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 02/07/24 13:55:08.417
  Feb  7 13:55:08.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename endpointslicemirroring @ 02/07/24 13:55:08.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:08.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:08.428
  STEP: mirroring a new custom Endpoint @ 02/07/24 13:55:08.44
  Feb  7 13:55:08.448: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  STEP: mirroring an update to a custom Endpoint @ 02/07/24 13:55:10.45
  Feb  7 13:55:10.455: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  STEP: mirroring deletion of a custom Endpoint @ 02/07/24 13:55:12.457
  Feb  7 13:55:12.463: INFO: Waiting for 0 EndpointSlices to exist, got 1
  Feb  7 13:55:14.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-4558" for this suite. @ 02/07/24 13:55:14.469
• [6.057 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 02/07/24 13:55:14.474
  Feb  7 13:55:14.474: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename security-context-test @ 02/07/24 13:55:14.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:14.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:14.486
  Feb  7 13:55:18.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6927" for this suite. @ 02/07/24 13:55:18.511
• [4.040 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 02/07/24 13:55:18.515
  Feb  7 13:55:18.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 13:55:18.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:18.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:18.527
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-752 @ 02/07/24 13:55:18.53
  STEP: changing the ExternalName service to type=NodePort @ 02/07/24 13:55:18.533
  STEP: creating replication controller externalname-service in namespace services-752 @ 02/07/24 13:55:18.546
  I0207 13:55:18.552411      23 runners.go:197] Created replication controller with name: externalname-service, namespace: services-752, replica count: 2
  I0207 13:55:21.603793      23 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 13:55:21.603: INFO: Creating new exec pod
  Feb  7 13:55:24.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-752 exec execpodns75m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Feb  7 13:55:24.737: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Feb  7 13:55:24.737: INFO: stdout: ""
  Feb  7 13:55:25.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-752 exec execpodns75m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Feb  7 13:55:25.733: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Feb  7 13:55:25.733: INFO: stdout: "externalname-service-tn9d6"
  Feb  7 13:55:25.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-752 exec execpodns75m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.137.108 80'
  Feb  7 13:55:25.843: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.137.108 80\nConnection to 10.106.137.108 80 port [tcp/http] succeeded!\n"
  Feb  7 13:55:25.843: INFO: stdout: "externalname-service-sh8n4"
  Feb  7 13:55:25.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-752 exec execpodns75m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.60.182 30319'
  Feb  7 13:55:25.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.60.182 30319\nConnection to 10.0.60.182 30319 port [tcp/*] succeeded!\n"
  Feb  7 13:55:25.957: INFO: stdout: "externalname-service-tn9d6"
  Feb  7 13:55:25.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-752 exec execpodns75m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 30319'
  Feb  7 13:55:26.084: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.58.191 30319\nConnection to 10.0.58.191 30319 port [tcp/*] succeeded!\n"
  Feb  7 13:55:26.084: INFO: stdout: "externalname-service-tn9d6"
  Feb  7 13:55:26.084: INFO: Cleaning up the ExternalName to NodePort test service
  Feb  7 13:55:26.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-752" for this suite. @ 02/07/24 13:55:26.106
• [7.596 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 02/07/24 13:55:26.111
  Feb  7 13:55:26.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replicaset @ 02/07/24 13:55:26.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:26.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:26.123
  Feb  7 13:55:26.139: INFO: Pod name sample-pod: Found 0 pods out of 1
  Feb  7 13:55:31.144: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/07/24 13:55:31.144
  STEP: Scaling up "test-rs" replicaset @ 02/07/24 13:55:31.144
  Feb  7 13:55:31.151: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 02/07/24 13:55:31.151
  Feb  7 13:55:31.159: INFO: observed ReplicaSet test-rs in namespace replicaset-4550 with ReadyReplicas 1, AvailableReplicas 1
  Feb  7 13:55:31.170: INFO: observed ReplicaSet test-rs in namespace replicaset-4550 with ReadyReplicas 1, AvailableReplicas 1
  Feb  7 13:55:31.183: INFO: observed ReplicaSet test-rs in namespace replicaset-4550 with ReadyReplicas 1, AvailableReplicas 1
  Feb  7 13:55:31.195: INFO: observed ReplicaSet test-rs in namespace replicaset-4550 with ReadyReplicas 1, AvailableReplicas 1
  Feb  7 13:55:32.031: INFO: observed ReplicaSet test-rs in namespace replicaset-4550 with ReadyReplicas 2, AvailableReplicas 2
  Feb  7 13:55:32.143: INFO: observed Replicaset test-rs in namespace replicaset-4550 with ReadyReplicas 3 found true
  Feb  7 13:55:32.143: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4550" for this suite. @ 02/07/24 13:55:32.146
• [6.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 02/07/24 13:55:32.151
  Feb  7 13:55:32.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 13:55:32.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:55:32.162
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:55:32.165
  STEP: Creating secret with name s-test-opt-del-513e0b7a-4456-4485-8ecd-bc999a6bd205 @ 02/07/24 13:55:32.17
  STEP: Creating secret with name s-test-opt-upd-4880d8b4-0dc2-4e3e-9f0d-87297a52b990 @ 02/07/24 13:55:32.174
  STEP: Creating the pod @ 02/07/24 13:55:32.177
  STEP: Deleting secret s-test-opt-del-513e0b7a-4456-4485-8ecd-bc999a6bd205 @ 02/07/24 13:55:34.205
  STEP: Updating secret s-test-opt-upd-4880d8b4-0dc2-4e3e-9f0d-87297a52b990 @ 02/07/24 13:55:34.208
  STEP: Creating secret with name s-test-opt-create-3f9bfc06-1c2f-4c57-b2e5-6f001f055c0f @ 02/07/24 13:55:34.211
  STEP: waiting to observe update in volume @ 02/07/24 13:55:34.215
  Feb  7 13:56:58.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2231" for this suite. @ 02/07/24 13:56:58.543
• [86.397 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 02/07/24 13:56:58.548
  Feb  7 13:56:58.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename limitrange @ 02/07/24 13:56:58.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:56:58.557
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:56:58.559
  STEP: Creating a LimitRange @ 02/07/24 13:56:58.562
  STEP: Setting up watch @ 02/07/24 13:56:58.562
  STEP: Submitting a LimitRange @ 02/07/24 13:56:58.664
  STEP: Verifying LimitRange creation was observed @ 02/07/24 13:56:58.668
  STEP: Fetching the LimitRange to ensure it has proper values @ 02/07/24 13:56:58.668
  Feb  7 13:56:58.670: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Feb  7 13:56:58.670: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 02/07/24 13:56:58.67
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 02/07/24 13:56:58.675
  Feb  7 13:56:58.677: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Feb  7 13:56:58.677: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 02/07/24 13:56:58.677
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 02/07/24 13:56:58.682
  Feb  7 13:56:58.684: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Feb  7 13:56:58.684: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 02/07/24 13:56:58.684
  STEP: Failing to create a Pod with more than max resources @ 02/07/24 13:56:58.686
  STEP: Updating a LimitRange @ 02/07/24 13:56:58.688
  STEP: Verifying LimitRange updating is effective @ 02/07/24 13:56:58.692
  STEP: Creating a Pod with less than former min resources @ 02/07/24 13:57:00.695
  STEP: Failing to create a Pod with more than max resources @ 02/07/24 13:57:00.7
  STEP: Deleting a LimitRange @ 02/07/24 13:57:00.702
  STEP: Verifying the LimitRange was deleted @ 02/07/24 13:57:00.708
  Feb  7 13:57:05.711: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 02/07/24 13:57:05.711
  Feb  7 13:57:05.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4324" for this suite. @ 02/07/24 13:57:05.72
• [7.178 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 02/07/24 13:57:05.726
  Feb  7 13:57:05.726: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 13:57:05.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:57:05.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:57:05.737
  Feb  7 13:57:05.748: INFO: created pod
  STEP: Saw pod success @ 02/07/24 13:57:09.756
  Feb  7 13:57:39.757: INFO: polling logs
  Feb  7 13:57:39.770: INFO: Pod logs: 
  I0207 13:57:06.267652       1 log.go:194] OK: Got token
  I0207 13:57:06.267713       1 log.go:194] validating with in-cluster discovery
  I0207 13:57:06.267973       1 log.go:194] OK: got issuer https://kubernetes.default.svc
  I0207 13:57:06.268008       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4387:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00021ead0), NotBefore:(*jwt.NumericDate)(0xc00021ebb8), IssuedAt:(*jwt.NumericDate)(0xc00021eae0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4387", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b2b4f359-c497-4e59-a9cb-22c9d451db2a"}}}
  I0207 13:57:06.276730       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0207 13:57:06.278223       1 log.go:194] OK: Validated signature on JWT
  I0207 13:57:06.278318       1 log.go:194] OK: Got valid claims from token!
  I0207 13:57:06.278385       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4387:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000505218), NotBefore:(*jwt.NumericDate)(0xc000505240), IssuedAt:(*jwt.NumericDate)(0xc000505220), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4387", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b2b4f359-c497-4e59-a9cb-22c9d451db2a"}}}

  Feb  7 13:57:39.771: INFO: completed pod
  Feb  7 13:57:39.774: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4387" for this suite. @ 02/07/24 13:57:39.776
• [34.054 seconds]
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 02/07/24 13:57:39.781
  Feb  7 13:57:39.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename init-container @ 02/07/24 13:57:39.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:57:39.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:57:39.792
  STEP: creating the pod @ 02/07/24 13:57:39.795
  Feb  7 13:57:39.795: INFO: PodSpec: initContainers in spec.initContainers
  Feb  7 13:57:42.470: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5770" for this suite. @ 02/07/24 13:57:42.474
• [2.697 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 02/07/24 13:57:42.478
  Feb  7 13:57:42.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename security-context @ 02/07/24 13:57:42.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:57:42.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:57:42.489
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 02/07/24 13:57:42.492
  STEP: Saw pod success @ 02/07/24 13:57:44.501
  Feb  7 13:57:44.503: INFO: Trying to get logs from node worker-0 pod security-context-4d1e0f0b-b3df-4f7e-8370-20911e993bae container test-container: <nil>
  STEP: delete the pod @ 02/07/24 13:57:44.508
  Feb  7 13:57:44.518: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6491" for this suite. @ 02/07/24 13:57:44.52
• [2.046 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 02/07/24 13:57:44.524
  Feb  7 13:57:44.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename disruption @ 02/07/24 13:57:44.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:57:44.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:57:44.537
  STEP: Waiting for the pdb to be processed @ 02/07/24 13:57:44.542
  STEP: Waiting for all pods to be running @ 02/07/24 13:57:46.557
  Feb  7 13:57:46.562: INFO: running pods: 0 < 3
  Feb  7 13:57:48.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8071" for this suite. @ 02/07/24 13:57:48.564
• [4.044 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 02/07/24 13:57:48.568
  Feb  7 13:57:48.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename cronjob @ 02/07/24 13:57:48.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 13:57:48.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 13:57:48.58
  STEP: Creating a suspended cronjob @ 02/07/24 13:57:48.582
  STEP: Ensuring no jobs are scheduled @ 02/07/24 13:57:48.586
  STEP: Ensuring no job exists by listing jobs explicitly @ 02/07/24 14:02:48.591
  STEP: Removing cronjob @ 02/07/24 14:02:48.593
  Feb  7 14:02:48.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2307" for this suite. @ 02/07/24 14:02:48.598
• [300.035 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 02/07/24 14:02:48.603
  Feb  7 14:02:48.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:02:48.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:02:48.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:02:48.615
  STEP: Setting up server cert @ 02/07/24 14:02:48.629
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:02:49.36
  STEP: Deploying the webhook pod @ 02/07/24 14:02:49.365
  STEP: Wait for the deployment to be ready @ 02/07/24 14:02:49.373
  Feb  7 14:02:49.379: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 02/07/24 14:02:51.387
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:02:51.396
  Feb  7 14:02:52.397: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 02/07/24 14:02:52.401
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 02/07/24 14:02:52.418
  STEP: Creating a configMap that should not be mutated @ 02/07/24 14:02:52.423
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 02/07/24 14:02:52.429
  STEP: Creating a configMap that should be mutated @ 02/07/24 14:02:52.435
  Feb  7 14:02:52.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8262" for this suite. @ 02/07/24 14:02:52.48
  STEP: Destroying namespace "webhook-markers-6744" for this suite. @ 02/07/24 14:02:52.485
• [3.887 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 02/07/24 14:02:52.491
  Feb  7 14:02:52.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename taint-single-pod @ 02/07/24 14:02:52.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:02:52.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:02:52.502
  Feb  7 14:02:52.504: INFO: Waiting up to 1m0s for all nodes to be ready
  Feb  7 14:03:52.505: INFO: Waiting for terminating namespaces to be deleted...
  Feb  7 14:03:52.508: INFO: Starting informer...
  STEP: Starting pod... @ 02/07/24 14:03:52.508
  Feb  7 14:03:52.718: INFO: Pod is running on worker-0. Tainting Node
  STEP: Trying to apply a taint on the Node @ 02/07/24 14:03:52.718
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/07/24 14:03:52.726
  STEP: Waiting short time to make sure Pod is queued for deletion @ 02/07/24 14:03:52.729
  Feb  7 14:03:52.729: INFO: Pod wasn't evicted. Proceeding
  Feb  7 14:03:52.729: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 02/07/24 14:03:52.737
  STEP: Waiting some time to make sure that toleration time passed. @ 02/07/24 14:03:52.739
  Feb  7 14:05:07.740: INFO: Pod wasn't evicted. Test successful
  Feb  7 14:05:07.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-6420" for this suite. @ 02/07/24 14:05:07.743
• [135.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 02/07/24 14:05:07.748
  Feb  7 14:05:07.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename apf @ 02/07/24 14:05:07.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:07.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:07.759
  STEP: getting /apis @ 02/07/24 14:05:07.762
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 02/07/24 14:05:07.765
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 02/07/24 14:05:07.766
  STEP: creating @ 02/07/24 14:05:07.767
  STEP: getting @ 02/07/24 14:05:07.778
  STEP: listing @ 02/07/24 14:05:07.78
  STEP: watching @ 02/07/24 14:05:07.782
  Feb  7 14:05:07.782: INFO: starting watch
  STEP: patching @ 02/07/24 14:05:07.783
  STEP: updating @ 02/07/24 14:05:07.786
  Feb  7 14:05:07.792: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 02/07/24 14:05:07.792
  STEP: patching /status @ 02/07/24 14:05:07.794
  STEP: updating /status @ 02/07/24 14:05:07.797
  STEP: deleting @ 02/07/24 14:05:07.803
  STEP: deleting a collection @ 02/07/24 14:05:07.81
  Feb  7 14:05:07.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-432" for this suite. @ 02/07/24 14:05:07.822
• [0.078 seconds]
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 02/07/24 14:05:07.826
  Feb  7 14:05:07.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:05:07.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:07.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:07.838
  STEP: creating the pod @ 02/07/24 14:05:07.84
  STEP: submitting the pod to kubernetes @ 02/07/24 14:05:07.84
  STEP: verifying the pod is in kubernetes @ 02/07/24 14:05:09.851
  STEP: updating the pod @ 02/07/24 14:05:09.853
  Feb  7 14:05:10.363: INFO: Successfully updated pod "pod-update-738c372f-1aa4-4f16-959e-b3967f216521"
  STEP: verifying the updated pod is in kubernetes @ 02/07/24 14:05:10.365
  Feb  7 14:05:10.367: INFO: Pod update OK
  Feb  7 14:05:10.367: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3249" for this suite. @ 02/07/24 14:05:10.37
• [2.547 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 02/07/24 14:05:10.374
  Feb  7 14:05:10.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 14:05:10.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:10.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:10.385
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 02/07/24 14:05:10.388
  Feb  7 14:05:10.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:05:11.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:05:16.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1488" for this suite. @ 02/07/24 14:05:16.74
• [6.370 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 02/07/24 14:05:16.744
  Feb  7 14:05:16.744: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename events @ 02/07/24 14:05:16.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:16.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:16.756
  STEP: creating a test event @ 02/07/24 14:05:16.758
  STEP: listing events in all namespaces @ 02/07/24 14:05:16.762
  STEP: listing events in test namespace @ 02/07/24 14:05:16.766
  STEP: listing events with field selection filtering on source @ 02/07/24 14:05:16.768
  STEP: listing events with field selection filtering on reportingController @ 02/07/24 14:05:16.769
  STEP: getting the test event @ 02/07/24 14:05:16.771
  STEP: patching the test event @ 02/07/24 14:05:16.773
  STEP: getting the test event @ 02/07/24 14:05:16.777
  STEP: updating the test event @ 02/07/24 14:05:16.779
  STEP: getting the test event @ 02/07/24 14:05:16.783
  STEP: deleting the test event @ 02/07/24 14:05:16.786
  STEP: listing events in all namespaces @ 02/07/24 14:05:16.789
  STEP: listing events in test namespace @ 02/07/24 14:05:16.793
  Feb  7 14:05:16.795: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4395" for this suite. @ 02/07/24 14:05:16.797
• [0.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 02/07/24 14:05:16.802
  Feb  7 14:05:16.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:05:16.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:16.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:16.812
  STEP: creating service in namespace services-1213 @ 02/07/24 14:05:16.815
  STEP: creating service affinity-clusterip in namespace services-1213 @ 02/07/24 14:05:16.815
  STEP: creating replication controller affinity-clusterip in namespace services-1213 @ 02/07/24 14:05:16.823
  I0207 14:05:16.829986      23 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-1213, replica count: 3
  I0207 14:05:19.880438      23 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 14:05:19.884: INFO: Creating new exec pod
  Feb  7 14:05:22.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-1213 exec execpod-affinitywlm2q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Feb  7 14:05:23.021: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Feb  7 14:05:23.021: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:05:23.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-1213 exec execpod-affinitywlm2q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.112.220 80'
  Feb  7 14:05:23.132: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.112.220 80\nConnection to 10.99.112.220 80 port [tcp/http] succeeded!\n"
  Feb  7 14:05:23.132: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:05:23.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-1213 exec execpod-affinitywlm2q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.99.112.220:80/ ; done'
  Feb  7 14:05:23.318: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.99.112.220:80/\n"
  Feb  7 14:05:23.318: INFO: stdout: "\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6\naffinity-clusterip-6xtv6"
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.318: INFO: Received response from host: affinity-clusterip-6xtv6
  Feb  7 14:05:23.319: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-1213, will wait for the garbage collector to delete the pods @ 02/07/24 14:05:23.325
  Feb  7 14:05:23.384: INFO: Deleting ReplicationController affinity-clusterip took: 3.412988ms
  Feb  7 14:05:23.484: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.176058ms
  Feb  7 14:05:26.299: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1213" for this suite. @ 02/07/24 14:05:26.301
• [9.502 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 02/07/24 14:05:26.305
  Feb  7 14:05:26.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename runtimeclass @ 02/07/24 14:05:26.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:26.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:26.318
  Feb  7 14:05:28.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8504" for this suite. @ 02/07/24 14:05:28.338
• [2.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 02/07/24 14:05:28.342
  Feb  7 14:05:28.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename cronjob @ 02/07/24 14:05:28.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:05:28.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:05:28.355
  STEP: Creating a cronjob @ 02/07/24 14:05:28.358
  STEP: Ensuring more than one job is running at a time @ 02/07/24 14:05:28.361
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 02/07/24 14:07:00.365
  STEP: Removing cronjob @ 02/07/24 14:07:00.367
  Feb  7 14:07:00.370: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2945" for this suite. @ 02/07/24 14:07:00.373
• [92.034 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 02/07/24 14:07:00.377
  Feb  7 14:07:00.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:07:00.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:00.391
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:00.395
  STEP: creating the pod @ 02/07/24 14:07:00.398
  STEP: submitting the pod to kubernetes @ 02/07/24 14:07:00.398
  STEP: verifying QOS class is set on the pod @ 02/07/24 14:07:00.408
  Feb  7 14:07:00.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5062" for this suite. @ 02/07/24 14:07:00.414
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 02/07/24 14:07:00.42
  Feb  7 14:07:00.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 14:07:00.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:00.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:00.432
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 02/07/24 14:07:00.434
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 02/07/24 14:07:00.434
  STEP: creating a pod to probe DNS @ 02/07/24 14:07:00.434
  STEP: submitting the pod to kubernetes @ 02/07/24 14:07:00.434
  STEP: retrieving the pod @ 02/07/24 14:07:02.445
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:07:02.448
  Feb  7 14:07:02.461: INFO: DNS probes using dns-3123/dns-test-2d486ef1-e843-4fb3-b533-466e931b7129 succeeded

  STEP: deleting the pod @ 02/07/24 14:07:02.462
  Feb  7 14:07:02.470: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3123" for this suite. @ 02/07/24 14:07:02.473
• [2.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 02/07/24 14:07:02.479
  Feb  7 14:07:02.479: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 14:07:02.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:02.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:02.49
  STEP: Creating a test headless service @ 02/07/24 14:07:02.492
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-972.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-972.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-972.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-972.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-972.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-972.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-972.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-972.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 128.70.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.70.128_udp@PTR;check="$$(dig +tcp +noall +answer +search 128.70.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.70.128_tcp@PTR;sleep 1; done
   @ 02/07/24 14:07:02.512
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-972.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-972.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-972.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-972.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-972.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-972.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-972.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-972.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-972.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 128.70.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.70.128_udp@PTR;check="$$(dig +tcp +noall +answer +search 128.70.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.70.128_tcp@PTR;sleep 1; done
   @ 02/07/24 14:07:02.512
  STEP: creating a pod to probe DNS @ 02/07/24 14:07:02.512
  STEP: submitting the pod to kubernetes @ 02/07/24 14:07:02.512
  STEP: retrieving the pod @ 02/07/24 14:07:04.533
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:07:04.535
  Feb  7 14:07:04.541: INFO: Unable to read wheezy_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:04.544: INFO: Unable to read wheezy_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:04.547: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:04.564: INFO: Unable to read jessie_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:04.566: INFO: Unable to read jessie_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:04.572: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:04.583: INFO: Lookups using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c failed for: [wheezy_udp@dns-test-service.dns-972.svc.cluster.local wheezy_tcp@dns-test-service.dns-972.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-972.svc.cluster.local jessie_udp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-972.svc.cluster.local]

  Feb  7 14:07:04.598: INFO: Pod client logs for webserver: 
  Feb  7 14:07:04.603: INFO: Pod client logs for querier: 
  Feb  7 14:07:04.607: INFO: Pod client logs for jessie-querier: 
  Feb  7 14:07:09.541: INFO: Unable to read wheezy_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:09.544: INFO: Unable to read wheezy_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:09.547: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:09.564: INFO: Unable to read jessie_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:09.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:09.584: INFO: Lookups using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c failed for: [wheezy_udp@dns-test-service.dns-972.svc.cluster.local wheezy_tcp@dns-test-service.dns-972.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-972.svc.cluster.local jessie_udp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@dns-test-service.dns-972.svc.cluster.local]

  Feb  7 14:07:09.589: INFO: Pod client logs for webserver: 
  Feb  7 14:07:09.593: INFO: Pod client logs for querier: 
  Feb  7 14:07:09.597: INFO: Pod client logs for jessie-querier: 
  Feb  7 14:07:14.542: INFO: Unable to read wheezy_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:14.545: INFO: Unable to read wheezy_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:14.565: INFO: Unable to read jessie_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:14.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:14.584: INFO: Lookups using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c failed for: [wheezy_udp@dns-test-service.dns-972.svc.cluster.local wheezy_tcp@dns-test-service.dns-972.svc.cluster.local jessie_udp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@dns-test-service.dns-972.svc.cluster.local]

  Feb  7 14:07:14.588: INFO: Pod client logs for webserver: 
  Feb  7 14:07:14.593: INFO: Pod client logs for querier: 
  Feb  7 14:07:14.597: INFO: Pod client logs for jessie-querier: 
  Feb  7 14:07:19.541: INFO: Unable to read wheezy_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:19.544: INFO: Unable to read wheezy_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:19.567: INFO: Unable to read jessie_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:19.570: INFO: Unable to read jessie_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:19.590: INFO: Lookups using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c failed for: [wheezy_udp@dns-test-service.dns-972.svc.cluster.local wheezy_tcp@dns-test-service.dns-972.svc.cluster.local jessie_udp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@dns-test-service.dns-972.svc.cluster.local]

  Feb  7 14:07:19.595: INFO: Pod client logs for webserver: 
  Feb  7 14:07:19.601: INFO: Pod client logs for querier: 
  Feb  7 14:07:19.605: INFO: Pod client logs for jessie-querier: 
  Feb  7 14:07:24.541: INFO: Unable to read wheezy_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:24.544: INFO: Unable to read wheezy_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:24.564: INFO: Unable to read jessie_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:24.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:24.583: INFO: Lookups using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c failed for: [wheezy_udp@dns-test-service.dns-972.svc.cluster.local wheezy_tcp@dns-test-service.dns-972.svc.cluster.local jessie_udp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@dns-test-service.dns-972.svc.cluster.local]

  Feb  7 14:07:24.587: INFO: Pod client logs for webserver: 
  Feb  7 14:07:24.591: INFO: Pod client logs for querier: 
  Feb  7 14:07:24.595: INFO: Pod client logs for jessie-querier: 
  Feb  7 14:07:29.540: INFO: Unable to read wheezy_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:29.543: INFO: Unable to read wheezy_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:29.562: INFO: Unable to read jessie_udp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:29.565: INFO: Unable to read jessie_tcp@dns-test-service.dns-972.svc.cluster.local from pod dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c: the server could not find the requested resource (get pods dns-test-579a3c9d-68d2-4f30-9c29-88878349053c)
  Feb  7 14:07:29.581: INFO: Lookups using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c failed for: [wheezy_udp@dns-test-service.dns-972.svc.cluster.local wheezy_tcp@dns-test-service.dns-972.svc.cluster.local jessie_udp@dns-test-service.dns-972.svc.cluster.local jessie_tcp@dns-test-service.dns-972.svc.cluster.local]

  Feb  7 14:07:29.585: INFO: Pod client logs for webserver: 
  Feb  7 14:07:29.590: INFO: Pod client logs for querier: 
  Feb  7 14:07:29.594: INFO: Pod client logs for jessie-querier: 
  Feb  7 14:07:34.582: INFO: DNS probes using dns-972/dns-test-579a3c9d-68d2-4f30-9c29-88878349053c succeeded

  STEP: deleting the pod @ 02/07/24 14:07:34.583
  STEP: deleting the test service @ 02/07/24 14:07:34.593
  STEP: deleting the test headless service @ 02/07/24 14:07:34.61
  Feb  7 14:07:34.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-972" for this suite. @ 02/07/24 14:07:34.62
• [32.145 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 02/07/24 14:07:34.624
  Feb  7 14:07:34.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:07:34.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:34.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:34.635
  STEP: validating api versions @ 02/07/24 14:07:34.638
  Feb  7 14:07:34.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-5616 api-versions'
  Feb  7 14:07:34.699: INFO: stderr: ""
  Feb  7 14:07:34.699: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautopilot.k0sproject.io/v1beta2\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nhelm.k0sproject.io/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Feb  7 14:07:34.699: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5616" for this suite. @ 02/07/24 14:07:34.702
• [0.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 02/07/24 14:07:34.706
  Feb  7 14:07:34.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename prestop @ 02/07/24 14:07:34.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:34.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:34.717
  STEP: Creating server pod server in namespace prestop-3130 @ 02/07/24 14:07:34.719
  STEP: Waiting for pods to come up. @ 02/07/24 14:07:34.724
  STEP: Creating tester pod tester in namespace prestop-3130 @ 02/07/24 14:07:36.731
  STEP: Deleting pre-stop pod @ 02/07/24 14:07:38.74
  Feb  7 14:07:43.751: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 02/07/24 14:07:43.751
  Feb  7 14:07:43.760: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-3130" for this suite. @ 02/07/24 14:07:43.763
• [9.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 02/07/24 14:07:43.769
  Feb  7 14:07:43.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:07:43.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:43.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:43.782
  STEP: Creating a ResourceQuota with terminating scope @ 02/07/24 14:07:43.784
  STEP: Ensuring ResourceQuota status is calculated @ 02/07/24 14:07:43.787
  STEP: Creating a ResourceQuota with not terminating scope @ 02/07/24 14:07:45.791
  STEP: Ensuring ResourceQuota status is calculated @ 02/07/24 14:07:45.796
  STEP: Creating a long running pod @ 02/07/24 14:07:47.798
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 02/07/24 14:07:47.806
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 02/07/24 14:07:49.809
  STEP: Deleting the pod @ 02/07/24 14:07:51.813
  STEP: Ensuring resource quota status released the pod usage @ 02/07/24 14:07:51.818
  STEP: Creating a terminating pod @ 02/07/24 14:07:53.821
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 02/07/24 14:07:53.829
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 02/07/24 14:07:55.833
  STEP: Deleting the pod @ 02/07/24 14:07:57.835
  STEP: Ensuring resource quota status released the pod usage @ 02/07/24 14:07:57.843
  Feb  7 14:07:59.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1099" for this suite. @ 02/07/24 14:07:59.849
• [16.083 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 02/07/24 14:07:59.852
  Feb  7 14:07:59.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:07:59.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:59.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:59.866
  STEP: creating a ConfigMap @ 02/07/24 14:07:59.868
  STEP: fetching the ConfigMap @ 02/07/24 14:07:59.871
  STEP: patching the ConfigMap @ 02/07/24 14:07:59.873
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 02/07/24 14:07:59.878
  STEP: deleting the ConfigMap by collection with a label selector @ 02/07/24 14:07:59.88
  STEP: listing all ConfigMaps in test namespace @ 02/07/24 14:07:59.884
  Feb  7 14:07:59.886: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5608" for this suite. @ 02/07/24 14:07:59.888
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 02/07/24 14:07:59.893
  Feb  7 14:07:59.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename conformance-tests @ 02/07/24 14:07:59.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:59.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:59.903
  STEP: Getting node addresses @ 02/07/24 14:07:59.906
  Feb  7 14:07:59.906: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Feb  7 14:07:59.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-3368" for this suite. @ 02/07/24 14:07:59.912
• [0.023 seconds]
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 02/07/24 14:07:59.915
  Feb  7 14:07:59.915: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:07:59.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:07:59.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:07:59.925
  STEP: Create set of pods @ 02/07/24 14:07:59.928
  Feb  7 14:07:59.932: INFO: created test-pod-1
  Feb  7 14:07:59.935: INFO: created test-pod-2
  Feb  7 14:07:59.939: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 02/07/24 14:07:59.939
  STEP: waiting for all pods to be deleted @ 02/07/24 14:08:01.971
  Feb  7 14:08:01.973: INFO: Pod quantity 3 is different from expected quantity 0
  Feb  7 14:08:02.974: INFO: Pod quantity 2 is different from expected quantity 0
  Feb  7 14:08:03.974: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-906" for this suite. @ 02/07/24 14:08:03.977
• [4.065 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 02/07/24 14:08:03.982
  Feb  7 14:08:03.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:08:03.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:08:03.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:08:03.993
  Feb  7 14:08:04.020: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8174" for this suite. @ 02/07/24 14:08:04.022
• [0.046 seconds]
------------------------------
SSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 02/07/24 14:08:04.027
  Feb  7 14:08:04.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 02/07/24 14:08:04.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:08:04.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:08:04.039
  STEP: Setting up the test @ 02/07/24 14:08:04.041
  STEP: Creating hostNetwork=false pod @ 02/07/24 14:08:04.041
  STEP: Creating hostNetwork=true pod @ 02/07/24 14:08:06.055
  STEP: Running the test @ 02/07/24 14:08:08.067
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 02/07/24 14:08:08.067
  Feb  7 14:08:08.067: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.068: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.068: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb  7 14:08:08.130: INFO: Exec stderr: ""
  Feb  7 14:08:08.130: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.130: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.131: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.131: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb  7 14:08:08.194: INFO: Exec stderr: ""
  Feb  7 14:08:08.194: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.194: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.194: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb  7 14:08:08.253: INFO: Exec stderr: ""
  Feb  7 14:08:08.253: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.254: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.254: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb  7 14:08:08.317: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 02/07/24 14:08:08.317
  Feb  7 14:08:08.317: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.318: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.318: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Feb  7 14:08:08.373: INFO: Exec stderr: ""
  Feb  7 14:08:08.373: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.374: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.374: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Feb  7 14:08:08.437: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 02/07/24 14:08:08.437
  Feb  7 14:08:08.437: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.438: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.438: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.438: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb  7 14:08:08.500: INFO: Exec stderr: ""
  Feb  7 14:08:08.500: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.500: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.500: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Feb  7 14:08:08.555: INFO: Exec stderr: ""
  Feb  7 14:08:08.555: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.556: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.556: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb  7 14:08:08.607: INFO: Exec stderr: ""
  Feb  7 14:08:08.607: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-602 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:08:08.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:08:08.608: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:08:08.608: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-602/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Feb  7 14:08:08.681: INFO: Exec stderr: ""
  Feb  7 14:08:08.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-602" for this suite. @ 02/07/24 14:08:08.684
• [4.660 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 02/07/24 14:08:08.688
  Feb  7 14:08:08.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:08:08.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:08:08.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:08:08.701
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 02/07/24 14:08:08.703
  STEP: Saw pod success @ 02/07/24 14:08:10.713
  Feb  7 14:08:10.715: INFO: Trying to get logs from node worker-1 pod pod-be8f1dc0-3e22-4453-b6f5-0f42f5e5b594 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:08:10.728
  Feb  7 14:08:10.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1988" for this suite. @ 02/07/24 14:08:10.74
• [2.056 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 02/07/24 14:08:10.744
  Feb  7 14:08:10.744: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:08:10.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:08:10.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:08:10.757
  Feb  7 14:08:32.804: INFO: Container started at 2024-02-07 14:08:11 +0000 UTC, pod became ready at 2024-02-07 14:08:31 +0000 UTC
  Feb  7 14:08:32.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7305" for this suite. @ 02/07/24 14:08:32.806
• [22.068 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 02/07/24 14:08:32.812
  Feb  7 14:08:32.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sysctl @ 02/07/24 14:08:32.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:08:32.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:08:32.823
  STEP: Creating a pod with one valid and two invalid sysctls @ 02/07/24 14:08:32.826
  Feb  7 14:08:32.830: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6462" for this suite. @ 02/07/24 14:08:32.833
• [0.026 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 02/07/24 14:08:32.838
  Feb  7 14:08:32.838: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 14:08:32.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:08:32.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:08:32.848
  STEP: creating the pod with failed condition @ 02/07/24 14:08:32.851
  STEP: updating the pod @ 02/07/24 14:10:32.858
  Feb  7 14:10:33.367: INFO: Successfully updated pod "var-expansion-780c483c-0c0e-4db3-bda9-9bbea5cacf9d"
  STEP: waiting for pod running @ 02/07/24 14:10:33.367
  STEP: deleting the pod gracefully @ 02/07/24 14:10:35.373
  Feb  7 14:10:35.373: INFO: Deleting pod "var-expansion-780c483c-0c0e-4db3-bda9-9bbea5cacf9d" in namespace "var-expansion-7104"
  Feb  7 14:10:35.377: INFO: Wait up to 5m0s for pod "var-expansion-780c483c-0c0e-4db3-bda9-9bbea5cacf9d" to be fully deleted
  Feb  7 14:11:07.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7104" for this suite. @ 02/07/24 14:11:07.436
• [154.603 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 02/07/24 14:11:07.441
  Feb  7 14:11:07.441: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:11:07.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:07.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:07.453
  STEP: creating service multi-endpoint-test in namespace services-237 @ 02/07/24 14:11:07.456
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-237 to expose endpoints map[] @ 02/07/24 14:11:07.466
  Feb  7 14:11:07.468: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  Feb  7 14:11:08.475: INFO: successfully validated that service multi-endpoint-test in namespace services-237 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-237 @ 02/07/24 14:11:08.475
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-237 to expose endpoints map[pod1:[100]] @ 02/07/24 14:11:10.487
  Feb  7 14:11:10.494: INFO: successfully validated that service multi-endpoint-test in namespace services-237 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-237 @ 02/07/24 14:11:10.494
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-237 to expose endpoints map[pod1:[100] pod2:[101]] @ 02/07/24 14:11:12.505
  Feb  7 14:11:12.514: INFO: successfully validated that service multi-endpoint-test in namespace services-237 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 02/07/24 14:11:12.514
  Feb  7 14:11:12.514: INFO: Creating new exec pod
  Feb  7 14:11:15.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-237 exec execpodf7qdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Feb  7 14:11:15.645: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Feb  7 14:11:15.645: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:11:15.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-237 exec execpodf7qdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.97.85 80'
  Feb  7 14:11:15.764: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.97.85 80\nConnection to 10.98.97.85 80 port [tcp/http] succeeded!\n"
  Feb  7 14:11:15.764: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:11:15.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-237 exec execpodf7qdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Feb  7 14:11:15.877: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Feb  7 14:11:15.877: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:11:15.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-237 exec execpodf7qdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.97.85 81'
  Feb  7 14:11:15.993: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.97.85 81\nConnection to 10.98.97.85 81 port [tcp/*] succeeded!\n"
  Feb  7 14:11:15.993: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-237 @ 02/07/24 14:11:15.993
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-237 to expose endpoints map[pod2:[101]] @ 02/07/24 14:11:16.002
  Feb  7 14:11:16.013: INFO: successfully validated that service multi-endpoint-test in namespace services-237 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-237 @ 02/07/24 14:11:16.013
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-237 to expose endpoints map[] @ 02/07/24 14:11:16.02
  Feb  7 14:11:17.033: INFO: successfully validated that service multi-endpoint-test in namespace services-237 exposes endpoints map[]
  Feb  7 14:11:17.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-237" for this suite. @ 02/07/24 14:11:17.048
• [9.611 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 02/07/24 14:11:17.052
  Feb  7 14:11:17.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 14:11:17.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:17.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:17.064
  Feb  7 14:11:17.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  W0207 14:11:19.601410      23 warnings.go:70] unknown field "alpha"
  W0207 14:11:19.601435      23 warnings.go:70] unknown field "beta"
  W0207 14:11:19.601441      23 warnings.go:70] unknown field "delta"
  W0207 14:11:19.601447      23 warnings.go:70] unknown field "epsilon"
  W0207 14:11:19.601453      23 warnings.go:70] unknown field "gamma"
  Feb  7 14:11:20.125: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2767" for this suite. @ 02/07/24 14:11:20.127
• [3.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 02/07/24 14:11:20.133
  Feb  7 14:11:20.133: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename subpath @ 02/07/24 14:11:20.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:20.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:20.145
  STEP: Setting up data @ 02/07/24 14:11:20.148
  STEP: Creating pod pod-subpath-test-projected-mfsn @ 02/07/24 14:11:20.154
  STEP: Creating a pod to test atomic-volume-subpath @ 02/07/24 14:11:20.154
  STEP: Saw pod success @ 02/07/24 14:11:42.196
  Feb  7 14:11:42.198: INFO: Trying to get logs from node worker-0 pod pod-subpath-test-projected-mfsn container test-container-subpath-projected-mfsn: <nil>
  STEP: delete the pod @ 02/07/24 14:11:42.21
  STEP: Deleting pod pod-subpath-test-projected-mfsn @ 02/07/24 14:11:42.22
  Feb  7 14:11:42.220: INFO: Deleting pod "pod-subpath-test-projected-mfsn" in namespace "subpath-1719"
  Feb  7 14:11:42.222: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1719" for this suite. @ 02/07/24 14:11:42.224
• [22.096 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 02/07/24 14:11:42.23
  Feb  7 14:11:42.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:11:42.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:42.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:42.241
  STEP: create deployment with httpd image @ 02/07/24 14:11:42.244
  Feb  7 14:11:42.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9089 create -f -'
  Feb  7 14:11:42.336: INFO: stderr: ""
  Feb  7 14:11:42.336: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 02/07/24 14:11:42.336
  Feb  7 14:11:42.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9089 diff -f -'
  Feb  7 14:11:42.456: INFO: rc: 1
  Feb  7 14:11:42.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9089 delete -f -'
  Feb  7 14:11:42.517: INFO: stderr: ""
  Feb  7 14:11:42.517: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Feb  7 14:11:42.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9089" for this suite. @ 02/07/24 14:11:42.521
• [0.295 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 02/07/24 14:11:42.525
  Feb  7 14:11:42.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replication-controller @ 02/07/24 14:11:42.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:42.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:42.537
  STEP: creating a ReplicationController @ 02/07/24 14:11:42.541
  STEP: waiting for RC to be added @ 02/07/24 14:11:42.549
  STEP: waiting for available Replicas @ 02/07/24 14:11:42.549
  STEP: patching ReplicationController @ 02/07/24 14:11:44.942
  STEP: waiting for RC to be modified @ 02/07/24 14:11:44.948
  STEP: patching ReplicationController status @ 02/07/24 14:11:44.948
  STEP: waiting for RC to be modified @ 02/07/24 14:11:44.952
  STEP: waiting for available Replicas @ 02/07/24 14:11:44.952
  STEP: fetching ReplicationController status @ 02/07/24 14:11:44.957
  STEP: patching ReplicationController scale @ 02/07/24 14:11:44.959
  STEP: waiting for RC to be modified @ 02/07/24 14:11:44.963
  STEP: waiting for ReplicationController's scale to be the max amount @ 02/07/24 14:11:44.963
  STEP: fetching ReplicationController; ensuring that it's patched @ 02/07/24 14:11:46.774
  STEP: updating ReplicationController status @ 02/07/24 14:11:46.775
  STEP: waiting for RC to be modified @ 02/07/24 14:11:46.779
  STEP: listing all ReplicationControllers @ 02/07/24 14:11:46.779
  STEP: checking that ReplicationController has expected values @ 02/07/24 14:11:46.781
  STEP: deleting ReplicationControllers by collection @ 02/07/24 14:11:46.781
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 02/07/24 14:11:46.787
  Feb  7 14:11:46.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0207 14:11:46.821043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9225" for this suite. @ 02/07/24 14:11:46.823
• [4.302 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 02/07/24 14:11:46.827
  Feb  7 14:11:46.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:11:46.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:46.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:46.838
  STEP: Creating secret with name secret-test-map-b813e09e-71d4-461d-8ad3-43101d0a5d3f @ 02/07/24 14:11:46.84
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:11:46.843
  E0207 14:11:47.822140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:48.822324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:49.823302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:50.823391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:11:50.856
  Feb  7 14:11:50.858: INFO: Trying to get logs from node worker-0 pod pod-secrets-c176a0a4-a47e-4789-ba6f-d230900228df container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:11:50.867
  Feb  7 14:11:50.877: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6747" for this suite. @ 02/07/24 14:11:50.879
• [4.055 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 02/07/24 14:11:50.883
  Feb  7 14:11:50.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename certificates @ 02/07/24 14:11:50.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:50.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:50.895
  STEP: getting /apis @ 02/07/24 14:11:51.16
  STEP: getting /apis/certificates.k8s.io @ 02/07/24 14:11:51.163
  STEP: getting /apis/certificates.k8s.io/v1 @ 02/07/24 14:11:51.164
  STEP: creating @ 02/07/24 14:11:51.165
  STEP: getting @ 02/07/24 14:11:51.176
  STEP: listing @ 02/07/24 14:11:51.178
  STEP: watching @ 02/07/24 14:11:51.18
  Feb  7 14:11:51.180: INFO: starting watch
  STEP: patching @ 02/07/24 14:11:51.183
  STEP: updating @ 02/07/24 14:11:51.188
  Feb  7 14:11:51.192: INFO: waiting for watch events with expected annotations
  Feb  7 14:11:51.192: INFO: saw patched and updated annotations
  STEP: getting /approval @ 02/07/24 14:11:51.192
  STEP: patching /approval @ 02/07/24 14:11:51.194
  STEP: updating /approval @ 02/07/24 14:11:51.199
  STEP: getting /status @ 02/07/24 14:11:51.204
  STEP: patching /status @ 02/07/24 14:11:51.206
  STEP: updating /status @ 02/07/24 14:11:51.211
  STEP: deleting @ 02/07/24 14:11:51.217
  STEP: deleting a collection @ 02/07/24 14:11:51.223
  Feb  7 14:11:51.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-6305" for this suite. @ 02/07/24 14:11:51.233
• [0.355 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 02/07/24 14:11:51.239
  Feb  7 14:11:51.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:11:51.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:51.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:51.249
  STEP: Creating a pod to test downward api env vars @ 02/07/24 14:11:51.252
  E0207 14:11:51.824167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:52.824720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:11:53.263
  Feb  7 14:11:53.265: INFO: Trying to get logs from node worker-0 pod downward-api-c8e7fdbc-ccc6-4db0-bf35-e6dbbe73c503 container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 14:11:53.272
  Feb  7 14:11:53.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8827" for this suite. @ 02/07/24 14:11:53.283
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 02/07/24 14:11:53.288
  Feb  7 14:11:53.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:11:53.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:11:53.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:11:53.299
  STEP: Creating service test in namespace statefulset-1312 @ 02/07/24 14:11:53.302
  STEP: Creating a new StatefulSet @ 02/07/24 14:11:53.305
  Feb  7 14:11:53.312: INFO: Found 0 stateful pods, waiting for 3
  E0207 14:11:53.825380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:54.825698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:55.826112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:56.826562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:57.826937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:58.827128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:11:59.827326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:00.827510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:01.827696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:02.827976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:12:03.314: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:12:03.314: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:12:03.314: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:12:03.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-1312 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:12:03.442: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:12:03.442: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:12:03.442: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0207 14:12:03.828059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:04.828189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:05.828392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:06.828861      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:07.829770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:08.830137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:09.830280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:10.830587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:11.830697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:12.830985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 02/07/24 14:12:13.449
  Feb  7 14:12:13.465: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 02/07/24 14:12:13.465
  E0207 14:12:13.831139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:14.831225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:15.831341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:16.832330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:17.832452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:18.832661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:19.832857      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:20.833194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:21.834145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:22.834609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 02/07/24 14:12:23.47
  Feb  7 14:12:23.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-1312 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:12:23.585: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:12:23.585: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:12:23.585: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0207 14:12:23.835657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:24.835767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:25.835870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:26.836134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:27.837169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:28.838183      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:29.838507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:30.838387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:31.838491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:32.838790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:33.838994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:34.839113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:35.839300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:36.839666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:37.839966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:38.840138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:39.840663      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:40.840833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:41.841026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:42.841342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:43.842109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:44.842222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:45.842363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:46.842486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:47.842825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:48.843016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:49.843223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:50.843343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:51.843503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:52.843773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 02/07/24 14:12:53.595
  Feb  7 14:12:53.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-1312 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:12:53.725: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:12:53.725: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:12:53.725: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0207 14:12:53.844280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:54.844473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:55.844581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:56.845588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:57.845883      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:58.846063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:12:59.846255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:00.846553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:01.846759      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:02.847092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:03.747: INFO: Updating stateful set ss2
  E0207 14:13:03.848119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:04.848310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:05.848503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:06.849040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:07.849179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:08.849465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:09.849579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:10.850246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:11.850433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:12.850555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 02/07/24 14:13:13.752
  Feb  7 14:13:13.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-1312 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0207 14:13:13.851134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:13.881: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:13:13.881: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:13:13.881: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0207 14:13:14.851253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:15.852120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:16.852417      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:17.852761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:18.852889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:19.853107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:20.853246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:21.854115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:22.855226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:23.855352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:23.891: INFO: Deleting all statefulset in ns statefulset-1312
  Feb  7 14:13:23.893: INFO: Scaling statefulset ss2 to 0
  E0207 14:13:24.855756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:25.855951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:26.856094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:27.856469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:28.856652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:29.856848      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:30.857056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:31.858131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:32.858517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:33.858626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:33.902: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:13:33.904: INFO: Deleting statefulset ss2
  Feb  7 14:13:33.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1312" for this suite. @ 02/07/24 14:13:33.915
• [100.630 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 02/07/24 14:13:33.919
  Feb  7 14:13:33.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:13:33.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:13:33.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:13:33.93
  STEP: creating pod @ 02/07/24 14:13:33.932
  E0207 14:13:34.859311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:35.859542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:35.946: INFO: Pod pod-hostip-9f595276-34b5-45a8-920a-24ab5edfdfbf has hostIP: 10.0.60.182
  Feb  7 14:13:35.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-596" for this suite. @ 02/07/24 14:13:35.948
• [2.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 02/07/24 14:13:35.952
  Feb  7 14:13:35.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pv @ 02/07/24 14:13:35.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:13:35.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:13:35.965
  STEP: Creating initial PV and PVC @ 02/07/24 14:13:35.967
  Feb  7 14:13:35.967: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-4003" @ 02/07/24 14:13:35.978
  STEP: Listing PVCs in namespace "pv-4003" @ 02/07/24 14:13:35.98
  STEP: Reading "pvc-vv5bp" Status @ 02/07/24 14:13:35.982
  STEP: Reading "pv-4003-pmp6z" Status @ 02/07/24 14:13:35.986
  STEP: Patching "pvc-vv5bp" Status @ 02/07/24 14:13:35.991
  STEP: Patching "pv-4003-pmp6z" Status @ 02/07/24 14:13:35.994
  STEP: Updating "pvc-vv5bp" Status @ 02/07/24 14:13:36.006
  STEP: Updating "pv-4003-pmp6z" Status @ 02/07/24 14:13:36.028
  Feb  7 14:13:36.033: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Feb  7 14:13:36.033: INFO: Deleting PersistentVolumeClaim "pvc-vv5bp"
  Feb  7 14:13:36.038: INFO: Deleting PersistentVolume "pv-4003-pmp6z"
  Feb  7 14:13:36.042: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-4003" for this suite. @ 02/07/24 14:13:36.044
• [0.096 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 02/07/24 14:13:36.049
  Feb  7 14:13:36.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:13:36.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:13:36.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:13:36.063
  STEP: Creating a pod to test emptydir volume type on node default medium @ 02/07/24 14:13:36.066
  E0207 14:13:36.860599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:37.861064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:38.861480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:39.861605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:13:40.081
  Feb  7 14:13:40.083: INFO: Trying to get logs from node worker-0 pod pod-cce4dfb8-a9c4-4fa5-a641-2faa3d4df6a9 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:13:40.097
  Feb  7 14:13:40.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7206" for this suite. @ 02/07/24 14:13:40.108
• [4.063 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 02/07/24 14:13:40.112
  Feb  7 14:13:40.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:13:40.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:13:40.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:13:40.124
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 02/07/24 14:13:40.127
  E0207 14:13:40.861714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:41.862141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:42.862719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:43.862934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:13:44.14
  Feb  7 14:13:44.142: INFO: Trying to get logs from node worker-0 pod pod-775bc96c-b3bb-4089-921a-e01a009a79a0 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:13:44.15
  Feb  7 14:13:44.159: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6952" for this suite. @ 02/07/24 14:13:44.162
• [4.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 02/07/24 14:13:44.168
  Feb  7 14:13:44.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 14:13:44.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:13:44.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:13:44.181
  Feb  7 14:13:44.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:13:44.863774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 02/07/24 14:13:45.491
  Feb  7 14:13:45.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 create -f -'
  E0207 14:13:45.864787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:46.865067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:47.566: INFO: stderr: ""
  Feb  7 14:13:47.566: INFO: stdout: "e2e-test-crd-publish-openapi-9979-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Feb  7 14:13:47.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 delete e2e-test-crd-publish-openapi-9979-crds test-foo'
  Feb  7 14:13:47.627: INFO: stderr: ""
  Feb  7 14:13:47.627: INFO: stdout: "e2e-test-crd-publish-openapi-9979-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Feb  7 14:13:47.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 apply -f -'
  Feb  7 14:13:47.694: INFO: stderr: ""
  Feb  7 14:13:47.694: INFO: stdout: "e2e-test-crd-publish-openapi-9979-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Feb  7 14:13:47.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 delete e2e-test-crd-publish-openapi-9979-crds test-foo'
  Feb  7 14:13:47.754: INFO: stderr: ""
  Feb  7 14:13:47.754: INFO: stdout: "e2e-test-crd-publish-openapi-9979-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 02/07/24 14:13:47.754
  Feb  7 14:13:47.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 create -f -'
  Feb  7 14:13:47.813: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 02/07/24 14:13:47.813
  Feb  7 14:13:47.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 create -f -'
  E0207 14:13:47.865376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:47.874: INFO: rc: 1
  Feb  7 14:13:47.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 apply -f -'
  Feb  7 14:13:47.940: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 02/07/24 14:13:47.94
  Feb  7 14:13:47.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 create -f -'
  Feb  7 14:13:48.000: INFO: rc: 1
  Feb  7 14:13:48.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 --namespace=crd-publish-openapi-7006 apply -f -'
  Feb  7 14:13:48.063: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 02/07/24 14:13:48.064
  Feb  7 14:13:48.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 explain e2e-test-crd-publish-openapi-9979-crds'
  Feb  7 14:13:48.121: INFO: stderr: ""
  Feb  7 14:13:48.122: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9979-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 02/07/24 14:13:48.122
  Feb  7 14:13:48.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 explain e2e-test-crd-publish-openapi-9979-crds.metadata'
  Feb  7 14:13:48.181: INFO: stderr: ""
  Feb  7 14:13:48.181: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9979-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Feb  7 14:13:48.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 explain e2e-test-crd-publish-openapi-9979-crds.spec'
  Feb  7 14:13:48.239: INFO: stderr: ""
  Feb  7 14:13:48.239: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9979-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Feb  7 14:13:48.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 explain e2e-test-crd-publish-openapi-9979-crds.spec.bars'
  Feb  7 14:13:48.297: INFO: stderr: ""
  Feb  7 14:13:48.297: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9979-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 02/07/24 14:13:48.298
  Feb  7 14:13:48.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-7006 explain e2e-test-crd-publish-openapi-9979-crds.spec.bars2'
  Feb  7 14:13:48.355: INFO: rc: 1
  E0207 14:13:48.865662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:13:49.635: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7006" for this suite. @ 02/07/24 14:13:49.642
• [5.479 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 02/07/24 14:13:49.647
  Feb  7 14:13:49.647: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename subpath @ 02/07/24 14:13:49.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:13:49.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:13:49.658
  STEP: Setting up data @ 02/07/24 14:13:49.661
  STEP: Creating pod pod-subpath-test-configmap-9wpw @ 02/07/24 14:13:49.667
  STEP: Creating a pod to test atomic-volume-subpath @ 02/07/24 14:13:49.667
  E0207 14:13:49.866426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:50.866611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:51.867477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:52.867856      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:53.868571      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:54.869190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:55.869311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:56.869604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:57.870366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:58.870487      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:13:59.870815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:00.871039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:01.871768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:02.872076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:03.872496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:04.872673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:05.873591      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:06.873909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:07.874581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:08.874781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:09.875544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:10.876027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:11.876864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:12.877068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:14:13.713
  Feb  7 14:14:13.715: INFO: Trying to get logs from node worker-0 pod pod-subpath-test-configmap-9wpw container test-container-subpath-configmap-9wpw: <nil>
  STEP: delete the pod @ 02/07/24 14:14:13.721
  STEP: Deleting pod pod-subpath-test-configmap-9wpw @ 02/07/24 14:14:13.731
  Feb  7 14:14:13.731: INFO: Deleting pod "pod-subpath-test-configmap-9wpw" in namespace "subpath-3580"
  Feb  7 14:14:13.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3580" for this suite. @ 02/07/24 14:14:13.735
• [24.091 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 02/07/24 14:14:13.739
  Feb  7 14:14:13.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/07/24 14:14:13.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:13.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:13.752
  STEP: create the container to handle the HTTPGet hook request. @ 02/07/24 14:14:13.757
  E0207 14:14:13.878041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:14.878247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/07/24 14:14:15.771
  E0207 14:14:15.879296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:16.879603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 02/07/24 14:14:17.782
  STEP: delete the pod with lifecycle hook @ 02/07/24 14:14:17.796
  E0207 14:14:17.880248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:18.880389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:14:19.806: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9973" for this suite. @ 02/07/24 14:14:19.809
• [6.074 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 02/07/24 14:14:19.813
  Feb  7 14:14:19.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:14:19.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:19.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:19.826
  STEP: creating an Endpoint @ 02/07/24 14:14:19.83
  STEP: waiting for available Endpoint @ 02/07/24 14:14:19.833
  STEP: listing all Endpoints @ 02/07/24 14:14:19.834
  STEP: updating the Endpoint @ 02/07/24 14:14:19.837
  STEP: fetching the Endpoint @ 02/07/24 14:14:19.842
  STEP: patching the Endpoint @ 02/07/24 14:14:19.844
  STEP: fetching the Endpoint @ 02/07/24 14:14:19.85
  STEP: deleting the Endpoint by Collection @ 02/07/24 14:14:19.852
  STEP: waiting for Endpoint deletion @ 02/07/24 14:14:19.856
  STEP: fetching the Endpoint @ 02/07/24 14:14:19.857
  Feb  7 14:14:19.859: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5323" for this suite. @ 02/07/24 14:14:19.861
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 02/07/24 14:14:19.865
  Feb  7 14:14:19.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename discovery @ 02/07/24 14:14:19.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:19.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:19.876
  STEP: Setting up server cert @ 02/07/24 14:14:19.879
  E0207 14:14:19.880454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:14:20.291: INFO: Checking APIGroup: apiregistration.k8s.io
  Feb  7 14:14:20.292: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Feb  7 14:14:20.292: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Feb  7 14:14:20.292: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Feb  7 14:14:20.292: INFO: Checking APIGroup: apps
  Feb  7 14:14:20.293: INFO: PreferredVersion.GroupVersion: apps/v1
  Feb  7 14:14:20.293: INFO: Versions found [{apps/v1 v1}]
  Feb  7 14:14:20.293: INFO: apps/v1 matches apps/v1
  Feb  7 14:14:20.293: INFO: Checking APIGroup: events.k8s.io
  Feb  7 14:14:20.294: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Feb  7 14:14:20.294: INFO: Versions found [{events.k8s.io/v1 v1}]
  Feb  7 14:14:20.294: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Feb  7 14:14:20.294: INFO: Checking APIGroup: authentication.k8s.io
  Feb  7 14:14:20.295: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Feb  7 14:14:20.295: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Feb  7 14:14:20.295: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Feb  7 14:14:20.295: INFO: Checking APIGroup: authorization.k8s.io
  Feb  7 14:14:20.296: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Feb  7 14:14:20.296: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Feb  7 14:14:20.296: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Feb  7 14:14:20.296: INFO: Checking APIGroup: autoscaling
  Feb  7 14:14:20.297: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Feb  7 14:14:20.297: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Feb  7 14:14:20.297: INFO: autoscaling/v2 matches autoscaling/v2
  Feb  7 14:14:20.297: INFO: Checking APIGroup: batch
  Feb  7 14:14:20.298: INFO: PreferredVersion.GroupVersion: batch/v1
  Feb  7 14:14:20.298: INFO: Versions found [{batch/v1 v1}]
  Feb  7 14:14:20.298: INFO: batch/v1 matches batch/v1
  Feb  7 14:14:20.298: INFO: Checking APIGroup: certificates.k8s.io
  Feb  7 14:14:20.299: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Feb  7 14:14:20.299: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Feb  7 14:14:20.299: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Feb  7 14:14:20.299: INFO: Checking APIGroup: networking.k8s.io
  Feb  7 14:14:20.299: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Feb  7 14:14:20.300: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Feb  7 14:14:20.300: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Feb  7 14:14:20.300: INFO: Checking APIGroup: policy
  Feb  7 14:14:20.300: INFO: PreferredVersion.GroupVersion: policy/v1
  Feb  7 14:14:20.300: INFO: Versions found [{policy/v1 v1}]
  Feb  7 14:14:20.300: INFO: policy/v1 matches policy/v1
  Feb  7 14:14:20.300: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Feb  7 14:14:20.301: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Feb  7 14:14:20.301: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Feb  7 14:14:20.301: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Feb  7 14:14:20.301: INFO: Checking APIGroup: storage.k8s.io
  Feb  7 14:14:20.302: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Feb  7 14:14:20.302: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Feb  7 14:14:20.302: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Feb  7 14:14:20.302: INFO: Checking APIGroup: admissionregistration.k8s.io
  Feb  7 14:14:20.303: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Feb  7 14:14:20.303: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Feb  7 14:14:20.303: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Feb  7 14:14:20.303: INFO: Checking APIGroup: apiextensions.k8s.io
  Feb  7 14:14:20.304: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Feb  7 14:14:20.304: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Feb  7 14:14:20.304: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Feb  7 14:14:20.304: INFO: Checking APIGroup: scheduling.k8s.io
  Feb  7 14:14:20.305: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Feb  7 14:14:20.305: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Feb  7 14:14:20.305: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Feb  7 14:14:20.305: INFO: Checking APIGroup: coordination.k8s.io
  Feb  7 14:14:20.306: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Feb  7 14:14:20.306: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Feb  7 14:14:20.306: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Feb  7 14:14:20.306: INFO: Checking APIGroup: node.k8s.io
  Feb  7 14:14:20.307: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Feb  7 14:14:20.307: INFO: Versions found [{node.k8s.io/v1 v1}]
  Feb  7 14:14:20.307: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Feb  7 14:14:20.307: INFO: Checking APIGroup: discovery.k8s.io
  Feb  7 14:14:20.308: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Feb  7 14:14:20.308: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Feb  7 14:14:20.308: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Feb  7 14:14:20.308: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Feb  7 14:14:20.309: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  Feb  7 14:14:20.309: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  Feb  7 14:14:20.309: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  Feb  7 14:14:20.309: INFO: Checking APIGroup: helm.k0sproject.io
  Feb  7 14:14:20.309: INFO: PreferredVersion.GroupVersion: helm.k0sproject.io/v1beta1
  Feb  7 14:14:20.309: INFO: Versions found [{helm.k0sproject.io/v1beta1 v1beta1}]
  Feb  7 14:14:20.309: INFO: helm.k0sproject.io/v1beta1 matches helm.k0sproject.io/v1beta1
  Feb  7 14:14:20.309: INFO: Checking APIGroup: autopilot.k0sproject.io
  Feb  7 14:14:20.310: INFO: PreferredVersion.GroupVersion: autopilot.k0sproject.io/v1beta2
  Feb  7 14:14:20.310: INFO: Versions found [{autopilot.k0sproject.io/v1beta2 v1beta2}]
  Feb  7 14:14:20.310: INFO: autopilot.k0sproject.io/v1beta2 matches autopilot.k0sproject.io/v1beta2
  Feb  7 14:14:20.310: INFO: Checking APIGroup: metrics.k8s.io
  Feb  7 14:14:20.311: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Feb  7 14:14:20.311: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Feb  7 14:14:20.311: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Feb  7 14:14:20.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-9906" for this suite. @ 02/07/24 14:14:20.314
• [0.453 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 02/07/24 14:14:20.318
  Feb  7 14:14:20.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:14:20.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:20.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:20.331
  STEP: Creating Pod @ 02/07/24 14:14:20.333
  E0207 14:14:20.881464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:21.881626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 02/07/24 14:14:22.344
  Feb  7 14:14:22.344: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1736 PodName:pod-sharedvolume-a075f7cc-b5b3-4703-a5d7-e817658b421c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:14:22.344: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:14:22.345: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:14:22.345: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-1736/pods/pod-sharedvolume-a075f7cc-b5b3-4703-a5d7-e817658b421c/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Feb  7 14:14:22.406: INFO: Exec stderr: ""
  Feb  7 14:14:22.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1736" for this suite. @ 02/07/24 14:14:22.409
• [2.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 02/07/24 14:14:22.414
  Feb  7 14:14:22.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:14:22.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:22.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:22.425
  STEP: Creating projection with secret that has name projected-secret-test-map-d6655ab8-d926-4856-98a8-0ba94843aae8 @ 02/07/24 14:14:22.427
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:14:22.43
  E0207 14:14:22.882543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:23.882960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:14:24.441
  Feb  7 14:14:24.443: INFO: Trying to get logs from node worker-0 pod pod-projected-secrets-c4a7f577-867f-48df-a3d2-0049371e6eda container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:14:24.449
  Feb  7 14:14:24.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4739" for this suite. @ 02/07/24 14:14:24.46
• [2.050 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 02/07/24 14:14:24.463
  Feb  7 14:14:24.464: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:14:24.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:24.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:24.474
  STEP: Setting up server cert @ 02/07/24 14:14:24.487
  E0207 14:14:24.883652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:14:24.935
  STEP: Deploying the webhook pod @ 02/07/24 14:14:24.94
  STEP: Wait for the deployment to be ready @ 02/07/24 14:14:24.951
  Feb  7 14:14:24.961: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:14:25.884728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:26.885252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:14:26.969
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:14:26.977
  E0207 14:14:27.885624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:14:27.977: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb  7 14:14:27.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 02/07/24 14:14:28.489
  STEP: Creating a custom resource that should be denied by the webhook @ 02/07/24 14:14:28.504
  E0207 14:14:28.885697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:29.885916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 02/07/24 14:14:30.528
  STEP: Updating the custom resource with disallowed data should be denied @ 02/07/24 14:14:30.534
  STEP: Deleting the custom resource should be denied @ 02/07/24 14:14:30.543
  STEP: Remove the offending key and value from the custom resource data @ 02/07/24 14:14:30.549
  STEP: Deleting the updated custom resource should be successful @ 02/07/24 14:14:30.557
  E0207 14:14:30.886689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:14:31.105: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3774" for this suite. @ 02/07/24 14:14:31.107
  STEP: Destroying namespace "webhook-markers-657" for this suite. @ 02/07/24 14:14:31.112
• [6.653 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 02/07/24 14:14:31.117
  Feb  7 14:14:31.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:14:31.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:31.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:31.129
  STEP: Creating projection with secret that has name projected-secret-test-bed6f472-93e4-433c-8671-7536a7e7880c @ 02/07/24 14:14:31.132
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:14:31.135
  E0207 14:14:31.887231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:32.887574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:33.887705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:34.887932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:14:35.148
  Feb  7 14:14:35.150: INFO: Trying to get logs from node worker-0 pod pod-projected-secrets-5a63d7f0-b886-4ebe-94a9-ab57d81c6b20 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:14:35.156
  Feb  7 14:14:35.166: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5812" for this suite. @ 02/07/24 14:14:35.168
• [4.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 02/07/24 14:14:35.173
  Feb  7 14:14:35.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:14:35.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:35.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:35.186
  STEP: Setting up server cert @ 02/07/24 14:14:35.201
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:14:35.477
  STEP: Deploying the webhook pod @ 02/07/24 14:14:35.481
  STEP: Wait for the deployment to be ready @ 02/07/24 14:14:35.491
  Feb  7 14:14:35.495: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:14:35.888946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:36.889067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:14:37.503
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:14:37.515
  E0207 14:14:37.889705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:14:38.515: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 02/07/24 14:14:38.519
  STEP: create a pod @ 02/07/24 14:14:38.535
  E0207 14:14:38.890108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:39.890309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 02/07/24 14:14:40.543
  Feb  7 14:14:40.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=webhook-3310 attach --namespace=webhook-3310 to-be-attached-pod -i -c=container1'
  Feb  7 14:14:40.615: INFO: rc: 1
  Feb  7 14:14:40.642: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3310" for this suite. @ 02/07/24 14:14:40.646
  STEP: Destroying namespace "webhook-markers-9510" for this suite. @ 02/07/24 14:14:40.651
• [5.484 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 02/07/24 14:14:40.657
  Feb  7 14:14:40.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 14:14:40.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:40.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:40.668
  Feb  7 14:14:40.683: INFO: created pod pod-service-account-defaultsa
  Feb  7 14:14:40.683: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Feb  7 14:14:40.690: INFO: created pod pod-service-account-mountsa
  Feb  7 14:14:40.690: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Feb  7 14:14:40.695: INFO: created pod pod-service-account-nomountsa
  Feb  7 14:14:40.695: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Feb  7 14:14:40.703: INFO: created pod pod-service-account-defaultsa-mountspec
  Feb  7 14:14:40.703: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Feb  7 14:14:40.709: INFO: created pod pod-service-account-mountsa-mountspec
  Feb  7 14:14:40.709: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Feb  7 14:14:40.716: INFO: created pod pod-service-account-nomountsa-mountspec
  Feb  7 14:14:40.716: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Feb  7 14:14:40.724: INFO: created pod pod-service-account-defaultsa-nomountspec
  Feb  7 14:14:40.724: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Feb  7 14:14:40.734: INFO: created pod pod-service-account-mountsa-nomountspec
  Feb  7 14:14:40.734: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Feb  7 14:14:40.741: INFO: created pod pod-service-account-nomountsa-nomountspec
  Feb  7 14:14:40.741: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Feb  7 14:14:40.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-393" for this suite. @ 02/07/24 14:14:40.745
• [0.096 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 02/07/24 14:14:40.772
  Feb  7 14:14:40.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename ingress @ 02/07/24 14:14:40.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:40.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:40.785
  STEP: getting /apis @ 02/07/24 14:14:40.788
  STEP: getting /apis/networking.k8s.io @ 02/07/24 14:14:40.792
  STEP: getting /apis/networking.k8s.iov1 @ 02/07/24 14:14:40.793
  STEP: creating @ 02/07/24 14:14:40.796
  STEP: getting @ 02/07/24 14:14:40.806
  STEP: listing @ 02/07/24 14:14:40.808
  STEP: watching @ 02/07/24 14:14:40.81
  Feb  7 14:14:40.810: INFO: starting watch
  STEP: cluster-wide listing @ 02/07/24 14:14:40.811
  STEP: cluster-wide watching @ 02/07/24 14:14:40.813
  Feb  7 14:14:40.814: INFO: starting watch
  STEP: patching @ 02/07/24 14:14:40.815
  STEP: updating @ 02/07/24 14:14:40.819
  Feb  7 14:14:40.828: INFO: waiting for watch events with expected annotations
  Feb  7 14:14:40.829: INFO: saw patched and updated annotations
  STEP: patching /status @ 02/07/24 14:14:40.829
  STEP: updating /status @ 02/07/24 14:14:40.834
  STEP: get /status @ 02/07/24 14:14:40.84
  STEP: deleting @ 02/07/24 14:14:40.847
  STEP: deleting a collection @ 02/07/24 14:14:40.857
  Feb  7 14:14:40.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-1377" for this suite. @ 02/07/24 14:14:40.869
• [0.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 02/07/24 14:14:40.89
  Feb  7 14:14:40.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename events @ 02/07/24 14:14:40.891
  E0207 14:14:40.891793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:40.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:40.902
  STEP: Create set of events @ 02/07/24 14:14:40.907
  Feb  7 14:14:40.910: INFO: created test-event-1
  Feb  7 14:14:40.917: INFO: created test-event-2
  Feb  7 14:14:40.922: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 02/07/24 14:14:40.922
  STEP: delete collection of events @ 02/07/24 14:14:40.925
  Feb  7 14:14:40.925: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 02/07/24 14:14:40.935
  Feb  7 14:14:40.935: INFO: requesting list of events to confirm quantity
  Feb  7 14:14:40.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-700" for this suite. @ 02/07/24 14:14:40.94
• [0.054 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 02/07/24 14:14:40.945
  Feb  7 14:14:40.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename disruption @ 02/07/24 14:14:40.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:40.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:40.958
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:14:40.965
  E0207 14:14:41.892265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:42.892808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 02/07/24 14:14:42.968
  STEP: Waiting for all pods to be running @ 02/07/24 14:14:42.975
  Feb  7 14:14:42.977: INFO: running pods: 0 < 1
  E0207 14:14:43.893886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:44.894065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 02/07/24 14:14:44.978
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:14:44.986
  STEP: Patching PodDisruptionBudget status @ 02/07/24 14:14:44.99
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:14:44.996
  Feb  7 14:14:44.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2230" for this suite. @ 02/07/24 14:14:45.001
• [4.060 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 02/07/24 14:14:45.005
  Feb  7 14:14:45.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:14:45.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:45.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:45.017
  STEP: Creating secret with name secret-test-1fce3df3-e75f-4e56-b654-bd2e0973d19e @ 02/07/24 14:14:45.032
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:14:45.036
  E0207 14:14:45.894536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:46.894890      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:47.895364      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:48.896443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:14:49.049
  Feb  7 14:14:49.051: INFO: Trying to get logs from node worker-1 pod pod-secrets-8588cfd0-89bb-482c-8934-40d5eeaaf378 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:14:49.056
  Feb  7 14:14:49.065: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5495" for this suite. @ 02/07/24 14:14:49.067
  STEP: Destroying namespace "secret-namespace-6577" for this suite. @ 02/07/24 14:14:49.071
• [4.072 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 02/07/24 14:14:49.077
  Feb  7 14:14:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:14:49.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:49.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:49.089
  Feb  7 14:14:49.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2071 version'
  Feb  7 14:14:49.146: INFO: stderr: ""
  Feb  7 14:14:49.146: INFO: stdout: "Client Version: v1.29.1\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.1+k0s\n"
  Feb  7 14:14:49.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2071" for this suite. @ 02/07/24 14:14:49.149
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 02/07/24 14:14:49.155
  Feb  7 14:14:49.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename job @ 02/07/24 14:14:49.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:49.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:49.167
  STEP: Creating a suspended job @ 02/07/24 14:14:49.172
  STEP: Patching the Job @ 02/07/24 14:14:49.177
  STEP: Watching for Job to be patched @ 02/07/24 14:14:49.191
  Feb  7 14:14:49.192: INFO: Event ADDED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-job-label:e2e-gcs5f] and annotations: map[]
  Feb  7 14:14:49.192: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-job-label:e2e-gcs5f] and annotations: map[]
  Feb  7 14:14:49.192: INFO: Event MODIFIED found for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[]
  STEP: Updating the job @ 02/07/24 14:14:49.192
  STEP: Watching for Job to be updated @ 02/07/24 14:14:49.198
  Feb  7 14:14:49.200: INFO: Event MODIFIED found for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:49.200: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 02/07/24 14:14:49.2
  Feb  7 14:14:49.202: INFO: Job: e2e-gcs5f as labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f]
  STEP: Waiting for job to complete @ 02/07/24 14:14:49.202
  E0207 14:14:49.897109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:50.897516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:51.897897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:52.898665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:53.899207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:54.899388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:55.899726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:56.900035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 02/07/24 14:14:57.205
  STEP: Watching for Job to be deleted @ 02/07/24 14:14:57.21
  Feb  7 14:14:57.211: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.211: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event MODIFIED observed for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  Feb  7 14:14:57.212: INFO: Event DELETED found for Job e2e-gcs5f in namespace job-4142 with labels: map[e2e-gcs5f:patched e2e-job-label:e2e-gcs5f] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 02/07/24 14:14:57.212
  Feb  7 14:14:57.214: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4142" for this suite. @ 02/07/24 14:14:57.218
• [8.073 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 02/07/24 14:14:57.23
  Feb  7 14:14:57.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:14:57.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:14:57.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:14:57.241
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 02/07/24 14:14:57.244
  E0207 14:14:57.900150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:58.900358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:14:59.901325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:00.901424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:15:01.258
  Feb  7 14:15:01.260: INFO: Trying to get logs from node worker-0 pod pod-a391affe-19d7-4479-9da1-9693f3ce8359 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:15:01.265
  Feb  7 14:15:01.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1898" for this suite. @ 02/07/24 14:15:01.277
• [4.052 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 02/07/24 14:15:01.281
  Feb  7 14:15:01.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:15:01.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:01.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:01.295
  STEP: creating service in namespace services-5346 @ 02/07/24 14:15:01.297
  STEP: creating service affinity-clusterip-transition in namespace services-5346 @ 02/07/24 14:15:01.297
  STEP: creating replication controller affinity-clusterip-transition in namespace services-5346 @ 02/07/24 14:15:01.306
  I0207 14:15:01.310892      23 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-5346, replica count: 3
  E0207 14:15:01.901948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:02.902034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:03.902252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 14:15:04.361974      23 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 14:15:04.366: INFO: Creating new exec pod
  E0207 14:15:04.902533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:05.902837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:06.902972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:15:07.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5346 exec execpod-affinity2rxxp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Feb  7 14:15:07.491: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Feb  7 14:15:07.491: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:15:07.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5346 exec execpod-affinity2rxxp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.147.90 80'
  Feb  7 14:15:07.607: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.147.90 80\nConnection to 10.111.147.90 80 port [tcp/http] succeeded!\n"
  Feb  7 14:15:07.607: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:15:07.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5346 exec execpod-affinity2rxxp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.111.147.90:80/ ; done'
  Feb  7 14:15:07.812: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n"
  Feb  7 14:15:07.812: INFO: stdout: "\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-9tsxq\naffinity-clusterip-transition-9tsxq\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-9tsxq\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-cftgh\naffinity-clusterip-transition-9tsxq"
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-9tsxq
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-9tsxq
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-9tsxq
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-cftgh
  Feb  7 14:15:07.812: INFO: Received response from host: affinity-clusterip-transition-9tsxq
  Feb  7 14:15:07.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5346 exec execpod-affinity2rxxp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.111.147.90:80/ ; done'
  E0207 14:15:07.903008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:15:08.018: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.111.147.90:80/\n"
  Feb  7 14:15:08.018: INFO: stdout: "\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs\naffinity-clusterip-transition-s7mcs"
  Feb  7 14:15:08.018: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.018: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.018: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.018: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.018: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Received response from host: affinity-clusterip-transition-s7mcs
  Feb  7 14:15:08.019: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5346, will wait for the garbage collector to delete the pods @ 02/07/24 14:15:08.026
  Feb  7 14:15:08.083: INFO: Deleting ReplicationController affinity-clusterip-transition took: 3.328054ms
  Feb  7 14:15:08.184: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.317455ms
  E0207 14:15:08.903316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:09.903873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:10.904215      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:15:11.299: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5346" for this suite. @ 02/07/24 14:15:11.302
• [10.024 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 02/07/24 14:15:11.306
  Feb  7 14:15:11.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pv @ 02/07/24 14:15:11.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:11.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:11.318
  STEP: Creating initial PV and PVC @ 02/07/24 14:15:11.321
  Feb  7 14:15:11.321: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-8819" @ 02/07/24 14:15:11.33
  STEP: Listing PVCs in namespace "pv-8819" @ 02/07/24 14:15:11.332
  STEP: Patching the PV "pv-8819-bwsb4" @ 02/07/24 14:15:11.334
  STEP: Patching the PVC "pvc-jr4qm" @ 02/07/24 14:15:11.347
  STEP: Getting PV "pv-8819-bwsb4" @ 02/07/24 14:15:11.353
  STEP: Getting PVC "pvc-jr4qm" @ 02/07/24 14:15:11.355
  STEP: Deleting PVC "pvc-jr4qm" @ 02/07/24 14:15:11.357
  STEP: Confirm deletion of PVC "pvc-jr4qm" @ 02/07/24 14:15:11.361
  E0207 14:15:11.905141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:12.905482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-8819-bwsb4" @ 02/07/24 14:15:13.366
  STEP: Confirm deletion of PV "pv-8819-bwsb4" @ 02/07/24 14:15:13.369
  E0207 14:15:13.905592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:14.905796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 02/07/24 14:15:15.374
  Feb  7 14:15:15.374: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-8819-r9bbp" @ 02/07/24 14:15:15.383
  STEP: Updating the PVC "pvc-v9mdk" @ 02/07/24 14:15:15.406
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-v9mdk=updated" @ 02/07/24 14:15:15.412
  STEP: Deleting PVC "pvc-v9mdk" via DeleteCollection @ 02/07/24 14:15:15.413
  STEP: Confirm deletion of PVC "pvc-v9mdk" @ 02/07/24 14:15:15.417
  E0207 14:15:15.906170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:16.906446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-8819-r9bbp" via DeleteCollection @ 02/07/24 14:15:17.422
  STEP: Confirm deletion of PV "pv-8819-r9bbp" @ 02/07/24 14:15:17.427
  E0207 14:15:17.906539      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:18.906622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:15:19.432: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Feb  7 14:15:19.432: INFO: Deleting PersistentVolumeClaim "pvc-v9mdk"
  Feb  7 14:15:19.434: INFO: Deleting PersistentVolume "pv-8819-r9bbp"
  Feb  7 14:15:19.436: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-8819" for this suite. @ 02/07/24 14:15:19.438
• [8.136 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 02/07/24 14:15:19.441
  Feb  7 14:15:19.441: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubelet-test @ 02/07/24 14:15:19.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:19.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:19.454
  E0207 14:15:19.907504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:20.908518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:21.908712      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:22.908960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:15:23.466: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8378" for this suite. @ 02/07/24 14:15:23.469
• [4.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 02/07/24 14:15:23.473
  Feb  7 14:15:23.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:15:23.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:23.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:23.486
  STEP: Creating a pod to test downward api env vars @ 02/07/24 14:15:23.488
  E0207 14:15:23.909058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:24.909236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:25.909764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:26.910041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:15:27.501
  Feb  7 14:15:27.503: INFO: Trying to get logs from node worker-0 pod downward-api-1f193d3a-4dd6-4280-b241-2a86d0a831e7 container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 14:15:27.509
  Feb  7 14:15:27.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3786" for this suite. @ 02/07/24 14:15:27.522
• [4.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 02/07/24 14:15:27.526
  Feb  7 14:15:27.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replicaset @ 02/07/24 14:15:27.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:27.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:27.538
  Feb  7 14:15:27.541: INFO: Creating ReplicaSet my-hostname-basic-ab22b112-0af6-4670-955b-e81c88ddcf9d
  Feb  7 14:15:27.548: INFO: Pod name my-hostname-basic-ab22b112-0af6-4670-955b-e81c88ddcf9d: Found 0 pods out of 1
  E0207 14:15:27.910763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:28.910947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:29.911073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:30.911278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:31.911372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:15:32.550: INFO: Pod name my-hostname-basic-ab22b112-0af6-4670-955b-e81c88ddcf9d: Found 1 pods out of 1
  Feb  7 14:15:32.550: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ab22b112-0af6-4670-955b-e81c88ddcf9d" is running
  Feb  7 14:15:32.552: INFO: Pod "my-hostname-basic-ab22b112-0af6-4670-955b-e81c88ddcf9d-xhqnl" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:15:28 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:15:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:15:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:15:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:15:27 +0000 UTC Reason: Message:}])
  Feb  7 14:15:32.552: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 02/07/24 14:15:32.552
  Feb  7 14:15:32.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4806" for this suite. @ 02/07/24 14:15:32.564
• [5.043 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 02/07/24 14:15:32.569
  Feb  7 14:15:32.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-runtime @ 02/07/24 14:15:32.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:32.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:32.584
  STEP: create the container @ 02/07/24 14:15:32.586
  W0207 14:15:32.594151      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 02/07/24 14:15:32.594
  E0207 14:15:32.911572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:33.911698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:34.912189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/07/24 14:15:35.605
  STEP: the container should be terminated @ 02/07/24 14:15:35.607
  STEP: the termination message should be set @ 02/07/24 14:15:35.607
  Feb  7 14:15:35.607: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 02/07/24 14:15:35.607
  Feb  7 14:15:35.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7914" for this suite. @ 02/07/24 14:15:35.621
• [3.057 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 02/07/24 14:15:35.626
  Feb  7 14:15:35.626: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 14:15:35.628
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:35.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:35.64
  Feb  7 14:15:35.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  W0207 14:15:35.645359      23 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc000d70830 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0207 14:15:35.912302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:36.913299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:37.913889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0207 14:15:38.182051      23 warnings.go:70] unknown field "alpha"
  W0207 14:15:38.182073      23 warnings.go:70] unknown field "beta"
  W0207 14:15:38.182079      23 warnings.go:70] unknown field "delta"
  W0207 14:15:38.182085      23 warnings.go:70] unknown field "epsilon"
  W0207 14:15:38.182091      23 warnings.go:70] unknown field "gamma"
  Feb  7 14:15:38.706: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4265" for this suite. @ 02/07/24 14:15:38.708
• [3.085 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 02/07/24 14:15:38.712
  Feb  7 14:15:38.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:15:38.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:38.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:38.725
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 02/07/24 14:15:38.727
  E0207 14:15:38.914515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:39.914709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:15:40.736
  Feb  7 14:15:40.739: INFO: Trying to get logs from node worker-0 pod pod-6ce65b25-c163-4e9b-bc1e-ec9a6a0e31e2 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:15:40.745
  Feb  7 14:15:40.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-577" for this suite. @ 02/07/24 14:15:40.756
• [2.047 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 02/07/24 14:15:40.759
  Feb  7 14:15:40.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:15:40.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:15:40.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:15:40.772
  STEP: Creating configMap with name configmap-test-upd-99a77d84-39c5-464d-8d7b-a9ef2230de9d @ 02/07/24 14:15:40.776
  STEP: Creating the pod @ 02/07/24 14:15:40.78
  E0207 14:15:40.914833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:41.915205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-99a77d84-39c5-464d-8d7b-a9ef2230de9d @ 02/07/24 14:15:42.797
  STEP: waiting to observe update in volume @ 02/07/24 14:15:42.8
  E0207 14:15:42.915551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:43.916063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:44.917129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:45.918191      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:46.918706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:47.919099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:48.920038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:49.920251      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:50.921137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:51.922117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:52.923140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:53.923350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:54.923828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:55.924034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:56.924642      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:57.924768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:58.925477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:15:59.925678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:00.926551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:01.926664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:02.927654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:03.927788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:04.928224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:05.928460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:06.929029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:07.929358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:08.930130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:09.930339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:10.930600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:11.930738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:12.930788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:13.930995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:14.931780      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:15.931972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:16.932135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:17.932678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:18.933068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:19.933272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:20.933992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:21.934179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:22.934661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:23.934788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:24.935019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:25.935161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:26.935542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:27.935714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:28.935917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:29.936898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:30.937120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:31.937245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:32.937607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:33.938140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:34.938332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:35.939196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:36.939474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:37.939866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:38.940055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:39.940719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:40.941062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:41.941218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:42.941504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:43.941936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:44.942245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:45.943094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:46.943489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:47.943655      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:48.943875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:16:49.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2218" for this suite. @ 02/07/24 14:16:49.039
• [68.283 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 02/07/24 14:16:49.043
  Feb  7 14:16:49.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename security-context-test @ 02/07/24 14:16:49.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:16:49.054
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:16:49.057
  E0207 14:16:49.944605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:50.945041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:16:51.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7233" for this suite. @ 02/07/24 14:16:51.072
• [2.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 02/07/24 14:16:51.076
  Feb  7 14:16:51.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:16:51.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:16:51.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:16:51.091
  STEP: Creating pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421 @ 02/07/24 14:16:51.094
  E0207 14:16:51.945256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:52.945730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:16:53.105
  Feb  7 14:16:53.107: INFO: Initial restart count of pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 is 0
  Feb  7 14:16:53.109: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:16:53.945870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:54.946002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:16:55.112: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:16:55.946123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:56.946410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:16:57.116: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:16:57.947086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:16:58.947175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:16:59.118: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:16:59.947754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:00.947964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:01.121: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:01.948442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:02.948852      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:03.124: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:03.949048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:04.950142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:05.127: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:05.950238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:06.951206      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:07.130: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:07.951756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:08.951871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:09.133: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:09.951981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:10.952186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:11.136: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:11.952640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:12.952975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:13.139: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:13.953680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:14.953788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:15.142: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:15.954617      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:16.955520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:17.146: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:17.956129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:18.956322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:19.149: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:19.956445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:20.956568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:21.152: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:21.956942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:22.957328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:23.154: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:23.957748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:24.957986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:25.158: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:25.958815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:26.959094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:27.160: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:27.959572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:28.959665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:29.163: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:29.960296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:30.960478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:31.166: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:31.961030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:32.961631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:33.169: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:33.962232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:34.962420      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:35.172: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:35.962727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:36.963016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:37.174: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:37.963118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:38.963296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:39.177: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:39.963424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:40.963625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:41.180: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:41.964043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:42.964370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:43.183: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:43.965197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:44.965381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:45.186: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:45.966124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:46.967206      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:47.189: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:47.967693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:48.967869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:49.192: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:49.968592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:50.968769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:51.195: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:51.969236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:52.969361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:53.198: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:53.969865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:54.970052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:55.201: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:55.970819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:56.971157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:57.203: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:57.971283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:17:58.971474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:17:59.206: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:17:59.972140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:00.972335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:01.209: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:01.973271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:02.973395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:03.212: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:03.973987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:04.974173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:05.215: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:05.974954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:06.975211      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:07.218: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:07.975951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:08.976299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:09.221: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:09.976862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:10.977042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:11.223: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:11.977159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:12.977500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:13.227: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:13.977634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:14.978116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:15.231: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:15.979181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:16.979289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:17.233: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:17.979927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:18.980126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:19.237: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:19.980892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:20.981105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:21.239: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:21.981605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:22.981950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:23.242: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:23.982665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:24.982860      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:25.245: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:25.983745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:26.984070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:27.249: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:27.985039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:28.986124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:29.251: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:29.986268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:30.986395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:31.255: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:31.987306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:32.987443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:33.258: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:33.988129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:34.988313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:35.261: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:35.988402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:36.988503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:37.264: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:37.989194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:38.989383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:39.267: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:39.989500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:40.989625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:41.270: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:41.989762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:42.990059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:43.274: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:43.990810      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:44.991021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:45.276: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:45.991563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:46.991903      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:47.279: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:47.992033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:48.992158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:49.282: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:49.992675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:50.992783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:51.285: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:51.993036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:52.993169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:53.289: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:53.993291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:54.993480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:55.292: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:55.994197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:56.994523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:57.295: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:57.994632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:18:58.994807      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:18:59.298: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:18:59.995291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:00.995467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:01.300: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:01.995688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:02.995980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:03.303: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:03.996121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:04.996243      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:05.307: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:05.997256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:06.998116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:07.310: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:07.998764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:08.998964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:09.312: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:09.999085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:10.999194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:11.315: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:11.999339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:12.999687      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:13.318: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:14.000192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:15.000369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:15.321: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:16.001423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:17.001700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:17.324: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:18.002220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:19.002350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:19.327: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:20.002462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:21.002695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:21.329: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:22.003089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:23.003208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:23.331: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:24.003616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:25.003803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:25.334: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:26.004672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:27.004828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:27.337: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:28.005190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:29.005299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:29.339: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:30.006105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:31.006285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:31.343: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:32.006926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:33.007185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:33.345: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:34.007499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:35.007666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:35.348: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:36.008165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:37.008867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:37.351: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:38.009037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:39.010110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:39.355: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:40.010651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:41.010832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:41.357: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:42.011227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:43.011814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:43.360: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:44.012465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:45.012635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:45.363: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:46.013520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:47.013580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:47.366: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:48.014384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:49.015298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:49.369: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:50.015841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:51.016020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:51.371: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:52.016473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:53.016590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:53.374: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:54.017040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:55.017150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:55.377: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:56.017939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:57.018320      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:57.382: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:19:58.018764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:19:59.018932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:19:59.384: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:00.019310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:01.019481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:01.387: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:02.019601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:03.019949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:03.390: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:04.020503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:05.020840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:05.393: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:06.020964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:07.021213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:07.397: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:08.022115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:09.022231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:09.399: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:10.022361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:11.022996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:11.402: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:12.023126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:13.023506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:13.405: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:14.024072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:15.024968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:15.408: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:16.025970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:17.026231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:17.411: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:18.026844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:19.027023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:19.413: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:20.027431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:21.027604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:21.416: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:22.027999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:23.028319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:23.419: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:24.029126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:25.029312      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:25.422: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:26.030103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:27.030388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:27.425: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:28.031085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:29.031263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:29.427: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:30.031308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:31.031478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:31.430: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:32.031595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:33.031992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:33.432: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:34.032112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:35.032304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:35.436: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:36.033245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:37.033490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:37.439: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:38.034269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:39.034380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:39.442: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:40.034873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:41.035638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:41.445: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:42.036351      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:43.036724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:43.448: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:44.036849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:45.037034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:45.452: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:46.037910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:47.038876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:47.454: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:48.038998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:49.039172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:49.457: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:50.039552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:51.039729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:20:51.459: INFO: Get pod test-grpc-45081f92-9e50-455b-8c73-9124bade0e65 in namespace container-probe-6421
  E0207 14:20:52.039945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:53.040300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/07/24 14:20:53.459
  Feb  7 14:20:53.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6421" for this suite. @ 02/07/24 14:20:53.472
• [242.399 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 02/07/24 14:20:53.475
  Feb  7 14:20:53.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:20:53.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:20:53.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:20:53.488
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 02/07/24 14:20:53.491
  E0207 14:20:54.040500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:55.040889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:56.041895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:57.042878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:20:57.503
  Feb  7 14:20:57.505: INFO: Trying to get logs from node worker-0 pod pod-131ac785-f1c0-4218-bff4-f6b683b809fc container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:20:57.52
  Feb  7 14:20:57.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5331" for this suite. @ 02/07/24 14:20:57.531
• [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 02/07/24 14:20:57.535
  Feb  7 14:20:57.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename watch @ 02/07/24 14:20:57.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:20:57.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:20:57.547
  STEP: creating a watch on configmaps with a certain label @ 02/07/24 14:20:57.549
  STEP: creating a new configmap @ 02/07/24 14:20:57.55
  STEP: modifying the configmap once @ 02/07/24 14:20:57.553
  STEP: changing the label value of the configmap @ 02/07/24 14:20:57.559
  STEP: Expecting to observe a delete notification for the watched object @ 02/07/24 14:20:57.564
  Feb  7 14:20:57.564: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2569  e8118a19-95d1-442d-8147-d8dd449208ee 13356 0 2024-02-07 14:20:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-07 14:20:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:20:57.564: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2569  e8118a19-95d1-442d-8147-d8dd449208ee 13357 0 2024-02-07 14:20:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-07 14:20:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:20:57.564: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2569  e8118a19-95d1-442d-8147-d8dd449208ee 13358 0 2024-02-07 14:20:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-07 14:20:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 02/07/24 14:20:57.564
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 02/07/24 14:20:57.568
  E0207 14:20:58.043387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:20:59.043477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:00.043679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:01.043880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:02.044060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:03.044409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:04.044613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:05.044818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:06.044906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:07.045266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 02/07/24 14:21:07.569
  STEP: modifying the configmap a third time @ 02/07/24 14:21:07.574
  STEP: deleting the configmap @ 02/07/24 14:21:07.579
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 02/07/24 14:21:07.582
  Feb  7 14:21:07.582: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2569  e8118a19-95d1-442d-8147-d8dd449208ee 13397 0 2024-02-07 14:20:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-07 14:21:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:21:07.582: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2569  e8118a19-95d1-442d-8147-d8dd449208ee 13398 0 2024-02-07 14:20:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-07 14:21:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:21:07.582: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2569  e8118a19-95d1-442d-8147-d8dd449208ee 13399 0 2024-02-07 14:20:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-02-07 14:21:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:21:07.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2569" for this suite. @ 02/07/24 14:21:07.585
• [10.054 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 02/07/24 14:21:07.589
  Feb  7 14:21:07.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename disruption @ 02/07/24 14:21:07.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:07.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:07.603
  STEP: Creating a pdb that targets all three pods in a test replica set @ 02/07/24 14:21:07.605
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:21:07.608
  E0207 14:21:08.045353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:09.046119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 02/07/24 14:21:09.615
  STEP: Waiting for all pods to be running @ 02/07/24 14:21:09.615
  Feb  7 14:21:09.617: INFO: pods: 0 < 3
  E0207 14:21:10.046225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:11.046437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 02/07/24 14:21:11.619
  STEP: Updating the pdb to allow a pod to be evicted @ 02/07/24 14:21:11.625
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:21:11.63
  E0207 14:21:12.047312      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:13.047629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 02/07/24 14:21:13.633
  STEP: Waiting for all pods to be running @ 02/07/24 14:21:13.633
  STEP: Waiting for the pdb to observed all healthy pods @ 02/07/24 14:21:13.635
  STEP: Patching the pdb to disallow a pod to be evicted @ 02/07/24 14:21:13.651
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:21:13.666
  E0207 14:21:14.047822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:15.048007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 02/07/24 14:21:15.668
  STEP: locating a running pod @ 02/07/24 14:21:15.671
  STEP: Deleting the pdb to allow a pod to be evicted @ 02/07/24 14:21:15.677
  STEP: Waiting for the pdb to be deleted @ 02/07/24 14:21:15.68
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 02/07/24 14:21:15.682
  STEP: Waiting for all pods to be running @ 02/07/24 14:21:15.682
  Feb  7 14:21:15.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8223" for this suite. @ 02/07/24 14:21:15.697
• [8.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 02/07/24 14:21:15.703
  Feb  7 14:21:15.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:21:15.704
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:15.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:15.719
  STEP: Creating projection with secret that has name projected-secret-test-b8cc2760-c0d9-4d90-a886-7efe43d6457d @ 02/07/24 14:21:15.722
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:21:15.726
  E0207 14:21:16.048900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:17.049108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:18.050134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:19.050312      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:21:19.74
  Feb  7 14:21:19.742: INFO: Trying to get logs from node worker-1 pod pod-projected-secrets-d2c7a72f-e757-4950-8e7d-8e41cedf51ef container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:21:19.756
  Feb  7 14:21:19.765: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6733" for this suite. @ 02/07/24 14:21:19.768
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 02/07/24 14:21:19.772
  Feb  7 14:21:19.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:21:19.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:19.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:19.785
  STEP: Creating configMap with name projected-configmap-test-volume-map-4666d69c-4b8f-47e9-8342-3e915f719d95 @ 02/07/24 14:21:19.787
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:21:19.79
  E0207 14:21:20.050521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:21.051282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:22.051757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:23.052049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:21:23.804
  Feb  7 14:21:23.806: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-c0209906-3d62-4292-82c5-004a62f891a1 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:21:23.811
  Feb  7 14:21:23.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8213" for this suite. @ 02/07/24 14:21:23.823
• [4.054 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 02/07/24 14:21:23.826
  Feb  7 14:21:23.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename apf @ 02/07/24 14:21:23.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:23.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:23.839
  STEP: getting /apis @ 02/07/24 14:21:23.841
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 02/07/24 14:21:23.845
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 02/07/24 14:21:23.846
  STEP: creating @ 02/07/24 14:21:23.847
  STEP: getting @ 02/07/24 14:21:23.857
  STEP: listing @ 02/07/24 14:21:23.859
  STEP: watching @ 02/07/24 14:21:23.861
  Feb  7 14:21:23.861: INFO: starting watch
  STEP: patching @ 02/07/24 14:21:23.862
  STEP: updating @ 02/07/24 14:21:23.868
  Feb  7 14:21:23.873: INFO: waiting for watch events with expected annotations
  Feb  7 14:21:23.873: INFO: missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 02/07/24 14:21:23.874
  STEP: patching /status @ 02/07/24 14:21:23.875
  STEP: updating /status @ 02/07/24 14:21:23.88
  STEP: deleting @ 02/07/24 14:21:23.903
  STEP: deleting a collection @ 02/07/24 14:21:23.91
  Feb  7 14:21:23.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-9909" for this suite. @ 02/07/24 14:21:23.923
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 02/07/24 14:21:23.927
  Feb  7 14:21:23.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename job @ 02/07/24 14:21:23.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:23.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:23.937
  STEP: Creating Indexed job @ 02/07/24 14:21:23.94
  STEP: Ensuring job reaches completions @ 02/07/24 14:21:23.944
  E0207 14:21:24.052556      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:25.052836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:26.053415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:27.053729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:28.054612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:29.054808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:30.055079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:31.055259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 02/07/24 14:21:31.947
  Feb  7 14:21:31.949: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9153" for this suite. @ 02/07/24 14:21:31.952
• [8.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 02/07/24 14:21:31.957
  Feb  7 14:21:31.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:21:31.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:31.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:31.969
  STEP: Setting up server cert @ 02/07/24 14:21:31.983
  E0207 14:21:32.055368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:21:32.729
  STEP: Deploying the webhook pod @ 02/07/24 14:21:32.734
  STEP: Wait for the deployment to be ready @ 02/07/24 14:21:32.742
  Feb  7 14:21:32.748: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:21:33.055422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:34.055616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:21:34.755
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:21:34.767
  E0207 14:21:35.056481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:21:35.768: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 02/07/24 14:21:35.772
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/07/24 14:21:35.772
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 02/07/24 14:21:35.788
  E0207 14:21:36.057035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 02/07/24 14:21:36.796
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/07/24 14:21:36.796
  E0207 14:21:37.057064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 02/07/24 14:21:37.817
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/07/24 14:21:37.817
  E0207 14:21:38.057749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:39.057826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:40.058023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:41.058207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:42.058399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 02/07/24 14:21:42.844
  STEP: Registering slow webhook via the AdmissionRegistration API @ 02/07/24 14:21:42.844
  E0207 14:21:43.058474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:44.058676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:45.058863      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:46.059482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:47.059850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:21:47.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2895" for this suite. @ 02/07/24 14:21:47.899
  STEP: Destroying namespace "webhook-markers-1033" for this suite. @ 02/07/24 14:21:47.903
• [15.951 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 02/07/24 14:21:47.909
  Feb  7 14:21:47.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-runtime @ 02/07/24 14:21:47.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:21:47.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:21:47.921
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 02/07/24 14:21:47.929
  E0207 14:21:48.060443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:49.061145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:50.061843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:51.062643      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:52.063631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:53.064413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:54.064943      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:55.065526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:56.066130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:57.067105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:58.067982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:21:59.068609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:00.069140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:01.069820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:02.070704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 02/07/24 14:22:02.972
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 02/07/24 14:22:02.974
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 02/07/24 14:22:02.978
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 02/07/24 14:22:02.978
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 02/07/24 14:22:02.991
  E0207 14:22:03.071025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:04.071615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:05.072029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 02/07/24 14:22:06.001
  E0207 14:22:06.072465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 02/07/24 14:22:07.005
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 02/07/24 14:22:07.009
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 02/07/24 14:22:07.009
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 02/07/24 14:22:07.023
  E0207 14:22:07.073210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 02/07/24 14:22:08.028
  E0207 14:22:08.073868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:09.074079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 02/07/24 14:22:10.036
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 02/07/24 14:22:10.04
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 02/07/24 14:22:10.04
  Feb  7 14:22:10.056: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-631" for this suite. @ 02/07/24 14:22:10.058
• [22.154 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 02/07/24 14:22:10.063
  Feb  7 14:22:10.063: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:22:10.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:22:10.071
  E0207 14:22:10.074093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:22:10.074
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:22:10.076
  E0207 14:22:11.074252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:12.074470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:13.074656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:14.074758      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:22:14.09
  Feb  7 14:22:14.092: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-811c05b3-ebfd-4535-a120-897117a59d0c container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:22:14.097
  Feb  7 14:22:14.107: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5972" for this suite. @ 02/07/24 14:22:14.11
• [4.051 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 02/07/24 14:22:14.114
  Feb  7 14:22:14.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:22:14.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:22:14.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:22:14.128
  STEP: Setting up server cert @ 02/07/24 14:22:14.142
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:22:14.587
  STEP: Deploying the webhook pod @ 02/07/24 14:22:14.594
  STEP: Wait for the deployment to be ready @ 02/07/24 14:22:14.602
  Feb  7 14:22:14.607: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:22:15.075508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:16.075802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:22:16.614
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:22:16.626
  E0207 14:22:17.076826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:22:17.627: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 02/07/24 14:22:17.676
  STEP: Creating a configMap that should be mutated @ 02/07/24 14:22:17.69
  STEP: Deleting the collection of validation webhooks @ 02/07/24 14:22:17.72
  STEP: Creating a configMap that should not be mutated @ 02/07/24 14:22:17.744
  Feb  7 14:22:17.775: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7312" for this suite. @ 02/07/24 14:22:17.777
  STEP: Destroying namespace "webhook-markers-4452" for this suite. @ 02/07/24 14:22:17.783
• [3.673 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 02/07/24 14:22:17.787
  Feb  7 14:22:17.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:22:17.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:22:17.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:22:17.798
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/07/24 14:22:17.801
  Feb  7 14:22:17.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2595 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Feb  7 14:22:17.869: INFO: stderr: ""
  Feb  7 14:22:17.869: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 02/07/24 14:22:17.869
  Feb  7 14:22:17.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2595 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  Feb  7 14:22:17.935: INFO: stderr: ""
  Feb  7 14:22:17.935: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/07/24 14:22:17.935
  Feb  7 14:22:17.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-2595 delete pods e2e-test-httpd-pod'
  E0207 14:22:18.077395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:19.077622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:22:19.294: INFO: stderr: ""
  Feb  7 14:22:19.294: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Feb  7 14:22:19.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2595" for this suite. @ 02/07/24 14:22:19.297
• [1.513 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 02/07/24 14:22:19.301
  Feb  7 14:22:19.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:22:19.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:22:19.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:22:19.311
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:22:19.314
  E0207 14:22:20.078628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:21.079050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:22.079489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:23.079867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:22:23.327
  Feb  7 14:22:23.329: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-a3cd4905-07af-42ef-9989-fb0939c3f1a3 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:22:23.333
  Feb  7 14:22:23.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9051" for this suite. @ 02/07/24 14:22:23.345
• [4.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 02/07/24 14:22:23.351
  Feb  7 14:22:23.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:22:23.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:22:23.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:22:23.362
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 02/07/24 14:22:23.365
  E0207 14:22:24.080007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:25.080105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:26.080748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:27.081117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:22:27.379
  Feb  7 14:22:27.381: INFO: Trying to get logs from node worker-0 pod pod-39bbf0ff-10f3-4572-bb0f-7ee242d98058 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:22:27.386
  Feb  7 14:22:27.396: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8229" for this suite. @ 02/07/24 14:22:27.399
• [4.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 02/07/24 14:22:27.404
  Feb  7 14:22:27.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-preemption @ 02/07/24 14:22:27.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:22:27.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:22:27.415
  Feb  7 14:22:27.426: INFO: Waiting up to 1m0s for all nodes to be ready
  E0207 14:22:28.081970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:29.082577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:30.083455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:31.083650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:32.083913      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:33.084293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:34.084364      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:35.084569      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:36.085602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:37.086595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:38.087534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:39.087721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:40.088569      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:41.089012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:42.089035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:43.090132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:44.090405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:45.090616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:46.091589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:47.091916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:48.092106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:49.092278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:50.092344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:51.092536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:52.092667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:53.093013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:54.093143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:55.093349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:56.094310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:57.094612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:58.095633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:22:59.095817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:00.096738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:01.096965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:02.098004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:03.098374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:04.098967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:05.099149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:06.099459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:07.099828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:08.099975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:09.100780      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:10.101662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:11.101849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:12.102834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:13.103103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:14.104080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:15.104272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:16.104693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:17.105041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:18.105093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:19.106117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:20.106212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:21.106339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:22.106394      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:23.106719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:24.106761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:25.106943      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:26.107084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:27.107302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:23:27.429: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 02/07/24 14:23:27.431
  Feb  7 14:23:27.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-preemption-path @ 02/07/24 14:23:27.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:23:27.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:23:27.443
  STEP: Finding an available node @ 02/07/24 14:23:27.446
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 02/07/24 14:23:27.446
  E0207 14:23:28.107404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:29.107622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 02/07/24 14:23:29.458
  Feb  7 14:23:29.466: INFO: found a healthy node: worker-0
  E0207 14:23:30.108385      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:31.108457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:32.108578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:33.109002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:34.109087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:35.109198      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:23:35.511: INFO: pods created so far: [1 1 1]
  Feb  7 14:23:35.511: INFO: length of pods created so far: 3
  E0207 14:23:36.109383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:37.110128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:23:37.518: INFO: pods created so far: [2 2 1]
  E0207 14:23:38.111007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:39.111218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:40.111318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:41.111517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:42.111698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:43.112116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:44.112200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:23:44.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2472" for this suite. @ 02/07/24 14:23:44.557
  Feb  7 14:23:44.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6186" for this suite. @ 02/07/24 14:23:44.563
• [77.163 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 02/07/24 14:23:44.568
  Feb  7 14:23:44.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename security-context @ 02/07/24 14:23:44.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:23:44.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:23:44.579
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 02/07/24 14:23:44.582
  E0207 14:23:45.112580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:46.113582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:47.113701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:48.114095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:23:48.597
  Feb  7 14:23:48.599: INFO: Trying to get logs from node worker-1 pod security-context-b1ecd3a1-a9dd-44e0-9461-6c0d4c0502d6 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:23:48.611
  Feb  7 14:23:48.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-2204" for this suite. @ 02/07/24 14:23:48.621
• [4.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 02/07/24 14:23:48.626
  Feb  7 14:23:48.627: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pod-network-test @ 02/07/24 14:23:48.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:23:48.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:23:48.638
  STEP: Performing setup for networking test in namespace pod-network-test-6807 @ 02/07/24 14:23:48.64
  STEP: creating a selector @ 02/07/24 14:23:48.64
  STEP: Creating the service pods in kubernetes @ 02/07/24 14:23:48.64
  Feb  7 14:23:48.640: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0207 14:23:49.114482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:50.114735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:51.114842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:52.115136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:53.116196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:54.116312      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:55.117051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:56.117246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:57.117630      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:58.118127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:23:59.118851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:00.119044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:01.119544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:02.119741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:03.120405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:04.120775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:05.121523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:06.122123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:07.122177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:08.122513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:09.123002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:10.123185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/07/24 14:24:10.7
  E0207 14:24:11.123505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:12.123763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:24:12.720: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Feb  7 14:24:12.720: INFO: Going to poll 10.244.1.133 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Feb  7 14:24:12.722: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.133:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6807 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:24:12.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:24:12.722: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:24:12.722: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6807/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.133%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb  7 14:24:12.785: INFO: Found all 1 expected endpoints: [netserver-0]
  Feb  7 14:24:12.785: INFO: Going to poll 10.244.0.53 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Feb  7 14:24:12.787: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.53:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6807 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:24:12.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:24:12.787: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:24:12.787: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6807/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.53%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Feb  7 14:24:12.849: INFO: Found all 1 expected endpoints: [netserver-1]
  Feb  7 14:24:12.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6807" for this suite. @ 02/07/24 14:24:12.851
• [24.229 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 02/07/24 14:24:12.855
  Feb  7 14:24:12.855: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 14:24:12.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:24:12.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:24:12.868
  Feb  7 14:24:12.876: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0207 14:24:13.123881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:14.124189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:15.124304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:16.124505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:17.124850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:24:17.881: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/07/24 14:24:17.881
  Feb  7 14:24:17.881: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 02/07/24 14:24:17.891
  Feb  7 14:24:17.898: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9509",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "59a3608b-6df9-45ff-ad02-f0ec4d1d3057",
      ResourceVersion: (string) (len=5) "14660",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842912657,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 14:24:17.902: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Feb  7 14:24:17.902: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Feb  7 14:24:17.902: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9509",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a0811922-b312-48b6-ae1e-caa73f9015ad",
      ResourceVersion: (string) (len=5) "14661",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842912652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "59a3608b-6df9-45ff-ad02-f0ec4d1d3057",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912657,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 35 39 61 33 36 30 38  |"uid\":\"59a3608|
              00000040  62 2d 36 64 66 39 2d 34  35 66 66 2d 61 64 30 32  |b-6df9-45ff-ad02|
              00000050  2d 66 30 65 63 34 64 31  64 33 30 35 37 5c 22 7d  |-f0ec4d1d3057\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:24:17.910: INFO: Pod "test-cleanup-controller-6f25h" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-6f25h",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-9509",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6195bcfb-d934-47e8-ad95-d39f21fd787b",
      ResourceVersion: (string) (len=5) "14647",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842912652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "a0811922-b312-48b6-ae1e-caa73f9015ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  61 30 38 31 31 39 32 32  |uid\":\"a0811922|
              00000080  2d 62 33 31 32 2d 34 38  62 36 2d 61 65 31 65 2d  |-b312-48b6-ae1e-|
              00000090  63 61 61 37 33 66 39 30  31 35 61 64 5c 22 7d 22  |caa73f9015ad\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 35  34 5c 22 7d 22 3a 7b 22  |.244.0.54\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-csskm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-csskm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912654,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842912652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.54",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.54"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842912652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842912653,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://999451e3ad9de64bbf3061b520282925ef32c8adc58993ab9de56fa5c7fdc08a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:24:17.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9509" for this suite. @ 02/07/24 14:24:17.921
• [5.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 02/07/24 14:24:17.927
  Feb  7 14:24:17.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename subpath @ 02/07/24 14:24:17.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:24:17.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:24:17.943
  STEP: Setting up data @ 02/07/24 14:24:17.946
  STEP: Creating pod pod-subpath-test-downwardapi-9wcv @ 02/07/24 14:24:17.953
  STEP: Creating a pod to test atomic-volume-subpath @ 02/07/24 14:24:17.953
  E0207 14:24:18.125809      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:19.126589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:20.127410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:21.127587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:22.128118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:23.128698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:24.129249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:25.129448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:26.130130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:27.130393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:28.130545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:29.131173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:30.131886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:31.132067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:32.132143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:33.132448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:34.133043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:35.133237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:36.133815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:37.134184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:38.134236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:39.135280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:24:39.995
  Feb  7 14:24:39.997: INFO: Trying to get logs from node worker-0 pod pod-subpath-test-downwardapi-9wcv container test-container-subpath-downwardapi-9wcv: <nil>
  STEP: delete the pod @ 02/07/24 14:24:40.011
  STEP: Deleting pod pod-subpath-test-downwardapi-9wcv @ 02/07/24 14:24:40.02
  Feb  7 14:24:40.020: INFO: Deleting pod "pod-subpath-test-downwardapi-9wcv" in namespace "subpath-8826"
  Feb  7 14:24:40.022: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8826" for this suite. @ 02/07/24 14:24:40.025
• [22.102 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 02/07/24 14:24:40.029
  Feb  7 14:24:40.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:24:40.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:24:40.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:24:40.049
  STEP: Setting up server cert @ 02/07/24 14:24:40.069
  E0207 14:24:40.136121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:24:40.811
  STEP: Deploying the webhook pod @ 02/07/24 14:24:40.817
  STEP: Wait for the deployment to be ready @ 02/07/24 14:24:40.826
  Feb  7 14:24:40.830: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0207 14:24:41.137033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:42.137261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:24:42.837
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:24:42.846
  E0207 14:24:43.137836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:24:43.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 02/07/24 14:24:43.85
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 02/07/24 14:24:43.866
  STEP: Creating a dummy validating-webhook-configuration object @ 02/07/24 14:24:43.881
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 02/07/24 14:24:43.889
  STEP: Creating a dummy mutating-webhook-configuration object @ 02/07/24 14:24:43.892
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 02/07/24 14:24:43.898
  Feb  7 14:24:43.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-195" for this suite. @ 02/07/24 14:24:43.938
  STEP: Destroying namespace "webhook-markers-5791" for this suite. @ 02/07/24 14:24:43.941
• [3.916 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 02/07/24 14:24:43.946
  Feb  7 14:24:43.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename namespaces @ 02/07/24 14:24:43.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:24:43.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:24:43.958
  STEP: Updating Namespace "namespaces-950" @ 02/07/24 14:24:43.961
  Feb  7 14:24:43.966: INFO: Namespace "namespaces-950" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"6f38753a-a54c-471f-9df2-0d69bb9619d8", "kubernetes.io/metadata.name":"namespaces-950", "namespaces-950":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Feb  7 14:24:43.966: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-950" for this suite. @ 02/07/24 14:24:43.968
• [0.026 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 02/07/24 14:24:43.972
  Feb  7 14:24:43.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:24:43.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:24:43.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:24:43.983
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 02/07/24 14:24:43.986
  E0207 14:24:44.138590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:45.139399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:24:45.996
  Feb  7 14:24:45.998: INFO: Trying to get logs from node worker-0 pod pod-9ad969e7-c1e7-4111-a211-720c53a5f2c5 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:24:46.003
  Feb  7 14:24:46.012: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6367" for this suite. @ 02/07/24 14:24:46.014
• [2.048 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 02/07/24 14:24:46.02
  Feb  7 14:24:46.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename watch @ 02/07/24 14:24:46.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:24:46.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:24:46.03
  STEP: creating a watch on configmaps with label A @ 02/07/24 14:24:46.033
  STEP: creating a watch on configmaps with label B @ 02/07/24 14:24:46.034
  STEP: creating a watch on configmaps with label A or B @ 02/07/24 14:24:46.035
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 02/07/24 14:24:46.036
  Feb  7 14:24:46.039: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14887 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:24:46.039: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14887 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 02/07/24 14:24:46.04
  Feb  7 14:24:46.046: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14888 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:24:46.046: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14888 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 02/07/24 14:24:46.046
  Feb  7 14:24:46.051: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14889 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:24:46.051: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14889 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 02/07/24 14:24:46.051
  Feb  7 14:24:46.055: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14890 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:24:46.055: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4590  858d1956-aab1-4139-b8cb-b5e6de007dab 14890 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 02/07/24 14:24:46.055
  Feb  7 14:24:46.058: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4590  28f41f1a-4fff-46a7-88f7-8eea92565615 14891 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:24:46.058: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4590  28f41f1a-4fff-46a7-88f7-8eea92565615 14891 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0207 14:24:46.140082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:47.140277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:48.141265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:49.142127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:50.142304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:51.142490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:52.142727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:53.143093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:54.143200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:55.143635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 02/07/24 14:24:56.059
  Feb  7 14:24:56.063: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4590  28f41f1a-4fff-46a7-88f7-8eea92565615 14938 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:24:56.063: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4590  28f41f1a-4fff-46a7-88f7-8eea92565615 14938 0 2024-02-07 14:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-02-07 14:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0207 14:24:56.144586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:57.144956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:58.145346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:24:59.146161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:00.146345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:01.146547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:02.146764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:03.147107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:04.147280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:05.147466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:06.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4590" for this suite. @ 02/07/24 14:25:06.067
• [20.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 02/07/24 14:25:06.072
  Feb  7 14:25:06.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:25:06.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:25:06.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:25:06.085
  STEP: creating Agnhost RC @ 02/07/24 14:25:06.087
  Feb  7 14:25:06.087: INFO: namespace kubectl-7917
  Feb  7 14:25:06.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7917 create -f -'
  E0207 14:25:06.148390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:06.204: INFO: stderr: ""
  Feb  7 14:25:06.204: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 02/07/24 14:25:06.204
  E0207 14:25:07.148721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:07.207: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 14:25:07.207: INFO: Found 0 / 1
  E0207 14:25:08.149049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:08.207: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 14:25:08.207: INFO: Found 1 / 1
  Feb  7 14:25:08.207: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Feb  7 14:25:08.209: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 14:25:08.209: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb  7 14:25:08.209: INFO: wait on agnhost-primary startup in kubectl-7917 
  Feb  7 14:25:08.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7917 logs agnhost-primary-c7szp agnhost-primary'
  Feb  7 14:25:08.271: INFO: stderr: ""
  Feb  7 14:25:08.271: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 02/07/24 14:25:08.271
  Feb  7 14:25:08.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7917 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Feb  7 14:25:08.346: INFO: stderr: ""
  Feb  7 14:25:08.346: INFO: stdout: "service/rm2 exposed\n"
  Feb  7 14:25:08.348: INFO: Service rm2 in namespace kubectl-7917 found.
  E0207 14:25:09.149121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:10.149346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 02/07/24 14:25:10.352
  Feb  7 14:25:10.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7917 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Feb  7 14:25:10.420: INFO: stderr: ""
  Feb  7 14:25:10.420: INFO: stdout: "service/rm3 exposed\n"
  Feb  7 14:25:10.423: INFO: Service rm3 in namespace kubectl-7917 found.
  E0207 14:25:11.150414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:12.150634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:12.428: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7917" for this suite. @ 02/07/24 14:25:12.431
• [6.364 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 02/07/24 14:25:12.436
  Feb  7 14:25:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:25:12.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:25:12.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:25:12.448
  STEP: Creating service test in namespace statefulset-5367 @ 02/07/24 14:25:12.451
  STEP: Creating statefulset ss in namespace statefulset-5367 @ 02/07/24 14:25:12.456
  Feb  7 14:25:12.461: INFO: Found 0 stateful pods, waiting for 1
  E0207 14:25:13.150776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:14.151072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:15.151282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:16.151479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:17.151802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:18.152102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:19.152229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:20.152291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:21.152503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:22.152697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:22.463: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 02/07/24 14:25:22.467
  STEP: updating a scale subresource @ 02/07/24 14:25:22.468
  STEP: verifying the statefulset Spec.Replicas was modified @ 02/07/24 14:25:22.472
  STEP: Patch a scale subresource @ 02/07/24 14:25:22.474
  STEP: verifying the statefulset Spec.Replicas was modified @ 02/07/24 14:25:22.479
  Feb  7 14:25:22.488: INFO: Deleting all statefulset in ns statefulset-5367
  Feb  7 14:25:22.491: INFO: Scaling statefulset ss to 0
  E0207 14:25:23.152805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:24.153131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:25.153323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:26.153524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:27.153844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:28.154346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:29.154530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:30.154731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:31.154945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:32.155125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:32.504: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:25:32.506: INFO: Deleting statefulset ss
  Feb  7 14:25:32.513: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5367" for this suite. @ 02/07/24 14:25:32.516
• [20.083 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 02/07/24 14:25:32.519
  Feb  7 14:25:32.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:25:32.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:25:32.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:25:32.531
  STEP: creating service multiprotocol-test in namespace services-382 @ 02/07/24 14:25:32.534
  STEP: creating pod pod1 in namespace services-382 @ 02/07/24 14:25:32.543
  STEP: Creating pod pod1 in namespace services-382 @ 02/07/24 14:25:32.543
  E0207 14:25:33.155966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:34.156190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-382 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 02/07/24 14:25:34.557
  Feb  7 14:25:34.563: INFO: successfully validated that service multiprotocol-test in namespace services-382 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 02/07/24 14:25:34.564
  Feb  7 14:25:34.564: INFO: Creating new exec pod
  E0207 14:25:35.156302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:36.156512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:36.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80'
  Feb  7 14:25:36.688: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.64.18 80\nConnection to 10.110.64.18 80 port [tcp/http] succeeded!\n"
  Feb  7 14:25:36.688: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:25:36.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.110.64.18 80'
  E0207 14:25:37.156777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:38.157174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:39.158166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:40.158363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:40.814: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.110.64.18 80\nConnection to 10.110.64.18 80 port [udp/*] succeeded!\n"
  Feb  7 14:25:40.814: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 02/07/24 14:25:40.815
  Feb  7 14:25:40.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80'
  Feb  7 14:25:40.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.64.18 80\nConnection to 10.110.64.18 80 port [tcp/http] succeeded!\n"
  Feb  7 14:25:40.944: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:25:40.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.110.64.18 80'
  E0207 14:25:41.159300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:42.159416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:43.159472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:44.159680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:45.063: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.110.64.18 80\nConnection to 10.110.64.18 80 port [udp/*] succeeded!\n"
  Feb  7 14:25:45.063: INFO: stdout: ""
  Feb  7 14:25:45.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.110.64.18 80'
  E0207 14:25:45.159722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:46.159958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:47.160433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:48.160746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:49.161128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:49.182: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.110.64.18 80\nConnection to 10.110.64.18 80 port [udp/*] succeeded!\n"
  Feb  7 14:25:49.182: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 02/07/24 14:25:49.182
  Feb  7 14:25:49.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.110.64.18 80'
  E0207 14:25:50.162144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:51.162381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:52.162685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:53.163041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:53.327: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.110.64.18 80\nConnection to 10.110.64.18 80 port [udp/*] succeeded!\n"
  Feb  7 14:25:53.327: INFO: stdout: "pod1"
  Feb  7 14:25:53.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80'
  E0207 14:25:54.163989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:55.164117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:55.446: INFO: rc: 1
  Feb  7 14:25:55.446: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.110.64.18 80
  nc: connect to 10.110.64.18 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 14:25:55.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80'
  E0207 14:25:56.165030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:57.166111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:57.574: INFO: rc: 1
  Feb  7 14:25:57.574: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.110.64.18 80
  nc: connect to 10.110.64.18 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 14:25:57.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80'
  E0207 14:25:58.166376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:25:59.166580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:25:59.694: INFO: rc: 1
  Feb  7 14:25:59.694: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-382 exec execpodnlbxs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.64.18 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.110.64.18 80
  nc: connect to 10.110.64.18 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 14:25:59.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-382" for this suite. @ 02/07/24 14:25:59.697
• [27.183 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 02/07/24 14:25:59.703
  Feb  7 14:25:59.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 14:25:59.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:25:59.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:25:59.714
  Feb  7 14:25:59.739: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6f5d0967-e363-45f9-bea7-624ef3bf810e", Controller:(*bool)(0xc00527bd66), BlockOwnerDeletion:(*bool)(0xc00527bd67)}}
  Feb  7 14:25:59.744: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a6d336af-f091-43fd-825c-49c41c0533d9", Controller:(*bool)(0xc00218bf2e), BlockOwnerDeletion:(*bool)(0xc00218bf2f)}}
  Feb  7 14:25:59.750: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f768bfc8-6db2-48a7-8b22-339419b67a4b", Controller:(*bool)(0xc00231a13a), BlockOwnerDeletion:(*bool)(0xc00231a13b)}}
  E0207 14:26:00.167475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:01.167589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:02.167803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:03.168145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:04.168247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:26:04.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5602" for this suite. @ 02/07/24 14:26:04.761
• [5.062 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 02/07/24 14:26:04.765
  Feb  7 14:26:04.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename discovery @ 02/07/24 14:26:04.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:04.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:04.782
  STEP: Setting up server cert @ 02/07/24 14:26:04.785
  E0207 14:26:05.168406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/api/v1" @ 02/07/24 14:26:05.213
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 02/07/24 14:26:05.215
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 02/07/24 14:26:05.216
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 02/07/24 14:26:05.217
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 02/07/24 14:26:05.218
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 02/07/24 14:26:05.219
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 02/07/24 14:26:05.22
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 02/07/24 14:26:05.221
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 02/07/24 14:26:05.221
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 02/07/24 14:26:05.222
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 02/07/24 14:26:05.223
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 02/07/24 14:26:05.224
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 02/07/24 14:26:05.225
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 02/07/24 14:26:05.226
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 02/07/24 14:26:05.227
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 02/07/24 14:26:05.228
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 02/07/24 14:26:05.229
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 02/07/24 14:26:05.229
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 02/07/24 14:26:05.23
  Feb  7 14:26:05.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8302" for this suite. @ 02/07/24 14:26:05.234
• [0.473 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 02/07/24 14:26:05.237
  Feb  7 14:26:05.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:26:05.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:05.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:05.25
  STEP: Creating configMap with name projected-configmap-test-volume-8eebb268-aeab-49c2-b910-9e0b69140799 @ 02/07/24 14:26:05.253
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:26:05.256
  E0207 14:26:06.169490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:07.169926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:08.171012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:09.171210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:26:09.27
  Feb  7 14:26:09.272: INFO: Trying to get logs from node worker-0 pod pod-projected-configmaps-c8b901d6-0156-4a35-908f-67b0579c2e1d container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:26:09.279
  Feb  7 14:26:09.288: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9315" for this suite. @ 02/07/24 14:26:09.291
• [4.057 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 02/07/24 14:26:09.295
  Feb  7 14:26:09.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 14:26:09.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:09.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:09.305
  STEP: Creating a test externalName service @ 02/07/24 14:26:09.307
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8532.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local; sleep 1; done
   @ 02/07/24 14:26:09.311
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8532.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local; sleep 1; done
   @ 02/07/24 14:26:09.311
  STEP: creating a pod to probe DNS @ 02/07/24 14:26:09.311
  STEP: submitting the pod to kubernetes @ 02/07/24 14:26:09.311
  E0207 14:26:10.171355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:11.172184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/07/24 14:26:11.323
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:26:11.325
  Feb  7 14:26:11.333: INFO: DNS probes using dns-test-3f1b7214-4237-4d66-bcb4-fc2c60902b08 succeeded

  STEP: changing the externalName to bar.example.com @ 02/07/24 14:26:11.333
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8532.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local; sleep 1; done
   @ 02/07/24 14:26:11.338
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8532.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local; sleep 1; done
   @ 02/07/24 14:26:11.338
  STEP: creating a second pod to probe DNS @ 02/07/24 14:26:11.338
  STEP: submitting the pod to kubernetes @ 02/07/24 14:26:11.338
  E0207 14:26:12.172301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:13.172462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:14.172982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:15.173118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:16.173748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:17.174143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:18.175136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:19.175227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/07/24 14:26:19.357
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:26:19.36
  Feb  7 14:26:19.365: INFO: File wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:19.368: INFO: File jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:19.368: INFO: Lookups using dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 failed for: [wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local]

  Feb  7 14:26:19.379: INFO: Pod client logs for webserver: 
  Feb  7 14:26:19.384: INFO: Pod client logs for querier: 
  Feb  7 14:26:19.388: INFO: Pod client logs for jessie-querier: 
  E0207 14:26:20.175775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:21.175969      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:22.176165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:23.176566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:24.176889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:26:24.363: INFO: File wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:24.366: INFO: File jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:24.366: INFO: Lookups using dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 failed for: [wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local]

  Feb  7 14:26:24.373: INFO: Pod client logs for webserver: 
  Feb  7 14:26:24.377: INFO: Pod client logs for querier: 
  Feb  7 14:26:24.382: INFO: Pod client logs for jessie-querier: 
  E0207 14:26:25.177060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:26.177249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:27.177533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:28.178126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:29.178332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:26:29.364: INFO: File wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:29.367: INFO: File jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:29.367: INFO: Lookups using dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 failed for: [wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local]

  Feb  7 14:26:29.371: INFO: Pod client logs for webserver: 
  Feb  7 14:26:29.376: INFO: Pod client logs for querier: 
  Feb  7 14:26:29.380: INFO: Pod client logs for jessie-querier: 
  E0207 14:26:30.179406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:31.179609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:32.179805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:33.180129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:34.180311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:26:34.364: INFO: File wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:34.367: INFO: File jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:34.367: INFO: Lookups using dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 failed for: [wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local]

  Feb  7 14:26:34.371: INFO: Pod client logs for webserver: 
  Feb  7 14:26:34.376: INFO: Pod client logs for querier: 
  Feb  7 14:26:34.380: INFO: Pod client logs for jessie-querier: 
  E0207 14:26:35.180381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:36.180477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:37.180826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:38.181162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:39.181282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:26:39.364: INFO: File wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:39.367: INFO: File jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local from pod  dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Feb  7 14:26:39.367: INFO: Lookups using dns-8532/dns-test-cfb8471c-257d-4d47-9219-6844a310b454 failed for: [wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local]

  Feb  7 14:26:39.372: INFO: Pod client logs for webserver: 
  Feb  7 14:26:39.376: INFO: Pod client logs for querier: 
  Feb  7 14:26:39.381: INFO: Pod client logs for jessie-querier: 
  E0207 14:26:40.181937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:41.182141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:42.182371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:43.182705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:44.182967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:26:44.366: INFO: DNS probes using dns-test-cfb8471c-257d-4d47-9219-6844a310b454 succeeded

  STEP: changing the service to type=ClusterIP @ 02/07/24 14:26:44.366
  W0207 14:26:44.379442      23 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8532.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8532.svc.cluster.local; sleep 1; done
   @ 02/07/24 14:26:44.379
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8532.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8532.svc.cluster.local; sleep 1; done
   @ 02/07/24 14:26:44.379
  STEP: creating a third pod to probe DNS @ 02/07/24 14:26:44.379
  STEP: submitting the pod to kubernetes @ 02/07/24 14:26:44.381
  E0207 14:26:45.183626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:46.183808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/07/24 14:26:46.392
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:26:46.395
  Feb  7 14:26:46.403: INFO: DNS probes using dns-test-b8f12444-1ccd-4f9f-a9ae-6358a84ee481 succeeded

  STEP: deleting the pod @ 02/07/24 14:26:46.403
  STEP: deleting the pod @ 02/07/24 14:26:46.412
  STEP: deleting the pod @ 02/07/24 14:26:46.424
  STEP: deleting the test externalName service @ 02/07/24 14:26:46.433
  Feb  7 14:26:46.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8532" for this suite. @ 02/07/24 14:26:46.449
• [37.158 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 02/07/24 14:26:46.453
  Feb  7 14:26:46.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:26:46.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:46.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:46.466
  STEP: Creating secret with name secret-test-e8fdbc71-490a-4fef-a003-67f122d68aa9 @ 02/07/24 14:26:46.468
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:26:46.472
  E0207 14:26:47.184187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:48.184289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:49.184339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:50.184540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:26:50.487
  Feb  7 14:26:50.489: INFO: Trying to get logs from node worker-0 pod pod-secrets-8705cfb7-7efb-40b2-ba16-6953cf05eacf container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:26:50.494
  Feb  7 14:26:50.504: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6019" for this suite. @ 02/07/24 14:26:50.507
• [4.059 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 02/07/24 14:26:50.512
  Feb  7 14:26:50.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:26:50.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:50.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:50.524
  STEP: Creating secret with name secret-test-f4d04ebb-87e1-4cbb-aa44-6835e279d4fc @ 02/07/24 14:26:50.526
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:26:50.531
  E0207 14:26:51.185031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:52.185059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:53.186070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:54.186277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:26:54.544
  Feb  7 14:26:54.545: INFO: Trying to get logs from node worker-0 pod pod-secrets-2d13dbb2-386f-4387-a40d-f0f376b740cf container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:26:54.55
  Feb  7 14:26:54.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3673" for this suite. @ 02/07/24 14:26:54.563
• [4.054 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 02/07/24 14:26:54.567
  Feb  7 14:26:54.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:26:54.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:54.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:54.58
  STEP: Creating configMap with name configmap-test-volume-map-db4c6411-462f-43a3-9a40-45580391c216 @ 02/07/24 14:26:54.582
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:26:54.585
  E0207 14:26:55.186900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:56.187114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:57.188046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:26:58.188441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:26:58.598
  Feb  7 14:26:58.600: INFO: Trying to get logs from node worker-0 pod pod-configmaps-198d4916-0e2b-48db-9285-f01599351f56 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:26:58.605
  Feb  7 14:26:58.613: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3242" for this suite. @ 02/07/24 14:26:58.616
• [4.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 02/07/24 14:26:58.625
  Feb  7 14:26:58.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename watch @ 02/07/24 14:26:58.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:58.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:58.638
  STEP: creating a new configmap @ 02/07/24 14:26:58.641
  STEP: modifying the configmap once @ 02/07/24 14:26:58.644
  STEP: modifying the configmap a second time @ 02/07/24 14:26:58.649
  STEP: deleting the configmap @ 02/07/24 14:26:58.654
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 02/07/24 14:26:58.658
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 02/07/24 14:26:58.659
  Feb  7 14:26:58.659: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1312  65ac7da4-b422-42cf-bbfb-cc037e992cfa 15622 0 2024-02-07 14:26:58 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-02-07 14:26:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:26:58.659: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1312  65ac7da4-b422-42cf-bbfb-cc037e992cfa 15623 0 2024-02-07 14:26:58 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-02-07 14:26:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:26:58.659: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1312" for this suite. @ 02/07/24 14:26:58.661
• [0.040 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 02/07/24 14:26:58.665
  Feb  7 14:26:58.665: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename watch @ 02/07/24 14:26:58.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:58.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:58.675
  STEP: creating a watch on configmaps @ 02/07/24 14:26:58.677
  STEP: creating a new configmap @ 02/07/24 14:26:58.678
  STEP: modifying the configmap once @ 02/07/24 14:26:58.681
  STEP: closing the watch once it receives two notifications @ 02/07/24 14:26:58.686
  Feb  7 14:26:58.686: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9823  d8738128-b845-4f6a-96b1-42d50879f6e3 15628 0 2024-02-07 14:26:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-07 14:26:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:26:58.686: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9823  d8738128-b845-4f6a-96b1-42d50879f6e3 15629 0 2024-02-07 14:26:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-07 14:26:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 02/07/24 14:26:58.686
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 02/07/24 14:26:58.691
  STEP: deleting the configmap @ 02/07/24 14:26:58.692
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 02/07/24 14:26:58.695
  Feb  7 14:26:58.695: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9823  d8738128-b845-4f6a-96b1-42d50879f6e3 15630 0 2024-02-07 14:26:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-07 14:26:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:26:58.695: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9823  d8738128-b845-4f6a-96b1-42d50879f6e3 15631 0 2024-02-07 14:26:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-02-07 14:26:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Feb  7 14:26:58.696: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9823" for this suite. @ 02/07/24 14:26:58.698
• [0.037 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 02/07/24 14:26:58.702
  Feb  7 14:26:58.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename security-context-test @ 02/07/24 14:26:58.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:26:58.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:26:58.714
  E0207 14:26:59.189188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:00.189300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:01.190160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:02.190267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:27:02.731: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5875" for this suite. @ 02/07/24 14:27:02.734
• [4.035 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 02/07/24 14:27:02.738
  Feb  7 14:27:02.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:27:02.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:27:02.748
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:27:02.75
  STEP: creating the pod @ 02/07/24 14:27:02.753
  STEP: setting up watch @ 02/07/24 14:27:02.753
  STEP: submitting the pod to kubernetes @ 02/07/24 14:27:02.855
  STEP: verifying the pod is in kubernetes @ 02/07/24 14:27:02.861
  STEP: verifying pod creation was observed @ 02/07/24 14:27:02.863
  E0207 14:27:03.190803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:04.191375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 02/07/24 14:27:04.871
  STEP: verifying pod deletion was observed @ 02/07/24 14:27:04.876
  E0207 14:27:05.191987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:27:05.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-630" for this suite. @ 02/07/24 14:27:05.929
• [3.195 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 02/07/24 14:27:05.933
  Feb  7 14:27:05.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:27:05.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:27:05.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:27:05.946
  STEP: Creating configMap with name projected-configmap-test-volume-2e3158b7-ea55-4128-bb82-39d2e1074b63 @ 02/07/24 14:27:05.949
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:27:05.952
  E0207 14:27:06.192421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:07.192482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:08.192832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:09.193037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:27:09.964
  Feb  7 14:27:09.966: INFO: Trying to get logs from node worker-0 pod pod-projected-configmaps-3df66139-3f82-4aca-b10c-2bf29c2615ce container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:27:09.971
  Feb  7 14:27:09.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4057" for this suite. @ 02/07/24 14:27:09.983
• [4.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 02/07/24 14:27:09.987
  Feb  7 14:27:09.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-preemption @ 02/07/24 14:27:09.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:27:09.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:27:10
  Feb  7 14:27:10.012: INFO: Waiting up to 1m0s for all nodes to be ready
  E0207 14:27:10.192874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:11.193084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:12.194078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:13.194456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:14.194563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:15.194840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:16.195325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:17.195599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:18.198823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:19.199025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:20.200077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:21.200295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:22.200802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:23.201158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:24.201580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:25.201697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:26.202286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:27.202558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:28.202612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:29.202788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:30.203583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:31.203792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:32.204118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:33.204513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:34.205255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:35.205460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:36.206122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:37.206415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:38.207176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:39.207401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:40.207559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:41.207679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:42.208775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:43.209126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:44.209568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:45.209779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:46.209990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:47.210383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:48.211360      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:49.211558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:50.212533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:51.212741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:52.213831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:53.214113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:54.214505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:55.214596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:56.215154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:57.215437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:58.216510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:27:59.216716      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:00.217651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:01.217858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:02.218606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:03.219028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:04.219967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:05.220154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:06.220734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:07.221041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:08.222077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:09.222284      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:10.016: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 02/07/24 14:28:10.018
  Feb  7 14:28:10.033: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Feb  7 14:28:10.038: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Feb  7 14:28:10.050: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Feb  7 14:28:10.058: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 02/07/24 14:28:10.058
  E0207 14:28:10.222714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:11.222828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 02/07/24 14:28:12.07
  E0207 14:28:12.223104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:13.223509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:14.224465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:15.224645      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:16.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1195" for this suite. @ 02/07/24 14:28:16.112
• [66.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 02/07/24 14:28:16.116
  Feb  7 14:28:16.116: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:28:16.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:28:16.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:28:16.128
  STEP: Creating service test in namespace statefulset-2933 @ 02/07/24 14:28:16.13
  STEP: Creating stateful set ss in namespace statefulset-2933 @ 02/07/24 14:28:16.134
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2933 @ 02/07/24 14:28:16.14
  Feb  7 14:28:16.142: INFO: Found 0 stateful pods, waiting for 1
  E0207 14:28:16.225344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:17.226235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:18.226606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:19.226801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:20.227001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:21.227596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:22.227880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:23.228207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:24.228317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:25.228423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:26.143: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 02/07/24 14:28:26.143
  Feb  7 14:28:26.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0207 14:28:26.228746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:26.254: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:28:26.255: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:28:26.255: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:28:26.257: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0207 14:28:27.229039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:28.229422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:29.230161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:30.230378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:31.230571      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:32.230768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:33.231124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:34.231247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:35.231431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:36.231606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:36.258: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:28:36.258: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb  7 14:28:36.269: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
  Feb  7 14:28:36.269: INFO: ss-0  worker-0  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:17 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:16 +0000 UTC  }]
  Feb  7 14:28:36.269: INFO: 
  Feb  7 14:28:36.269: INFO: StatefulSet ss has not reached scale 3, at 1
  E0207 14:28:37.231821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:37.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997589799s
  E0207 14:28:38.232144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:38.276: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99444456s
  E0207 14:28:39.232253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:39.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990268455s
  E0207 14:28:40.233059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:40.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986472551s
  E0207 14:28:41.233157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:41.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982356932s
  E0207 14:28:42.234121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:42.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979291704s
  E0207 14:28:43.234654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:43.295: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975828745s
  E0207 14:28:44.234877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:44.299: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971634927s
  E0207 14:28:45.235543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:45.302: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.955633ms
  E0207 14:28:46.235664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2933 @ 02/07/24 14:28:46.302
  Feb  7 14:28:46.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:28:46.439: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:28:46.439: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:28:46.439: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:28:46.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:28:46.564: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Feb  7 14:28:46.564: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:28:46.564: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:28:46.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:28:46.686: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Feb  7 14:28:46.686: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:28:46.686: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:28:46.689: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:28:46.689: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:28:46.689: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 02/07/24 14:28:46.689
  Feb  7 14:28:46.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:28:46.807: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:28:46.807: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:28:46.807: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:28:46.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:28:46.927: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:28:46.927: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:28:46.927: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:28:46.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-2933 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:28:47.044: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:28:47.044: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:28:47.044: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:28:47.044: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb  7 14:28:47.046: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0207 14:28:47.236719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:48.237045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:49.238130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:50.238319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:51.238519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:52.238720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:53.239040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:54.239158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:55.239336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:28:56.239519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:57.049: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:28:57.049: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:28:57.049: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:28:57.059: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
  Feb  7 14:28:57.059: INFO: ss-0  worker-0  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:17 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:16 +0000 UTC  }]
  Feb  7 14:28:57.059: INFO: ss-1  worker-0  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:37 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:36 +0000 UTC  }]
  Feb  7 14:28:57.059: INFO: ss-2  worker-1  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:37 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:36 +0000 UTC  }]
  Feb  7 14:28:57.059: INFO: 
  Feb  7 14:28:57.059: INFO: StatefulSet ss has not reached scale 0, at 3
  E0207 14:28:57.240162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:58.062: INFO: POD   NODE      PHASE      GRACE  CONDITIONS
  Feb  7 14:28:58.062: INFO: ss-0  worker-0  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:57 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:16 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:16 +0000 UTC  }]
  Feb  7 14:28:58.062: INFO: ss-1  worker-0  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:57 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:36 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:47 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:28:36 +0000 UTC  }]
  Feb  7 14:28:58.062: INFO: 
  Feb  7 14:28:58.062: INFO: StatefulSet ss has not reached scale 0, at 2
  E0207 14:28:58.240299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:28:59.064: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.994431039s
  E0207 14:28:59.240591      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:00.066: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.992117103s
  E0207 14:29:00.241248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:01.069: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.989411462s
  E0207 14:29:01.241908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:02.072: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.986810439s
  E0207 14:29:02.242552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:03.075: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.9840337s
  E0207 14:29:03.243529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:04.077: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.981193374s
  E0207 14:29:04.243960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:05.080: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.978752905s
  E0207 14:29:05.244523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:06.082: INFO: Verifying statefulset ss doesn't scale past 0 for another 976.181693ms
  E0207 14:29:06.245043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2933 @ 02/07/24 14:29:07.083
  Feb  7 14:29:07.086: INFO: Scaling statefulset ss to 0
  Feb  7 14:29:07.093: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:29:07.095: INFO: Deleting all statefulset in ns statefulset-2933
  Feb  7 14:29:07.096: INFO: Scaling statefulset ss to 0
  Feb  7 14:29:07.103: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:29:07.105: INFO: Deleting statefulset ss
  Feb  7 14:29:07.111: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2933" for this suite. @ 02/07/24 14:29:07.114
• [51.003 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 02/07/24 14:29:07.119
  Feb  7 14:29:07.119: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename namespaces @ 02/07/24 14:29:07.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:07.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:07.131
  STEP: creating a Namespace @ 02/07/24 14:29:07.134
  STEP: patching the Namespace @ 02/07/24 14:29:07.142
  STEP: get the Namespace and ensuring it has the label @ 02/07/24 14:29:07.147
  Feb  7 14:29:07.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-308" for this suite. @ 02/07/24 14:29:07.155
  STEP: Destroying namespace "nspatchtest-30db3c20-d2ed-4dfb-95c4-364b8fcad687-652" for this suite. @ 02/07/24 14:29:07.159
• [0.044 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 02/07/24 14:29:07.165
  Feb  7 14:29:07.165: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 14:29:07.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:07.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:07.175
  STEP: creating a Deployment @ 02/07/24 14:29:07.179
  STEP: waiting for Deployment to be created @ 02/07/24 14:29:07.183
  STEP: waiting for all Replicas to be Ready @ 02/07/24 14:29:07.184
  Feb  7 14:29:07.185: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.185: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.192: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.192: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.202: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.202: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.223: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.223: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0207 14:29:07.245511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:07.748: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Feb  7 14:29:07.749: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Feb  7 14:29:08.166: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 02/07/24 14:29:08.166
  Feb  7 14:29:08.171: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 02/07/24 14:29:08.171
  Feb  7 14:29:08.173: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.173: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.173: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.173: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 0
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.174: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.181: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.181: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.194: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.194: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:08.200: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:08.200: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:08.209: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:08.209: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  E0207 14:29:08.246305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:09.175: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:09.175: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:09.191: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  STEP: listing Deployments @ 02/07/24 14:29:09.191
  Feb  7 14:29:09.194: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 02/07/24 14:29:09.194
  Feb  7 14:29:09.211: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 02/07/24 14:29:09.211
  Feb  7 14:29:09.216: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:09.220: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:09.235: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0207 14:29:09.246578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:09.248: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:09.254: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:09.774: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:10.185: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:10.214: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Feb  7 14:29:10.222: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0207 14:29:10.247335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:10.771: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 02/07/24 14:29:10.784
  STEP: fetching the DeploymentStatus @ 02/07/24 14:29:10.795
  Feb  7 14:29:10.801: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:10.801: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:10.801: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:10.801: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:10.802: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 1
  Feb  7 14:29:10.802: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:10.802: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 3
  Feb  7 14:29:10.802: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:10.802: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 2
  Feb  7 14:29:10.802: INFO: observed Deployment test-deployment in namespace deployment-3654 with ReadyReplicas 3
  STEP: deleting the Deployment @ 02/07/24 14:29:10.802
  Feb  7 14:29:10.810: INFO: observed event type MODIFIED
  Feb  7 14:29:10.810: INFO: observed event type MODIFIED
  Feb  7 14:29:10.810: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.811: INFO: observed event type MODIFIED
  Feb  7 14:29:10.812: INFO: observed event type MODIFIED
  Feb  7 14:29:10.812: INFO: observed event type MODIFIED
  Feb  7 14:29:10.814: INFO: Log out all the ReplicaSets if there is no deployment created
  Feb  7 14:29:10.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3654" for this suite. @ 02/07/24 14:29:10.822
• [3.665 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 02/07/24 14:29:10.831
  Feb  7 14:29:10.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:29:10.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:10.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:10.845
  STEP: Creating projection with secret that has name projected-secret-test-cc55f244-18ab-46fa-9fe5-8f40ef74b0fd @ 02/07/24 14:29:10.848
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:29:10.852
  E0207 14:29:11.248332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:12.248695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:13.249323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:14.250129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:29:14.87
  Feb  7 14:29:14.872: INFO: Trying to get logs from node worker-0 pod pod-projected-secrets-ce7c4a04-5ff3-4bea-a6e2-2551e0b7b729 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:29:14.885
  Feb  7 14:29:14.894: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4280" for this suite. @ 02/07/24 14:29:14.897
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 02/07/24 14:29:14.901
  Feb  7 14:29:14.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 14:29:14.902
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:14.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:14.914
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 02/07/24 14:29:14.917
  Feb  7 14:29:14.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:29:15.250759      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:16.251685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:17.251721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:18.252532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:19.253493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 02/07/24 14:29:20.083
  Feb  7 14:29:20.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:29:20.254402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:21.255085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:21.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:29:22.255343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:23.255825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:24.256475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:25.257528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:26.258245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:26.438: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9951" for this suite. @ 02/07/24 14:29:26.445
• [11.549 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 02/07/24 14:29:26.451
  Feb  7 14:29:26.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:29:26.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:26.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:26.464
  STEP: Creating the pod @ 02/07/24 14:29:26.466
  E0207 14:29:27.258710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:28.259146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:28.995: INFO: Successfully updated pod "labelsupdate33a1255a-2211-4071-b0a0-2f7d89d51b33"
  E0207 14:29:29.259620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:30.259811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:31.260599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:32.260931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:33.014: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-609" for this suite. @ 02/07/24 14:29:33.017
• [6.570 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 02/07/24 14:29:33.022
  Feb  7 14:29:33.022: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:29:33.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:33.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:33.034
  STEP: Creating a pod to test downward api env vars @ 02/07/24 14:29:33.037
  E0207 14:29:33.261332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:34.261519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:29:35.05
  Feb  7 14:29:35.052: INFO: Trying to get logs from node worker-1 pod downward-api-4a37215c-b2c9-48ab-8970-b5cd25a341ca container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 14:29:35.064
  Feb  7 14:29:35.075: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8690" for this suite. @ 02/07/24 14:29:35.077
• [2.061 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 02/07/24 14:29:35.083
  Feb  7 14:29:35.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:29:35.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:35.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:35.095
  STEP: validating cluster-info @ 02/07/24 14:29:35.097
  Feb  7 14:29:35.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-5438 cluster-info'
  Feb  7 14:29:35.158: INFO: stderr: ""
  Feb  7 14:29:35.158: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Feb  7 14:29:35.158: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5438" for this suite. @ 02/07/24 14:29:35.161
• [0.083 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 02/07/24 14:29:35.167
  Feb  7 14:29:35.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:29:35.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:29:35.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:29:35.179
  STEP: Creating pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879 @ 02/07/24 14:29:35.181
  E0207 14:29:35.261678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:36.262145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:29:37.193
  Feb  7 14:29:37.196: INFO: Initial restart count of pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 is 0
  Feb  7 14:29:37.197: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:37.262307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:38.262868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:39.200: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:39.263091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:40.263329      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:41.203: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:41.263928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:42.264256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:43.206: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:43.264653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:44.265163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:45.210: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:45.266225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:46.266403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:47.213: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:47.267471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:48.267645      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:49.216: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:49.268710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:50.268815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:51.219: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:51.269596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:52.270362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:53.222: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:53.271007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:54.271197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:55.225: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:55.271736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:56.271949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:57.228: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:57.273021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:29:58.273224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:29:59.232: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:29:59.273401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:00.273592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:01.235: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:01.274365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:02.275382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:03.237: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:03.276128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:04.276450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:05.241: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:05.277317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:06.277516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:07.253: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:07.278420      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:08.278689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:09.256: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:09.279360      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:10.279485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:11.259: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:11.280155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:12.280630      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:13.261: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:13.281574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:14.281755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:15.264: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:15.282537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:16.282723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:17.267: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:17.283732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:18.283880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:19.270: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:19.283963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:20.284144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:21.273: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:21.284735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:22.285379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:23.276: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:23.286359      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:24.286545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:25.279: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  E0207 14:30:25.287177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:26.287304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:27.282: INFO: Get pod busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 in namespace container-probe-6879
  Feb  7 14:30:27.282: INFO: Restart count of pod container-probe-6879/busybox-0bde524f-3e87-4eab-b91c-bceb3a549d89 is now 1 (50.086077831s elapsed)
  STEP: deleting the pod @ 02/07/24 14:30:27.282
  E0207 14:30:27.288225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:27.291: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6879" for this suite. @ 02/07/24 14:30:27.293
• [52.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 02/07/24 14:30:27.299
  Feb  7 14:30:27.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename disruption @ 02/07/24 14:30:27.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:30:27.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:30:27.311
  STEP: Creating a kubernetes client @ 02/07/24 14:30:27.314
  Feb  7 14:30:27.314: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename disruption-2 @ 02/07/24 14:30:27.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:30:27.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:30:27.328
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:30:27.334
  E0207 14:30:28.288326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:29.288472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:30:29.343
  E0207 14:30:30.288884      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:31.289063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 02/07/24 14:30:31.35
  E0207 14:30:32.289319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:33.290111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 02/07/24 14:30:33.352
  STEP: listing a collection of PDBs in namespace disruption-3323 @ 02/07/24 14:30:33.354
  STEP: deleting a collection of PDBs @ 02/07/24 14:30:33.356
  STEP: Waiting for the PDB collection to be deleted @ 02/07/24 14:30:33.363
  Feb  7 14:30:33.364: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-1405" for this suite. @ 02/07/24 14:30:33.367
  Feb  7 14:30:33.370: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3323" for this suite. @ 02/07/24 14:30:33.373
• [6.077 seconds]
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 02/07/24 14:30:33.377
  Feb  7 14:30:33.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:30:33.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:30:33.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:30:33.391
  STEP: Creating pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728 @ 02/07/24 14:30:33.394
  E0207 14:30:34.290242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:35.290553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:30:35.406
  Feb  7 14:30:35.408: INFO: Initial restart count of pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 is 0
  Feb  7 14:30:35.410: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:36.290675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:37.291242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:37.413: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:38.291972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:39.292173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:39.416: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:40.292373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:41.292507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:41.419: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:42.293375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:43.294131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:43.421: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:44.294947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:45.295144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:45.425: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:46.295374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:47.295911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:47.428: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:48.296678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:49.296874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:49.432: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:50.297262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:51.297366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:51.435: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:52.298326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:53.298530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:53.438: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:54.299391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:55.299577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:55.441: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  Feb  7 14:30:55.441: INFO: Restart count of pod container-probe-5728/liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 is now 1 (20.032887898s elapsed)
  E0207 14:30:56.299689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:57.300217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:57.445: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:30:58.300339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:30:59.300449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:30:59.448: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:00.300517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:01.300733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:01.451: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:02.300954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:03.301185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:03.455: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:04.301276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:05.301598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:05.458: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:06.302282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:07.302381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:07.461: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:08.302718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:09.302951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:09.464: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:10.303088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:11.303271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:11.467: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:12.304269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:13.304485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:13.470: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:14.304635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:15.304872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:15.473: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  Feb  7 14:31:15.473: INFO: Restart count of pod container-probe-5728/liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 is now 2 (40.065268618s elapsed)
  E0207 14:31:16.305052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:17.305512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:17.477: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:18.306341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:19.306545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:19.481: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:20.306815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:21.307012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:21.483: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:22.307391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:23.307908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:23.486: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:24.308628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:25.308818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:25.489: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:26.309008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:27.309478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:27.492: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:28.310035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:29.310240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:29.495: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:30.310380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:31.310588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:31.498: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:32.311551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:33.311766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:33.501: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:34.312274      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:35.312467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:35.504: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  Feb  7 14:31:35.504: INFO: Restart count of pod container-probe-5728/liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 is now 3 (1m0.095656091s elapsed)
  E0207 14:31:36.313112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:37.313676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:37.507: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:38.314408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:39.314599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:39.510: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:40.315557      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:41.315652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:41.513: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:42.316357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:43.316554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:43.516: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:44.316647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:45.316763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:45.519: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:46.317309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:47.317946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:47.522: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:48.318551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:49.318739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:49.526: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:50.319493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:51.319954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:51.528: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:52.320544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:53.320733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:53.531: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:54.321173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:55.321545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:55.534: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  Feb  7 14:31:55.534: INFO: Restart count of pod container-probe-5728/liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 is now 4 (1m20.125556617s elapsed)
  E0207 14:31:56.321959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:57.322451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:57.537: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:31:58.323067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:31:59.323408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:31:59.540: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:00.324454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:01.324546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:01.543: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:02.325256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:03.325483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:03.546: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:04.325922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:05.326124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:05.548: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:06.326537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:07.326897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:07.552: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:08.327346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:09.327561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:09.555: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:10.327657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:11.327792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:11.558: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:12.328675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:13.328867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:13.561: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:14.329614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:15.329894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:15.564: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:16.330601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:17.331168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:17.568: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:18.331758      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:19.331934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:19.571: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:20.332995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:21.333180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:21.574: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:22.334218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:23.334400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:23.577: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:24.334533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:25.334705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:25.580: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:26.334904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:27.335304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:27.583: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:28.335915      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:29.336392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:29.586: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:30.336421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:31.336606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:31.589: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:32.337275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:33.337461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:33.592: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:34.338079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:35.338299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:35.595: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:36.339016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:37.339471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:37.598: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:38.340144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:39.340323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:39.601: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:40.340456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:41.340651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:41.604: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:42.341379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:43.341560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:43.607: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:44.341686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:45.341871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:45.610: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:46.341993      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:47.342469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:47.613: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:48.343328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:49.343515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:49.616: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:50.344521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:51.344692      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:51.619: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:52.345230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:53.345421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:53.622: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:54.345901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:55.346083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:55.624: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:56.346306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:57.346668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:57.627: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:32:58.347308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:32:59.347430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:32:59.630: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:33:00.348327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:01.348513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:01.633: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:33:02.349266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:03.349456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:03.636: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  E0207 14:33:04.349585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:05.349796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:05.639: INFO: Get pod liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 in namespace container-probe-5728
  Feb  7 14:33:05.639: INFO: Restart count of pod container-probe-5728/liveness-140d4ea1-1994-4a16-b8e0-6cd11fba5325 is now 5 (2m30.230624051s elapsed)
  STEP: deleting the pod @ 02/07/24 14:33:05.639
  Feb  7 14:33:05.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5728" for this suite. @ 02/07/24 14:33:05.649
• [152.277 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 02/07/24 14:33:05.654
  Feb  7 14:33:05.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:33:05.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:33:05.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:33:05.665
  STEP: Creating pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522 @ 02/07/24 14:33:05.668
  E0207 14:33:06.349990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:07.350451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:33:07.678
  Feb  7 14:33:07.680: INFO: Initial restart count of pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 is 0
  Feb  7 14:33:07.682: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:08.350971      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:09.351069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:09.685: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:10.351247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:11.351447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:11.688: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:12.352446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:13.352507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:13.691: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:14.352966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:15.353053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:15.694: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:16.353732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:17.354295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:17.697: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:18.354405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:19.354619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:19.700: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:20.355470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:21.355661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:21.703: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:22.356310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:23.356514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:23.706: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:24.356615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:25.356804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:25.708: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:26.356962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:27.357438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:27.711: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:28.357984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:29.358072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:29.714: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:30.359167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:31.359359      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:31.717: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:32.359753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:33.359952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:33.719: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:34.360350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:35.360658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:35.722: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:36.361650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:37.362102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:37.726: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:38.362950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:39.363195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:39.729: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:40.364175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:41.364592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:41.732: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:42.365439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:43.366134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:43.735: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:44.366533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:45.366739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:45.738: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:46.367173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:47.367715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:47.741: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:48.368164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:49.368368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:49.744: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:50.369326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:51.369531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:51.747: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:52.370382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:53.370599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:53.750: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:54.370899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:55.371085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:55.752: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:56.371661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:57.372274      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:57.756: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:33:58.372868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:33:59.373116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:33:59.759: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:00.373893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:01.374091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:01.762: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:02.374905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:03.375106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:03.764: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:04.375303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:05.375501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:05.767: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:06.375589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:07.376130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:07.769: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:08.376435      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:09.376631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:09.772: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:10.377531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:11.377752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:11.775: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:12.378501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:13.378687      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:13.778: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:14.379055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:15.379236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:15.781: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:16.379957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:17.380009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:17.783: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:18.380516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:19.380694      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:19.787: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:20.380768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:21.380967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:21.789: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:22.381811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:23.382108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:23.792: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:24.382493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:25.382675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:25.795: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:26.383106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:27.383424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:27.798: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:28.383911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:29.384089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:29.801: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:30.384964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:31.385160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:31.804: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:32.385504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:33.386533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:33.807: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:34.386858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:35.386980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:35.810: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:36.387668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:37.388438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:37.813: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:38.388976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:39.389165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:39.816: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:40.390176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:41.390296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:41.819: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:42.391104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:43.391276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:43.821: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:44.392306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:45.392479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:45.824: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:46.393035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:47.393609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:47.827: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:48.394182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:49.394350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:49.830: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:50.394462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:51.394649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:51.833: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:52.395421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:53.395539      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:53.836: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:54.395621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:55.395798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:55.838: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:56.396534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:57.396987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:57.842: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:34:58.397749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:34:59.397925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:34:59.845: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:00.399001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:01.399170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:01.848: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:02.399958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:03.400131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:03.850: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:04.400485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:05.400670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:05.853: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:06.401040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:07.401426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:07.856: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:08.401977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:09.402164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:09.859: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:10.402223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:11.402398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:11.862: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:12.403083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:13.403266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:13.865: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:14.403677      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:15.403850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:15.867: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:16.404492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:17.404961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:17.871: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:18.405813      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:19.405997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:19.874: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:20.406952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:21.407135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:21.876: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:22.407344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:23.407517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:23.879: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:24.407726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:25.407897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:25.881: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:26.408617      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:27.409450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:27.885: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:28.410129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:29.410302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:29.888: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:30.411000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:31.411172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:31.890: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:32.411388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:33.411499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:33.893: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:34.412379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:35.412584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:35.896: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:36.413407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:37.413834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:37.899: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:38.414328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:39.414508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:39.902: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:40.415440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:41.415566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:41.905: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:42.416407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:43.416581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:43.908: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:44.417041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:45.417230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:45.911: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:46.417885      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:47.418349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:47.914: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:48.419041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:49.419223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:49.917: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:50.419261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:51.419443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:51.920: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:52.420155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:53.420337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:53.923: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:54.420697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:55.420896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:55.926: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:56.421636      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:57.422096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:57.929: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:35:58.423039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:35:59.423221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:35:59.932: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:00.423321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:01.423520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:01.935: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:02.424470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:03.424669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:03.938: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:04.424853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:05.425042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:05.941: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:06.425721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:07.426115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:07.943: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:08.426384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:09.426575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:09.947: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:10.426586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:11.426776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:11.949: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:12.427294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:13.427462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:13.952: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:14.427756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:15.427951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:15.955: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:16.428699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:17.429224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:17.958: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:18.430051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:19.430236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:19.961: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:20.430289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:21.430467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:21.964: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:22.431105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:23.431276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:23.966: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:24.432249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:25.432373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:25.969: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:26.432808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:27.433305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:27.972: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:28.434251      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:29.434384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:29.975: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:30.435209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:31.435402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:31.978: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:32.435981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:33.436656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:33.981: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:34.436740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:35.436939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:35.985: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:36.437445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:37.438318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:37.988: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:38.439002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:39.439197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:39.991: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:40.439967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:41.440146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:41.994: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:42.441132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:43.441324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:43.997: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:44.441737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:45.441908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:45.999: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:46.442096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:47.442502      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:48.002: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:48.443264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:49.443389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:50.005: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:50.444096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:51.444271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:52.008: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:52.444794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:53.445015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:54.010: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:54.445084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:55.445261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:56.014: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:56.445374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:57.445722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:36:58.016: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:36:58.446323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:36:59.446497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:00.019: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:37:00.447449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:01.447629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:02.022: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:37:02.448401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:03.448587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:04.025: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:37:04.448987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:05.449168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:06.028: INFO: Get pod busybox-64c4a8ee-2a9d-434c-aa0f-19a125259364 in namespace container-probe-1522
  E0207 14:37:06.449593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:07.450042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/07/24 14:37:08.029
  Feb  7 14:37:08.038: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1522" for this suite. @ 02/07/24 14:37:08.042
• [242.393 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 02/07/24 14:37:08.047
  Feb  7 14:37:08.047: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:37:08.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:37:08.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:37:08.059
  STEP: Creating service test in namespace statefulset-7320 @ 02/07/24 14:37:08.062
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 02/07/24 14:37:08.065
  STEP: Creating stateful set ss in namespace statefulset-7320 @ 02/07/24 14:37:08.067
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7320 @ 02/07/24 14:37:08.073
  Feb  7 14:37:08.075: INFO: Found 0 stateful pods, waiting for 1
  E0207 14:37:08.450947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:09.451934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:10.452054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:11.452266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:12.452621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:13.452817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:14.453022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:15.453227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:16.453433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:17.453877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:18.077: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 02/07/24 14:37:18.077
  Feb  7 14:37:18.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:37:18.207: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:37:18.207: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:37:18.207: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:37:18.209: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0207 14:37:18.454676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:19.454884      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:20.455089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:21.455262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:22.455720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:23.455832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:24.456035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:25.456127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:26.456330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:27.456769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:28.210: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:37:28.210: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb  7 14:37:28.220: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999997926s
  E0207 14:37:28.457468      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:29.222: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997702228s
  E0207 14:37:29.457935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:30.225: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995235964s
  E0207 14:37:30.458662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:31.228: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992505306s
  E0207 14:37:31.459278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:32.230: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989901524s
  E0207 14:37:32.460038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:33.233: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.987127271s
  E0207 14:37:33.460686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:34.235: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.984523328s
  E0207 14:37:34.461175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:35.238: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.982064026s
  E0207 14:37:35.461895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:36.241: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.979270065s
  E0207 14:37:36.461928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:37.244: INFO: Verifying statefulset ss doesn't scale past 1 for another 976.053957ms
  E0207 14:37:37.462949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7320 @ 02/07/24 14:37:38.244
  Feb  7 14:37:38.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:37:38.364: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:37:38.364: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:37:38.364: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:37:38.366: INFO: Found 1 stateful pods, waiting for 3
  E0207 14:37:38.463666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:39.463899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:40.464007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:41.464221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:42.464474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:43.464582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:44.464694      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:45.464878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:46.465086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:47.465699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:48.368: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:37:48.368: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:37:48.368: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 02/07/24 14:37:48.368
  STEP: Scale down will halt with unhealthy stateful pod @ 02/07/24 14:37:48.368
  Feb  7 14:37:48.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0207 14:37:48.466311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:48.483: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:37:48.483: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:37:48.483: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:37:48.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:37:48.605: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:37:48.606: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:37:48.606: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:37:48.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Feb  7 14:37:48.732: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Feb  7 14:37:48.732: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Feb  7 14:37:48.732: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Feb  7 14:37:48.732: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Feb  7 14:37:48.734: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0207 14:37:49.466740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:50.466964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:51.467256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:52.467622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:53.467735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:54.467956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:55.468164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:56.468289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:57.468764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:37:58.469001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:58.737: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:37:58.737: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:37:58.737: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Feb  7 14:37:58.746: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998687s
  E0207 14:37:59.469152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:37:59.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997620682s
  E0207 14:38:00.469843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:00.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994110441s
  E0207 14:38:01.470227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:01.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990435525s
  E0207 14:38:02.470411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:02.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987326932s
  E0207 14:38:03.471292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:03.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984432608s
  E0207 14:38:04.472159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:04.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981585179s
  E0207 14:38:05.473159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:05.768: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978587004s
  E0207 14:38:06.474044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:06.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975535555s
  E0207 14:38:07.474395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:07.774: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.320025ms
  E0207 14:38:08.475280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7320 @ 02/07/24 14:38:08.774
  Feb  7 14:38:08.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:38:08.895: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:38:08.895: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:38:08.895: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:38:08.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:38:09.009: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:38:09.009: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:38:09.009: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:38:09.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=statefulset-7320 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Feb  7 14:38:09.132: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Feb  7 14:38:09.132: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Feb  7 14:38:09.132: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Feb  7 14:38:09.132: INFO: Scaling statefulset ss to 0
  E0207 14:38:09.475436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:10.476079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:11.476469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:12.476667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:13.476877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:14.477066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:15.477281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:16.477399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:17.477893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:18.478017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 02/07/24 14:38:19.14
  Feb  7 14:38:19.140: INFO: Deleting all statefulset in ns statefulset-7320
  Feb  7 14:38:19.142: INFO: Scaling statefulset ss to 0
  Feb  7 14:38:19.149: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:38:19.151: INFO: Deleting statefulset ss
  Feb  7 14:38:19.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7320" for this suite. @ 02/07/24 14:38:19.16
• [71.118 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 02/07/24 14:38:19.164
  Feb  7 14:38:19.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:38:19.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:19.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:19.176
  STEP: Creating configMap with name configmap-projected-all-test-volume-d77e1905-8edc-4d8a-a832-a961cd744664 @ 02/07/24 14:38:19.178
  STEP: Creating secret with name secret-projected-all-test-volume-bc205634-1d06-45a6-8bdf-dcaac0220966 @ 02/07/24 14:38:19.182
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 02/07/24 14:38:19.185
  E0207 14:38:19.478790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:20.479043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:21.479754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:22.480558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:38:23.201
  Feb  7 14:38:23.204: INFO: Trying to get logs from node worker-0 pod projected-volume-521c61d6-bb02-4f7b-bdc0-8ce3504475b3 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:38:23.217
  Feb  7 14:38:23.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1493" for this suite. @ 02/07/24 14:38:23.229
• [4.068 seconds]
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 02/07/24 14:38:23.233
  Feb  7 14:38:23.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:38:23.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:23.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:23.244
  Feb  7 14:38:23.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: creating the pod @ 02/07/24 14:38:23.248
  STEP: submitting the pod to kubernetes @ 02/07/24 14:38:23.248
  E0207 14:38:23.481355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:24.481465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:25.328: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7949" for this suite. @ 02/07/24 14:38:25.331
• [2.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 02/07/24 14:38:25.336
  Feb  7 14:38:25.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:38:25.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:25.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:25.349
  STEP: Creating secret with name secret-test-8348d418-a943-4083-9b59-8368bf1c6aa7 @ 02/07/24 14:38:25.352
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:38:25.355
  E0207 14:38:25.481638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:26.481838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:38:27.365
  Feb  7 14:38:27.368: INFO: Trying to get logs from node worker-0 pod pod-secrets-c4f41122-ab51-4d59-b9f4-a16ef821c828 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:38:27.373
  Feb  7 14:38:27.383: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3097" for this suite. @ 02/07/24 14:38:27.385
• [2.052 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 02/07/24 14:38:27.389
  Feb  7 14:38:27.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 14:38:27.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:27.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:27.4
  Feb  7 14:38:27.403: INFO: Creating deployment "webserver-deployment"
  Feb  7 14:38:27.406: INFO: Waiting for observed generation 1
  E0207 14:38:27.482835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:28.483038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:29.412: INFO: Waiting for all required pods to come up
  Feb  7 14:38:29.415: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 02/07/24 14:38:29.415
  Feb  7 14:38:29.415: INFO: Waiting for deployment "webserver-deployment" to complete
  Feb  7 14:38:29.419: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Feb  7 14:38:29.425: INFO: Updating deployment webserver-deployment
  Feb  7 14:38:29.425: INFO: Waiting for observed generation 2
  E0207 14:38:29.483487      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:30.483561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:31.430: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Feb  7 14:38:31.432: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Feb  7 14:38:31.434: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Feb  7 14:38:31.440: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Feb  7 14:38:31.440: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Feb  7 14:38:31.441: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Feb  7 14:38:31.445: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Feb  7 14:38:31.445: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Feb  7 14:38:31.452: INFO: Updating deployment webserver-deployment
  Feb  7 14:38:31.452: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Feb  7 14:38:31.459: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Feb  7 14:38:31.461: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Feb  7 14:38:31.472: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0093d118-5edb-43c3-903e-249529e4f44a",
      ResourceVersion: (string) (len=5) "18408",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 14:38:31.478: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
      ResourceVersion: (string) (len=5) "18414",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "0093d118-5edb-43c3-903e-249529e4f44a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 30 39 33 64 31  31 38 2d 35 65 64 62 2d  |\"0093d118-5edb-|
              00000120  34 33 63 33 2d 39 30 33  65 2d 32 34 39 35 32 39  |43c3-903e-249529|
              00000130  65 34 66 34 34 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e4f44a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:38:31.480: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Feb  7 14:38:31.480: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
      ResourceVersion: (string) (len=5) "18411",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "0093d118-5edb-43c3-903e-249529e4f44a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 30 39 33 64 31  31 38 2d 35 65 64 62 2d  |\"0093d118-5edb-|
              00000120  34 33 63 33 2d 39 30 33  65 2d 32 34 39 35 32 39  |43c3-903e-249529|
              00000130  65 34 66 34 34 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e4f44a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  E0207 14:38:31.484498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:31.493: INFO: Pod "webserver-deployment-557759b7c7-7cft8" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7cft8",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0bfe3318-d79b-43aa-b0bf-2b8e0055b7ad",
      ResourceVersion: (string) (len=5) "18425",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kkwn4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kkwn4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.496: INFO: Pod "webserver-deployment-557759b7c7-8gnck" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-8gnck",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dccc6ca9-2536-4477-90d5-37aef5de82fc",
      ResourceVersion: (string) (len=5) "18419",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zgv8z",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zgv8z",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.501: INFO: Pod "webserver-deployment-557759b7c7-b2b78" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-b2b78",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8126cc39-bca1-49d2-b34c-23dcc8954729",
      ResourceVersion: (string) (len=5) "18289",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  37 33 5c 22 7d 22 3a 7b  |.244.1.173\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g4b4v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g4b4v",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.173",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.173"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f3ff846f887f32fc6286734a644e42ff927472c88795d4a6ec15d85b367cab3c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.507: INFO: Pod "webserver-deployment-557759b7c7-b7smg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-b7smg",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ad79024a-a327-4bbd-b254-06157be18362",
      ResourceVersion: (string) (len=5) "18292",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  37 32 5c 22 7d 22 3a 7b  |.244.1.172\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-phlx8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-phlx8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.172",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.172"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a46a909dba3f4ced4492c2a29ff6a2b4b5c3b1f002c33b1285d534bf0f4679f3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.510: INFO: Pod "webserver-deployment-557759b7c7-bkk6l" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-bkk6l",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b32f38b9-ea1f-4ae3-933a-ef4ac0cf803b",
      ResourceVersion: (string) (len=5) "18426",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fwzs6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fwzs6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.512: INFO: Pod "webserver-deployment-557759b7c7-d4mtt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-d4mtt",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cc710593-354f-42c9-88aa-1186ce48a154",
      ResourceVersion: (string) (len=5) "18421",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-czczm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-czczm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.515: INFO: Pod "webserver-deployment-557759b7c7-fd792" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-fd792",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e819d7c2-df21-48a5-b0ee-0ed7528c108d",
      ResourceVersion: (string) (len=5) "18310",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 36  34 5c 22 7d 22 3a 7b 22  |.244.0.64\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-584ks",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-584ks",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.64",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.64"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://67a6f08f9922a369b7d561d5e791001b4a34c3d3fdea2d0a1d55855027cdaff5",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.518: INFO: Pod "webserver-deployment-557759b7c7-hjl97" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-hjl97",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5a9bd77f-bb7e-4400-a408-fc31b3638366",
      ResourceVersion: (string) (len=5) "18427",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6brjg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6brjg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.520: INFO: Pod "webserver-deployment-557759b7c7-hvxkj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-hvxkj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "27054caf-3cd9-46e7-a32d-b2eaebea19b8",
      ResourceVersion: (string) (len=5) "18308",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 36  37 5c 22 7d 22 3a 7b 22  |.244.0.67\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h4sq9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h4sq9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.67",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.67"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://6600274a74421f88c36ffb9ef4bad5959c9907266d472c321195cefe18c91f2c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.523: INFO: Pod "webserver-deployment-557759b7c7-j2s5j" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-j2s5j",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dd3736b8-045c-4aac-af03-ac07e64b65de",
      ResourceVersion: (string) (len=5) "18286",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  36 39 5c 22 7d 22 3a 7b  |.244.1.169\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-58fmp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-58fmp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.169",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.169"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c97bd254118f3848b01d340db1daa9edc6b176acc4e8c006b0dd4faaeef004cc",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.526: INFO: Pod "webserver-deployment-557759b7c7-lh64v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-lh64v",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f409ce35-76c4-49ae-879c-efe0b4a873be",
      ResourceVersion: (string) (len=5) "18432",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-trwtr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-trwtr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.528: INFO: Pod "webserver-deployment-557759b7c7-q7wgf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-q7wgf",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "13dd6957-557e-4c82-bf96-6722851607b7",
      ResourceVersion: (string) (len=5) "18319",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 36  36 5c 22 7d 22 3a 7b 22  |.244.0.66\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bcwzh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bcwzh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.66",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.66"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://3ed3d9ed6f60964c7bd46bc4b4704ceeff92a3f4eed2c7f0b3c5e9df7c174853",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.531: INFO: Pod "webserver-deployment-557759b7c7-qcq2c" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-qcq2c",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "de4dcf28-facf-4b05-9fa6-b39f46323dbc",
      ResourceVersion: (string) (len=5) "18280",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  37 30 5c 22 7d 22 3a 7b  |.244.1.170\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t7wh5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t7wh5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.170",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.170"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://10a6ff56851e141cfd2ef689f02e3cd7916ae2a2a12b09ba68fbe45e154da0f0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.537: INFO: Pod "webserver-deployment-557759b7c7-v5gvj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-v5gvj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c924fcde-d119-4f13-9a22-547b6aa29562",
      ResourceVersion: (string) (len=5) "18317",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 36  38 5c 22 7d 22 3a 7b 22  |.244.0.68\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jgxcl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jgxcl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913508,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.68",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.68"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913507,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913508,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8b46240b00f1af18a0257744a206320e5eab81beeeff8f58e97e9a49952c23e6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.540: INFO: Pod "webserver-deployment-557759b7c7-vd8c4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-vd8c4",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3028f954-46c5-44e0-9902-2aece3839eef",
      ResourceVersion: (string) (len=5) "18424",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "8c3e525c-e32c-4e8c-851f-385abec0a9c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 63  33 65 35 32 35 63 2d 65  |d\":\"8c3e525c-e|
              00000090  33 32 63 2d 34 65 38 63  2d 38 35 31 66 2d 33 38  |32c-4e8c-851f-38|
              000000a0  35 61 62 65 63 30 61 39  63 38 5c 22 7d 22 3a 7b  |5abec0a9c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2qnqj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2qnqj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.543: INFO: Pod "webserver-deployment-9b4f5bf69-85tgr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-85tgr",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08dd500d-f890-4d72-aae1-585e08a252f2",
      ResourceVersion: (string) (len=5) "18406",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  64 32 34 33 34 32 2d 62  |d\":\"cad24342-b|
              00000090  61 30 63 2d 34 31 30 65  2d 39 32 37 66 2d 34 66  |a0c-410e-927f-4f|
              000000a0  31 32 63 36 36 33 34 30  39 32 5c 22 7d 22 3a 7b  |12c6634092\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=706) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 31 2e 31 37 34 5c  22 7d 22 3a 7b 22 2e 22  |4.1.174\"}":{"."|
              000002a0  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              000002b0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000002c0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vl5px",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vl5px",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.174",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.174"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.546: INFO: Pod "webserver-deployment-9b4f5bf69-bfwwm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-bfwwm",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b37e21bb-185d-402c-aaf9-48867359ee95",
      ResourceVersion: (string) (len=5) "18397",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  64 32 34 33 34 32 2d 62  |d\":\"cad24342-b|
              00000090  61 30 63 2d 34 31 30 65  2d 39 32 37 66 2d 34 66  |a0c-410e-927f-4f|
              000000a0  31 32 63 36 36 33 34 30  39 32 5c 22 7d 22 3a 7b  |12c6634092\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913510,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 30 2e 36 39 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.0.69\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tfwb8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tfwb8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913510,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.69",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.69"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.549: INFO: Pod "webserver-deployment-9b4f5bf69-h7rt8" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-h7rt8",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b5a22ba7-4af3-4392-8784-72a73f8aa82b",
      ResourceVersion: (string) (len=5) "18357",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  64 32 34 33 34 32 2d 62  |d\":\"cad24342-b|
              00000090  61 30 63 2d 34 31 30 65  2d 39 32 37 66 2d 34 66  |a0c-410e-927f-4f|
              000000a0  31 32 63 36 36 33 34 30  39 32 5c 22 7d 22 3a 7b  |12c6634092\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bnflj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bnflj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.558: INFO: Pod "webserver-deployment-9b4f5bf69-tdvjk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-tdvjk",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eacdbb6f-e837-4115-84f6-7d6123235e62",
      ResourceVersion: (string) (len=5) "18403",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  64 32 34 33 34 32 2d 62  |d\":\"cad24342-b|
              00000090  61 30 63 2d 34 31 30 65  2d 39 32 37 66 2d 34 66  |a0c-410e-927f-4f|
              000000a0  31 32 63 36 36 33 34 30  39 32 5c 22 7d 22 3a 7b  |12c6634092\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=706) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 31 2e 31 37 36 5c  22 7d 22 3a 7b 22 2e 22  |4.1.176\"}":{"."|
              000002a0  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              000002b0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000002c0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5lpw9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5lpw9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.176",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.176"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.561: INFO: Pod "webserver-deployment-9b4f5bf69-w5df4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-w5df4",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "05a0e6bd-5f2b-48bf-8155-25a1d0eaf1c8",
      ResourceVersion: (string) (len=5) "18428",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913511,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  64 32 34 33 34 32 2d 62  |d\":\"cad24342-b|
              00000090  61 30 63 2d 34 31 30 65  2d 39 32 37 66 2d 34 66  |a0c-410e-927f-4f|
              000000a0  31 32 63 36 36 33 34 30  39 32 5c 22 7d 22 3a 7b  |12c6634092\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ff5wz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ff5wz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913511,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.563: INFO: Pod "webserver-deployment-9b4f5bf69-z5l6v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-z5l6v",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4019",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2acd7931-945d-44cf-b064-dfa55d24fb27",
      ResourceVersion: (string) (len=5) "18374",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "cad24342-ba0c-410e-927f-4f12c6634092",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  64 32 34 33 34 32 2d 62  |d\":\"cad24342-b|
              00000090  61 30 63 2d 34 31 30 65  2d 39 32 37 66 2d 34 66  |a0c-410e-927f-4f|
              000000a0  31 32 63 36 36 33 34 30  39 32 5c 22 7d 22 3a 7b  |12c6634092\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5wk27",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5wk27",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913509,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913509,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:38:31.569: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4019" for this suite. @ 02/07/24 14:38:31.579
• [4.195 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 02/07/24 14:38:31.585
  Feb  7 14:38:31.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replication-controller @ 02/07/24 14:38:31.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:31.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:31.6
  STEP: Creating replication controller my-hostname-basic-2fb9e179-46f7-4f1b-9a0c-d6a35c536a81 @ 02/07/24 14:38:31.604
  Feb  7 14:38:31.616: INFO: Pod name my-hostname-basic-2fb9e179-46f7-4f1b-9a0c-d6a35c536a81: Found 0 pods out of 1
  E0207 14:38:32.484550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:33.485009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:34.485227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:35.486144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:36.486323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:36.619: INFO: Pod name my-hostname-basic-2fb9e179-46f7-4f1b-9a0c-d6a35c536a81: Found 1 pods out of 1
  Feb  7 14:38:36.619: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2fb9e179-46f7-4f1b-9a0c-d6a35c536a81" are running
  Feb  7 14:38:36.621: INFO: Pod "my-hostname-basic-2fb9e179-46f7-4f1b-9a0c-d6a35c536a81-x6vr4" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:38:32 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:38:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:38:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:38:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-02-07 14:38:31 +0000 UTC Reason: Message:}])
  Feb  7 14:38:36.621: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 02/07/24 14:38:36.621
  Feb  7 14:38:36.632: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8949" for this suite. @ 02/07/24 14:38:36.635
• [5.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 02/07/24 14:38:36.641
  Feb  7 14:38:36.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/07/24 14:38:36.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:36.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:36.666
  STEP: create the container to handle the HTTPGet hook request. @ 02/07/24 14:38:36.672
  E0207 14:38:37.486419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:38.486798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/07/24 14:38:38.689
  E0207 14:38:39.487612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:40.487731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 02/07/24 14:38:40.701
  E0207 14:38:41.488222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:42.489130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 02/07/24 14:38:42.711
  Feb  7 14:38:42.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-968" for this suite. @ 02/07/24 14:38:42.719
• [6.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 02/07/24 14:38:42.723
  Feb  7 14:38:42.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:38:42.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:42.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:42.737
  STEP: Setting up server cert @ 02/07/24 14:38:42.753
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:38:43.462
  STEP: Deploying the webhook pod @ 02/07/24 14:38:43.467
  STEP: Wait for the deployment to be ready @ 02/07/24 14:38:43.477
  Feb  7 14:38:43.482: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:38:43.489393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:44.489666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:38:45.489
  E0207 14:38:45.489728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:38:45.499
  E0207 14:38:46.490197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:46.499: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 02/07/24 14:38:46.503
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 02/07/24 14:38:46.505
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 02/07/24 14:38:46.505
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 02/07/24 14:38:46.505
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 02/07/24 14:38:46.506
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 02/07/24 14:38:46.506
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 02/07/24 14:38:46.507
  Feb  7 14:38:46.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1832" for this suite. @ 02/07/24 14:38:46.534
  STEP: Destroying namespace "webhook-markers-4509" for this suite. @ 02/07/24 14:38:46.541
• [3.822 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 02/07/24 14:38:46.546
  Feb  7 14:38:46.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename ingressclass @ 02/07/24 14:38:46.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:46.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:46.558
  STEP: getting /apis @ 02/07/24 14:38:46.561
  STEP: getting /apis/networking.k8s.io @ 02/07/24 14:38:46.565
  STEP: getting /apis/networking.k8s.iov1 @ 02/07/24 14:38:46.566
  STEP: creating @ 02/07/24 14:38:46.567
  STEP: getting @ 02/07/24 14:38:46.578
  STEP: listing @ 02/07/24 14:38:46.58
  STEP: watching @ 02/07/24 14:38:46.582
  Feb  7 14:38:46.582: INFO: starting watch
  STEP: patching @ 02/07/24 14:38:46.583
  STEP: updating @ 02/07/24 14:38:46.586
  Feb  7 14:38:46.589: INFO: waiting for watch events with expected annotations
  Feb  7 14:38:46.589: INFO: saw patched and updated annotations
  STEP: deleting @ 02/07/24 14:38:46.589
  STEP: deleting a collection @ 02/07/24 14:38:46.596
  Feb  7 14:38:46.604: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-9569" for this suite. @ 02/07/24 14:38:46.606
• [0.064 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 02/07/24 14:38:46.61
  Feb  7 14:38:46.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 14:38:46.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:46.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:46.622
  Feb  7 14:38:46.636: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 02/07/24 14:38:46.641
  Feb  7 14:38:46.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:46.643: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 02/07/24 14:38:46.643
  Feb  7 14:38:46.657: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:46.657: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:38:47.490699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:47.657: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:38:47.657: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 02/07/24 14:38:47.659
  Feb  7 14:38:47.672: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:38:47.672: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0207 14:38:48.490819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:48.671: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:48.671: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 02/07/24 14:38:48.671
  Feb  7 14:38:48.683: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:48.683: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:38:49.490997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:49.684: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:38:49.684: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 02/07/24 14:38:49.688
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9379, will wait for the garbage collector to delete the pods @ 02/07/24 14:38:49.688
  Feb  7 14:38:49.744: INFO: Deleting DaemonSet.extensions daemon-set took: 4.123115ms
  Feb  7 14:38:49.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.148793ms
  E0207 14:38:50.491458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:51.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:51.347: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb  7 14:38:51.349: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18989"},"items":null}

  Feb  7 14:38:51.351: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18989"},"items":null}

  Feb  7 14:38:51.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9379" for this suite. @ 02/07/24 14:38:51.373
• [4.769 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 02/07/24 14:38:51.379
  Feb  7 14:38:51.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 14:38:51.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:51.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:51.392
  Feb  7 14:38:51.411: INFO: Create a RollingUpdate DaemonSet
  Feb  7 14:38:51.416: INFO: Check that daemon pods launch on every node of the cluster
  Feb  7 14:38:51.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:51.421: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:38:51.492339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:52.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:38:52.422: INFO: Node worker-1 is running 0 daemon pod, expected 1
  E0207 14:38:52.492863      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:53.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 14:38:53.422: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  Feb  7 14:38:53.422: INFO: Update the DaemonSet to trigger a rollout
  Feb  7 14:38:53.428: INFO: Updating DaemonSet daemon-set
  E0207 14:38:53.493880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:54.437: INFO: Roll back the DaemonSet before rollout is complete
  Feb  7 14:38:54.443: INFO: Updating DaemonSet daemon-set
  Feb  7 14:38:54.443: INFO: Make sure DaemonSet rollback is complete
  Feb  7 14:38:54.447: INFO: Wrong image for pod: daemon-set-k9sn5. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Feb  7 14:38:54.447: INFO: Pod daemon-set-k9sn5 is not available
  E0207 14:38:54.494907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:55.495437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:38:56.495941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:57.447: INFO: Pod daemon-set-54cfk is not available
  STEP: Deleting DaemonSet "daemon-set" @ 02/07/24 14:38:57.453
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3020, will wait for the garbage collector to delete the pods @ 02/07/24 14:38:57.453
  E0207 14:38:57.496005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:57.510: INFO: Deleting DaemonSet.extensions daemon-set took: 3.774677ms
  Feb  7 14:38:57.610: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.152434ms
  E0207 14:38:58.497029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:38:58.913: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:38:58.913: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb  7 14:38:58.914: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19125"},"items":null}

  Feb  7 14:38:58.916: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19125"},"items":null}

  Feb  7 14:38:58.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3020" for this suite. @ 02/07/24 14:38:58.924
• [7.549 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 02/07/24 14:38:58.928
  Feb  7 14:38:58.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-runtime @ 02/07/24 14:38:58.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:38:58.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:38:58.941
  STEP: create the container @ 02/07/24 14:38:58.943
  W0207 14:38:58.950009      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 02/07/24 14:38:58.95
  E0207 14:38:59.497953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:00.498717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:01.498925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/07/24 14:39:01.961
  STEP: the container should be terminated @ 02/07/24 14:39:01.963
  STEP: the termination message should be set @ 02/07/24 14:39:01.963
  Feb  7 14:39:01.963: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 02/07/24 14:39:01.963
  Feb  7 14:39:01.974: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9746" for this suite. @ 02/07/24 14:39:01.977
• [3.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 02/07/24 14:39:01.981
  Feb  7 14:39:01.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:39:01.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:01.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:01.994
  STEP: Creating service test in namespace statefulset-9214 @ 02/07/24 14:39:01.997
  Feb  7 14:39:02.008: INFO: Found 0 stateful pods, waiting for 1
  E0207 14:39:02.499572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:03.499958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:04.500146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:05.500369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:06.500532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:07.501044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:08.501257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:09.501484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:10.501672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:11.501878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:39:12.010: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 02/07/24 14:39:12.014
  W0207 14:39:12.023135      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Feb  7 14:39:12.028: INFO: Found 1 stateful pods, waiting for 2
  E0207 14:39:12.502162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:13.502451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:14.502638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:15.502843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:16.503075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:17.504137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:18.504351      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:19.504474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:20.504671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:21.504872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:39:22.028: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:39:22.028: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 02/07/24 14:39:22.033
  STEP: Delete all of the StatefulSets @ 02/07/24 14:39:22.035
  STEP: Verify that StatefulSets have been deleted @ 02/07/24 14:39:22.039
  Feb  7 14:39:22.041: INFO: Deleting all statefulset in ns statefulset-9214
  Feb  7 14:39:22.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9214" for this suite. @ 02/07/24 14:39:22.061
• [20.089 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 02/07/24 14:39:22.071
  Feb  7 14:39:22.071: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:39:22.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:22.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:22.087
  STEP: Creating configMap with name projected-configmap-test-volume-c274b10a-2173-43de-948a-38d53f26c61d @ 02/07/24 14:39:22.091
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:39:22.095
  E0207 14:39:22.505291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:23.505585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:24.506138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:25.506363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:39:26.112
  Feb  7 14:39:26.114: INFO: Trying to get logs from node worker-0 pod pod-projected-configmaps-74302f90-89e1-4c21-b85e-0c82fc5ccb72 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:39:26.119
  Feb  7 14:39:26.128: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9706" for this suite. @ 02/07/24 14:39:26.131
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 02/07/24 14:39:26.135
  Feb  7 14:39:26.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-runtime @ 02/07/24 14:39:26.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:26.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:26.146
  STEP: create the container @ 02/07/24 14:39:26.149
  W0207 14:39:26.153883      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 02/07/24 14:39:26.153
  E0207 14:39:26.507409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:27.507880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:28.508607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/07/24 14:39:29.164
  STEP: the container should be terminated @ 02/07/24 14:39:29.166
  STEP: the termination message should be set @ 02/07/24 14:39:29.166
  Feb  7 14:39:29.166: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 02/07/24 14:39:29.166
  Feb  7 14:39:29.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-27" for this suite. @ 02/07/24 14:39:29.178
• [3.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 02/07/24 14:39:29.183
  Feb  7 14:39:29.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:39:29.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:29.194
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:29.196
  STEP: Creating a ResourceQuota @ 02/07/24 14:39:29.199
  STEP: Getting a ResourceQuota @ 02/07/24 14:39:29.202
  STEP: Listing all ResourceQuotas with LabelSelector @ 02/07/24 14:39:29.204
  STEP: Patching the ResourceQuota @ 02/07/24 14:39:29.206
  STEP: Deleting a Collection of ResourceQuotas @ 02/07/24 14:39:29.211
  STEP: Verifying the deleted ResourceQuota @ 02/07/24 14:39:29.217
  Feb  7 14:39:29.218: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4742" for this suite. @ 02/07/24 14:39:29.221
• [0.041 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 02/07/24 14:39:29.224
  Feb  7 14:39:29.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:39:29.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:29.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:29.235
  STEP: creating the pod @ 02/07/24 14:39:29.238
  Feb  7 14:39:29.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 create -f -'
  Feb  7 14:39:29.370: INFO: stderr: ""
  Feb  7 14:39:29.370: INFO: stdout: "pod/pause created\n"
  E0207 14:39:29.509217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:30.509352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 02/07/24 14:39:31.376
  Feb  7 14:39:31.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 label pods pause testing-label=testing-label-value'
  Feb  7 14:39:31.441: INFO: stderr: ""
  Feb  7 14:39:31.441: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 02/07/24 14:39:31.441
  Feb  7 14:39:31.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 get pod pause -L testing-label'
  Feb  7 14:39:31.503: INFO: stderr: ""
  Feb  7 14:39:31.503: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 02/07/24 14:39:31.504
  Feb  7 14:39:31.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 label pods pause testing-label-'
  E0207 14:39:31.509471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:39:31.570: INFO: stderr: ""
  Feb  7 14:39:31.570: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 02/07/24 14:39:31.57
  Feb  7 14:39:31.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 get pod pause -L testing-label'
  Feb  7 14:39:31.630: INFO: stderr: ""
  Feb  7 14:39:31.630: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 02/07/24 14:39:31.63
  Feb  7 14:39:31.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 delete --grace-period=0 --force -f -'
  Feb  7 14:39:31.701: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 14:39:31.701: INFO: stdout: "pod \"pause\" force deleted\n"
  Feb  7 14:39:31.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 get rc,svc -l name=pause --no-headers'
  Feb  7 14:39:31.767: INFO: stderr: "No resources found in kubectl-7334 namespace.\n"
  Feb  7 14:39:31.767: INFO: stdout: ""
  Feb  7 14:39:31.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-7334 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Feb  7 14:39:31.824: INFO: stderr: ""
  Feb  7 14:39:31.824: INFO: stdout: ""
  Feb  7 14:39:31.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7334" for this suite. @ 02/07/24 14:39:31.827
• [2.607 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 02/07/24 14:39:31.831
  Feb  7 14:39:31.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 14:39:31.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:31.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:31.845
  STEP: set up a multi version CRD @ 02/07/24 14:39:31.847
  Feb  7 14:39:31.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:39:32.510561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:33.511285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:34.511957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 02/07/24 14:39:35.093
  STEP: check the new version name is served @ 02/07/24 14:39:35.121
  E0207 14:39:35.512626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 02/07/24 14:39:35.853
  STEP: check the other version is not changed @ 02/07/24 14:39:36.507
  E0207 14:39:36.513567      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:37.514092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:38.515036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:39:39.071: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1361" for this suite. @ 02/07/24 14:39:39.078
• [7.252 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 02/07/24 14:39:39.084
  Feb  7 14:39:39.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:39:39.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:39.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:39.102
  STEP: Creating service test in namespace statefulset-4846 @ 02/07/24 14:39:39.105
  STEP: Creating statefulset ss in namespace statefulset-4846 @ 02/07/24 14:39:39.116
  Feb  7 14:39:39.124: INFO: Found 0 stateful pods, waiting for 1
  E0207 14:39:39.515859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:40.516148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:41.516252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:42.516554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:43.516641      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:44.516844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:45.517062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:46.517794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:47.518098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:48.518309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:39:49.124: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 02/07/24 14:39:49.128
  STEP: Getting /status @ 02/07/24 14:39:49.133
  Feb  7 14:39:49.142: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 02/07/24 14:39:49.142
  Feb  7 14:39:49.148: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 02/07/24 14:39:49.148
  Feb  7 14:39:49.150: INFO: Observed &StatefulSet event: ADDED
  Feb  7 14:39:49.150: INFO: Found Statefulset ss in namespace statefulset-4846 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 14:39:49.150: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 02/07/24 14:39:49.15
  Feb  7 14:39:49.150: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Feb  7 14:39:49.156: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 02/07/24 14:39:49.156
  Feb  7 14:39:49.158: INFO: Observed &StatefulSet event: ADDED
  Feb  7 14:39:49.158: INFO: Observed Statefulset ss in namespace statefulset-4846 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 14:39:49.158: INFO: Observed &StatefulSet event: MODIFIED
  Feb  7 14:39:49.158: INFO: Found Statefulset ss in namespace statefulset-4846 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Feb  7 14:39:49.158: INFO: Deleting all statefulset in ns statefulset-4846
  Feb  7 14:39:49.160: INFO: Scaling statefulset ss to 0
  E0207 14:39:49.518950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:50.519143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:51.519241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:52.519532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:53.519736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:54.519918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:55.520128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:56.520547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:57.520852      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:39:58.520972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:39:59.170: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:39:59.172: INFO: Deleting statefulset ss
  Feb  7 14:39:59.179: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4846" for this suite. @ 02/07/24 14:39:59.181
• [20.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 02/07/24 14:39:59.186
  Feb  7 14:39:59.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:39:59.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:39:59.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:39:59.197
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-4612 @ 02/07/24 14:39:59.2
  STEP: changing the ExternalName service to type=ClusterIP @ 02/07/24 14:39:59.203
  STEP: creating replication controller externalname-service in namespace services-4612 @ 02/07/24 14:39:59.215
  I0207 14:39:59.222227      23 runners.go:197] Created replication controller with name: externalname-service, namespace: services-4612, replica count: 2
  E0207 14:39:59.522020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:00.522731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:01.522832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 14:40:02.274063      23 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 14:40:02.274: INFO: Creating new exec pod
  E0207 14:40:02.523602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:03.523931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:04.524910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:05.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4612 exec execpodhfjz4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Feb  7 14:40:05.404: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Feb  7 14:40:05.404: INFO: stdout: "externalname-service-28c8m"
  Feb  7 14:40:05.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4612 exec execpodhfjz4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.97.166 80'
  Feb  7 14:40:05.523: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.97.166 80\nConnection to 10.100.97.166 80 port [tcp/http] succeeded!\n"
  Feb  7 14:40:05.523: INFO: stdout: ""
  E0207 14:40:05.525027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:06.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4612 exec execpodhfjz4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.97.166 80'
  Feb  7 14:40:06.521: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.97.166 80\nConnection to 10.100.97.166 80 port [tcp/http] succeeded!\n"
  Feb  7 14:40:06.521: INFO: stdout: "externalname-service-dpf2z"
  Feb  7 14:40:06.521: INFO: Cleaning up the ExternalName to ClusterIP test service
  E0207 14:40:06.526117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:06.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4612" for this suite. @ 02/07/24 14:40:06.537
• [7.356 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 02/07/24 14:40:06.542
  Feb  7 14:40:06.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:40:06.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:06.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:06.554
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:40:06.556
  E0207 14:40:07.526730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:08.526937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:09.527779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:10.527886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:40:10.571
  Feb  7 14:40:10.573: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-a282db6e-95fb-4aae-962d-37772dc66b57 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:40:10.586
  Feb  7 14:40:10.597: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8450" for this suite. @ 02/07/24 14:40:10.599
• [4.061 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 02/07/24 14:40:10.603
  Feb  7 14:40:10.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:40:10.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:10.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:10.615
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/07/24 14:40:10.618
  Feb  7 14:40:10.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-719 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Feb  7 14:40:10.686: INFO: stderr: ""
  Feb  7 14:40:10.686: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 02/07/24 14:40:10.686
  Feb  7 14:40:10.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-719 delete pods e2e-test-httpd-pod'
  E0207 14:40:11.528653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:12.005: INFO: stderr: ""
  Feb  7 14:40:12.005: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Feb  7 14:40:12.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-719" for this suite. @ 02/07/24 14:40:12.009
• [1.410 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 02/07/24 14:40:12.013
  Feb  7 14:40:12.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 14:40:12.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:12.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:12.027
  Feb  7 14:40:12.032: INFO: Got root ca configmap in namespace "svcaccounts-4034"
  Feb  7 14:40:12.036: INFO: Deleted root ca configmap in namespace "svcaccounts-4034"
  E0207 14:40:12.529035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 02/07/24 14:40:12.537
  Feb  7 14:40:12.539: INFO: Recreated root ca configmap in namespace "svcaccounts-4034"
  Feb  7 14:40:12.543: INFO: Updated root ca configmap in namespace "svcaccounts-4034"
  STEP: waiting for the root ca configmap reconciled @ 02/07/24 14:40:13.043
  Feb  7 14:40:13.045: INFO: Reconciled root ca configmap in namespace "svcaccounts-4034"
  Feb  7 14:40:13.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4034" for this suite. @ 02/07/24 14:40:13.048
• [1.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 02/07/24 14:40:13.052
  Feb  7 14:40:13.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-webhook @ 02/07/24 14:40:13.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:13.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:13.063
  STEP: Setting up server cert @ 02/07/24 14:40:13.065
  E0207 14:40:13.529792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 02/07/24 14:40:13.607
  STEP: Deploying the custom resource conversion webhook pod @ 02/07/24 14:40:13.612
  STEP: Wait for the deployment to be ready @ 02/07/24 14:40:13.621
  Feb  7 14:40:13.627: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0207 14:40:14.530010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:15.530888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:40:15.635
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:40:15.643
  E0207 14:40:16.531809      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:16.644: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Feb  7 14:40:16.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:40:17.532465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:18.532851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 02/07/24 14:40:19.187
  STEP: v2 custom resource should be converted @ 02/07/24 14:40:19.191
  E0207 14:40:19.533037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:19.732: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-871" for this suite. @ 02/07/24 14:40:19.734
• [6.688 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 02/07/24 14:40:19.741
  Feb  7 14:40:19.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename containers @ 02/07/24 14:40:19.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:19.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:19.753
  STEP: Creating a pod to test override command @ 02/07/24 14:40:19.755
  E0207 14:40:20.533122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:21.533195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:40:21.765
  Feb  7 14:40:21.767: INFO: Trying to get logs from node worker-0 pod client-containers-d8f583a5-e95a-4142-9cd2-0389d78facc9 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:40:21.771
  Feb  7 14:40:21.782: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5070" for this suite. @ 02/07/24 14:40:21.784
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 02/07/24 14:40:21.79
  Feb  7 14:40:21.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:40:21.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:21.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:21.801
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:40:21.804
  E0207 14:40:22.534134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:23.534239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:40:23.816
  Feb  7 14:40:23.818: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-9a7af1f1-6d43-4396-990c-65e99a764fbc container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:40:23.823
  Feb  7 14:40:23.836: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6517" for this suite. @ 02/07/24 14:40:23.839
• [2.053 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 02/07/24 14:40:23.844
  Feb  7 14:40:23.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:40:23.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:23.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:23.856
  STEP: Creating configMap with name projected-configmap-test-volume-map-b0493981-303d-476c-b4cb-e7aa82014a6a @ 02/07/24 14:40:23.859
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:40:23.862
  E0207 14:40:24.534558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:25.534914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:40:25.874
  Feb  7 14:40:25.876: INFO: Trying to get logs from node worker-0 pod pod-projected-configmaps-b08f568f-b0c1-4323-ae77-1d92f57288b5 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:40:25.881
  Feb  7 14:40:25.892: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-980" for this suite. @ 02/07/24 14:40:25.895
• [2.056 seconds]
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 02/07/24 14:40:25.9
  Feb  7 14:40:25.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:40:25.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:25.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:25.911
  STEP: Creating configMap with name cm-test-opt-del-5e2246a3-b52e-428b-85d3-281e2085403a @ 02/07/24 14:40:25.915
  STEP: Creating configMap with name cm-test-opt-upd-8ba2c036-94c9-4083-801b-60f933fe81d1 @ 02/07/24 14:40:25.92
  STEP: Creating the pod @ 02/07/24 14:40:25.923
  E0207 14:40:26.535892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:27.536513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-5e2246a3-b52e-428b-85d3-281e2085403a @ 02/07/24 14:40:27.95
  STEP: Updating configmap cm-test-opt-upd-8ba2c036-94c9-4083-801b-60f933fe81d1 @ 02/07/24 14:40:27.954
  STEP: Creating configMap with name cm-test-opt-create-918cafc1-d42b-41f8-883d-0d391ac61554 @ 02/07/24 14:40:27.957
  STEP: waiting to observe update in volume @ 02/07/24 14:40:27.96
  E0207 14:40:28.537259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:29.537363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:30.538196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:31.538402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:31.985: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7017" for this suite. @ 02/07/24 14:40:31.987
• [6.093 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 02/07/24 14:40:31.993
  Feb  7 14:40:31.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pod-network-test @ 02/07/24 14:40:31.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:32.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:32.005
  STEP: Performing setup for networking test in namespace pod-network-test-7614 @ 02/07/24 14:40:32.007
  STEP: creating a selector @ 02/07/24 14:40:32.007
  STEP: Creating the service pods in kubernetes @ 02/07/24 14:40:32.007
  Feb  7 14:40:32.007: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0207 14:40:32.539236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:33.539553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:34.539870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:35.540054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:36.540438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:37.540878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:38.541684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:39.541869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:40.542365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:41.542454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:42.543180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:43.543386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/07/24 14:40:44.05
  E0207 14:40:44.543485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:45.544120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:46.071: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Feb  7 14:40:46.071: INFO: Going to poll 10.244.1.196 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Feb  7 14:40:46.073: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.196 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7614 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:40:46.073: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:40:46.073: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:40:46.073: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-7614/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.196+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0207 14:40:46.544763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:47.127: INFO: Found all 1 expected endpoints: [netserver-0]
  Feb  7 14:40:47.127: INFO: Going to poll 10.244.0.79 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Feb  7 14:40:47.129: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.79 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7614 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:40:47.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:40:47.129: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:40:47.130: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-7614/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.79+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0207 14:40:47.545606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:48.198: INFO: Found all 1 expected endpoints: [netserver-1]
  Feb  7 14:40:48.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7614" for this suite. @ 02/07/24 14:40:48.201
• [16.213 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 02/07/24 14:40:48.207
  Feb  7 14:40:48.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename events @ 02/07/24 14:40:48.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:48.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:48.218
  STEP: creating a test event @ 02/07/24 14:40:48.221
  STEP: listing all events in all namespaces @ 02/07/24 14:40:48.224
  STEP: patching the test event @ 02/07/24 14:40:48.226
  STEP: fetching the test event @ 02/07/24 14:40:48.232
  STEP: updating the test event @ 02/07/24 14:40:48.234
  STEP: getting the test event @ 02/07/24 14:40:48.239
  STEP: deleting the test event @ 02/07/24 14:40:48.241
  STEP: listing all events in all namespaces @ 02/07/24 14:40:48.245
  Feb  7 14:40:48.247: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8648" for this suite. @ 02/07/24 14:40:48.249
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 02/07/24 14:40:48.253
  Feb  7 14:40:48.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:40:48.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:40:48.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:40:48.27
  STEP: Creating pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682 @ 02/07/24 14:40:48.272
  E0207 14:40:48.545664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:49.545772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:40:50.282
  Feb  7 14:40:50.284: INFO: Initial restart count of pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 is 0
  Feb  7 14:40:50.286: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:40:50.546685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:51.546877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:52.289: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:40:52.547283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:53.547491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:54.292: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:40:54.547865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:55.548046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:56.295: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:40:56.548757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:57.549622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:40:58.297: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:40:58.550125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:40:59.550331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:00.300: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:41:00.550899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:01.551081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:02.303: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:41:02.551145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:03.551354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:04.306: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:41:04.551558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:05.551780      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:06.309: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:41:06.552500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:07.552782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:08.312: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  E0207 14:41:08.553499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:09.553709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:10.315: INFO: Get pod liveness-f36c7088-081d-4941-9857-2fbd95e17094 in namespace container-probe-2682
  Feb  7 14:41:10.315: INFO: Restart count of pod container-probe-2682/liveness-f36c7088-081d-4941-9857-2fbd95e17094 is now 1 (20.030703892s elapsed)
  STEP: deleting the pod @ 02/07/24 14:41:10.315
  Feb  7 14:41:10.322: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2682" for this suite. @ 02/07/24 14:41:10.327
• [22.077 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 02/07/24 14:41:10.331
  Feb  7 14:41:10.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename server-version @ 02/07/24 14:41:10.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:41:10.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:41:10.342
  STEP: Request ServerVersion @ 02/07/24 14:41:10.347
  STEP: Confirm major version @ 02/07/24 14:41:10.349
  Feb  7 14:41:10.349: INFO: Major version: 1
  STEP: Confirm minor version @ 02/07/24 14:41:10.349
  Feb  7 14:41:10.349: INFO: cleanMinorVersion: 29
  Feb  7 14:41:10.349: INFO: Minor version: 29
  Feb  7 14:41:10.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-1457" for this suite. @ 02/07/24 14:41:10.352
• [0.026 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 02/07/24 14:41:10.358
  Feb  7 14:41:10.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/07/24 14:41:10.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:41:10.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:41:10.37
  Feb  7 14:41:10.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:41:10.554618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:11.555228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:12.555563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:41:13.439: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9512" for this suite. @ 02/07/24 14:41:13.442
• [3.089 seconds]
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 02/07/24 14:41:13.446
  Feb  7 14:41:13.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-preemption @ 02/07/24 14:41:13.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:41:13.455
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:41:13.457
  Feb  7 14:41:13.468: INFO: Waiting up to 1m0s for all nodes to be ready
  E0207 14:41:13.555705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:14.556269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:15.557096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:16.557776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:17.557864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:18.558097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:19.558961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:20.559070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:21.559133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:22.559562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:23.560138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:24.560340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:25.560479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:26.560826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:27.561890      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:28.562060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:29.563156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:30.563357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:31.563419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:32.563693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:33.564106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:34.564328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:35.565089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:36.565473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:37.565783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:38.565977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:39.566995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:40.567097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:41.568013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:42.568754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:43.569637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:44.570025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:45.570560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:46.570859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:47.571114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:48.571319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:49.571669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:50.571792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:51.572108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:52.572561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:53.573208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:54.573432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:55.573836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:56.574174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:57.574278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:58.574489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:41:59.575304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:00.575399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:01.575924      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:02.576495      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:03.577155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:04.577379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:05.577745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:06.578652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:07.578732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:08.578922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:09.579804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:10.579996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:11.580233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:12.580562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:42:13.472: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 02/07/24 14:42:13.475
  Feb  7 14:42:13.487: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Feb  7 14:42:13.493: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Feb  7 14:42:13.507: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Feb  7 14:42:13.514: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 02/07/24 14:42:13.514
  E0207 14:42:13.580754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:14.580991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 02/07/24 14:42:15.528
  E0207 14:42:15.581389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:16.582152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:17.583150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:18.583349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:19.583700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:42:19.590: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5036" for this suite. @ 02/07/24 14:42:19.594
• [66.153 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 02/07/24 14:42:19.599
  Feb  7 14:42:19.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:42:19.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:19.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:19.611
  STEP: Setting up server cert @ 02/07/24 14:42:19.628
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:42:20.185
  STEP: Deploying the webhook pod @ 02/07/24 14:42:20.189
  STEP: Wait for the deployment to be ready @ 02/07/24 14:42:20.198
  Feb  7 14:42:20.205: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:42:20.584602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:21.584799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:42:22.212
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:42:22.221
  E0207 14:42:22.585546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:42:23.222: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb  7 14:42:23.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:42:23.586131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3704-crds.webhook.example.com via the AdmissionRegistration API @ 02/07/24 14:42:23.738
  STEP: Creating a custom resource that should be mutated by the webhook @ 02/07/24 14:42:23.754
  E0207 14:42:24.586197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:25.586287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:42:26.358: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9438" for this suite. @ 02/07/24 14:42:26.361
  STEP: Destroying namespace "webhook-markers-634" for this suite. @ 02/07/24 14:42:26.366
• [6.771 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 02/07/24 14:42:26.371
  Feb  7 14:42:26.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:42:26.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:26.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:26.382
  STEP: Creating a ResourceQuota @ 02/07/24 14:42:26.385
  STEP: Getting a ResourceQuota @ 02/07/24 14:42:26.388
  STEP: Updating a ResourceQuota @ 02/07/24 14:42:26.39
  STEP: Verifying a ResourceQuota was modified @ 02/07/24 14:42:26.395
  STEP: Deleting a ResourceQuota @ 02/07/24 14:42:26.398
  STEP: Verifying the deleted ResourceQuota @ 02/07/24 14:42:26.403
  Feb  7 14:42:26.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5550" for this suite. @ 02/07/24 14:42:26.407
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 02/07/24 14:42:26.412
  Feb  7 14:42:26.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:42:26.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:26.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:26.425
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:42:26.427
  E0207 14:42:26.587247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:27.587545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:28.587845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:29.588041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:42:30.441
  Feb  7 14:42:30.443: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-bcc1f9a9-16ca-4233-ac7f-ba141581f867 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:42:30.456
  Feb  7 14:42:30.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-134" for this suite. @ 02/07/24 14:42:30.47
• [4.062 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 02/07/24 14:42:30.475
  Feb  7 14:42:30.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:42:30.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:30.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:30.487
  STEP: Discovering how many secrets are in namespace by default @ 02/07/24 14:42:30.49
  E0207 14:42:30.588525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:31.589604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:32.590107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:33.591164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:34.591944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 02/07/24 14:42:35.493
  E0207 14:42:35.592236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:36.592239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:37.593116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:38.593581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:39.593844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 14:42:40.496
  STEP: Ensuring resource quota status is calculated @ 02/07/24 14:42:40.506
  E0207 14:42:40.594384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:41.594588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 02/07/24 14:42:42.508
  STEP: Ensuring resource quota status captures secret creation @ 02/07/24 14:42:42.517
  E0207 14:42:42.594946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:43.595161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 02/07/24 14:42:44.521
  STEP: Ensuring resource quota status released usage @ 02/07/24 14:42:44.525
  E0207 14:42:44.595684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:45.595893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:42:46.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3107" for this suite. @ 02/07/24 14:42:46.531
• [16.060 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 02/07/24 14:42:46.535
  Feb  7 14:42:46.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:42:46.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:46.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:46.549
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 02/07/24 14:42:46.552
  E0207 14:42:46.596386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:47.596673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:48.597531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:49.598105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:42:50.565
  Feb  7 14:42:50.567: INFO: Trying to get logs from node worker-0 pod pod-982379ea-4943-4944-9935-843d1a15da55 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:42:50.573
  Feb  7 14:42:50.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6011" for this suite. @ 02/07/24 14:42:50.586
• [4.055 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 02/07/24 14:42:50.59
  Feb  7 14:42:50.590: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:42:50.591
  E0207 14:42:50.598129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:50.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:50.604
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 02/07/24 14:42:50.606
  E0207 14:42:51.598973      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:52.599298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:53.600130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:54.600328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:42:54.622
  Feb  7 14:42:54.624: INFO: Trying to get logs from node worker-0 pod pod-40386d8f-c60a-40f7-bb8d-d8caf1e96122 container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:42:54.629
  Feb  7 14:42:54.639: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7655" for this suite. @ 02/07/24 14:42:54.641
• [4.055 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 02/07/24 14:42:54.646
  Feb  7 14:42:54.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:42:54.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:54.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:54.657
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:42:54.659
  E0207 14:42:55.600471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:56.601235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:57.601614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:42:58.601729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:42:58.674
  Feb  7 14:42:58.676: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-67a73289-3cbf-41b8-ad9c-b1b90cbed331 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:42:58.681
  Feb  7 14:42:58.691: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3193" for this suite. @ 02/07/24 14:42:58.694
• [4.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 02/07/24 14:42:58.699
  Feb  7 14:42:58.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:42:58.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:42:58.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:42:58.71
  STEP: Creating configMap with name configmap-test-volume-d46e9772-8423-46d5-94e8-45121089f81f @ 02/07/24 14:42:58.713
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:42:58.716
  E0207 14:42:59.602146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:00.602262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:01.603115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:02.603504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:43:02.731
  Feb  7 14:43:02.733: INFO: Trying to get logs from node worker-0 pod pod-configmaps-0f7afb88-1344-4c41-ad30-898f9d5945bd container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:43:02.738
  Feb  7 14:43:02.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8947" for this suite. @ 02/07/24 14:43:02.752
• [4.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 02/07/24 14:43:02.756
  Feb  7 14:43:02.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:43:02.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:02.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:02.769
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:43:02.772
  E0207 14:43:03.604099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:04.604445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:05.605422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:06.606213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:43:06.786
  Feb  7 14:43:06.788: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-d1212df7-a1e7-46e0-84fd-6c5f73ea5f9c container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:43:06.794
  Feb  7 14:43:06.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2810" for this suite. @ 02/07/24 14:43:06.807
• [4.057 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 02/07/24 14:43:06.813
  Feb  7 14:43:06.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename namespaces @ 02/07/24 14:43:06.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:06.824
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:06.826
  STEP: Creating a test namespace @ 02/07/24 14:43:06.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:06.838
  STEP: Creating a service in the namespace @ 02/07/24 14:43:06.84
  STEP: Deleting the namespace @ 02/07/24 14:43:06.85
  STEP: Waiting for the namespace to be removed. @ 02/07/24 14:43:06.855
  E0207 14:43:07.606743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:08.607393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:09.608133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:10.609054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:11.610105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:12.611184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 02/07/24 14:43:12.858
  STEP: Verifying there is no service in the namespace @ 02/07/24 14:43:12.869
  Feb  7 14:43:12.871: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1329" for this suite. @ 02/07/24 14:43:12.873
  STEP: Destroying namespace "nsdeletetest-3950" for this suite. @ 02/07/24 14:43:12.877
  Feb  7 14:43:12.879: INFO: Namespace nsdeletetest-3950 was already deleted
  STEP: Destroying namespace "nsdeletetest-592" for this suite. @ 02/07/24 14:43:12.879
• [6.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 02/07/24 14:43:12.883
  Feb  7 14:43:12.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:43:12.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:12.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:12.896
  STEP: Setting up server cert @ 02/07/24 14:43:12.911
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:43:13.271
  STEP: Deploying the webhook pod @ 02/07/24 14:43:13.276
  STEP: Wait for the deployment to be ready @ 02/07/24 14:43:13.286
  Feb  7 14:43:13.293: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:43:13.611503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:14.611828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:43:15.301
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:43:15.311
  E0207 14:43:15.612802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:43:16.311: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 02/07/24 14:43:16.316
  STEP: Creating a custom resource definition that should be denied by the webhook @ 02/07/24 14:43:16.333
  Feb  7 14:43:16.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:43:16.374: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3605" for this suite. @ 02/07/24 14:43:16.377
  STEP: Destroying namespace "webhook-markers-6505" for this suite. @ 02/07/24 14:43:16.383
• [3.504 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 02/07/24 14:43:16.393
  Feb  7 14:43:16.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename watch @ 02/07/24 14:43:16.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:16.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:16.407
  STEP: getting a starting resourceVersion @ 02/07/24 14:43:16.41
  STEP: starting a background goroutine to produce watch events @ 02/07/24 14:43:16.412
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 02/07/24 14:43:16.412
  E0207 14:43:16.612877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:17.613729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:18.614570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:43:19.200: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8315" for this suite. @ 02/07/24 14:43:19.248
• [2.906 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 02/07/24 14:43:19.299
  Feb  7 14:43:19.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:43:19.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:19.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:19.313
  STEP: Creating configMap with name configmap-test-volume-88995697-7ad7-4951-9a87-2bbede54f7e8 @ 02/07/24 14:43:19.315
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:43:19.319
  E0207 14:43:19.615260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:20.616240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:43:21.331
  Feb  7 14:43:21.333: INFO: Trying to get logs from node worker-0 pod pod-configmaps-49d028b8-4ada-4631-95db-373f80139fa1 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:43:21.338
  Feb  7 14:43:21.348: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4345" for this suite. @ 02/07/24 14:43:21.351
• [2.056 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 02/07/24 14:43:21.356
  Feb  7 14:43:21.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:43:21.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:21.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:21.369
  STEP: Creating configMap with name configmap-test-volume-bda4a980-b60c-4e03-93ff-a2a7bfab8b41 @ 02/07/24 14:43:21.371
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:43:21.374
  E0207 14:43:21.617094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:22.617662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:23.618267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:24.618497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:43:25.389
  Feb  7 14:43:25.391: INFO: Trying to get logs from node worker-0 pod pod-configmaps-fd9066e0-e4e8-427a-ae05-b9437c1f454f container configmap-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:43:25.398
  Feb  7 14:43:25.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1550" for this suite. @ 02/07/24 14:43:25.411
• [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 02/07/24 14:43:25.415
  Feb  7 14:43:25.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 14:43:25.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:25.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:25.428
  STEP: Creating a pod to test service account token:  @ 02/07/24 14:43:25.431
  E0207 14:43:25.619052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:26.619543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:27.619734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:28.619791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:43:29.446
  Feb  7 14:43:29.449: INFO: Trying to get logs from node worker-0 pod test-pod-a996c716-f056-4ddf-8292-1e1be170a947 container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:43:29.454
  Feb  7 14:43:29.464: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8069" for this suite. @ 02/07/24 14:43:29.466
• [4.055 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 02/07/24 14:43:29.471
  Feb  7 14:43:29.471: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:43:29.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:29.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:29.483
  STEP: Creating configMap with name projected-configmap-test-volume-map-69df5699-7746-4a2a-8965-c2c78eb3d15a @ 02/07/24 14:43:29.486
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:43:29.489
  E0207 14:43:29.620453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:30.620662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:31.621455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:32.621734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:43:33.503
  Feb  7 14:43:33.505: INFO: Trying to get logs from node worker-0 pod pod-projected-configmaps-8b193ba7-fcfa-42c2-a225-71d74aadd2ac container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:43:33.511
  Feb  7 14:43:33.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4961" for this suite. @ 02/07/24 14:43:33.524
• [4.057 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 02/07/24 14:43:33.528
  Feb  7 14:43:33.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename init-container @ 02/07/24 14:43:33.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:33.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:33.54
  STEP: creating the pod @ 02/07/24 14:43:33.543
  Feb  7 14:43:33.543: INFO: PodSpec: initContainers in spec.initContainers
  E0207 14:43:33.621858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:34.622190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:35.622278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:36.623139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:43:36.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5728" for this suite. @ 02/07/24 14:43:36.983
• [3.460 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 02/07/24 14:43:36.989
  Feb  7 14:43:36.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:43:36.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:43:37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:43:37.002
  E0207 14:43:37.623798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:38.624737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:39.625822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:40.626201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:41.626793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:42.626960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:43.627831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:44.628700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:45.628828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:46.629869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:47.630690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:48.631521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:49.632438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:50.633288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:51.633845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:52.634688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:53.635203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 02/07/24 14:43:54.008
  E0207 14:43:54.635984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:55.636537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:56.636897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:57.637690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:43:58.638334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 14:43:59.011
  STEP: Ensuring resource quota status is calculated @ 02/07/24 14:43:59.015
  E0207 14:43:59.638431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:00.638620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 02/07/24 14:44:01.018
  STEP: Ensuring resource quota status captures configMap creation @ 02/07/24 14:44:01.027
  E0207 14:44:01.639404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:02.639715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 02/07/24 14:44:03.031
  STEP: Ensuring resource quota status released usage @ 02/07/24 14:44:03.034
  E0207 14:44:03.640521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:04.640720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:05.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3716" for this suite. @ 02/07/24 14:44:05.04
• [28.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 02/07/24 14:44:05.045
  Feb  7 14:44:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 14:44:05.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:44:05.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:44:05.059
  Feb  7 14:44:05.061: INFO: Creating deployment "test-recreate-deployment"
  Feb  7 14:44:05.065: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Feb  7 14:44:05.070: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E0207 14:44:05.640839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:06.641941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:07.076: INFO: Waiting deployment "test-recreate-deployment" to complete
  Feb  7 14:44:07.078: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Feb  7 14:44:07.083: INFO: Updating deployment test-recreate-deployment
  Feb  7 14:44:07.083: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Feb  7 14:44:07.137: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4701",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e0e06ba1-c1be-479d-9507-2eb74a164ba4",
      ResourceVersion: (string) (len=5) "21313",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913845,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 14:44:07.141: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4701",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "04c64778-1ce8-427c-8e37-50dd668b29cf",
      ResourceVersion: (string) (len=5) "21310",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "e0e06ba1-c1be-479d-9507-2eb74a164ba4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 30 65 30 36 62  61 31 2d 63 31 62 65 2d  |\"e0e06ba1-c1be-|
              00000120  34 37 39 64 2d 39 35 30  37 2d 32 65 62 37 34 61  |479d-9507-2eb74a|
              00000130  31 36 34 62 61 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |164ba4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:44:07.142: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Feb  7 14:44:07.143: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-dd4bc9d6d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4701",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7878523d-63de-4bd9-8558-517939b7d4f4",
      ResourceVersion: (string) (len=5) "21302",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913845,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "e0e06ba1-c1be-479d-9507-2eb74a164ba4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 30 65 30 36 62  61 31 2d 63 31 62 65 2d  |\"e0e06ba1-c1be-|
              00000120  34 37 39 64 2d 39 35 30  37 2d 32 65 62 37 34 61  |479d-9507-2eb74a|
              00000130  31 36 34 62 61 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |164ba4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:44:07.146: INFO: Pod "test-recreate-deployment-76fb77d45-jvmrx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-jvmrx",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-4701",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "36cfd914-f7cd-4722-a6c1-9e495870ae33",
      ResourceVersion: (string) (len=5) "21314",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "04c64778-1ce8-427c-8e37-50dd668b29cf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 34  63 36 34 37 37 38 2d 31  |d\":\"04c64778-1|
              00000090  63 65 38 2d 34 32 37 63  2d 38 65 33 37 2d 35 30  |ce8-427c-8e37-50|
              000000a0  64 64 36 36 38 62 32 39  63 66 5c 22 7d 22 3a 7b  |dd668b29cf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gd4g5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gd4g5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:44:07.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4701" for this suite. @ 02/07/24 14:44:07.151
• [2.111 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 02/07/24 14:44:07.156
  Feb  7 14:44:07.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 14:44:07.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:44:07.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:44:07.169
  STEP: Creating a test headless service @ 02/07/24 14:44:07.171
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local;sleep 1; done
   @ 02/07/24 14:44:07.175
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9446.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local;sleep 1; done
   @ 02/07/24 14:44:07.175
  STEP: creating a pod to probe DNS @ 02/07/24 14:44:07.175
  STEP: submitting the pod to kubernetes @ 02/07/24 14:44:07.175
  E0207 14:44:07.642297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:08.642414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/07/24 14:44:09.19
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:44:09.192
  Feb  7 14:44:09.198: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.201: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.204: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.207: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.210: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.213: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.216: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.219: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:09.219: INFO: Lookups using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local]

  Feb  7 14:44:09.224: INFO: Pod client logs for webserver: 
  Feb  7 14:44:09.229: INFO: Pod client logs for querier: 
  Feb  7 14:44:09.234: INFO: Pod client logs for jessie-querier: 
  E0207 14:44:09.642687      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:10.642904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:11.643157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:12.643571      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:13.643782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:14.197: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.200: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.203: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.206: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.209: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.212: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.215: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.218: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:14.218: INFO: Lookups using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local]

  Feb  7 14:44:14.222: INFO: Pod client logs for webserver: 
  Feb  7 14:44:14.227: INFO: Pod client logs for querier: 
  Feb  7 14:44:14.231: INFO: Pod client logs for jessie-querier: 
  E0207 14:44:14.643873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:15.644261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:16.644896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:17.645247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:18.646119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:19.197: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.201: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.204: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.207: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.210: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.212: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.215: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.218: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:19.218: INFO: Lookups using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local]

  Feb  7 14:44:19.223: INFO: Pod client logs for webserver: 
  Feb  7 14:44:19.228: INFO: Pod client logs for querier: 
  Feb  7 14:44:19.232: INFO: Pod client logs for jessie-querier: 
  E0207 14:44:19.647171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:20.647378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:21.647578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:22.647856      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:23.648055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:24.196: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.199: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.202: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.205: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.208: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.211: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.214: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.217: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:24.217: INFO: Lookups using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local]

  Feb  7 14:44:24.222: INFO: Pod client logs for webserver: 
  Feb  7 14:44:24.226: INFO: Pod client logs for querier: 
  Feb  7 14:44:24.231: INFO: Pod client logs for jessie-querier: 
  E0207 14:44:24.648844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:25.649073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:26.649650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:27.649924      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:28.650673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:29.197: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.201: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.204: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.207: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.210: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.213: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.216: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.219: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:29.219: INFO: Lookups using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local]

  Feb  7 14:44:29.224: INFO: Pod client logs for webserver: 
  Feb  7 14:44:29.230: INFO: Pod client logs for querier: 
  Feb  7 14:44:29.234: INFO: Pod client logs for jessie-querier: 
  E0207 14:44:29.650977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:30.651293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:31.651392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:32.651805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:33.651979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:34.196: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.200: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.203: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.206: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.209: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.212: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.214: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.217: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local from pod dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a: the server could not find the requested resource (get pods dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a)
  Feb  7 14:44:34.217: INFO: Lookups using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9446.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9446.svc.cluster.local jessie_udp@dns-test-service-2.dns-9446.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9446.svc.cluster.local]

  Feb  7 14:44:34.222: INFO: Pod client logs for webserver: 
  Feb  7 14:44:34.227: INFO: Pod client logs for querier: 
  Feb  7 14:44:34.231: INFO: Pod client logs for jessie-querier: 
  E0207 14:44:34.652258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:35.652450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:36.653174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:37.653553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:38.653738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:39.220: INFO: DNS probes using dns-9446/dns-test-8efb1b62-d17e-4e09-98ee-773d4e87d12a succeeded

  STEP: deleting the pod @ 02/07/24 14:44:39.22
  STEP: deleting the test headless service @ 02/07/24 14:44:39.23
  Feb  7 14:44:39.242: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9446" for this suite. @ 02/07/24 14:44:39.252
• [32.101 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 02/07/24 14:44:39.257
  Feb  7 14:44:39.257: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename containers @ 02/07/24 14:44:39.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:44:39.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:44:39.271
  STEP: Creating a pod to test override arguments @ 02/07/24 14:44:39.274
  E0207 14:44:39.653825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:40.654893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:44:41.284
  Feb  7 14:44:41.286: INFO: Trying to get logs from node worker-0 pod client-containers-e9ac02bc-204d-4e16-988e-61f204a012ad container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 14:44:41.291
  Feb  7 14:44:41.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6424" for this suite. @ 02/07/24 14:44:41.303
• [2.050 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 02/07/24 14:44:41.307
  Feb  7 14:44:41.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename proxy @ 02/07/24 14:44:41.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:44:41.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:44:41.321
  Feb  7 14:44:41.323: INFO: Creating pod...
  E0207 14:44:41.655897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:42.656186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:44:43.338: INFO: Creating service...
  Feb  7 14:44:43.348: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/DELETE
  Feb  7 14:44:43.355: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb  7 14:44:43.355: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/GET
  Feb  7 14:44:43.358: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Feb  7 14:44:43.358: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/HEAD
  Feb  7 14:44:43.361: INFO: http.Client request:HEAD | StatusCode:200
  Feb  7 14:44:43.361: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/OPTIONS
  Feb  7 14:44:43.364: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb  7 14:44:43.364: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/PATCH
  Feb  7 14:44:43.367: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb  7 14:44:43.367: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/POST
  Feb  7 14:44:43.371: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb  7 14:44:43.371: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/pods/agnhost/proxy/some/path/with/PUT
  Feb  7 14:44:43.374: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb  7 14:44:43.374: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/DELETE
  Feb  7 14:44:43.378: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb  7 14:44:43.378: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/GET
  Feb  7 14:44:43.382: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Feb  7 14:44:43.382: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/HEAD
  Feb  7 14:44:43.385: INFO: http.Client request:HEAD | StatusCode:200
  Feb  7 14:44:43.385: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/OPTIONS
  Feb  7 14:44:43.388: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb  7 14:44:43.388: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/PATCH
  Feb  7 14:44:43.391: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb  7 14:44:43.391: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/POST
  Feb  7 14:44:43.395: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb  7 14:44:43.395: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2270/services/test-service/proxy/some/path/with/PUT
  Feb  7 14:44:43.398: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb  7 14:44:43.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2270" for this suite. @ 02/07/24 14:44:43.401
• [2.098 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 02/07/24 14:44:43.405
  Feb  7 14:44:43.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:44:43.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:44:43.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:44:43.419
  STEP: fetching services @ 02/07/24 14:44:43.421
  Feb  7 14:44:43.423: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4216" for this suite. @ 02/07/24 14:44:43.426
• [0.025 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 02/07/24 14:44:43.43
  Feb  7 14:44:43.430: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:44:43.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:44:43.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:44:43.442
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-58360760-3a43-402b-bc62-f57b4879fae8 @ 02/07/24 14:44:43.447
  STEP: Creating the pod @ 02/07/24 14:44:43.45
  E0207 14:44:43.656583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:44.657439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-58360760-3a43-402b-bc62-f57b4879fae8 @ 02/07/24 14:44:45.467
  STEP: waiting to observe update in volume @ 02/07/24 14:44:45.471
  E0207 14:44:45.658146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:46.658967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:47.660032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:48.660295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:49.660791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:50.660999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:51.661055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:52.661412      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:53.661718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:54.661946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:55.662067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:56.662915      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:57.663386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:58.663568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:44:59.664442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:00.664633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:01.665475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:02.665867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:03.665964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:04.666197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:05.666449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:06.666984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:07.667371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:08.667482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:09.667967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:10.668161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:11.669078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:12.669453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:13.670404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:14.670533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:15.671266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:16.671926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:17.672116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:18.672877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:19.673775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:20.673915      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:21.674580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:22.675670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:23.676115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:24.676269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:25.677059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:26.677550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:27.678595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:28.678735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:29.679105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:30.680164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:31.680355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:32.680711      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:33.681585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:34.681776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:35.682178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:36.682516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:37.683060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:38.683231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:39.683970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:40.684957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:41.685208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:42.685600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:43.686279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:44.686626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:45.686721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:46.687098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:47.687466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:48.688441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:49.688556      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:50.689142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:51.689242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:52.689357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:53.689462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:54.689726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:55.689919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:56.690739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:57.691773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:58.692167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:45:59.692394      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:00.692616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:01.692792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:02.693822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:03.694128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:03.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3409" for this suite. @ 02/07/24 14:46:03.764
• [80.338 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 02/07/24 14:46:03.768
  Feb  7 14:46:03.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 14:46:03.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:03.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:03.782
  Feb  7 14:46:03.785: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Feb  7 14:46:03.791: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0207 14:46:04.694604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:05.694803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:06.695441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:07.695817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:08.696011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:08.796: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/07/24 14:46:08.796
  Feb  7 14:46:08.796: INFO: Creating deployment "test-rolling-update-deployment"
  Feb  7 14:46:08.800: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Feb  7 14:46:08.804: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0207 14:46:09.696184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:10.696390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:10.809: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Feb  7 14:46:10.811: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Feb  7 14:46:10.817: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5472",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "03a5e063-0ce9-4148-b1f0-7411f6c40701",
      ResourceVersion: (string) (len=5) "21775",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913968,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=82) "ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 14:46:10.821: INFO: New ReplicaSet "test-rolling-update-deployment-7f5c55c64" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5472",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "36f82f85-09ea-4b37-bf3e-96d287507602",
      ResourceVersion: (string) (len=5) "21765",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913968,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "03a5e063-0ce9-4148-b1f0-7411f6c40701",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 33 61 35 65 30  36 33 2d 30 63 65 39 2d  |\"03a5e063-0ce9-|
              00000120  34 31 34 38 2d 62 31 66  30 2d 37 34 31 31 66 36  |4148-b1f0-7411f6|
              00000130  63 34 30 37 30 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c40701\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:46:10.823: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Feb  7 14:46:10.823: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5472",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a80b8abf-63d7-48f9-ac73-c9352b803221",
      ResourceVersion: (string) (len=5) "21774",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913963,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "03a5e063-0ce9-4148-b1f0-7411f6c40701",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913963,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 30 33 61 35 65 30 36  |"uid\":\"03a5e06|
              000000b0  33 2d 30 63 65 39 2d 34  31 34 38 2d 62 31 66 30  |3-0ce9-4148-b1f0|
              000000c0  2d 37 34 31 31 66 36 63  34 30 37 30 31 5c 22 7d  |-7411f6c40701\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:46:10.827: INFO: Pod "test-rolling-update-deployment-7f5c55c64-5f94r" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=46) "test-rolling-update-deployment-7f5c55c64-5f94r",
      GenerateName: (string) (len=41) "test-rolling-update-deployment-7f5c55c64-",
      Namespace: (string) (len=15) "deployment-5472",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2741f154-753e-4a66-8502-851f98d52e0c",
      ResourceVersion: (string) (len=5) "21763",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913968,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
          UID: (types.UID) (len=36) "36f82f85-09ea-4b37-bf3e-96d287507602",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 36  66 38 32 66 38 35 2d 30  |d\":\"36f82f85-0|
              00000090  39 65 61 2d 34 62 33 37  2d 62 66 33 65 2d 39 36  |9ea-4b37-bf3e-96|
              000000a0  64 32 38 37 35 30 37 36  30 32 5c 22 7d 22 3a 7b  |d287507602\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 38  33 5c 22 7d 22 3a 7b 22  |.244.0.83\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hsrqn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hsrqn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913969,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842913968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) (len=11) "10.244.0.83",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.83"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842913968,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842913969,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://7e379291618b636467a12a0fe18fd5e234d02790b9f25a2eb4ecebda752fdcc3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:46:10.830: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5472" for this suite. @ 02/07/24 14:46:10.832
• [7.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 02/07/24 14:46:10.837
  Feb  7 14:46:10.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:46:10.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:10.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:10.85
  STEP: Counting existing ResourceQuota @ 02/07/24 14:46:10.853
  E0207 14:46:11.697408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:12.698111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:13.698825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:14.699327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:15.700145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 14:46:15.857
  STEP: Ensuring resource quota status is calculated @ 02/07/24 14:46:15.861
  E0207 14:46:16.700804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:17.701051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 02/07/24 14:46:17.865
  STEP: Ensuring resource quota status captures replicaset creation @ 02/07/24 14:46:17.875
  E0207 14:46:18.701915      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:19.702109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 02/07/24 14:46:19.878
  STEP: Ensuring resource quota status released usage @ 02/07/24 14:46:19.882
  E0207 14:46:20.702305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:21.702555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:21.885: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-777" for this suite. @ 02/07/24 14:46:21.888
• [11.057 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 02/07/24 14:46:21.894
  Feb  7 14:46:21.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:46:21.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:21.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:21.906
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 02/07/24 14:46:21.909
  Feb  7 14:46:21.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9547 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Feb  7 14:46:21.975: INFO: stderr: ""
  Feb  7 14:46:21.975: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 02/07/24 14:46:21.975
  E0207 14:46:22.703200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:23.704190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:24.704406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:25.704836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:26.705175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 02/07/24 14:46:27.026
  Feb  7 14:46:27.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9547 get pod e2e-test-httpd-pod -o json'
  Feb  7 14:46:27.088: INFO: stderr: ""
  Feb  7 14:46:27.088: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-02-07T14:46:21Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9547\",\n        \"resourceVersion\": \"21848\",\n        \"uid\": \"e009e651-6bfb-499f-819d-536365afb2a5\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-jl8dc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker-0\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-jl8dc\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-07T14:46:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-07T14:46:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-07T14:46:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-07T14:46:23Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-02-07T14:46:21Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://40fa8c2b5a4c98c8fa09f6aa8836513baa27e4831b973a8fc05a20b185d532b2\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-02-07T14:46:22Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.60.182\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"10.0.60.182\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.220\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.220\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-02-07T14:46:21Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 02/07/24 14:46:27.088
  Feb  7 14:46:27.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9547 replace -f -'
  Feb  7 14:46:27.208: INFO: stderr: ""
  Feb  7 14:46:27.208: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 02/07/24 14:46:27.208
  Feb  7 14:46:27.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9547 delete pods e2e-test-httpd-pod'
  E0207 14:46:27.705553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:28.706147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:29.332: INFO: stderr: ""
  Feb  7 14:46:29.332: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Feb  7 14:46:29.332: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9547" for this suite. @ 02/07/24 14:46:29.335
• [7.446 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 02/07/24 14:46:29.341
  Feb  7 14:46:29.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:46:29.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:29.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:29.355
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 02/07/24 14:46:29.358
  E0207 14:46:29.706875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:30.706999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:31.707155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:32.707504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:46:33.372
  Feb  7 14:46:33.375: INFO: Trying to get logs from node worker-0 pod pod-34b90c99-945a-4293-a138-0f55bf191e1f container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:46:33.38
  Feb  7 14:46:33.389: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9074" for this suite. @ 02/07/24 14:46:33.391
• [4.054 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 02/07/24 14:46:33.395
  Feb  7 14:46:33.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir @ 02/07/24 14:46:33.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:33.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:33.409
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 02/07/24 14:46:33.412
  E0207 14:46:33.707918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:34.708119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:35.708953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:36.709331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:46:37.427
  Feb  7 14:46:37.429: INFO: Trying to get logs from node worker-0 pod pod-7103822c-73ff-4add-b853-9cc83293844c container test-container: <nil>
  STEP: delete the pod @ 02/07/24 14:46:37.434
  Feb  7 14:46:37.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-810" for this suite. @ 02/07/24 14:46:37.448
• [4.057 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 02/07/24 14:46:37.453
  Feb  7 14:46:37.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename lease-test @ 02/07/24 14:46:37.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:37.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:37.465
  Feb  7 14:46:37.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-4401" for this suite. @ 02/07/24 14:46:37.508
• [0.060 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 02/07/24 14:46:37.513
  Feb  7 14:46:37.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename emptydir-wrapper @ 02/07/24 14:46:37.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:37.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:37.525
  STEP: Creating 50 configmaps @ 02/07/24 14:46:37.527
  E0207 14:46:37.710075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 02/07/24 14:46:37.768
  Feb  7 14:46:37.876: INFO: Pod name wrapped-volume-race-d22002b0-e911-4c69-8f1f-02305a4e8aea: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 02/07/24 14:46:37.876
  E0207 14:46:38.710737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:39.710910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 02/07/24 14:46:39.935
  Feb  7 14:46:39.946: INFO: Pod name wrapped-volume-race-e38cf0c0-e2ce-4120-981e-f1243e14e47a: Found 0 pods out of 5
  E0207 14:46:40.713106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:41.714142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:42.714358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:43.714660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:44.714869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:44.954: INFO: Pod name wrapped-volume-race-e38cf0c0-e2ce-4120-981e-f1243e14e47a: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 02/07/24 14:46:44.954
  STEP: Creating RC which spawns configmap-volume pods @ 02/07/24 14:46:44.97
  Feb  7 14:46:44.984: INFO: Pod name wrapped-volume-race-b864b563-5b86-4060-b9ca-9e29dc7b68c1: Found 0 pods out of 5
  E0207 14:46:45.714930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:46.715578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:47.715812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:48.716009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:49.716190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:49.991: INFO: Pod name wrapped-volume-race-b864b563-5b86-4060-b9ca-9e29dc7b68c1: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 02/07/24 14:46:49.991
  STEP: deleting ReplicationController wrapped-volume-race-b864b563-5b86-4060-b9ca-9e29dc7b68c1 in namespace emptydir-wrapper-4689, will wait for the garbage collector to delete the pods @ 02/07/24 14:46:50.004
  Feb  7 14:46:50.061: INFO: Deleting ReplicationController wrapped-volume-race-b864b563-5b86-4060-b9ca-9e29dc7b68c1 took: 4.748221ms
  Feb  7 14:46:50.162: INFO: Terminating ReplicationController wrapped-volume-race-b864b563-5b86-4060-b9ca-9e29dc7b68c1 pods took: 100.935806ms
  E0207 14:46:50.716847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-e38cf0c0-e2ce-4120-981e-f1243e14e47a in namespace emptydir-wrapper-4689, will wait for the garbage collector to delete the pods @ 02/07/24 14:46:51.563
  Feb  7 14:46:51.624: INFO: Deleting ReplicationController wrapped-volume-race-e38cf0c0-e2ce-4120-981e-f1243e14e47a took: 6.670822ms
  E0207 14:46:51.717104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:51.724: INFO: Terminating ReplicationController wrapped-volume-race-e38cf0c0-e2ce-4120-981e-f1243e14e47a pods took: 100.204199ms
  E0207 14:46:52.717836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-d22002b0-e911-4c69-8f1f-02305a4e8aea in namespace emptydir-wrapper-4689, will wait for the garbage collector to delete the pods @ 02/07/24 14:46:52.924
  Feb  7 14:46:52.984: INFO: Deleting ReplicationController wrapped-volume-race-d22002b0-e911-4c69-8f1f-02305a4e8aea took: 5.264305ms
  Feb  7 14:46:53.085: INFO: Terminating ReplicationController wrapped-volume-race-d22002b0-e911-4c69-8f1f-02305a4e8aea pods took: 100.875678ms
  E0207 14:46:53.717902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 02/07/24 14:46:53.985
  Feb  7 14:46:54.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4689" for this suite. @ 02/07/24 14:46:54.17
• [16.660 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 02/07/24 14:46:54.174
  Feb  7 14:46:54.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:46:54.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:54.186
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:54.188
  STEP: creating a collection of services @ 02/07/24 14:46:54.191
  Feb  7 14:46:54.191: INFO: Creating e2e-svc-a-vgklq
  Feb  7 14:46:54.203: INFO: Creating e2e-svc-b-2k4z9
  Feb  7 14:46:54.214: INFO: Creating e2e-svc-c-rc8ng
  STEP: deleting service collection @ 02/07/24 14:46:54.23
  Feb  7 14:46:54.256: INFO: Collection of services has been deleted
  Feb  7 14:46:54.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6337" for this suite. @ 02/07/24 14:46:54.259
• [0.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 02/07/24 14:46:54.265
  Feb  7 14:46:54.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:46:54.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:46:54.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:46:54.277
  STEP: Setting up server cert @ 02/07/24 14:46:54.294
  E0207 14:46:54.718615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:46:54.929
  STEP: Deploying the webhook pod @ 02/07/24 14:46:54.935
  STEP: Wait for the deployment to be ready @ 02/07/24 14:46:54.947
  Feb  7 14:46:54.952: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:46:55.719558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:56.719959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:46:56.96
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:46:56.973
  E0207 14:46:57.720242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:46:57.973: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 02/07/24 14:46:57.978
  E0207 14:46:58.720534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:46:59.720724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:00.720945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:01.721071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:02.721492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:02.996: INFO: Waiting for webhook configuration to be ready...
  STEP: create a configmap that should be updated by the webhook @ 02/07/24 14:47:03.108
  Feb  7 14:47:03.153: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9943" for this suite. @ 02/07/24 14:47:03.157
  STEP: Destroying namespace "webhook-markers-4545" for this suite. @ 02/07/24 14:47:03.162
• [8.903 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 02/07/24 14:47:03.169
  Feb  7 14:47:03.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename subpath @ 02/07/24 14:47:03.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:03.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:03.18
  STEP: Setting up data @ 02/07/24 14:47:03.183
  STEP: Creating pod pod-subpath-test-secret-mkg7 @ 02/07/24 14:47:03.191
  STEP: Creating a pod to test atomic-volume-subpath @ 02/07/24 14:47:03.191
  E0207 14:47:03.721612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:04.721736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:05.721855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:06.722559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:07.722686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:08.722872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:09.723666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:10.723762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:11.724618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:12.724879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:13.725744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:14.725944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:15.726577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:16.727091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:17.727498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:18.727469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:19.727524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:20.727708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:21.728401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:22.728514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:23.729361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:24.729541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:25.729580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:26.729919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:47:27.238
  Feb  7 14:47:27.240: INFO: Trying to get logs from node worker-0 pod pod-subpath-test-secret-mkg7 container test-container-subpath-secret-mkg7: <nil>
  STEP: delete the pod @ 02/07/24 14:47:27.246
  STEP: Deleting pod pod-subpath-test-secret-mkg7 @ 02/07/24 14:47:27.257
  Feb  7 14:47:27.258: INFO: Deleting pod "pod-subpath-test-secret-mkg7" in namespace "subpath-8565"
  Feb  7 14:47:27.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8565" for this suite. @ 02/07/24 14:47:27.262
• [24.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 02/07/24 14:47:27.267
  Feb  7 14:47:27.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 14:47:27.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:27.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:27.281
  Feb  7 14:47:27.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 create -f -'
  Feb  7 14:47:27.404: INFO: stderr: ""
  Feb  7 14:47:27.404: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Feb  7 14:47:27.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 create -f -'
  Feb  7 14:47:27.535: INFO: stderr: ""
  Feb  7 14:47:27.535: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 02/07/24 14:47:27.535
  E0207 14:47:27.730038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:28.539: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 14:47:28.539: INFO: Found 1 / 1
  Feb  7 14:47:28.539: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Feb  7 14:47:28.541: INFO: Selector matched 1 pods for map[app:agnhost]
  Feb  7 14:47:28.541: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Feb  7 14:47:28.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 describe pod agnhost-primary-sj7f6'
  Feb  7 14:47:28.610: INFO: stderr: ""
  Feb  7 14:47:28.610: INFO: stdout: "Name:             agnhost-primary-sj7f6\nNamespace:        kubectl-4009\nPriority:         0\nService Account:  default\nNode:             worker-0/10.0.60.182\nStart Time:       Wed, 07 Feb 2024 14:47:27 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.230\nIPs:\n  IP:           10.244.1.230\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://e524a7753303512608a00d40c677f9f591e75e8a0e2ea01d893c76f55e216b69\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.45\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 07 Feb 2024 14:47:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-664r6 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-664r6:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-4009/agnhost-primary-sj7f6 to worker-0\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.45\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Feb  7 14:47:28.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 describe rc agnhost-primary'
  Feb  7 14:47:28.695: INFO: stderr: ""
  Feb  7 14:47:28.695: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-4009\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-sj7f6\n"
  Feb  7 14:47:28.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 describe service agnhost-primary'
  E0207 14:47:28.730953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:28.759: INFO: stderr: ""
  Feb  7 14:47:28.759: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-4009\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.110.205.248\nIPs:               10.110.205.248\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.1.230:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Feb  7 14:47:28.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 describe node worker-0'
  Feb  7 14:47:28.837: INFO: stderr: ""
  Feb  7 14:47:28.837: INFO: stdout: "Name:               worker-0\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=worker-0\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 07 Feb 2024 13:36:37 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  worker-0\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 07 Feb 2024 14:47:25 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 07 Feb 2024 14:43:17 +0000   Wed, 07 Feb 2024 13:36:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 07 Feb 2024 14:43:17 +0000   Wed, 07 Feb 2024 13:36:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 07 Feb 2024 14:43:17 +0000   Wed, 07 Feb 2024 13:36:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 07 Feb 2024 14:43:17 +0000   Wed, 07 Feb 2024 13:36:53 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.60.182\n  Hostname:    worker-0\nCapacity:\n  cpu:                  4\n  ephemeral-storage:    50620216Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               7604732Ki\n  pods:                 110\nAllocatable:\n  cpu:                  4\n  ephemeral-storage:    46651590989\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               7502332Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 2582feb4b59745b7bbf1658e1efd7515\n  System UUID:                ec279fa9-7c64-8f81-88e1-9106fe14d1d4\n  Boot ID:                    dfa15c41-9a91-4a73-a415-4f0c46ad36f0\n  Kernel Version:             6.2.0-1018-aws\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.12\n  Kubelet Version:            v1.29.1+k0s\n  Kube-Proxy Version:         v1.29.1+k0s\nPodCIDR:                      10.244.1.0/24\nPodCIDRs:                     10.244.1.0/24\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-555d98c87b-tdvsz                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     43m\n  kube-system                 konnectivity-agent-x99jt                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                 kube-proxy-l28q5                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                 kube-router-wfgm8                                          250m (6%)     0 (0%)      16Mi (0%)        0 (0%)         70m\n  kubectl-4009                agnhost-primary-sj7f6                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         1s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-2wkv5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests   Limits\n  --------             --------   ------\n  cpu                  350m (8%)  0 (0%)\n  memory               86Mi (1%)  170Mi (2%)\n  ephemeral-storage    0 (0%)     0 (0%)\n  hugepages-1Gi        0 (0%)     0 (0%)\n  hugepages-2Mi        0 (0%)     0 (0%)\n  example.com/fakecpu  0          0\nEvents:                <none>\n"
  Feb  7 14:47:28.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-4009 describe namespace kubectl-4009'
  Feb  7 14:47:28.903: INFO: stderr: ""
  Feb  7 14:47:28.903: INFO: stdout: "Name:         kubectl-4009\nLabels:       e2e-framework=kubectl\n              e2e-run=6f38753a-a54c-471f-9df2-0d69bb9619d8\n              kubernetes.io/metadata.name=kubectl-4009\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Feb  7 14:47:28.903: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4009" for this suite. @ 02/07/24 14:47:28.906
• [1.643 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 02/07/24 14:47:28.91
  Feb  7 14:47:28.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename cronjob @ 02/07/24 14:47:28.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:28.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:28.924
  STEP: Creating a cronjob @ 02/07/24 14:47:28.927
  STEP: creating @ 02/07/24 14:47:28.927
  STEP: getting @ 02/07/24 14:47:28.932
  STEP: listing @ 02/07/24 14:47:28.934
  STEP: watching @ 02/07/24 14:47:28.936
  Feb  7 14:47:28.936: INFO: starting watch
  STEP: cluster-wide listing @ 02/07/24 14:47:28.938
  STEP: cluster-wide watching @ 02/07/24 14:47:28.94
  Feb  7 14:47:28.940: INFO: starting watch
  STEP: patching @ 02/07/24 14:47:28.941
  STEP: updating @ 02/07/24 14:47:28.947
  Feb  7 14:47:28.953: INFO: waiting for watch events with expected annotations
  Feb  7 14:47:28.953: INFO: saw patched and updated annotations
  STEP: patching /status @ 02/07/24 14:47:28.953
  STEP: updating /status @ 02/07/24 14:47:28.958
  STEP: get /status @ 02/07/24 14:47:28.963
  STEP: deleting @ 02/07/24 14:47:28.965
  STEP: deleting a collection @ 02/07/24 14:47:28.975
  Feb  7 14:47:28.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7695" for this suite. @ 02/07/24 14:47:28.983
• [0.077 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 02/07/24 14:47:28.988
  Feb  7 14:47:28.988: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:47:28.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:28.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:29.001
  STEP: Creating secret with name secret-test-bca3d1d0-bcd7-4fa2-8938-13e12c496bf2 @ 02/07/24 14:47:29.003
  STEP: Creating a pod to test consume secrets @ 02/07/24 14:47:29.007
  E0207 14:47:29.731994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:30.732163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:31.732465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:32.732748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:47:33.022
  Feb  7 14:47:33.025: INFO: Trying to get logs from node worker-0 pod pod-secrets-e9c193b6-d387-4365-a648-d8eff7666e01 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 14:47:33.03
  Feb  7 14:47:33.039: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7943" for this suite. @ 02/07/24 14:47:33.042
• [4.058 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 02/07/24 14:47:33.046
  Feb  7 14:47:33.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:47:33.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:33.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:33.06
  STEP: Setting up server cert @ 02/07/24 14:47:33.075
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:47:33.715
  STEP: Deploying the webhook pod @ 02/07/24 14:47:33.721
  STEP: Wait for the deployment to be ready @ 02/07/24 14:47:33.731
  E0207 14:47:33.733723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:33.736: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:47:34.734658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:35.734855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:47:35.744
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:47:35.754
  E0207 14:47:36.735178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:36.754: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 02/07/24 14:47:36.759
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/07/24 14:47:36.776
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 02/07/24 14:47:36.786
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/07/24 14:47:36.793
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 02/07/24 14:47:36.801
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/07/24 14:47:36.807
  Feb  7 14:47:36.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-0" for this suite. @ 02/07/24 14:47:36.845
  STEP: Destroying namespace "webhook-markers-7986" for this suite. @ 02/07/24 14:47:36.851
• [3.809 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 02/07/24 14:47:36.856
  Feb  7 14:47:36.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 14:47:36.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:36.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:36.87
  STEP: Creating a test headless service @ 02/07/24 14:47:36.872
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2657.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2657.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 02/07/24 14:47:36.876
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2657.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2657.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 02/07/24 14:47:36.876
  STEP: creating a pod to probe DNS @ 02/07/24 14:47:36.876
  STEP: submitting the pod to kubernetes @ 02/07/24 14:47:36.877
  E0207 14:47:37.736267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:38.736619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/07/24 14:47:38.892
  STEP: looking for the results for each expected name from probers @ 02/07/24 14:47:38.894
  Feb  7 14:47:38.909: INFO: DNS probes using dns-2657/dns-test-0651812b-89cd-4351-9e29-d5ff0a0009b7 succeeded

  STEP: deleting the pod @ 02/07/24 14:47:38.909
  STEP: deleting the test headless service @ 02/07/24 14:47:38.921
  Feb  7 14:47:38.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2657" for this suite. @ 02/07/24 14:47:38.931
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 02/07/24 14:47:38.936
  Feb  7 14:47:38.936: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:47:38.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:47:38.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:47:38.949
  STEP: Creating pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054 @ 02/07/24 14:47:38.952
  E0207 14:47:39.737593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:40.738107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:47:40.964
  Feb  7 14:47:40.966: INFO: Initial restart count of pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 is 0
  Feb  7 14:47:40.968: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:41.738985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:42.739321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:42.971: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:43.740063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:44.740251      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:44.974: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:45.740354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:46.740802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:46.977: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:47.741768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:48.741872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:48.980: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:49.742124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:50.742420      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:50.984: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:51.743161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:52.743523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:52.987: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:53.743985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:54.744864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:54.990: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:55.745066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:56.745437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:56.994: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:57.745585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:47:58.745946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:47:58.998: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:47:59.746982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:00.747179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:01.001: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:01.747929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:02.748301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:03.004: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:03.749286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:04.749483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:05.007: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:05.750193      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:06.750527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:07.010: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:07.750726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:08.751162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:09.013: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:09.751626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:10.751820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:11.016: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:11.752222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:12.752579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:13.019: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:13.752968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:14.753078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:15.023: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:15.753972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:16.754128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:17.026: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:17.754810      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:18.755099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:19.030: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:19.756088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:20.756285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:21.033: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:21.757160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:22.757681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:23.036: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:23.757765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:24.757982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:25.040: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:25.759037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:26.759292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:27.043: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:27.759669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:28.759851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:29.046: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:29.760707      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:30.760939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:31.049: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:31.761325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:32.761755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:33.052: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:33.762295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:34.762423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:35.055: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:35.763322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:36.763638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:37.059: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:37.763768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:38.763864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:39.061: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:39.764628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:40.764838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:41.064: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:41.765568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:42.765867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:43.068: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:43.766165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:44.766357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:45.071: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:45.766518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:46.766979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:47.075: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:47.767350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:48.767540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:49.078: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:49.768445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:50.768630      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:51.081: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:51.769594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:52.769766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:53.084: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:53.769877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:54.770083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:55.088: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:55.770191      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:56.770501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:57.091: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:57.770708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:48:58.770941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:48:59.095: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:48:59.771866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:00.771966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:01.098: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:01.772073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:02.772415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:03.101: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:03.773283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:04.773500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:05.104: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:05.774140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:06.774430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:07.107: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:07.774741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:08.774852      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:09.111: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:09.775819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:10.775996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:11.114: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:11.776896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:12.777265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:13.117: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:13.778129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:14.778328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:15.120: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:15.779199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:16.780032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:17.124: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:17.780414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:18.780452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:19.127: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:19.780384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:20.780511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:21.130: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:21.781262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:22.781651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:23.133: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:23.782486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:24.782664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:25.136: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:25.783318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:26.783878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:27.140: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:27.783938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:28.784125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:29.144: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:29.784709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:30.784918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:31.147: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:31.785747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:32.786011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:33.150: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:33.786800      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:34.786987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:35.152: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:35.787510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:36.787918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:37.156: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:37.788019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:38.788203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:39.159: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:39.789130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:40.790181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:41.162: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:41.791057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:42.791174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:43.165: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:43.792129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:44.792306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:45.168: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:45.793032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:46.793287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:47.171: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:47.793428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:48.793623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:49.174: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:49.794506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:50.794682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:51.177: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:51.795290      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:52.795403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:53.180: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:53.796134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:54.796233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:55.183: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:55.797045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:56.797326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:57.186: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:57.797548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:49:58.797731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:49:59.189: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:49:59.798547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:00.798721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:01.192: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:01.799302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:02.799652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:03.196: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:03.800699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:04.800878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:05.199: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:05.801847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:06.802534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:07.203: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:07.802997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:08.803446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:09.206: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:09.804337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:10.804509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:11.209: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:11.805336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:12.805669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:13.212: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:13.806115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:14.806287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:15.216: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:15.807137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:16.807384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:17.220: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:17.807494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:18.807667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:19.222: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:19.808551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:20.808725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:21.225: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:21.809526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:22.809784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:23.228: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:23.810104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:24.810292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:25.232: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:25.811044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:26.811980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:27.236: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:27.812405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:28.812575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:29.239: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:29.813373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:30.814109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:31.243: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:31.815113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:32.815428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:33.246: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:33.816282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:34.816454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:35.249: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:35.817231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:36.818116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:37.252: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:37.818407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:38.818592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:39.255: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:39.819346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:40.819546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:41.258: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:41.820047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:42.820384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:43.261: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:43.821187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:44.822115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:45.265: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:45.822889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:46.823184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:47.268: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:47.823423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:48.823539      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:49.271: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:49.824233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:50.824405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:51.274: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:51.825178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:52.825509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:53.277: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:53.825722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:54.825891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:55.280: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:55.826116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:56.826354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:57.283: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:57.826660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:50:58.826858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:50:59.286: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:50:59.827669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:00.827788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:01.288: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:01.828487      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:02.828607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:03.291: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:03.829340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:04.829519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:05.294: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:05.830363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:06.830488      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:07.298: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:07.830736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:08.830944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:09.301: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:09.831754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:10.831880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:11.304: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:11.832756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:12.833032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:13.307: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:13.833787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:14.834107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:15.310: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:15.834678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:16.834967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:17.313: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:17.835382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:18.835575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:19.317: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:19.835582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:20.835764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:21.319: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:21.836527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:22.836831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:23.323: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:23.837552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:24.838108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:25.326: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:25.839043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:26.839303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:27.329: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:27.840284      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:28.840459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:29.332: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:29.840560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:30.840669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:31.335: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:31.841361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:32.841688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:33.338: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:33.842104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:34.842271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:35.341: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:35.842639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:36.842968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:37.344: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:37.843066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:38.843182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:39.347: INFO: Get pod test-webserver-eb4d933e-a590-4190-9dd5-e28f575c7914 in namespace container-probe-4054
  E0207 14:51:39.843612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:40.844280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/07/24 14:51:41.348
  Feb  7 14:51:41.355: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4054" for this suite. @ 02/07/24 14:51:41.358
• [242.428 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 02/07/24 14:51:41.364
  Feb  7 14:51:41.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 14:51:41.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:51:41.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:51:41.376
  STEP: create the rc1 @ 02/07/24 14:51:41.381
  STEP: create the rc2 @ 02/07/24 14:51:41.385
  E0207 14:51:41.845048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:42.846164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:43.852390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:44.853176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:45.854908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:46.860891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 02/07/24 14:51:47.394
  STEP: delete the rc simpletest-rc-to-be-deleted @ 02/07/24 14:51:47.704
  STEP: wait for the rc to be deleted @ 02/07/24 14:51:47.709
  E0207 14:51:47.861397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:48.862147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:49.862441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:50.862562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:51.862938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:52.719: INFO: 69 pods remaining
  Feb  7 14:51:52.719: INFO: 69 pods has nil DeletionTimestamp
  Feb  7 14:51:52.719: INFO: 
  E0207 14:51:52.863771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:53.864001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:54.865046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:55.865100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:51:56.865393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/07/24 14:51:57.718
  W0207 14:51:57.722612      23 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb  7 14:51:57.722: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb  7 14:51:57.722: INFO: Deleting pod "simpletest-rc-to-be-deleted-2c4jr" in namespace "gc-2597"
  Feb  7 14:51:57.730: INFO: Deleting pod "simpletest-rc-to-be-deleted-2w49d" in namespace "gc-2597"
  Feb  7 14:51:57.741: INFO: Deleting pod "simpletest-rc-to-be-deleted-42kz9" in namespace "gc-2597"
  Feb  7 14:51:57.750: INFO: Deleting pod "simpletest-rc-to-be-deleted-4hl9s" in namespace "gc-2597"
  Feb  7 14:51:57.759: INFO: Deleting pod "simpletest-rc-to-be-deleted-4hzr7" in namespace "gc-2597"
  Feb  7 14:51:57.766: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qnbx" in namespace "gc-2597"
  Feb  7 14:51:57.774: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vks9" in namespace "gc-2597"
  Feb  7 14:51:57.782: INFO: Deleting pod "simpletest-rc-to-be-deleted-4w9sb" in namespace "gc-2597"
  Feb  7 14:51:57.790: INFO: Deleting pod "simpletest-rc-to-be-deleted-4z6rb" in namespace "gc-2597"
  Feb  7 14:51:57.797: INFO: Deleting pod "simpletest-rc-to-be-deleted-56cwd" in namespace "gc-2597"
  Feb  7 14:51:57.805: INFO: Deleting pod "simpletest-rc-to-be-deleted-59d76" in namespace "gc-2597"
  Feb  7 14:51:57.817: INFO: Deleting pod "simpletest-rc-to-be-deleted-5m7gc" in namespace "gc-2597"
  Feb  7 14:51:57.825: INFO: Deleting pod "simpletest-rc-to-be-deleted-5thcs" in namespace "gc-2597"
  Feb  7 14:51:57.832: INFO: Deleting pod "simpletest-rc-to-be-deleted-5x6hb" in namespace "gc-2597"
  Feb  7 14:51:57.841: INFO: Deleting pod "simpletest-rc-to-be-deleted-64k6j" in namespace "gc-2597"
  Feb  7 14:51:57.849: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fv5w" in namespace "gc-2597"
  Feb  7 14:51:57.857: INFO: Deleting pod "simpletest-rc-to-be-deleted-6g257" in namespace "gc-2597"
  E0207 14:51:57.865946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:57.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kkgg" in namespace "gc-2597"
  Feb  7 14:51:57.875: INFO: Deleting pod "simpletest-rc-to-be-deleted-72pnd" in namespace "gc-2597"
  Feb  7 14:51:57.885: INFO: Deleting pod "simpletest-rc-to-be-deleted-7sjj5" in namespace "gc-2597"
  Feb  7 14:51:57.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bjnw" in namespace "gc-2597"
  Feb  7 14:51:57.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-8lvwr" in namespace "gc-2597"
  Feb  7 14:51:57.910: INFO: Deleting pod "simpletest-rc-to-be-deleted-8r4sb" in namespace "gc-2597"
  Feb  7 14:51:57.917: INFO: Deleting pod "simpletest-rc-to-be-deleted-8svtv" in namespace "gc-2597"
  Feb  7 14:51:57.925: INFO: Deleting pod "simpletest-rc-to-be-deleted-95ghz" in namespace "gc-2597"
  Feb  7 14:51:57.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-95vhz" in namespace "gc-2597"
  Feb  7 14:51:57.941: INFO: Deleting pod "simpletest-rc-to-be-deleted-9pv66" in namespace "gc-2597"
  Feb  7 14:51:57.949: INFO: Deleting pod "simpletest-rc-to-be-deleted-9tphb" in namespace "gc-2597"
  Feb  7 14:51:57.958: INFO: Deleting pod "simpletest-rc-to-be-deleted-bhpgq" in namespace "gc-2597"
  Feb  7 14:51:57.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnwpz" in namespace "gc-2597"
  Feb  7 14:51:57.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-bpc29" in namespace "gc-2597"
  Feb  7 14:51:57.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-bttfr" in namespace "gc-2597"
  Feb  7 14:51:58.005: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwwzr" in namespace "gc-2597"
  Feb  7 14:51:58.011: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxmq7" in namespace "gc-2597"
  Feb  7 14:51:58.025: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxmww" in namespace "gc-2597"
  Feb  7 14:51:58.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2tn6" in namespace "gc-2597"
  Feb  7 14:51:58.047: INFO: Deleting pod "simpletest-rc-to-be-deleted-c52z7" in namespace "gc-2597"
  Feb  7 14:51:58.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-cldnw" in namespace "gc-2597"
  Feb  7 14:51:58.064: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkmfm" in namespace "gc-2597"
  Feb  7 14:51:58.087: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9kqq" in namespace "gc-2597"
  Feb  7 14:51:58.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmg7g" in namespace "gc-2597"
  Feb  7 14:51:58.120: INFO: Deleting pod "simpletest-rc-to-be-deleted-gn6s2" in namespace "gc-2597"
  Feb  7 14:51:58.138: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxrjb" in namespace "gc-2597"
  Feb  7 14:51:58.153: INFO: Deleting pod "simpletest-rc-to-be-deleted-hb4kv" in namespace "gc-2597"
  Feb  7 14:51:58.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-hkrx9" in namespace "gc-2597"
  Feb  7 14:51:58.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-hr5kg" in namespace "gc-2597"
  Feb  7 14:51:58.185: INFO: Deleting pod "simpletest-rc-to-be-deleted-htlq8" in namespace "gc-2597"
  Feb  7 14:51:58.195: INFO: Deleting pod "simpletest-rc-to-be-deleted-hvwz7" in namespace "gc-2597"
  Feb  7 14:51:58.205: INFO: Deleting pod "simpletest-rc-to-be-deleted-hzszf" in namespace "gc-2597"
  Feb  7 14:51:58.219: INFO: Deleting pod "simpletest-rc-to-be-deleted-jxdjw" in namespace "gc-2597"
  Feb  7 14:51:58.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2597" for this suite. @ 02/07/24 14:51:58.234
• [16.875 seconds]
------------------------------
SS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 02/07/24 14:51:58.24
  Feb  7 14:51:58.240: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename csistoragecapacity @ 02/07/24 14:51:58.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:51:58.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:51:58.258
  STEP: getting /apis @ 02/07/24 14:51:58.261
  STEP: getting /apis/storage.k8s.io @ 02/07/24 14:51:58.266
  STEP: getting /apis/storage.k8s.io/v1 @ 02/07/24 14:51:58.268
  STEP: creating @ 02/07/24 14:51:58.281
  STEP: watching @ 02/07/24 14:51:58.301
  Feb  7 14:51:58.302: INFO: starting watch
  STEP: getting @ 02/07/24 14:51:58.307
  STEP: listing in namespace @ 02/07/24 14:51:58.309
  STEP: listing across namespaces @ 02/07/24 14:51:58.312
  STEP: patching @ 02/07/24 14:51:58.314
  STEP: updating @ 02/07/24 14:51:58.318
  Feb  7 14:51:58.321: INFO: waiting for watch events with expected annotations in namespace
  Feb  7 14:51:58.322: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 02/07/24 14:51:58.322
  STEP: deleting a collection @ 02/07/24 14:51:58.329
  Feb  7 14:51:58.341: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-4607" for this suite. @ 02/07/24 14:51:58.346
• [0.115 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 02/07/24 14:51:58.355
  Feb  7 14:51:58.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 14:51:58.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:51:58.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:51:58.374
  STEP: Creating simple DaemonSet "daemon-set" @ 02/07/24 14:51:58.397
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/07/24 14:51:58.403
  Feb  7 14:51:58.415: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:51:58.415: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:51:58.866222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:51:59.408: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:51:59.408: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:51:59.866820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:00.408: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 14:52:00.408: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 02/07/24 14:52:00.41
  Feb  7 14:52:00.420: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:52:00.420: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:52:00.867896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:01.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:52:01.421: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:52:01.868992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:02.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 14:52:02.421: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 02/07/24 14:52:02.423
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6821, will wait for the garbage collector to delete the pods @ 02/07/24 14:52:02.423
  Feb  7 14:52:02.479: INFO: Deleting DaemonSet.extensions daemon-set took: 3.43671ms
  Feb  7 14:52:02.579: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.633623ms
  E0207 14:52:02.869038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:03.869273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:04.482: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:52:04.482: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb  7 14:52:04.484: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25271"},"items":null}

  Feb  7 14:52:04.487: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25272"},"items":null}

  Feb  7 14:52:04.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6821" for this suite. @ 02/07/24 14:52:04.499
• [6.148 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 02/07/24 14:52:04.504
  Feb  7 14:52:04.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename podtemplate @ 02/07/24 14:52:04.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:04.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:04.517
  STEP: Create a pod template @ 02/07/24 14:52:04.519
  STEP: Replace a pod template @ 02/07/24 14:52:04.523
  Feb  7 14:52:04.530: INFO: Found updated podtemplate annotation: "true"

  Feb  7 14:52:04.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3695" for this suite. @ 02/07/24 14:52:04.533
• [0.033 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 02/07/24 14:52:04.537
  Feb  7 14:52:04.537: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 14:52:04.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:04.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:04.548
  STEP: creating a secret @ 02/07/24 14:52:04.55
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 02/07/24 14:52:04.555
  STEP: patching the secret @ 02/07/24 14:52:04.557
  STEP: deleting the secret using a LabelSelector @ 02/07/24 14:52:04.563
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 02/07/24 14:52:04.568
  Feb  7 14:52:04.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3166" for this suite. @ 02/07/24 14:52:04.573
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 02/07/24 14:52:04.578
  Feb  7 14:52:04.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:52:04.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:04.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:04.591
  STEP: Counting existing ResourceQuota @ 02/07/24 14:52:04.594
  E0207 14:52:04.870068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:05.870819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:06.870932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:07.871701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:08.872706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 14:52:09.597
  STEP: Ensuring resource quota status is calculated @ 02/07/24 14:52:09.602
  E0207 14:52:09.873473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:10.873721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 02/07/24 14:52:11.605
  STEP: Creating a NodePort Service @ 02/07/24 14:52:11.619
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 02/07/24 14:52:11.636
  STEP: Ensuring resource quota status captures service creation @ 02/07/24 14:52:11.653
  E0207 14:52:11.873955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:12.874308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 02/07/24 14:52:13.656
  STEP: Ensuring resource quota status released usage @ 02/07/24 14:52:13.685
  E0207 14:52:13.874479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:14.874661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:15.688: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-870" for this suite. @ 02/07/24 14:52:15.691
• [11.116 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 02/07/24 14:52:15.695
  Feb  7 14:52:15.695: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 14:52:15.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:15.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:15.708
  STEP: Creating a pod to test env composition @ 02/07/24 14:52:15.71
  E0207 14:52:15.875261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:16.876088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:52:17.72
  Feb  7 14:52:17.722: INFO: Trying to get logs from node worker-0 pod var-expansion-430d0723-13f6-4df1-99c8-93c110a5bb62 container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 14:52:17.737
  Feb  7 14:52:17.747: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8008" for this suite. @ 02/07/24 14:52:17.749
• [2.059 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 02/07/24 14:52:17.754
  Feb  7 14:52:17.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename namespaces @ 02/07/24 14:52:17.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:17.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:17.766
  STEP: Creating namespace "e2e-ns-74rvr" @ 02/07/24 14:52:17.769
  Feb  7 14:52:17.778: INFO: Namespace "e2e-ns-74rvr-4447" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-74rvr-4447" @ 02/07/24 14:52:17.778
  Feb  7 14:52:17.784: INFO: Namespace "e2e-ns-74rvr-4447" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-74rvr-4447" @ 02/07/24 14:52:17.784
  Feb  7 14:52:17.791: INFO: Namespace "e2e-ns-74rvr-4447" has []v1.FinalizerName{"kubernetes"}
  Feb  7 14:52:17.791: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1058" for this suite. @ 02/07/24 14:52:17.793
  STEP: Destroying namespace "e2e-ns-74rvr-4447" for this suite. @ 02/07/24 14:52:17.797
• [0.046 seconds]
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 02/07/24 14:52:17.801
  Feb  7 14:52:17.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 14:52:17.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:17.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:17.811
  STEP: creating service endpoint-test2 in namespace services-4727 @ 02/07/24 14:52:17.814
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4727 to expose endpoints map[] @ 02/07/24 14:52:17.824
  Feb  7 14:52:17.827: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0207 14:52:17.876409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:18.833: INFO: successfully validated that service endpoint-test2 in namespace services-4727 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4727 @ 02/07/24 14:52:18.833
  E0207 14:52:18.877401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:19.877600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4727 to expose endpoints map[pod1:[80]] @ 02/07/24 14:52:20.847
  Feb  7 14:52:20.853: INFO: successfully validated that service endpoint-test2 in namespace services-4727 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 02/07/24 14:52:20.853
  Feb  7 14:52:20.853: INFO: Creating new exec pod
  E0207 14:52:20.877879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:21.878054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:22.878965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:23.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4727 exec execpodl6c8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0207 14:52:23.879410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:23.989: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Feb  7 14:52:23.989: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:52:23.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4727 exec execpodl6c8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.8.218 80'
  Feb  7 14:52:24.101: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.8.218 80\nConnection to 10.108.8.218 80 port [tcp/http] succeeded!\n"
  Feb  7 14:52:24.101: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-4727 @ 02/07/24 14:52:24.101
  E0207 14:52:24.879682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:25.879874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4727 to expose endpoints map[pod1:[80] pod2:[80]] @ 02/07/24 14:52:26.113
  Feb  7 14:52:26.121: INFO: successfully validated that service endpoint-test2 in namespace services-4727 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 02/07/24 14:52:26.121
  E0207 14:52:26.880283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:27.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4727 exec execpodl6c8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Feb  7 14:52:27.249: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Feb  7 14:52:27.249: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:52:27.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4727 exec execpodl6c8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.8.218 80'
  Feb  7 14:52:27.365: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.8.218 80\nConnection to 10.108.8.218 80 port [tcp/http] succeeded!\n"
  Feb  7 14:52:27.365: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4727 @ 02/07/24 14:52:27.365
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4727 to expose endpoints map[pod2:[80]] @ 02/07/24 14:52:27.373
  Feb  7 14:52:27.384: INFO: successfully validated that service endpoint-test2 in namespace services-4727 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 02/07/24 14:52:27.384
  E0207 14:52:27.881137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:28.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4727 exec execpodl6c8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Feb  7 14:52:28.505: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Feb  7 14:52:28.505: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 14:52:28.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-4727 exec execpodl6c8q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.8.218 80'
  Feb  7 14:52:28.625: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.8.218 80\nConnection to 10.108.8.218 80 port [tcp/http] succeeded!\n"
  Feb  7 14:52:28.625: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-4727 @ 02/07/24 14:52:28.625
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4727 to expose endpoints map[] @ 02/07/24 14:52:28.635
  Feb  7 14:52:28.642: INFO: successfully validated that service endpoint-test2 in namespace services-4727 exposes endpoints map[]
  Feb  7 14:52:28.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4727" for this suite. @ 02/07/24 14:52:28.657
• [10.861 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 02/07/24 14:52:28.661
  Feb  7 14:52:28.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:52:28.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:28.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:28.675
  STEP: Setting up server cert @ 02/07/24 14:52:28.69
  E0207 14:52:28.881835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:52:28.98
  STEP: Deploying the webhook pod @ 02/07/24 14:52:28.986
  STEP: Wait for the deployment to be ready @ 02/07/24 14:52:28.995
  Feb  7 14:52:29.000: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:52:29.882570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:30.882783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:52:31.008
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:52:31.017
  E0207 14:52:31.882838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:32.018: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Feb  7 14:52:32.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6461-crds.webhook.example.com via the AdmissionRegistration API @ 02/07/24 14:52:32.531
  STEP: Creating a custom resource while v1 is storage version @ 02/07/24 14:52:32.548
  E0207 14:52:32.883586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:33.883905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 02/07/24 14:52:34.563
  STEP: Patching the custom resource while v2 is storage version @ 02/07/24 14:52:34.583
  E0207 14:52:34.884059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:35.151: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5756" for this suite. @ 02/07/24 14:52:35.154
  STEP: Destroying namespace "webhook-markers-4439" for this suite. @ 02/07/24 14:52:35.159
• [6.501 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 02/07/24 14:52:35.162
  Feb  7 14:52:35.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename statefulset @ 02/07/24 14:52:35.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:52:35.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:52:35.174
  STEP: Creating service test in namespace statefulset-7745 @ 02/07/24 14:52:35.177
  STEP: Creating a new StatefulSet @ 02/07/24 14:52:35.18
  Feb  7 14:52:35.188: INFO: Found 0 stateful pods, waiting for 3
  E0207 14:52:35.884146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:36.884506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:37.884862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:38.885110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:39.885216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:40.886216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:41.886457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:42.886788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:43.886992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:44.887157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:52:45.189: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:52:45.189: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:52:45.189: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 02/07/24 14:52:45.196
  Feb  7 14:52:45.211: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 02/07/24 14:52:45.211
  E0207 14:52:45.887473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:46.887888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:47.888145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:48.888354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:49.888446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:50.888723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:51.888935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:52.889334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:53.889534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:54.889673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 02/07/24 14:52:55.217
  STEP: Performing a canary update @ 02/07/24 14:52:55.217
  Feb  7 14:52:55.232: INFO: Updating stateful set ss2
  Feb  7 14:52:55.239: INFO: Waiting for Pod statefulset-7745/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0207 14:52:55.890282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:56.891137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:57.891489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:58.891612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:52:59.891796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:00.892003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:01.892111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:02.892541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:03.892729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:04.892837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 02/07/24 14:53:05.238
  Feb  7 14:53:05.264: INFO: Found 2 stateful pods, waiting for 3
  E0207 14:53:05.893873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:06.894089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:07.894466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:08.894709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:09.894967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:10.895085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:11.895291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:12.895644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:13.895832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:14.896027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:15.264: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:53:15.264: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Feb  7 14:53:15.264: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 02/07/24 14:53:15.269
  Feb  7 14:53:15.285: INFO: Updating stateful set ss2
  Feb  7 14:53:15.291: INFO: Waiting for Pod statefulset-7745/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0207 14:53:15.896316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:16.897151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:17.897545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:18.897524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:19.897612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:20.898141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:21.898316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:22.898624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:23.898795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:24.898972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:25.308: INFO: Updating stateful set ss2
  Feb  7 14:53:25.312: INFO: Waiting for StatefulSet statefulset-7745/ss2 to complete update
  Feb  7 14:53:25.312: INFO: Waiting for Pod statefulset-7745/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0207 14:53:25.899031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:26.899313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:27.899656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:28.899854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:29.900036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:30.900151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:31.900328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:32.900646      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:33.900768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:34.900981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:35.313: INFO: Deleting all statefulset in ns statefulset-7745
  Feb  7 14:53:35.315: INFO: Scaling statefulset ss2 to 0
  E0207 14:53:35.901466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:36.902143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:37.902451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:38.902653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:39.902828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:40.902946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:41.903155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:42.903504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:43.903677      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:44.903853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:45.326: INFO: Waiting for statefulset status.replicas updated to 0
  Feb  7 14:53:45.327: INFO: Deleting statefulset ss2
  Feb  7 14:53:45.334: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7745" for this suite. @ 02/07/24 14:53:45.337
• [70.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 02/07/24 14:53:45.341
  Feb  7 14:53:45.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename job @ 02/07/24 14:53:45.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:53:45.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:53:45.355
  STEP: Creating a job @ 02/07/24 14:53:45.357
  STEP: Ensuring active pods == parallelism @ 02/07/24 14:53:45.362
  E0207 14:53:45.904839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:46.905036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 02/07/24 14:53:47.365
  STEP: deleting Job.batch foo in namespace job-6009, will wait for the garbage collector to delete the pods @ 02/07/24 14:53:47.365
  Feb  7 14:53:47.421: INFO: Deleting Job.batch foo took: 3.630343ms
  Feb  7 14:53:47.522: INFO: Terminating Job.batch foo pods took: 100.555988ms
  E0207 14:53:47.905361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 02/07/24 14:53:48.722
  Feb  7 14:53:48.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6009" for this suite. @ 02/07/24 14:53:48.727
• [3.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 02/07/24 14:53:48.731
  Feb  7 14:53:48.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:53:48.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:53:48.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:53:48.743
  STEP: creating a Pod with a static label @ 02/07/24 14:53:48.748
  STEP: watching for Pod to be ready @ 02/07/24 14:53:48.753
  Feb  7 14:53:48.754: INFO: observed Pod pod-test in namespace pods-7551 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Feb  7 14:53:48.757: INFO: observed Pod pod-test in namespace pods-7551 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC  }]
  Feb  7 14:53:48.766: INFO: observed Pod pod-test in namespace pods-7551 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC  }]
  E0207 14:53:48.905728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:49.684: INFO: Found Pod pod-test in namespace pods-7551 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:49 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-02-07 14:53:48 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 02/07/24 14:53:49.686
  STEP: getting the Pod and ensuring that it's patched @ 02/07/24 14:53:49.692
  STEP: replacing the Pod's status Ready condition to False @ 02/07/24 14:53:49.694
  STEP: check the Pod again to ensure its Ready conditions are False @ 02/07/24 14:53:49.702
  STEP: deleting the Pod via a Collection with a LabelSelector @ 02/07/24 14:53:49.702
  STEP: watching for the Pod to be deleted @ 02/07/24 14:53:49.708
  Feb  7 14:53:49.709: INFO: observed event type MODIFIED
  E0207 14:53:49.906691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:50.907124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:51.688: INFO: observed event type MODIFIED
  Feb  7 14:53:51.785: INFO: observed event type MODIFIED
  E0207 14:53:51.907788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:52.692: INFO: observed event type MODIFIED
  Feb  7 14:53:52.701: INFO: observed event type MODIFIED
  Feb  7 14:53:52.706: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7551" for this suite. @ 02/07/24 14:53:52.708
• [3.981 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 02/07/24 14:53:52.713
  Feb  7 14:53:52.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:53:52.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:53:52.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:53:52.725
  STEP: Setting up server cert @ 02/07/24 14:53:52.738
  E0207 14:53:52.907841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:53:53.579
  STEP: Deploying the webhook pod @ 02/07/24 14:53:53.584
  STEP: Wait for the deployment to be ready @ 02/07/24 14:53:53.594
  Feb  7 14:53:53.598: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:53:53.908016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:54.908224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:53:55.605
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:53:55.617
  E0207 14:53:55.908390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:53:56.617: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 02/07/24 14:53:56.622
  STEP: create a pod that should be denied by the webhook @ 02/07/24 14:53:56.638
  STEP: create a pod that causes the webhook to hang @ 02/07/24 14:53:56.652
  E0207 14:53:56.908497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:57.908899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:58.909040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:53:59.909261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:00.910110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:01.910328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:02.910702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:03.910905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:04.910995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:05.911172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 02/07/24 14:54:06.658
  STEP: create a configmap that should be admitted by the webhook @ 02/07/24 14:54:06.679
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 02/07/24 14:54:06.689
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 02/07/24 14:54:06.695
  STEP: create a namespace that bypass the webhook @ 02/07/24 14:54:06.698
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 02/07/24 14:54:06.707
  Feb  7 14:54:06.746: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3399" for this suite. @ 02/07/24 14:54:06.75
  STEP: Destroying namespace "webhook-markers-9391" for this suite. @ 02/07/24 14:54:06.756
  STEP: Destroying namespace "exempted-namespace-8704" for this suite. @ 02/07/24 14:54:06.761
• [14.051 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 02/07/24 14:54:06.764
  Feb  7 14:54:06.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 14:54:06.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:54:06.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:54:06.775
  E0207 14:54:06.911951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:07.912303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:08.787: INFO: Deleting pod "var-expansion-f4513377-953e-4f87-8990-c5e116e265fc" in namespace "var-expansion-5313"
  Feb  7 14:54:08.791: INFO: Wait up to 5m0s for pod "var-expansion-f4513377-953e-4f87-8990-c5e116e265fc" to be fully deleted
  E0207 14:54:08.913047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:09.913066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:10.796: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5313" for this suite. @ 02/07/24 14:54:10.798
• [4.040 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 02/07/24 14:54:10.804
  Feb  7 14:54:10.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:54:10.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:54:10.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:54:10.815
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:54:10.818
  E0207 14:54:10.913195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:11.913267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:12.914236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:13.914434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:54:14.833
  Feb  7 14:54:14.835: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-4b3f5826-1e71-497c-8820-4e27e5beda70 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:54:14.847
  Feb  7 14:54:14.857: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6271" for this suite. @ 02/07/24 14:54:14.859
• [4.060 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 02/07/24 14:54:14.864
  Feb  7 14:54:14.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 14:54:14.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:54:14.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:54:14.876
  STEP: create the rc @ 02/07/24 14:54:14.88
  W0207 14:54:14.885169      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0207 14:54:14.915417      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:15.917239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:16.917875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:17.920258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:18.920550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:19.921552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 02/07/24 14:54:20.888
  STEP: wait for the rc to be deleted @ 02/07/24 14:54:20.899
  E0207 14:54:20.922101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:21.911: INFO: 80 pods remaining
  Feb  7 14:54:21.911: INFO: 80 pods has nil DeletionTimestamp
  Feb  7 14:54:21.911: INFO: 
  E0207 14:54:21.922782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:22.910: INFO: 72 pods remaining
  Feb  7 14:54:22.910: INFO: 72 pods has nil DeletionTimestamp
  Feb  7 14:54:22.910: INFO: 
  E0207 14:54:22.922997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:23.911: INFO: 58 pods remaining
  Feb  7 14:54:23.911: INFO: 58 pods has nil DeletionTimestamp
  Feb  7 14:54:23.911: INFO: 
  E0207 14:54:23.923219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:24.907: INFO: 40 pods remaining
  Feb  7 14:54:24.907: INFO: 40 pods has nil DeletionTimestamp
  Feb  7 14:54:24.907: INFO: 
  E0207 14:54:24.925061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:25.907: INFO: 32 pods remaining
  Feb  7 14:54:25.907: INFO: 32 pods has nil DeletionTimestamp
  Feb  7 14:54:25.907: INFO: 
  E0207 14:54:25.926166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:26.908: INFO: 19 pods remaining
  Feb  7 14:54:26.908: INFO: 18 pods has nil DeletionTimestamp
  Feb  7 14:54:26.908: INFO: 
  E0207 14:54:26.927186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/07/24 14:54:27.904
  W0207 14:54:27.908200      23 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb  7 14:54:27.908: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb  7 14:54:27.908: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9841" for this suite. @ 02/07/24 14:54:27.91
• [13.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 02/07/24 14:54:27.915
  Feb  7 14:54:27.915: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 14:54:27.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:54:27.927
  E0207 14:54:27.927461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:54:27.93
  STEP: Creating pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353 @ 02/07/24 14:54:27.933
  E0207 14:54:28.928380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:29.928583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 14:54:29.944
  Feb  7 14:54:29.946: INFO: Initial restart count of pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 is 0
  Feb  7 14:54:29.948: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:30.929094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:31.929195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:31.950: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:32.930164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:33.930367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:33.954: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:34.930527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:35.930724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:35.957: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:36.931762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:37.932036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:37.960: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:38.933007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:39.933186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:39.963: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:40.933344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:41.934148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:41.967: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:42.934315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:43.934516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:43.969: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:44.934937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:45.935121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:45.972: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:46.935557      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:47.935924      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:47.975: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:48.936907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:49.937141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:49.980: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:50.937316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:51.937512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:51.983: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:52.937966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:53.938167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:53.985: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:54.938531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:55.938713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:55.988: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:56.939268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:57.939604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:57.991: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:54:58.940426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:54:59.940610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:54:59.994: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:00.941084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:01.941279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:01.996: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:02.942034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:03.942140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:03.999: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:04.942277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:05.942484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:06.003: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:06.943127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:07.943497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:08.006: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:08.944292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:09.944517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:10.009: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:10.945062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:11.945181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:12.011: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:12.945842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:13.946053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:14.014: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:14.946414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:15.946526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:16.016: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:16.947164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:17.947499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:18.020: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:18.948307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:19.948495      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:20.023: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:20.949042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:21.949227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:22.027: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:22.949946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:23.950126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:24.029: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:24.950512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:25.950695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:26.032: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:26.951099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:27.951411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:28.035: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:28.952478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:29.952655      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:30.038: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:30.953204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:31.953382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:32.041: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  E0207 14:55:32.954273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:33.954459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:34.043: INFO: Get pod test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 in namespace container-probe-7353
  Feb  7 14:55:34.044: INFO: Restart count of pod container-probe-7353/test-grpc-94cfec59-623e-4eec-8ff4-7ab234b31057 is now 1 (1m4.097728933s elapsed)
  STEP: deleting the pod @ 02/07/24 14:55:34.044
  Feb  7 14:55:34.053: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7353" for this suite. @ 02/07/24 14:55:34.055
• [66.144 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 02/07/24 14:55:34.06
  Feb  7 14:55:34.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-pred @ 02/07/24 14:55:34.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:55:34.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:55:34.073
  Feb  7 14:55:34.076: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb  7 14:55:34.080: INFO: Waiting for terminating namespaces to be deleted...
  Feb  7 14:55:34.082: INFO: 
  Logging pods the apiserver thinks is on node worker-0 before test
  Feb  7 14:55:34.086: INFO: coredns-555d98c87b-tdvsz from kube-system started at 2024-02-07 14:03:53 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.086: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: konnectivity-agent-x99jt from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.086: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: kube-proxy-l28q5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.086: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: kube-router-wfgm8 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.086: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: sonobuoy from sonobuoy started at 2024-02-07 13:37:03 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.086: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-2wkv5 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 14:55:34.086: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb  7 14:55:34.086: INFO: 
  Logging pods the apiserver thinks is on node worker-1 before test
  Feb  7 14:55:34.090: INFO: coredns-555d98c87b-f8t6j from kube-system started at 2024-02-07 13:37:51 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: konnectivity-agent-bt2h5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: kube-proxy-qvgjm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: kube-router-mqgnm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: metrics-server-7556957bb7-6kv5t from kube-system started at 2024-02-07 13:36:50 +0000 UTC (1 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container metrics-server ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: sonobuoy-e2e-job-fedf139ced3a4f30 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container e2e ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-rq8vf from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 14:55:34.090: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 14:55:34.090: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 02/07/24 14:55:34.09
  E0207 14:55:34.955255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:35.955556      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 02/07/24 14:55:36.102
  STEP: Trying to apply a random label on the found node. @ 02/07/24 14:55:36.109
  STEP: verifying the node has the label kubernetes.io/e2e-cab86394-9cf7-410a-a250-d8e295b4a5a9 42 @ 02/07/24 14:55:36.116
  STEP: Trying to relaunch the pod, now with labels. @ 02/07/24 14:55:36.119
  E0207 14:55:36.956314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:37.956768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-cab86394-9cf7-410a-a250-d8e295b4a5a9 off the node worker-0 @ 02/07/24 14:55:38.129
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-cab86394-9cf7-410a-a250-d8e295b4a5a9 @ 02/07/24 14:55:38.137
  Feb  7 14:55:38.139: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-9659" for this suite. @ 02/07/24 14:55:38.141
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 02/07/24 14:55:38.148
  Feb  7 14:55:38.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 14:55:38.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:55:38.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:55:38.159
  STEP: Creating a pod to test substitution in volume subpath @ 02/07/24 14:55:38.161
  E0207 14:55:38.957107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:39.957296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:55:40.173
  Feb  7 14:55:40.175: INFO: Trying to get logs from node worker-0 pod var-expansion-b5045c1d-4224-4c70-aaba-b6d0ab90811c container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 14:55:40.179
  Feb  7 14:55:40.189: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4480" for this suite. @ 02/07/24 14:55:40.191
• [2.049 seconds]
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 02/07/24 14:55:40.196
  Feb  7 14:55:40.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 14:55:40.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:55:40.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:55:40.209
  STEP: creating the pod @ 02/07/24 14:55:40.212
  STEP: submitting the pod to kubernetes @ 02/07/24 14:55:40.212
  W0207 14:55:40.218193      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0207 14:55:40.958152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:41.958461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 02/07/24 14:55:42.225
  STEP: updating the pod @ 02/07/24 14:55:42.227
  Feb  7 14:55:42.735: INFO: Successfully updated pod "pod-update-activedeadlineseconds-44e82515-c3a2-4bf8-b17f-540f41bb6ec3"
  E0207 14:55:42.959575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:43.959859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:44.960951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:45.961038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:46.743: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3083" for this suite. @ 02/07/24 14:55:46.746
• [6.553 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 02/07/24 14:55:46.75
  Feb  7 14:55:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 14:55:46.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:55:46.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:55:46.764
  Feb  7 14:55:46.776: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/07/24 14:55:46.781
  Feb  7 14:55:46.785: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:55:46.785: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:55:46.961059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:47.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:55:47.786: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:55:47.962058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:48.787: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 14:55:48.787: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 02/07/24 14:55:48.795
  STEP: Check that daemon pods images are updated. @ 02/07/24 14:55:48.803
  Feb  7 14:55:48.805: INFO: Wrong image for pod: daemon-set-kwmjw. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Feb  7 14:55:48.805: INFO: Wrong image for pod: daemon-set-t2dq7. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0207 14:55:48.962876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:49.806: INFO: Pod daemon-set-s8vrm is not available
  Feb  7 14:55:49.806: INFO: Wrong image for pod: daemon-set-t2dq7. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0207 14:55:49.963840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:50.806: INFO: Pod daemon-set-6hjvm is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 02/07/24 14:55:50.808
  Feb  7 14:55:50.812: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:55:50.812: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:55:50.963920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:51.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 14:55:51.813: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 14:55:51.964733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:52.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 14:55:52.813: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 02/07/24 14:55:52.823
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6234, will wait for the garbage collector to delete the pods @ 02/07/24 14:55:52.823
  Feb  7 14:55:52.879: INFO: Deleting DaemonSet.extensions daemon-set took: 3.609975ms
  E0207 14:55:52.965338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:52.979: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.583756ms
  E0207 14:55:53.965690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:53.981: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 14:55:53.981: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb  7 14:55:53.985: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28354"},"items":null}

  Feb  7 14:55:53.986: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28354"},"items":null}

  Feb  7 14:55:53.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6234" for this suite. @ 02/07/24 14:55:53.994
• [7.249 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 02/07/24 14:55:53.999
  Feb  7 14:55:53.999: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replication-controller @ 02/07/24 14:55:54
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:55:54.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:55:54.01
  STEP: Given a ReplicationController is created @ 02/07/24 14:55:54.013
  STEP: When the matched label of one of its pods change @ 02/07/24 14:55:54.017
  Feb  7 14:55:54.019: INFO: Pod name pod-release: Found 0 pods out of 1
  E0207 14:55:54.966625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:55.966724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:56.967093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:57.967444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:55:58.967637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:55:59.023: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 02/07/24 14:55:59.031
  E0207 14:55:59.968036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:00.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8767" for this suite. @ 02/07/24 14:56:00.039
• [6.045 seconds]
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 02/07/24 14:56:00.044
  Feb  7 14:56:00.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename runtimeclass @ 02/07/24 14:56:00.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:00.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:00.055
  Feb  7 14:56:00.062: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3608" for this suite. @ 02/07/24 14:56:00.064
• [0.024 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 02/07/24 14:56:00.069
  Feb  7 14:56:00.069: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 14:56:00.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:00.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:00.08
  Feb  7 14:56:00.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:56:00.968885      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 02/07/24 14:56:01.356
  Feb  7 14:56:01.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-3435 --namespace=crd-publish-openapi-3435 create -f -'
  E0207 14:56:01.969074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:02.969441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:03.442: INFO: stderr: ""
  Feb  7 14:56:03.442: INFO: stdout: "e2e-test-crd-publish-openapi-6662-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Feb  7 14:56:03.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-3435 --namespace=crd-publish-openapi-3435 delete e2e-test-crd-publish-openapi-6662-crds test-cr'
  Feb  7 14:56:03.505: INFO: stderr: ""
  Feb  7 14:56:03.505: INFO: stdout: "e2e-test-crd-publish-openapi-6662-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Feb  7 14:56:03.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-3435 --namespace=crd-publish-openapi-3435 apply -f -'
  Feb  7 14:56:03.575: INFO: stderr: ""
  Feb  7 14:56:03.575: INFO: stdout: "e2e-test-crd-publish-openapi-6662-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Feb  7 14:56:03.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-3435 --namespace=crd-publish-openapi-3435 delete e2e-test-crd-publish-openapi-6662-crds test-cr'
  Feb  7 14:56:03.637: INFO: stderr: ""
  Feb  7 14:56:03.637: INFO: stdout: "e2e-test-crd-publish-openapi-6662-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 02/07/24 14:56:03.637
  Feb  7 14:56:03.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-3435 explain e2e-test-crd-publish-openapi-6662-crds'
  Feb  7 14:56:03.696: INFO: stderr: ""
  Feb  7 14:56:03.696: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-6662-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0207 14:56:03.969704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:04.929: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3435" for this suite. @ 02/07/24 14:56:04.936
• [4.871 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 02/07/24 14:56:04.941
  Feb  7 14:56:04.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:56:04.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:04.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:04.953
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:56:04.955
  E0207 14:56:04.969955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:05.970900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:06.971908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:07.972362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:56:08.968
  Feb  7 14:56:08.970: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-4f8d8547-e59b-40dd-8d35-29566e3e34c2 container client-container: <nil>
  E0207 14:56:08.973058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 02/07/24 14:56:08.984
  Feb  7 14:56:08.993: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2768" for this suite. @ 02/07/24 14:56:08.996
• [4.058 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 02/07/24 14:56:09
  Feb  7 14:56:09.000: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 14:56:09.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:09.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:09.014
  Feb  7 14:56:09.022: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0207 14:56:09.974139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:10.974345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:11.974560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:12.974948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:13.975035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:14.025: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/07/24 14:56:14.025
  Feb  7 14:56:14.025: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0207 14:56:14.975547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:15.975750      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:16.028: INFO: Creating deployment "test-rollover-deployment"
  Feb  7 14:56:16.033: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0207 14:56:16.975841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:17.976157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:18.038: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Feb  7 14:56:18.042: INFO: Ensure that both replica sets have 1 created replica
  Feb  7 14:56:18.046: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Feb  7 14:56:18.052: INFO: Updating deployment test-rollover-deployment
  Feb  7 14:56:18.052: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0207 14:56:18.976843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:19.977033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:20.056: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Feb  7 14:56:20.061: INFO: Make sure deployment "test-rollover-deployment" is complete
  Feb  7 14:56:20.065: INFO: all replica sets need to contain the pod-template-hash label
  Feb  7 14:56:20.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:56:20.977504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:21.977720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:22.071: INFO: all replica sets need to contain the pod-template-hash label
  Feb  7 14:56:22.071: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:56:22.978098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:23.978277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:24.071: INFO: all replica sets need to contain the pod-template-hash label
  Feb  7 14:56:24.071: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:56:24.978951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:25.979137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:26.070: INFO: all replica sets need to contain the pod-template-hash label
  Feb  7 14:56:26.070: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:56:26.979434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:27.979825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:28.070: INFO: all replica sets need to contain the pod-template-hash label
  Feb  7 14:56:28.070: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 56, 18, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 56, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:56:28.980583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:29.980798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:30.070: INFO: 
  Feb  7 14:56:30.070: INFO: Ensure that both old replica sets have no replicas
  Feb  7 14:56:30.076: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5402",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "58a6b1c9-cccd-4bd2-ab10-fcc748b637d8",
      ResourceVersion: (string) (len=5) "28635",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842914576,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914589,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914589,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5d484bf7f9\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 14:56:30.080: INFO: New ReplicaSet "test-rollover-deployment-5d484bf7f9" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5402",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "509f429b-5d8d-4e6c-890e-417133ee2cca",
      ResourceVersion: (string) (len=5) "28625",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842914578,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "58a6b1c9-cccd-4bd2-ab10-fcc748b637d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 38 61 36 62 31  63 39 2d 63 63 63 64 2d  |\"58a6b1c9-cccd-|
              00000120  34 62 64 32 2d 61 62 31  30 2d 66 63 63 37 34 38  |4bd2-ab10-fcc748|
              00000130  62 36 33 37 64 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b637d8\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:56:30.081: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Feb  7 14:56:30.081: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5402",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "64694c76-fecd-421b-ad4c-37823f2b70e7",
      ResourceVersion: (string) (len=5) "28634",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842914569,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "58a6b1c9-cccd-4bd2-ab10-fcc748b637d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914569,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914589,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  35 38 61 36 62 31 63 39  2d 63 63 63 64 2d 34 62  |58a6b1c9-cccd-4b|
              000000c0  64 32 2d 61 62 31 30 2d  66 63 63 37 34 38 62 36  |d2-ab10-fcc748b6|
              000000d0  33 37 64 38 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |37d8\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914589,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:56:30.083: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5402",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "47255bce-47e2-4887-b6ad-bf7850bb800c",
      ResourceVersion: (string) (len=5) "28587",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842914576,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "58a6b1c9-cccd-4bd2-ab10-fcc748b637d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 38 61 36 62 31  63 39 2d 63 63 63 64 2d  |\"58a6b1c9-cccd-|
              00000120  34 62 64 32 2d 61 62 31  30 2d 66 63 63 37 34 38  |4bd2-ab10-fcc748|
              00000130  62 36 33 37 64 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b637d8\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 14:56:30.086: INFO: Pod "test-rollover-deployment-5d484bf7f9-z2jsb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5d484bf7f9-z2jsb",
      GenerateName: (string) (len=36) "test-rollover-deployment-5d484bf7f9-",
      Namespace: (string) (len=15) "deployment-5402",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3e2b6493-9bf5-4cd3-97a2-cd6272796b94",
      ResourceVersion: (string) (len=5) "28602",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842914578,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
          UID: (types.UID) (len=36) "509f429b-5d8d-4e6c-890e-417133ee2cca",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 30  39 66 34 32 39 62 2d 35  |d\":\"509f429b-5|
              00000090  64 38 64 2d 34 65 36 63  2d 38 39 30 65 2d 34 31  |d8d-4e6c-890e-41|
              000000a0  37 31 33 33 65 65 32 63  63 61 5c 22 7d 22 3a 7b  |7133ee2cca\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  31 34 5c 22 7d 22 3a 7b  |.244.1.114\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nkjss",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nkjss",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842914578,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.114",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.114"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842914578,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842914578,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://f2de27ae32d37349ceac58a8ceaebf2f48c25070721a2fffbfb1d4b4bfc09a46",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 14:56:30.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5402" for this suite. @ 02/07/24 14:56:30.093
• [21.097 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 02/07/24 14:56:30.097
  Feb  7 14:56:30.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename security-context-test @ 02/07/24 14:56:30.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:30.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:30.108
  E0207 14:56:30.981880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:31.982066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:56:32.126: INFO: Got logs for pod "busybox-privileged-false-e9f44cb2-04b6-4f02-8e02-496ee9935c40": "ip: RTNETLINK answers: Operation not permitted\n"
  Feb  7 14:56:32.126: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6074" for this suite. @ 02/07/24 14:56:32.129
• [2.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 02/07/24 14:56:32.133
  Feb  7 14:56:32.133: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 14:56:32.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:32.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:32.145
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 14:56:32.148
  E0207 14:56:32.983033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:33.983160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:56:34.158
  Feb  7 14:56:34.160: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-28108abd-a40a-4656-a8d8-43ddd797a31a container client-container: <nil>
  STEP: delete the pod @ 02/07/24 14:56:34.165
  Feb  7 14:56:34.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4464" for this suite. @ 02/07/24 14:56:34.178
• [2.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 02/07/24 14:56:34.182
  Feb  7 14:56:34.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-watch @ 02/07/24 14:56:34.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:56:34.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:56:34.194
  Feb  7 14:56:34.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:56:34.983322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:35.983766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 02/07/24 14:56:36.727
  Feb  7 14:56:36.730: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-07T14:56:36Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-07T14:56:36Z]] name:name1 resourceVersion:28726 uid:2470ebc1-d079-4b2b-ab77-5a02090b3393] num:map[num1:9223372036854775807 num2:1000000]]}
  E0207 14:56:36.983816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:37.983972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:38.984168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:39.984365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:40.984604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:41.984872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:42.985177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:43.986118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:44.986316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:45.986540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 02/07/24 14:56:46.731
  Feb  7 14:56:46.735: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-07T14:56:46Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-07T14:56:46Z]] name:name2 resourceVersion:28765 uid:dee35057-d20c-4140-81be-370fd11b3f5b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0207 14:56:46.986798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:47.987047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:48.987238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:49.987411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:50.987539      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:51.987768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:52.988092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:53.988288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:54.988482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:55.988682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 02/07/24 14:56:56.735
  Feb  7 14:56:56.740: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-07T14:56:36Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-07T14:56:56Z]] name:name1 resourceVersion:28786 uid:2470ebc1-d079-4b2b-ab77-5a02090b3393] num:map[num1:9223372036854775807 num2:1000000]]}
  E0207 14:56:56.989118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:57.990104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:58.990318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:56:59.990511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:00.990722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:01.990935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:02.991322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:03.991536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:04.991639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:05.991757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 02/07/24 14:57:06.741
  Feb  7 14:57:06.747: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-07T14:56:46Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-07T14:57:06Z]] name:name2 resourceVersion:28807 uid:dee35057-d20c-4140-81be-370fd11b3f5b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0207 14:57:06.992173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:07.992554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:08.993156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:09.993357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:10.994102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:11.994293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:12.994657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:13.994792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:14.995121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:15.995344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 02/07/24 14:57:16.748
  Feb  7 14:57:16.753: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-07T14:56:36Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-07T14:56:56Z]] name:name1 resourceVersion:28828 uid:2470ebc1-d079-4b2b-ab77-5a02090b3393] num:map[num1:9223372036854775807 num2:1000000]]}
  E0207 14:57:16.995463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:17.995825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:18.996163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:19.996270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:20.996682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:21.996882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:22.997285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:23.997475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:24.997797      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:25.997988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 02/07/24 14:57:26.753
  Feb  7 14:57:26.758: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-02-07T14:56:46Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-02-07T14:57:06Z]] name:name2 resourceVersion:28850 uid:dee35057-d20c-4140-81be-370fd11b3f5b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0207 14:57:26.998109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:27.998558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:28.998773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:29.999003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:30.999207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:31.999392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:32.999801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:34.000002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:35.000315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:36.000494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:37.001405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:57:37.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-4767" for this suite. @ 02/07/24 14:57:37.271
• [63.093 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 02/07/24 14:57:37.275
  Feb  7 14:57:37.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/07/24 14:57:37.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:57:37.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:57:37.288
  STEP: create the container to handle the HTTPGet hook request. @ 02/07/24 14:57:37.293
  E0207 14:57:38.002171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:39.002280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/07/24 14:57:39.31
  E0207 14:57:40.002728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:41.002928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 02/07/24 14:57:41.321
  STEP: delete the pod with lifecycle hook @ 02/07/24 14:57:41.332
  E0207 14:57:42.003453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:43.003581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:57:43.341: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5161" for this suite. @ 02/07/24 14:57:43.344
• [6.072 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 02/07/24 14:57:43.348
  Feb  7 14:57:43.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replicaset @ 02/07/24 14:57:43.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:57:43.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:57:43.36
  STEP: Create a Replicaset @ 02/07/24 14:57:43.365
  STEP: Verify that the required pods have come up. @ 02/07/24 14:57:43.368
  Feb  7 14:57:43.371: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0207 14:57:44.004183      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:45.004502      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:46.005344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:47.005618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:48.006004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:57:48.375: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/07/24 14:57:48.375
  STEP: Getting /status @ 02/07/24 14:57:48.375
  Feb  7 14:57:48.377: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 02/07/24 14:57:48.378
  Feb  7 14:57:48.385: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 02/07/24 14:57:48.385
  Feb  7 14:57:48.387: INFO: Observed &ReplicaSet event: ADDED
  Feb  7 14:57:48.387: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.387: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.387: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.387: INFO: Found replicaset test-rs in namespace replicaset-528 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb  7 14:57:48.387: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 02/07/24 14:57:48.387
  Feb  7 14:57:48.387: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Feb  7 14:57:48.392: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 02/07/24 14:57:48.392
  Feb  7 14:57:48.393: INFO: Observed &ReplicaSet event: ADDED
  Feb  7 14:57:48.393: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.394: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.394: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.394: INFO: Observed replicaset test-rs in namespace replicaset-528 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 14:57:48.394: INFO: Observed &ReplicaSet event: MODIFIED
  Feb  7 14:57:48.394: INFO: Found replicaset test-rs in namespace replicaset-528 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Feb  7 14:57:48.394: INFO: Replicaset test-rs has a patched status
  Feb  7 14:57:48.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-528" for this suite. @ 02/07/24 14:57:48.398
• [5.054 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 02/07/24 14:57:48.402
  Feb  7 14:57:48.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubelet-test @ 02/07/24 14:57:48.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:57:48.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:57:48.42
  Feb  7 14:57:48.439: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-790" for this suite. @ 02/07/24 14:57:48.443
• [0.046 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 02/07/24 14:57:48.448
  Feb  7 14:57:48.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 14:57:48.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:57:48.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:57:48.46
  E0207 14:57:49.006145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:50.006241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 02/07/24 14:57:50.476
  Feb  7 14:57:50.476: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6687 pod-service-account-ad35a89c-9a2e-4b0f-bb9e-884b03b1ce79 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 02/07/24 14:57:50.591
  Feb  7 14:57:50.591: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6687 pod-service-account-ad35a89c-9a2e-4b0f-bb9e-884b03b1ce79 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 02/07/24 14:57:50.704
  Feb  7 14:57:50.704: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6687 pod-service-account-ad35a89c-9a2e-4b0f-bb9e-884b03b1ce79 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Feb  7 14:57:50.821: INFO: Got root ca configmap in namespace "svcaccounts-6687"
  Feb  7 14:57:50.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6687" for this suite. @ 02/07/24 14:57:50.826
• [2.381 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 02/07/24 14:57:50.83
  Feb  7 14:57:50.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 14:57:50.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:57:50.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:57:50.842
  STEP: creating the pod @ 02/07/24 14:57:50.845
  STEP: waiting for pod running @ 02/07/24 14:57:50.852
  E0207 14:57:51.006332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:52.006701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 02/07/24 14:57:52.857
  Feb  7 14:57:52.859: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7640 PodName:var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:57:52.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:57:52.859: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:57:52.859: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-7640/pods/var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 02/07/24 14:57:52.924
  Feb  7 14:57:52.926: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7640 PodName:var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 14:57:52.926: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 14:57:52.926: INFO: ExecWithOptions: Clientset creation
  Feb  7 14:57:52.926: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-7640/pods/var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 02/07/24 14:57:53.003
  E0207 14:57:53.007483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:57:53.515: INFO: Successfully updated pod "var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08"
  STEP: waiting for annotated pod running @ 02/07/24 14:57:53.515
  STEP: deleting the pod gracefully @ 02/07/24 14:57:53.517
  Feb  7 14:57:53.517: INFO: Deleting pod "var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08" in namespace "var-expansion-7640"
  Feb  7 14:57:53.523: INFO: Wait up to 5m0s for pod "var-expansion-67afa29b-d4d6-499f-8a61-637ee0d10b08" to be fully deleted
  E0207 14:57:54.007577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:55.007775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:56.007944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:57.008286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:58.009033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:57:59.009038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:00.010129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:01.010311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:02.011322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:03.011680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:04.011772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:05.011879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:06.012399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:07.012762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:08.013400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:09.013608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:10.014632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:11.014719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:12.015280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:13.015668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:14.016305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:15.016483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:16.017152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:17.017335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:18.018018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:19.018196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:20.019058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:21.019237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:22.019349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:23.019423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:24.019905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:25.019997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:25.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7640" for this suite. @ 02/07/24 14:58:25.574
• [34.748 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 02/07/24 14:58:25.578
  Feb  7 14:58:25.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 14:58:25.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:58:25.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:58:25.592
  STEP: Setting up server cert @ 02/07/24 14:58:25.606
  E0207 14:58:26.020846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 14:58:26.169
  STEP: Deploying the webhook pod @ 02/07/24 14:58:26.176
  STEP: Wait for the deployment to be ready @ 02/07/24 14:58:26.184
  Feb  7 14:58:26.189: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0207 14:58:27.021770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:28.022166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:28.196: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:58:29.022778      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:30.022979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:30.200: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:58:31.023887      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:32.024076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:32.200: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:58:33.025037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:34.025032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:34.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:58:35.026130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:36.026316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:36.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 14, 58, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 14:58:37.026585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:38.027065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 14:58:38.2
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 14:58:38.209
  E0207 14:58:39.027503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:39.209: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 02/07/24 14:58:39.258
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/07/24 14:58:39.294
  STEP: Deleting the collection of validation webhooks @ 02/07/24 14:58:39.327
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 02/07/24 14:58:39.352
  Feb  7 14:58:39.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4238" for this suite. @ 02/07/24 14:58:39.389
  STEP: Destroying namespace "webhook-markers-3480" for this suite. @ 02/07/24 14:58:39.394
• [13.820 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 02/07/24 14:58:39.399
  Feb  7 14:58:39.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 14:58:39.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:58:39.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:58:39.414
  STEP: create the deployment @ 02/07/24 14:58:39.417
  W0207 14:58:39.420803      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 02/07/24 14:58:39.42
  STEP: delete the deployment @ 02/07/24 14:58:39.925
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 02/07/24 14:58:39.93
  E0207 14:58:40.028443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/07/24 14:58:40.44
  W0207 14:58:40.443467      23 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb  7 14:58:40.443: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb  7 14:58:40.443: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3783" for this suite. @ 02/07/24 14:58:40.445
• [1.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 02/07/24 14:58:40.451
  Feb  7 14:58:40.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 14:58:40.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:58:40.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:58:40.462
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 02/07/24 14:58:40.464
  Feb  7 14:58:40.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:58:41.029283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:41.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 14:58:42.030376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:43.031332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:44.031948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:45.032404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:46.033390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:46.815: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5686" for this suite. @ 02/07/24 14:58:46.822
• [6.376 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 02/07/24 14:58:46.827
  Feb  7 14:58:46.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:58:46.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:58:46.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:58:46.839
  STEP: Counting existing ResourceQuota @ 02/07/24 14:58:46.842
  E0207 14:58:47.034443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:48.034984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:49.035467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:50.036178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:51.037260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 14:58:51.845
  STEP: Ensuring resource quota status is calculated @ 02/07/24 14:58:51.849
  E0207 14:58:52.037452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:53.037809      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:58:53.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1783" for this suite. @ 02/07/24 14:58:53.854
• [7.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 02/07/24 14:58:53.86
  Feb  7 14:58:53.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 14:58:53.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:58:53.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:58:53.872
  STEP: Counting existing ResourceQuota @ 02/07/24 14:58:53.874
  E0207 14:58:54.037980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:55.038822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:56.039497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:57.040159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:58:58.040960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 14:58:58.878
  STEP: Ensuring resource quota status is calculated @ 02/07/24 14:58:58.883
  E0207 14:58:59.041407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:00.042383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 02/07/24 14:59:00.886
  STEP: Ensuring ResourceQuota status captures the pod usage @ 02/07/24 14:59:00.897
  E0207 14:59:01.042814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:02.042949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 02/07/24 14:59:02.9
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 02/07/24 14:59:02.902
  STEP: Ensuring a pod cannot update its resource requirements @ 02/07/24 14:59:02.904
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 02/07/24 14:59:02.907
  E0207 14:59:03.043920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:04.044020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/07/24 14:59:04.91
  STEP: Ensuring resource quota status released the pod usage @ 02/07/24 14:59:04.919
  E0207 14:59:05.044143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:06.044351      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:59:06.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5951" for this suite. @ 02/07/24 14:59:06.924
• [13.068 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 02/07/24 14:59:06.929
  Feb  7 14:59:06.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replicaset @ 02/07/24 14:59:06.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:59:06.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:59:06.94
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 02/07/24 14:59:06.943
  E0207 14:59:07.045459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:08.045849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 02/07/24 14:59:08.955
  STEP: Then the orphan pod is adopted @ 02/07/24 14:59:08.959
  E0207 14:59:09.046613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 02/07/24 14:59:09.964
  Feb  7 14:59:09.966: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 02/07/24 14:59:09.974
  E0207 14:59:10.047498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:59:10.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-493" for this suite. @ 02/07/24 14:59:10.982
• [4.058 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 02/07/24 14:59:10.987
  Feb  7 14:59:10.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 14:59:10.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:59:10.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:59:10.999
  STEP: Creating the pod @ 02/07/24 14:59:11.002
  E0207 14:59:11.048370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:12.048575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:13.049524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:59:13.536: INFO: Successfully updated pod "annotationupdateb46f00d6-edeb-4bc6-88e9-f950710cf0c4"
  E0207 14:59:14.050572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:15.050764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:16.050892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:17.051935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:59:17.554: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3383" for this suite. @ 02/07/24 14:59:17.557
• [6.574 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 02/07/24 14:59:17.561
  Feb  7 14:59:17.561: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replication-controller @ 02/07/24 14:59:17.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:59:17.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:59:17.576
  STEP: Creating ReplicationController "e2e-rc-mjd4d" @ 02/07/24 14:59:17.578
  Feb  7 14:59:17.583: INFO: Get Replication Controller "e2e-rc-mjd4d" to confirm replicas
  E0207 14:59:18.052041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:59:18.583: INFO: Get Replication Controller "e2e-rc-mjd4d" to confirm replicas
  Feb  7 14:59:18.586: INFO: Found 1 replicas for "e2e-rc-mjd4d" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-mjd4d" @ 02/07/24 14:59:18.586
  STEP: Updating a scale subresource @ 02/07/24 14:59:18.588
  STEP: Verifying replicas where modified for replication controller "e2e-rc-mjd4d" @ 02/07/24 14:59:18.591
  Feb  7 14:59:18.591: INFO: Get Replication Controller "e2e-rc-mjd4d" to confirm replicas
  E0207 14:59:19.052820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 14:59:19.592: INFO: Get Replication Controller "e2e-rc-mjd4d" to confirm replicas
  Feb  7 14:59:19.595: INFO: Found 2 replicas for "e2e-rc-mjd4d" replication controller
  Feb  7 14:59:19.595: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6024" for this suite. @ 02/07/24 14:59:19.597
• [2.040 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 02/07/24 14:59:19.601
  Feb  7 14:59:19.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 14:59:19.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:59:19.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:59:19.612
  STEP: Creating configMap configmap-5574/configmap-test-37cd6fc2-93a8-4d01-bd07-90c9b11f6a32 @ 02/07/24 14:59:19.614
  STEP: Creating a pod to test consume configMaps @ 02/07/24 14:59:19.617
  E0207 14:59:20.052974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:21.053229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 14:59:21.627
  Feb  7 14:59:21.629: INFO: Trying to get logs from node worker-0 pod pod-configmaps-165bb961-07bb-43ec-abbb-ade43d0934ca container env-test: <nil>
  STEP: delete the pod @ 02/07/24 14:59:21.644
  Feb  7 14:59:21.652: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5574" for this suite. @ 02/07/24 14:59:21.654
• [2.058 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 02/07/24 14:59:21.66
  Feb  7 14:59:21.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-pred @ 02/07/24 14:59:21.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 14:59:21.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 14:59:21.671
  Feb  7 14:59:21.674: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb  7 14:59:21.679: INFO: Waiting for terminating namespaces to be deleted...
  Feb  7 14:59:21.681: INFO: 
  Logging pods the apiserver thinks is on node worker-0 before test
  Feb  7 14:59:21.686: INFO: coredns-555d98c87b-tdvsz from kube-system started at 2024-02-07 14:03:53 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: konnectivity-agent-x99jt from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: kube-proxy-l28q5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: kube-router-wfgm8 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: e2e-rc-mjd4d-txl2w from replication-controller-6024 started at 2024-02-07 14:59:17 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container httpd ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: sonobuoy from sonobuoy started at 2024-02-07 13:37:03 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-2wkv5 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 14:59:21.686: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb  7 14:59:21.686: INFO: 
  Logging pods the apiserver thinks is on node worker-1 before test
  Feb  7 14:59:21.690: INFO: annotationupdateb46f00d6-edeb-4bc6-88e9-f950710cf0c4 from downward-api-3383 started at 2024-02-07 14:59:11 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container client-container ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: coredns-555d98c87b-f8t6j from kube-system started at 2024-02-07 13:37:51 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: konnectivity-agent-bt2h5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: kube-proxy-qvgjm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: kube-router-mqgnm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: metrics-server-7556957bb7-6kv5t from kube-system started at 2024-02-07 13:36:50 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container metrics-server ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: e2e-rc-mjd4d-lgqlj from replication-controller-6024 started at 2024-02-07 14:59:18 +0000 UTC (1 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container httpd ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: sonobuoy-e2e-job-fedf139ced3a4f30 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container e2e ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-rq8vf from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 14:59:21.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 14:59:21.690: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 02/07/24 14:59:21.69
  E0207 14:59:22.053334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:23.053730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 02/07/24 14:59:23.703
  STEP: Trying to apply a random label on the found node. @ 02/07/24 14:59:23.715
  STEP: verifying the node has the label kubernetes.io/e2e-87d04226-36db-4005-be8a-4f58571183d4 95 @ 02/07/24 14:59:23.722
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 02/07/24 14:59:23.724
  E0207 14:59:24.054586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:25.054791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.0.60.182 on the node which pod4 resides and expect not scheduled @ 02/07/24 14:59:25.732
  E0207 14:59:26.054922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:27.055247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:28.055995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:29.056113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:30.056713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:31.056814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:32.057590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:33.057949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:34.058597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:35.058953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:36.059043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:37.059352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:38.060076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:39.060204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:40.061151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:41.061343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:42.061405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:43.062128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:44.062202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:45.062325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:46.062753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:47.063141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:48.063171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:49.063288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:50.063832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:51.064078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:52.065053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:53.065413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:54.066167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:55.066356      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:56.066690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:57.067023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:58.067949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 14:59:59.068140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:00.068819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:01.069050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:02.069111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:03.070115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:04.070683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:05.070912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:06.070944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:07.071231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:08.072198      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:09.072400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:10.072538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:11.072724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:12.072837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:13.073049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:14.073665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:15.073773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:16.073894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:17.074338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:18.075299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:19.075519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:20.075725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:21.075849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:22.075932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:23.076296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:24.076868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:25.077093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:26.077820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:27.078241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:28.079119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:29.079314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:30.079428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:31.079649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:32.080028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:33.080422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:34.081488      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:35.082116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:36.082573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:37.083039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:38.083142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:39.083462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:40.084082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:41.084346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:42.084442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:43.085035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:44.085638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:45.085817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:46.085934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:47.086366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:48.087101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:49.087291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:50.087905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:51.088081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:52.089121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:53.089457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:54.090063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:55.090238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:56.090777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:57.091103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:58.091995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:00:59.092177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:00.092408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:01.092590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:02.093654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:03.093998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:04.094407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:05.094714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:06.095057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:07.095296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:08.096075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:09.096257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:10.096691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:11.096876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:12.097014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:13.097468      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:14.098049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:15.098222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:16.098427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:17.098777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:18.099297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:19.099500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:20.100003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:21.100203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:22.101277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:23.101606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:24.102100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:25.102273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:26.102741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:27.103050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:28.103923      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:29.104132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:30.104517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:31.104836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:32.105806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:33.105929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:34.106524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:35.106700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:36.106847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:37.107188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:38.108016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:39.108193      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:40.108771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:41.108980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:42.109944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:43.110276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:44.110885      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:45.111057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:46.111495      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:47.111564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:48.112386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:49.112753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:50.113162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:51.113349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:52.114259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:53.114618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:54.114728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:55.114898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:56.115021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:57.115784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:58.116671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:01:59.116784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:00.117159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:01.117341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:02.117516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:03.117859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:04.118401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:05.118599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:06.118901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:07.119949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:08.120615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:09.120733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:10.121148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:11.121334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:12.122121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:13.122648      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:14.123144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:15.123322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:16.123799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:17.124116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:18.125049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:19.125227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:20.126118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:21.126305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:22.126406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:23.126720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:24.126757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:25.126864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:26.127596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:27.127752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:28.128544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:29.128720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:30.129129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:31.129329      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:32.130380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:33.130707      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:34.131572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:35.131751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:36.132015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:37.132386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:38.133330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:39.133436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:40.134292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:41.134419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:42.135406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:43.135739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:44.136160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:45.136346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:46.137349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:47.137679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:48.138361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:49.138468      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:50.138823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:51.139016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:52.140029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:53.140369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:54.141324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:55.141512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:56.142415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:57.142620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:58.143383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:02:59.144232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:00.144794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:01.145017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:02.146054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:03.146379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:04.146953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:05.147132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:06.147418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:07.147530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:08.148488      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:09.148663      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:10.148905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:11.149123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:12.149734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:13.149851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:14.150326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:15.150505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:16.150599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:17.150648      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:18.151335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:19.151510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:20.151827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:21.152016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:22.152937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:23.153066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:24.153525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:25.153710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:26.154000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:27.154249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:28.154957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:29.155067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:30.155531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:31.155702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:32.156714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:33.157032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:34.157342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:35.157520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:36.157755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:37.158112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:38.158837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:39.159559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:40.160058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:41.160178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:42.160976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:43.161046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:44.161547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:45.161884      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:46.162077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:47.162354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:48.162634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:49.162843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:50.162907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:51.163024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:52.163957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:53.164116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:54.164561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:55.164689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:56.165119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:57.165372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:58.165647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:03:59.165772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:00.165963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:01.166075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:02.167124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:03.167260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:04.167862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:05.168052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:06.168461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:07.168857      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:08.169790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:09.169988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:10.170360      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:11.170699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:12.170777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:13.171108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:14.171447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:15.171592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:16.172159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:17.172457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:18.172855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:19.173037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:20.173781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:21.173951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:22.174001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:23.174302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:24.175205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:25.175380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-87d04226-36db-4005-be8a-4f58571183d4 off the node worker-0 @ 02/07/24 15:04:25.738
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-87d04226-36db-4005-be8a-4f58571183d4 @ 02/07/24 15:04:25.747
  Feb  7 15:04:25.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-133" for this suite. @ 02/07/24 15:04:25.751
• [304.096 seconds]
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 02/07/24 15:04:25.756
  Feb  7 15:04:25.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 15:04:25.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:04:25.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:04:25.769
  STEP: Creating pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966 @ 02/07/24 15:04:25.772
  E0207 15:04:26.176007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:27.176289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 02/07/24 15:04:27.782
  Feb  7 15:04:27.784: INFO: Initial restart count of pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 is 0
  Feb  7 15:04:27.786: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:28.176620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:29.176819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:29.788: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:30.177024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:31.177052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:31.791: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:32.177446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:33.177970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:33.793: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:34.178386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:35.178611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:35.796: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:36.178845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:37.179200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:37.799: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:38.179911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:39.180098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:39.801: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:40.181174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:41.181378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:41.804: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:42.181485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:43.182112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:43.806: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:44.182310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:45.182511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:45.809: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:46.182721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:47.183197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:47.812: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:48.183451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:49.183557      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:49.816: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:50.183704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:51.183821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:51.818: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:52.184227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:53.184348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:53.821: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:54.185147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:55.185331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:55.824: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:56.185463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:57.185590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:57.826: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:04:58.186500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:04:59.186679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:04:59.829: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:00.186858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:01.186988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:01.832: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:02.187960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:03.188283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:03.835: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:04.189221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:05.189401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:05.838: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:06.189744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:07.190073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:07.840: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:08.190282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:09.190475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:09.843: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:10.190929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:11.191126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:11.846: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:12.191855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:13.192147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:13.849: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:14.193144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:15.194109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:15.852: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:16.194578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:17.194931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:17.855: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:18.195699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:19.195886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:19.858: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:20.196516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:21.196709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:21.860: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:22.197319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:23.197637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:23.863: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:24.198415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:25.198621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:25.866: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:26.199050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:27.199186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:27.869: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:28.200024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:29.200208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:29.872: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:30.200666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:31.200848      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:31.874: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:32.200989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:33.201345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:33.877: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:34.202363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:35.202555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:35.880: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:36.203169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:37.203410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:37.883: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:38.203956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:39.204074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:39.886: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:40.204583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:41.204764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:41.889: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:42.205553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:43.205661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:43.892: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:44.206548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:45.206736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:45.894: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:46.207321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:47.207622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:47.897: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:48.207878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:49.208068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:49.900: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:50.208676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:51.208794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:51.903: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:52.209587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:53.209927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:53.906: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:54.210039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:55.210224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:55.909: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:56.210747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:57.211018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:57.912: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:05:58.211241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:05:59.211381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:05:59.914: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:00.212157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:01.212342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:01.917: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:02.213136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:03.213237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:03.920: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:04.214137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:05.214322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:05.923: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:06.214764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:07.215124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:07.926: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:08.216155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:09.216368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:09.929: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:10.216832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:11.217029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:11.932: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:12.217751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:13.218077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:13.935: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:14.218673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:15.219014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:15.938: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:16.219735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:17.219847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:17.941: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:18.220650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:19.220822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:19.944: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:20.221489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:21.222108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:21.947: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:22.222709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:23.223044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:23.950: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:24.223742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:25.223917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:25.953: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:26.224595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:27.224937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:27.956: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:28.225837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:29.225961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:29.959: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:30.226614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:31.226784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:31.962: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:32.227648      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:33.227771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:33.965: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:34.228514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:35.228689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:35.968: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:36.229640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:37.229975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:37.971: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:38.230648      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:39.230770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:39.974: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:40.231372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:41.231489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:41.977: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:42.232333      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:43.232820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:43.980: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:44.233547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:45.234105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:45.983: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:46.234589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:47.234897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:47.985: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:48.235098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:49.235279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:49.988: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:50.235830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:51.236012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:51.991: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:52.236847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:53.237041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:53.994: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:54.238103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:55.238270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:55.997: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:56.238761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:57.239238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:06:58.000: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:06:58.239998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:06:59.240171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:00.003: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:00.240340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:01.240513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:02.005: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:02.241270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:03.241622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:04.008: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:04.242113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:05.242253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:06.011: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:06.242462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:07.242582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:08.014: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:08.243494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:09.243704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:10.016: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:10.244092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:11.244278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:12.019: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:12.245124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:13.245224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:14.022: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:14.245952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:15.246069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:16.026: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:16.246181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:17.246571      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:18.029: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:18.247181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:19.247356      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:20.031: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:20.247705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:21.247879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:22.033: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:22.248267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:23.248601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:24.036: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:24.248689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:25.248866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:26.039: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:26.249031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:27.249308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:28.041: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:28.250009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:29.250185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:30.044: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:30.250573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:31.250771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:32.047: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:32.251533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:33.251710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:34.050: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:34.252397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:35.252504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:36.052: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:36.252999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:37.253464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:38.055: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:38.253596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:39.253790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:40.058: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:40.254272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:41.254469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:42.060: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:42.255249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:43.255419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:44.063: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:44.256194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:45.256379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:46.066: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:46.256755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:47.257129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:48.069: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:48.257957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:49.258134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:50.072: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:50.258934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:51.259109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:52.075: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:52.260090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:53.260265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:54.079: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:54.260381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:55.260562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:56.081: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:56.261139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:57.261541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:07:58.085: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:07:58.262337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:07:59.262538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:00.088: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:00.263294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:01.263477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:02.091: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:02.264291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:03.264479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:04.094: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:04.265475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:05.265669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:06.097: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:06.266384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:07.267334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:08.100: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:08.267932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:09.268110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:10.103: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:10.268722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:11.268907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:12.106: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:12.269894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:13.270073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:14.110: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:14.270524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:15.270705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:16.113: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:16.271456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:17.272358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:18.116: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:18.273210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:19.273389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:20.118: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:20.273902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:21.274077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:22.121: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:22.274825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:23.275731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:24.124: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:24.276591      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:25.276779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:26.127: INFO: Get pod liveness-f0885097-c02f-419b-8652-3b17910f13f8 in namespace container-probe-5966
  E0207 15:08:26.276906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:27.277415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 02/07/24 15:08:28.128
  Feb  7 15:08:28.137: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5966" for this suite. @ 02/07/24 15:08:28.14
• [242.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 02/07/24 15:08:28.145
  Feb  7 15:08:28.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 15:08:28.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:08:28.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:08:28.157
  Feb  7 15:08:28.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 15:08:28.278379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:29.279329      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:30.279514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:31.219: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8297" for this suite. @ 02/07/24 15:08:31.221
• [3.079 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 02/07/24 15:08:31.225
  Feb  7 15:08:31.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename proxy @ 02/07/24 15:08:31.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:08:31.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:08:31.238
  STEP: starting an echo server on multiple ports @ 02/07/24 15:08:31.249
  STEP: creating replication controller proxy-service-nl7cc in namespace proxy-3470 @ 02/07/24 15:08:31.249
  I0207 15:08:31.257090      23 runners.go:197] Created replication controller with name: proxy-service-nl7cc, namespace: proxy-3470, replica count: 1
  E0207 15:08:31.280318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:32.281125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 15:08:32.308381      23 runners.go:197] proxy-service-nl7cc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0207 15:08:33.282151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 15:08:33.309412      23 runners.go:197] proxy-service-nl7cc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 15:08:33.311: INFO: setup took 2.070974536s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 02/07/24 15:08:33.311
  Feb  7 15:08:33.319: INFO: (0) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 8.005381ms)
  Feb  7 15:08:33.321: INFO: (0) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 9.992084ms)
  Feb  7 15:08:33.323: INFO: (0) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 11.467776ms)
  Feb  7 15:08:33.324: INFO: (0) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 12.366631ms)
  Feb  7 15:08:33.325: INFO: (0) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 13.258474ms)
  Feb  7 15:08:33.325: INFO: (0) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 13.574343ms)
  Feb  7 15:08:33.326: INFO: (0) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 14.617877ms)
  Feb  7 15:08:33.326: INFO: (0) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 14.79411ms)
  Feb  7 15:08:33.327: INFO: (0) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 15.888677ms)
  Feb  7 15:08:33.329: INFO: (0) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 18.093903ms)
  Feb  7 15:08:33.330: INFO: (0) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 18.08753ms)
  Feb  7 15:08:33.334: INFO: (0) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 22.749924ms)
  Feb  7 15:08:33.334: INFO: (0) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 22.964377ms)
  Feb  7 15:08:33.334: INFO: (0) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 23.36683ms)
  Feb  7 15:08:33.334: INFO: (0) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 23.170644ms)
  Feb  7 15:08:33.339: INFO: (0) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 27.428029ms)
  Feb  7 15:08:33.346: INFO: (1) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 7.663241ms)
  Feb  7 15:08:33.347: INFO: (1) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 7.783556ms)
  Feb  7 15:08:33.347: INFO: (1) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 8.587576ms)
  Feb  7 15:08:33.347: INFO: (1) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 8.258757ms)
  Feb  7 15:08:33.347: INFO: (1) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 8.383377ms)
  Feb  7 15:08:33.348: INFO: (1) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 9.067673ms)
  Feb  7 15:08:33.348: INFO: (1) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 8.905904ms)
  Feb  7 15:08:33.348: INFO: (1) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 8.950846ms)
  Feb  7 15:08:33.349: INFO: (1) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 9.718435ms)
  Feb  7 15:08:33.349: INFO: (1) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 9.711321ms)
  Feb  7 15:08:33.349: INFO: (1) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 10.048822ms)
  Feb  7 15:08:33.350: INFO: (1) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 10.643136ms)
  Feb  7 15:08:33.351: INFO: (1) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 12.404451ms)
  Feb  7 15:08:33.352: INFO: (1) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 12.494856ms)
  Feb  7 15:08:33.352: INFO: (1) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 12.460358ms)
  Feb  7 15:08:33.352: INFO: (1) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 12.443719ms)
  Feb  7 15:08:33.358: INFO: (2) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 6.391605ms)
  Feb  7 15:08:33.359: INFO: (2) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 6.690196ms)
  Feb  7 15:08:33.359: INFO: (2) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 7.671312ms)
  Feb  7 15:08:33.362: INFO: (2) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 10.091392ms)
  Feb  7 15:08:33.362: INFO: (2) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 10.005333ms)
  Feb  7 15:08:33.362: INFO: (2) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 9.513331ms)
  Feb  7 15:08:33.362: INFO: (2) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 9.656397ms)
  Feb  7 15:08:33.364: INFO: (2) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 10.62379ms)
  Feb  7 15:08:33.364: INFO: (2) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 10.522533ms)
  Feb  7 15:08:33.364: INFO: (2) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 10.837255ms)
  Feb  7 15:08:33.364: INFO: (2) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 10.672827ms)
  Feb  7 15:08:33.365: INFO: (2) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 12.20108ms)
  Feb  7 15:08:33.365: INFO: (2) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 11.223885ms)
  Feb  7 15:08:33.365: INFO: (2) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 12.242283ms)
  Feb  7 15:08:33.365: INFO: (2) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 12.556333ms)
  Feb  7 15:08:33.365: INFO: (2) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 12.892229ms)
  Feb  7 15:08:33.370: INFO: (3) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 4.191931ms)
  Feb  7 15:08:33.371: INFO: (3) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 4.971951ms)
  Feb  7 15:08:33.372: INFO: (3) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 6.192389ms)
  Feb  7 15:08:33.373: INFO: (3) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 6.794212ms)
  Feb  7 15:08:33.373: INFO: (3) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 7.12956ms)
  Feb  7 15:08:33.375: INFO: (3) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 9.237712ms)
  Feb  7 15:08:33.376: INFO: (3) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 9.654417ms)
  Feb  7 15:08:33.376: INFO: (3) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 9.546347ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 10.381516ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 10.20695ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 10.289957ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 10.195734ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 10.86533ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 10.355481ms)
  Feb  7 15:08:33.377: INFO: (3) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 10.578739ms)
  Feb  7 15:08:33.378: INFO: (3) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 11.391615ms)
  Feb  7 15:08:33.381: INFO: (4) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 3.396563ms)
  Feb  7 15:08:33.383: INFO: (4) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 5.395183ms)
  Feb  7 15:08:33.384: INFO: (4) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 5.571815ms)
  Feb  7 15:08:33.384: INFO: (4) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 6.06965ms)
  Feb  7 15:08:33.385: INFO: (4) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 6.592241ms)
  Feb  7 15:08:33.387: INFO: (4) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 8.449472ms)
  Feb  7 15:08:33.388: INFO: (4) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 9.206199ms)
  Feb  7 15:08:33.388: INFO: (4) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 9.749416ms)
  Feb  7 15:08:33.388: INFO: (4) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 9.930462ms)
  Feb  7 15:08:33.388: INFO: (4) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 9.773762ms)
  Feb  7 15:08:33.388: INFO: (4) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 9.923848ms)
  Feb  7 15:08:33.388: INFO: (4) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 10.070257ms)
  Feb  7 15:08:33.389: INFO: (4) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 10.704147ms)
  Feb  7 15:08:33.389: INFO: (4) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 10.923263ms)
  Feb  7 15:08:33.390: INFO: (4) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 11.498346ms)
  Feb  7 15:08:33.390: INFO: (4) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 11.320733ms)
  Feb  7 15:08:33.394: INFO: (5) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 4.449309ms)
  Feb  7 15:08:33.397: INFO: (5) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 6.47641ms)
  Feb  7 15:08:33.398: INFO: (5) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 8.007988ms)
  Feb  7 15:08:33.399: INFO: (5) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 8.506928ms)
  Feb  7 15:08:33.400: INFO: (5) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 10.253596ms)
  Feb  7 15:08:33.403: INFO: (5) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 13.311955ms)
  Feb  7 15:08:33.403: INFO: (5) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 13.602512ms)
  Feb  7 15:08:33.405: INFO: (5) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 15.238182ms)
  Feb  7 15:08:33.405: INFO: (5) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 15.381999ms)
  Feb  7 15:08:33.406: INFO: (5) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 16.250869ms)
  Feb  7 15:08:33.406: INFO: (5) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 16.326743ms)
  Feb  7 15:08:33.406: INFO: (5) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 16.235144ms)
  Feb  7 15:08:33.407: INFO: (5) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 16.58367ms)
  Feb  7 15:08:33.407: INFO: (5) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 17.01627ms)
  Feb  7 15:08:33.408: INFO: (5) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 17.609236ms)
  Feb  7 15:08:33.408: INFO: (5) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 18.142454ms)
  Feb  7 15:08:33.421: INFO: (6) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 12.969405ms)
  Feb  7 15:08:33.422: INFO: (6) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 13.729466ms)
  Feb  7 15:08:33.423: INFO: (6) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 14.399319ms)
  Feb  7 15:08:33.423: INFO: (6) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 14.848962ms)
  Feb  7 15:08:33.424: INFO: (6) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 15.747388ms)
  Feb  7 15:08:33.424: INFO: (6) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 15.880675ms)
  Feb  7 15:08:33.424: INFO: (6) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 16.274137ms)
  Feb  7 15:08:33.425: INFO: (6) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 16.179758ms)
  Feb  7 15:08:33.425: INFO: (6) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 16.423639ms)
  Feb  7 15:08:33.425: INFO: (6) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 16.027934ms)
  Feb  7 15:08:33.425: INFO: (6) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 16.390541ms)
  Feb  7 15:08:33.425: INFO: (6) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 16.245118ms)
  Feb  7 15:08:33.425: INFO: (6) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 16.911172ms)
  Feb  7 15:08:33.426: INFO: (6) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 17.77479ms)
  Feb  7 15:08:33.427: INFO: (6) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 18.842006ms)
  Feb  7 15:08:33.427: INFO: (6) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 18.894714ms)
  Feb  7 15:08:33.436: INFO: (7) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 8.8283ms)
  Feb  7 15:08:33.438: INFO: (7) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 10.691952ms)
  Feb  7 15:08:33.438: INFO: (7) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 10.693166ms)
  Feb  7 15:08:33.438: INFO: (7) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 10.791684ms)
  Feb  7 15:08:33.439: INFO: (7) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 11.547927ms)
  Feb  7 15:08:33.439: INFO: (7) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 11.563384ms)
  Feb  7 15:08:33.439: INFO: (7) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 11.781154ms)
  Feb  7 15:08:33.440: INFO: (7) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 12.651263ms)
  Feb  7 15:08:33.442: INFO: (7) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 14.61167ms)
  Feb  7 15:08:33.442: INFO: (7) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 14.889683ms)
  Feb  7 15:08:33.443: INFO: (7) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 15.048171ms)
  Feb  7 15:08:33.444: INFO: (7) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 16.1621ms)
  Feb  7 15:08:33.444: INFO: (7) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 16.03543ms)
  Feb  7 15:08:33.444: INFO: (7) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 16.07216ms)
  Feb  7 15:08:33.445: INFO: (7) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 17.551663ms)
  Feb  7 15:08:33.445: INFO: (7) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 17.883069ms)
  Feb  7 15:08:33.449: INFO: (8) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 4.049491ms)
  Feb  7 15:08:33.451: INFO: (8) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 5.577534ms)
  Feb  7 15:08:33.454: INFO: (8) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 8.673955ms)
  Feb  7 15:08:33.454: INFO: (8) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 8.680718ms)
  Feb  7 15:08:33.454: INFO: (8) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 9.107572ms)
  Feb  7 15:08:33.458: INFO: (8) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 12.934832ms)
  Feb  7 15:08:33.458: INFO: (8) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 12.977692ms)
  Feb  7 15:08:33.459: INFO: (8) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 13.422116ms)
  Feb  7 15:08:33.459: INFO: (8) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 13.520952ms)
  Feb  7 15:08:33.459: INFO: (8) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 13.508059ms)
  Feb  7 15:08:33.460: INFO: (8) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 14.882026ms)
  Feb  7 15:08:33.460: INFO: (8) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 14.72368ms)
  Feb  7 15:08:33.461: INFO: (8) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 15.638861ms)
  Feb  7 15:08:33.461: INFO: (8) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 15.735513ms)
  Feb  7 15:08:33.461: INFO: (8) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 15.740568ms)
  Feb  7 15:08:33.461: INFO: (8) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 15.775548ms)
  Feb  7 15:08:33.467: INFO: (9) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 5.245149ms)
  Feb  7 15:08:33.471: INFO: (9) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 9.308067ms)
  Feb  7 15:08:33.473: INFO: (9) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.013411ms)
  Feb  7 15:08:33.473: INFO: (9) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 11.070074ms)
  Feb  7 15:08:33.476: INFO: (9) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 14.643417ms)
  Feb  7 15:08:33.476: INFO: (9) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 14.82882ms)
  Feb  7 15:08:33.476: INFO: (9) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 14.985225ms)
  Feb  7 15:08:33.477: INFO: (9) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 14.859392ms)
  Feb  7 15:08:33.477: INFO: (9) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 15.764619ms)
  Feb  7 15:08:33.477: INFO: (9) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 15.746291ms)
  Feb  7 15:08:33.478: INFO: (9) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 15.79543ms)
  Feb  7 15:08:33.478: INFO: (9) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 16.204715ms)
  Feb  7 15:08:33.478: INFO: (9) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 16.463697ms)
  Feb  7 15:08:33.478: INFO: (9) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 16.723147ms)
  Feb  7 15:08:33.479: INFO: (9) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 16.894671ms)
  Feb  7 15:08:33.479: INFO: (9) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 17.037159ms)
  Feb  7 15:08:33.485: INFO: (10) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 6.199128ms)
  Feb  7 15:08:33.485: INFO: (10) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 6.494563ms)
  Feb  7 15:08:33.486: INFO: (10) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 7.297398ms)
  Feb  7 15:08:33.489: INFO: (10) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 9.59942ms)
  Feb  7 15:08:33.490: INFO: (10) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 11.222028ms)
  Feb  7 15:08:33.490: INFO: (10) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 11.20572ms)
  Feb  7 15:08:33.493: INFO: (10) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 13.179075ms)
  Feb  7 15:08:33.493: INFO: (10) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 13.955548ms)
  Feb  7 15:08:33.494: INFO: (10) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 14.781041ms)
  Feb  7 15:08:33.494: INFO: (10) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 15.239498ms)
  Feb  7 15:08:33.494: INFO: (10) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 15.295282ms)
  Feb  7 15:08:33.495: INFO: (10) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 15.368577ms)
  Feb  7 15:08:33.495: INFO: (10) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 15.293684ms)
  Feb  7 15:08:33.495: INFO: (10) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 15.770515ms)
  Feb  7 15:08:33.495: INFO: (10) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 16.213833ms)
  Feb  7 15:08:33.495: INFO: (10) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 16.204058ms)
  Feb  7 15:08:33.502: INFO: (11) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 6.01765ms)
  Feb  7 15:08:33.505: INFO: (11) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 9.313557ms)
  Feb  7 15:08:33.506: INFO: (11) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 10.090822ms)
  Feb  7 15:08:33.507: INFO: (11) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 10.879079ms)
  Feb  7 15:08:33.507: INFO: (11) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 10.756415ms)
  Feb  7 15:08:33.507: INFO: (11) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 10.934498ms)
  Feb  7 15:08:33.507: INFO: (11) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 10.690527ms)
  Feb  7 15:08:33.507: INFO: (11) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.295139ms)
  Feb  7 15:08:33.510: INFO: (11) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 14.272768ms)
  Feb  7 15:08:33.510: INFO: (11) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 14.156196ms)
  Feb  7 15:08:33.510: INFO: (11) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 14.413192ms)
  Feb  7 15:08:33.510: INFO: (11) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 14.583407ms)
  Feb  7 15:08:33.511: INFO: (11) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 14.928991ms)
  Feb  7 15:08:33.511: INFO: (11) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 15.179739ms)
  Feb  7 15:08:33.511: INFO: (11) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 15.390625ms)
  Feb  7 15:08:33.511: INFO: (11) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 15.198954ms)
  Feb  7 15:08:33.518: INFO: (12) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 6.972359ms)
  Feb  7 15:08:33.519: INFO: (12) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 7.722355ms)
  Feb  7 15:08:33.521: INFO: (12) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 9.576823ms)
  Feb  7 15:08:33.523: INFO: (12) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 10.960277ms)
  Feb  7 15:08:33.523: INFO: (12) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 11.268197ms)
  Feb  7 15:08:33.523: INFO: (12) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 11.399949ms)
  Feb  7 15:08:33.524: INFO: (12) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 12.249351ms)
  Feb  7 15:08:33.525: INFO: (12) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 13.210808ms)
  Feb  7 15:08:33.525: INFO: (12) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 13.845875ms)
  Feb  7 15:08:33.527: INFO: (12) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 15.076003ms)
  Feb  7 15:08:33.527: INFO: (12) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 15.407289ms)
  Feb  7 15:08:33.527: INFO: (12) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 15.547902ms)
  Feb  7 15:08:33.527: INFO: (12) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 15.550316ms)
  Feb  7 15:08:33.527: INFO: (12) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 15.968462ms)
  Feb  7 15:08:33.527: INFO: (12) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 15.804149ms)
  Feb  7 15:08:33.528: INFO: (12) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 16.245737ms)
  Feb  7 15:08:33.538: INFO: (13) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 10.549353ms)
  Feb  7 15:08:33.538: INFO: (13) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 10.77645ms)
  Feb  7 15:08:33.539: INFO: (13) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 10.934204ms)
  Feb  7 15:08:33.539: INFO: (13) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.648437ms)
  Feb  7 15:08:33.540: INFO: (13) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 12.025417ms)
  Feb  7 15:08:33.540: INFO: (13) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 12.194791ms)
  Feb  7 15:08:33.540: INFO: (13) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 12.355482ms)
  Feb  7 15:08:33.541: INFO: (13) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 12.831936ms)
  Feb  7 15:08:33.544: INFO: (13) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 16.121245ms)
  Feb  7 15:08:33.544: INFO: (13) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 16.243254ms)
  Feb  7 15:08:33.545: INFO: (13) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 16.68517ms)
  Feb  7 15:08:33.545: INFO: (13) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 16.782289ms)
  Feb  7 15:08:33.546: INFO: (13) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 17.923844ms)
  Feb  7 15:08:33.546: INFO: (13) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 17.832647ms)
  Feb  7 15:08:33.546: INFO: (13) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 18.266223ms)
  Feb  7 15:08:33.548: INFO: (13) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 20.115986ms)
  Feb  7 15:08:33.556: INFO: (14) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 7.478342ms)
  Feb  7 15:08:33.560: INFO: (14) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 11.194161ms)
  Feb  7 15:08:33.561: INFO: (14) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 12.428763ms)
  Feb  7 15:08:33.561: INFO: (14) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 13.167445ms)
  Feb  7 15:08:33.561: INFO: (14) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 13.020896ms)
  Feb  7 15:08:33.562: INFO: (14) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 13.286344ms)
  Feb  7 15:08:33.562: INFO: (14) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 13.830688ms)
  Feb  7 15:08:33.563: INFO: (14) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 14.739374ms)
  Feb  7 15:08:33.563: INFO: (14) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 15.18491ms)
  Feb  7 15:08:33.564: INFO: (14) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 15.382688ms)
  Feb  7 15:08:33.565: INFO: (14) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 16.583635ms)
  Feb  7 15:08:33.565: INFO: (14) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 16.751105ms)
  Feb  7 15:08:33.566: INFO: (14) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 17.205543ms)
  Feb  7 15:08:33.566: INFO: (14) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 17.575273ms)
  Feb  7 15:08:33.566: INFO: (14) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 17.915332ms)
  Feb  7 15:08:33.567: INFO: (14) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 18.236278ms)
  Feb  7 15:08:33.575: INFO: (15) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 7.946457ms)
  Feb  7 15:08:33.575: INFO: (15) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 7.921408ms)
  Feb  7 15:08:33.579: INFO: (15) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.264906ms)
  Feb  7 15:08:33.579: INFO: (15) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.635502ms)
  Feb  7 15:08:33.579: INFO: (15) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 12.106978ms)
  Feb  7 15:08:33.579: INFO: (15) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 12.302883ms)
  Feb  7 15:08:33.579: INFO: (15) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 12.531589ms)
  Feb  7 15:08:33.579: INFO: (15) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 12.395612ms)
  Feb  7 15:08:33.580: INFO: (15) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 12.74559ms)
  Feb  7 15:08:33.580: INFO: (15) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 12.934285ms)
  Feb  7 15:08:33.580: INFO: (15) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 13.17034ms)
  Feb  7 15:08:33.580: INFO: (15) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 13.096453ms)
  Feb  7 15:08:33.581: INFO: (15) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 14.012686ms)
  Feb  7 15:08:33.581: INFO: (15) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 13.835099ms)
  Feb  7 15:08:33.582: INFO: (15) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 14.474685ms)
  Feb  7 15:08:33.582: INFO: (15) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 14.535705ms)
  Feb  7 15:08:33.588: INFO: (16) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 5.992325ms)
  Feb  7 15:08:33.589: INFO: (16) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 7.310039ms)
  Feb  7 15:08:33.589: INFO: (16) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 7.418376ms)
  Feb  7 15:08:33.592: INFO: (16) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 9.925293ms)
  Feb  7 15:08:33.593: INFO: (16) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 11.114872ms)
  Feb  7 15:08:33.593: INFO: (16) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 11.322809ms)
  Feb  7 15:08:33.593: INFO: (16) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 11.347064ms)
  Feb  7 15:08:33.593: INFO: (16) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.452284ms)
  Feb  7 15:08:33.594: INFO: (16) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 11.922625ms)
  Feb  7 15:08:33.594: INFO: (16) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 12.239264ms)
  Feb  7 15:08:33.595: INFO: (16) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 12.91618ms)
  Feb  7 15:08:33.595: INFO: (16) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 12.857955ms)
  Feb  7 15:08:33.595: INFO: (16) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 13.071608ms)
  Feb  7 15:08:33.595: INFO: (16) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 13.240139ms)
  Feb  7 15:08:33.596: INFO: (16) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 13.832089ms)
  Feb  7 15:08:33.596: INFO: (16) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 13.834629ms)
  Feb  7 15:08:33.601: INFO: (17) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 5.534658ms)
  Feb  7 15:08:33.603: INFO: (17) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 6.421286ms)
  Feb  7 15:08:33.603: INFO: (17) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 7.211419ms)
  Feb  7 15:08:33.604: INFO: (17) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 7.369524ms)
  Feb  7 15:08:33.605: INFO: (17) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 8.594611ms)
  Feb  7 15:08:33.605: INFO: (17) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 9.062712ms)
  Feb  7 15:08:33.606: INFO: (17) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 9.765715ms)
  Feb  7 15:08:33.606: INFO: (17) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 9.914833ms)
  Feb  7 15:08:33.606: INFO: (17) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 9.936631ms)
  Feb  7 15:08:33.606: INFO: (17) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 9.960753ms)
  Feb  7 15:08:33.607: INFO: (17) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 10.555849ms)
  Feb  7 15:08:33.607: INFO: (17) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 10.681546ms)
  Feb  7 15:08:33.607: INFO: (17) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 10.468436ms)
  Feb  7 15:08:33.607: INFO: (17) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 10.99823ms)
  Feb  7 15:08:33.607: INFO: (17) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 11.178551ms)
  Feb  7 15:08:33.608: INFO: (17) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.220146ms)
  Feb  7 15:08:33.614: INFO: (18) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 5.984617ms)
  Feb  7 15:08:33.614: INFO: (18) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 6.245624ms)
  Feb  7 15:08:33.614: INFO: (18) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 6.770302ms)
  Feb  7 15:08:33.615: INFO: (18) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 7.319017ms)
  Feb  7 15:08:33.616: INFO: (18) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 7.761381ms)
  Feb  7 15:08:33.616: INFO: (18) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 7.782559ms)
  Feb  7 15:08:33.616: INFO: (18) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 7.52236ms)
  Feb  7 15:08:33.616: INFO: (18) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 8.423766ms)
  Feb  7 15:08:33.616: INFO: (18) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 8.57532ms)
  Feb  7 15:08:33.617: INFO: (18) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 9.309382ms)
  Feb  7 15:08:33.618: INFO: (18) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 9.598322ms)
  Feb  7 15:08:33.618: INFO: (18) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 10.154152ms)
  Feb  7 15:08:33.619: INFO: (18) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 10.700357ms)
  Feb  7 15:08:33.619: INFO: (18) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 11.52515ms)
  Feb  7 15:08:33.620: INFO: (18) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 11.840703ms)
  Feb  7 15:08:33.620: INFO: (18) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 12.426218ms)
  Feb  7 15:08:33.628: INFO: (19) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 7.415233ms)
  Feb  7 15:08:33.628: INFO: (19) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:162/proxy/: bar (200; 7.710846ms)
  Feb  7 15:08:33.629: INFO: (19) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">... (200; 7.297056ms)
  Feb  7 15:08:33.629: INFO: (19) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:460/proxy/: tls baz (200; 8.183123ms)
  Feb  7 15:08:33.629: INFO: (19) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:443/proxy/tlsrewritem... (200; 8.080874ms)
  Feb  7 15:08:33.629: INFO: (19) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 8.498562ms)
  Feb  7 15:08:33.629: INFO: (19) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname2/proxy/: bar (200; 8.851808ms)
  Feb  7 15:08:33.631: INFO: (19) /api/v1/namespaces/proxy-3470/pods/https:proxy-service-nl7cc-hhv8g:462/proxy/: tls qux (200; 10.388907ms)
  Feb  7 15:08:33.631: INFO: (19) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname2/proxy/: tls qux (200; 10.927713ms)
  Feb  7 15:08:33.633: INFO: (19) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname2/proxy/: bar (200; 11.73636ms)
  Feb  7 15:08:33.633: INFO: (19) /api/v1/namespaces/proxy-3470/services/proxy-service-nl7cc:portname1/proxy/: foo (200; 11.824085ms)
  Feb  7 15:08:33.633: INFO: (19) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g/proxy/rewriteme">test</a> (200; 12.028662ms)
  Feb  7 15:08:33.633: INFO: (19) /api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/: <a href="/api/v1/namespaces/proxy-3470/pods/proxy-service-nl7cc-hhv8g:1080/proxy/rewriteme">test<... (200; 11.958913ms)
  Feb  7 15:08:33.633: INFO: (19) /api/v1/namespaces/proxy-3470/pods/http:proxy-service-nl7cc-hhv8g:160/proxy/: foo (200; 11.919045ms)
  Feb  7 15:08:33.633: INFO: (19) /api/v1/namespaces/proxy-3470/services/https:proxy-service-nl7cc:tlsportname1/proxy/: tls baz (200; 12.194833ms)
  Feb  7 15:08:33.634: INFO: (19) /api/v1/namespaces/proxy-3470/services/http:proxy-service-nl7cc:portname1/proxy/: foo (200; 13.414293ms)
  STEP: deleting ReplicationController proxy-service-nl7cc in namespace proxy-3470, will wait for the garbage collector to delete the pods @ 02/07/24 15:08:33.634
  Feb  7 15:08:33.692: INFO: Deleting ReplicationController proxy-service-nl7cc took: 4.372921ms
  Feb  7 15:08:33.792: INFO: Terminating ReplicationController proxy-service-nl7cc pods took: 100.915302ms
  E0207 15:08:34.282207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:35.282764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:36.283120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:36.393: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3470" for this suite. @ 02/07/24 15:08:36.396
• [5.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 02/07/24 15:08:36.407
  Feb  7 15:08:36.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 15:08:36.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:08:36.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:08:36.42
  STEP: set up a multi version CRD @ 02/07/24 15:08:36.422
  Feb  7 15:08:36.422: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 15:08:37.283218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:38.283490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:39.283585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 02/07/24 15:08:39.654
  STEP: check the unserved version gets removed @ 02/07/24 15:08:39.668
  E0207 15:08:40.284651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 02/07/24 15:08:40.426
  E0207 15:08:41.285533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:42.285970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:42.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3291" for this suite. @ 02/07/24 15:08:42.968
• [6.566 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 02/07/24 15:08:42.974
  Feb  7 15:08:42.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename daemonsets @ 02/07/24 15:08:42.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:08:42.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:08:42.985
  STEP: Creating a simple DaemonSet "daemon-set" @ 02/07/24 15:08:43
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/07/24 15:08:43.003
  Feb  7 15:08:43.007: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 15:08:43.007: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 15:08:43.286541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:44.009: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 15:08:44.009: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 15:08:44.287588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:45.010: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 15:08:45.010: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 02/07/24 15:08:45.011
  Feb  7 15:08:45.028: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Feb  7 15:08:45.029: INFO: Node worker-1 is running 0 daemon pod, expected 1
  E0207 15:08:45.288218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:46.025: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Feb  7 15:08:46.025: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 02/07/24 15:08:46.025
  STEP: Deleting DaemonSet "daemon-set" @ 02/07/24 15:08:46.029
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6296, will wait for the garbage collector to delete the pods @ 02/07/24 15:08:46.029
  Feb  7 15:08:46.085: INFO: Deleting DaemonSet.extensions daemon-set took: 3.666264ms
  Feb  7 15:08:46.185: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.070203ms
  E0207 15:08:46.288796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:47.289205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:47.888: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Feb  7 15:08:47.888: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Feb  7 15:08:47.889: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30950"},"items":null}

  Feb  7 15:08:47.891: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30950"},"items":null}

  Feb  7 15:08:47.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6296" for this suite. @ 02/07/24 15:08:47.9
• [4.929 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 02/07/24 15:08:47.904
  Feb  7 15:08:47.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 15:08:47.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:08:47.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:08:47.917
  STEP: Creating resourceQuota "e2e-rq-status-lhrc9" @ 02/07/24 15:08:47.921
  Feb  7 15:08:47.925: INFO: Resource quota "e2e-rq-status-lhrc9" reports spec: hard cpu limit of 500m
  Feb  7 15:08:47.925: INFO: Resource quota "e2e-rq-status-lhrc9" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-lhrc9" /status @ 02/07/24 15:08:47.925
  STEP: Confirm /status for "e2e-rq-status-lhrc9" resourceQuota via watch @ 02/07/24 15:08:47.932
  Feb  7 15:08:47.933: INFO: observed resourceQuota "e2e-rq-status-lhrc9" in namespace "resourcequota-2854" with hard status: v1.ResourceList(nil)
  Feb  7 15:08:47.933: INFO: Found resourceQuota "e2e-rq-status-lhrc9" in namespace "resourcequota-2854" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Feb  7 15:08:47.933: INFO: ResourceQuota "e2e-rq-status-lhrc9" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 02/07/24 15:08:47.935
  Feb  7 15:08:47.939: INFO: Resource quota "e2e-rq-status-lhrc9" reports spec: hard cpu limit of 1
  Feb  7 15:08:47.939: INFO: Resource quota "e2e-rq-status-lhrc9" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-lhrc9" /status @ 02/07/24 15:08:47.939
  STEP: Confirm /status for "e2e-rq-status-lhrc9" resourceQuota via watch @ 02/07/24 15:08:47.943
  Feb  7 15:08:47.944: INFO: observed resourceQuota "e2e-rq-status-lhrc9" in namespace "resourcequota-2854" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Feb  7 15:08:47.944: INFO: Found resourceQuota "e2e-rq-status-lhrc9" in namespace "resourcequota-2854" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Feb  7 15:08:47.944: INFO: ResourceQuota "e2e-rq-status-lhrc9" /status was patched
  STEP: Get "e2e-rq-status-lhrc9" /status @ 02/07/24 15:08:47.944
  Feb  7 15:08:47.947: INFO: Resourcequota "e2e-rq-status-lhrc9" reports status: hard cpu of 1
  Feb  7 15:08:47.947: INFO: Resourcequota "e2e-rq-status-lhrc9" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-lhrc9" /status before checking Spec is unchanged @ 02/07/24 15:08:47.949
  Feb  7 15:08:47.953: INFO: Resourcequota "e2e-rq-status-lhrc9" reports status: hard cpu of 2
  Feb  7 15:08:47.953: INFO: Resourcequota "e2e-rq-status-lhrc9" reports status: hard memory of 2Gi
  Feb  7 15:08:47.954: INFO: Found resourceQuota "e2e-rq-status-lhrc9" in namespace "resourcequota-2854" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Feb  7 15:08:47.956: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051111a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051111d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111200), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:08:48.289743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:49.290101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:50.290286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:51.290510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:52.290911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:52.956: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111428), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111458), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051114a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:08:53.291027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:54.291255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:55.291459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:56.291670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:57.292301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:08:57.958: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051116f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111740), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111770), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:08:58.292472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:08:59.292665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:00.293342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:01.293395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:02.294372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:02.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33920), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33950), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33980), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:03.295122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:04.295322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:05.295445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:06.295628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:07.296150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:07.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111ba8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111bd8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005111c20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:08.297023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:09.297227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:10.297429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:11.297614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:12.298355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:12.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33c80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33cb0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33cf8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:13.299029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:14.299241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:15.299441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:16.299623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:17.300342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:17.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004cb9d70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004cb9da0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004cb9dd0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:18.301150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:19.301248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:20.302131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:21.302257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:22.302307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:22.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33f50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33f80), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004e33fb0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:23.302519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:24.302730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:25.302823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:26.303832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:27.304270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:27.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f605e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f60618), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f60678), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:28.304469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:29.304673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:30.304870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:31.305035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:32.305347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:32.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f60af8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f60b58), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f60bb8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:33.305399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:34.305583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:35.306117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:36.306300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:37.306698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:37.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608510), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608570), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016085b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:38.307418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:39.307621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:40.307804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:41.307922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:42.308342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:42.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608960), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016089f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608a38), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:43.309000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:44.309074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:45.309284      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:46.309467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:47.309917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:47.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030600), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030678), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040306a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:48.309966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:49.310156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:50.310276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:51.310485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:52.310803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:52.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f61638), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f61668), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f616f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:53.311431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:54.311624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:55.311842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:56.312031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:57.312478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:09:57.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0040308e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030960), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030990), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:09:58.313483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:09:59.313680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:00.313884      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:01.314068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:02.314385      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:02.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030d38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030d80), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004030de0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:03.314946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:04.315047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:05.315261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:06.315461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:07.315941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:07.956: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016092c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001609308), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016093c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:08.316056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:09.316180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:10.316401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:11.316594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:12.316866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:12.956: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f61ea8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f61f38), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f61fe0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:13.317491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:14.317684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:15.317867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:16.318073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:17.318592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:17.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a288), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a2b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a300), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:18.319344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:19.319440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:20.319630      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:21.319828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:22.320173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:22.958: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a648), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a6c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a6f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:23.320389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:24.320572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:25.320696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:26.320904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:27.321386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:27.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a8e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a948), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a9a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:28.322240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:29.322342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:30.322528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:31.323195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:32.323340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:32.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004031638), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004031740), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004031770), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:33.323970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:34.324148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:35.324362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:36.324559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:37.324871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:37.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004031b78), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004031bc0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004031c50), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:38.325628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:39.325820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:40.326023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:41.326214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:42.326526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:42.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016d1f98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016d1fe0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c24030), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:43.326832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:44.327009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:45.327211      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:46.327396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:47.327856      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:47.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a0f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a120), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a168), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:48.328154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:49.328335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:50.328444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:51.328620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:52.329395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:52.956: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016083a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608408), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608438), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:53.330277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:54.330459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:55.330636      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:56.330763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:57.331352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:10:57.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a648), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a6c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444a6f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:10:58.332080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:10:59.332263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:00.332452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:01.332637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:02.332897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:02.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608948), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608990), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608a20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:11:03.333517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:04.334637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:05.334894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:06.335091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:07.335379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:07.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608de0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608e58), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001608e88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:11:08.335955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:09.336135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:10.336258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:11.336440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:12.337406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:12.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444aab0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444aaf8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00444ab28), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:11:13.338112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:14.338291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:15.338479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:16.338671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:17.339266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:17.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c247f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c24840), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c24888), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:11:18.339673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:19.339854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:20.340031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:21.340226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:22.340554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:22.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c24c18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c24c60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c24ca8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:11:23.341240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:24.341362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:25.341553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:26.341751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:27.342236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:27.956: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-lhrc9", GenerateName:"", Namespace:"resourcequota-2854", SelfLink:"", UID:"a24130ef-0853-40a2-b107-fd111ba81d7a", ResourceVersion:"30960", Generation:0, CreationTimestamp:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-lhrc9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016097e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001609830), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.February, 7, 15, 8, 47, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001609860), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0207 15:11:28.343249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:29.343448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:30.343629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:31.343817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:32.344140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:32.957: INFO: ResourceQuota "e2e-rq-status-lhrc9" Spec was unchanged and /status reset
  Feb  7 15:11:32.957: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2854" for this suite. @ 02/07/24 15:11:32.959
• [165.059 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 02/07/24 15:11:32.963
  Feb  7 15:11:32.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename limitrange @ 02/07/24 15:11:32.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:32.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:32.975
  STEP: Creating LimitRange "e2e-limitrange-q85zv" in namespace "limitrange-2241" @ 02/07/24 15:11:32.978
  STEP: Creating another limitRange in another namespace @ 02/07/24 15:11:32.981
  Feb  7 15:11:32.988: INFO: Namespace "e2e-limitrange-q85zv-949" created
  Feb  7 15:11:32.988: INFO: Creating LimitRange "e2e-limitrange-q85zv" in namespace "e2e-limitrange-q85zv-949"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-q85zv" @ 02/07/24 15:11:32.992
  Feb  7 15:11:32.994: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-q85zv" in "limitrange-2241" namespace @ 02/07/24 15:11:32.994
  Feb  7 15:11:32.999: INFO: LimitRange "e2e-limitrange-q85zv" has been patched
  STEP: Delete LimitRange "e2e-limitrange-q85zv" by Collection with labelSelector: "e2e-limitrange-q85zv=patched" @ 02/07/24 15:11:32.999
  STEP: Confirm that the limitRange "e2e-limitrange-q85zv" has been deleted @ 02/07/24 15:11:33.003
  Feb  7 15:11:33.003: INFO: Requesting list of LimitRange to confirm quantity
  Feb  7 15:11:33.005: INFO: Found 0 LimitRange with label "e2e-limitrange-q85zv=patched"
  Feb  7 15:11:33.005: INFO: LimitRange "e2e-limitrange-q85zv" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-q85zv" @ 02/07/24 15:11:33.005
  Feb  7 15:11:33.007: INFO: Found 1 limitRange
  Feb  7 15:11:33.007: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2241" for this suite. @ 02/07/24 15:11:33.009
  STEP: Destroying namespace "e2e-limitrange-q85zv-949" for this suite. @ 02/07/24 15:11:33.013
• [0.054 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 02/07/24 15:11:33.018
  Feb  7 15:11:33.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 15:11:33.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:33.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:33.028
  Feb  7 15:11:33.031: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 15:11:33.344791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:34.345897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:35.346094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0207 15:11:35.566716      23 warnings.go:70] unknown field "alpha"
  W0207 15:11:35.566738      23 warnings.go:70] unknown field "beta"
  W0207 15:11:35.566744      23 warnings.go:70] unknown field "delta"
  W0207 15:11:35.566750      23 warnings.go:70] unknown field "epsilon"
  W0207 15:11:35.566756      23 warnings.go:70] unknown field "gamma"
  Feb  7 15:11:36.094: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-444" for this suite. @ 02/07/24 15:11:36.096
• [3.082 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 02/07/24 15:11:36.1
  Feb  7 15:11:36.100: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename field-validation @ 02/07/24 15:11:36.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:36.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:36.113
  STEP: apply creating a deployment @ 02/07/24 15:11:36.115
  Feb  7 15:11:36.124: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2932" for this suite. @ 02/07/24 15:11:36.126
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 02/07/24 15:11:36.13
  Feb  7 15:11:36.130: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 15:11:36.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:36.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:36.142
  STEP: Creating ServiceAccount "e2e-sa-krt95"  @ 02/07/24 15:11:36.144
  Feb  7 15:11:36.147: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-krt95"  @ 02/07/24 15:11:36.147
  Feb  7 15:11:36.152: INFO: AutomountServiceAccountToken: true
  Feb  7 15:11:36.152: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-446" for this suite. @ 02/07/24 15:11:36.155
• [0.029 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 02/07/24 15:11:36.16
  Feb  7 15:11:36.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 15:11:36.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:36.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:36.17
  STEP: Counting existing ResourceQuota @ 02/07/24 15:11:36.172
  E0207 15:11:36.347139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:37.348203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:38.348302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:39.348761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:40.349130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 02/07/24 15:11:41.175
  STEP: Ensuring resource quota status is calculated @ 02/07/24 15:11:41.182
  E0207 15:11:41.349600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:42.350420      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 02/07/24 15:11:43.184
  STEP: Ensuring resource quota status captures replication controller creation @ 02/07/24 15:11:43.193
  E0207 15:11:43.351031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:44.351210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 02/07/24 15:11:45.196
  STEP: Ensuring resource quota status released usage @ 02/07/24 15:11:45.2
  E0207 15:11:45.351575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:46.351775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:47.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1941" for this suite. @ 02/07/24 15:11:47.206
• [11.049 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 02/07/24 15:11:47.209
  Feb  7 15:11:47.209: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 15:11:47.21
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:47.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:47.222
  STEP: Creating configMap with name configmap-test-upd-69ed1003-e35f-4e20-8e56-4f34d31948cb @ 02/07/24 15:11:47.227
  STEP: Creating the pod @ 02/07/24 15:11:47.23
  E0207 15:11:47.352020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:48.352082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 02/07/24 15:11:49.242
  STEP: Waiting for pod with binary data @ 02/07/24 15:11:49.255
  Feb  7 15:11:49.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2727" for this suite. @ 02/07/24 15:11:49.262
• [2.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 02/07/24 15:11:49.266
  Feb  7 15:11:49.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename events @ 02/07/24 15:11:49.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:49.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:49.28
  STEP: Create set of events @ 02/07/24 15:11:49.282
  STEP: get a list of Events with a label in the current namespace @ 02/07/24 15:11:49.291
  STEP: delete a list of events @ 02/07/24 15:11:49.293
  Feb  7 15:11:49.293: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 02/07/24 15:11:49.304
  Feb  7 15:11:49.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4151" for this suite. @ 02/07/24 15:11:49.309
• [0.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 02/07/24 15:11:49.315
  Feb  7 15:11:49.315: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename csiinlinevolumes @ 02/07/24 15:11:49.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:49.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:49.326
  STEP: Creating two CSIDrivers @ 02/07/24 15:11:49.328
  STEP: Getting "inline-driver-3459c4b2-976d-4d54-b660-4f91ac2b125f" & "inline-driver-efb9a60f-3dca-42a2-9480-ffdf594eedfc" @ 02/07/24 15:11:49.338
  STEP: Patching the CSIDriver "inline-driver-efb9a60f-3dca-42a2-9480-ffdf594eedfc" @ 02/07/24 15:11:49.341
  STEP: Updating the CSIDriver "inline-driver-efb9a60f-3dca-42a2-9480-ffdf594eedfc" @ 02/07/24 15:11:49.347
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-6067" @ 02/07/24 15:11:49.352
  E0207 15:11:49.352479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting CSIDriver "inline-driver-3459c4b2-976d-4d54-b660-4f91ac2b125f" @ 02/07/24 15:11:49.354
  STEP: Confirm deletion of CSIDriver "inline-driver-3459c4b2-976d-4d54-b660-4f91ac2b125f" @ 02/07/24 15:11:49.357
  STEP: Deleting CSIDriver "inline-driver-efb9a60f-3dca-42a2-9480-ffdf594eedfc" via DeleteCollection @ 02/07/24 15:11:49.359
  STEP: Confirm deletion of CSIDriver "inline-driver-efb9a60f-3dca-42a2-9480-ffdf594eedfc" @ 02/07/24 15:11:49.363
  Feb  7 15:11:49.365: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6067" for this suite. @ 02/07/24 15:11:49.368
• [0.056 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 02/07/24 15:11:49.371
  Feb  7 15:11:49.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename aggregator @ 02/07/24 15:11:49.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:11:49.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:11:49.383
  Feb  7 15:11:49.386: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Registering the sample API server. @ 02/07/24 15:11:49.386
  Feb  7 15:11:49.950: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Feb  7 15:11:49.970: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0207 15:11:50.353357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:51.353565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:52.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:11:52.354261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:53.354441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:54.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:11:54.355565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:55.355782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:56.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:11:56.356739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:57.357297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:11:58.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:11:58.358313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:11:59.358518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:00.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:00.359211      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:01.359349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:02.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:02.360081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:03.360358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:04.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:04.361130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:05.361322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:06.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:06.362147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:07.362590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:08.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:08.363230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:09.363433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:10.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:10.363504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:11.364529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:12.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 11, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:12:12.364941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:13.365053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:14.122: INFO: Waited 110.391561ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 02/07/24 15:12:14.161
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 02/07/24 15:12:14.163
  STEP: List APIServices @ 02/07/24 15:12:14.168
  Feb  7 15:12:14.173: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 02/07/24 15:12:14.173
  Feb  7 15:12:14.184: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 02/07/24 15:12:14.184
  Feb  7 15:12:14.191: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.February, 7, 15, 12, 14, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 02/07/24 15:12:14.191
  Feb  7 15:12:14.194: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-02-07 15:12:14 +0000 UTC Passed all checks passed}
  Feb  7 15:12:14.194: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 15:12:14.194: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 02/07/24 15:12:14.194
  Feb  7 15:12:14.202: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-466130802" @ 02/07/24 15:12:14.202
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 02/07/24 15:12:14.214
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 02/07/24 15:12:14.223
  STEP: Patch APIService Status @ 02/07/24 15:12:14.225
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 02/07/24 15:12:14.23
  Feb  7 15:12:14.233: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-02-07 15:12:14 +0000 UTC Passed all checks passed}
  Feb  7 15:12:14.233: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Feb  7 15:12:14.233: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Feb  7 15:12:14.233: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 02/07/24 15:12:14.233
  STEP: Confirm that the generated APIService has been deleted @ 02/07/24 15:12:14.239
  Feb  7 15:12:14.239: INFO: Requesting list of APIServices to confirm quantity
  Feb  7 15:12:14.242: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  Feb  7 15:12:14.242: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Feb  7 15:12:14.313: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-4895" for this suite. @ 02/07/24 15:12:14.315
• [24.948 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 02/07/24 15:12:14.319
  Feb  7 15:12:14.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename custom-resource-definition @ 02/07/24 15:12:14.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:14.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:14.334
  STEP: fetching the /apis discovery document @ 02/07/24 15:12:14.338
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 02/07/24 15:12:14.339
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 02/07/24 15:12:14.339
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 02/07/24 15:12:14.339
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 02/07/24 15:12:14.34
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 02/07/24 15:12:14.34
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 02/07/24 15:12:14.343
  Feb  7 15:12:14.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5366" for this suite. @ 02/07/24 15:12:14.346
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 02/07/24 15:12:14.354
  Feb  7 15:12:14.354: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename job @ 02/07/24 15:12:14.355
  E0207 15:12:14.365666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:14.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:14.369
  STEP: Creating a job @ 02/07/24 15:12:14.372
  STEP: Ensure pods equal to parallelism count is attached to the job @ 02/07/24 15:12:14.377
  E0207 15:12:15.366395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:16.366814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 02/07/24 15:12:16.38
  STEP: updating /status @ 02/07/24 15:12:16.386
  STEP: get /status @ 02/07/24 15:12:16.393
  Feb  7 15:12:16.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7733" for this suite. @ 02/07/24 15:12:16.398
• [2.047 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 02/07/24 15:12:16.401
  Feb  7 15:12:16.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 15:12:16.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:16.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:16.412
  STEP: Creating configMap configmap-8405/configmap-test-3da6692d-b88a-473a-b877-aa3d643befee @ 02/07/24 15:12:16.415
  STEP: Creating a pod to test consume configMaps @ 02/07/24 15:12:16.418
  E0207 15:12:17.367607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:18.367702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:12:18.428
  Feb  7 15:12:18.430: INFO: Trying to get logs from node worker-1 pod pod-configmaps-572b2374-2f47-4c12-bbc2-bfafdeb47a78 container env-test: <nil>
  STEP: delete the pod @ 02/07/24 15:12:18.445
  Feb  7 15:12:18.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8405" for this suite. @ 02/07/24 15:12:18.458
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 02/07/24 15:12:18.462
  Feb  7 15:12:18.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename job @ 02/07/24 15:12:18.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:18.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:18.474
  STEP: Creating a job @ 02/07/24 15:12:18.476
  STEP: Ensuring active pods == parallelism @ 02/07/24 15:12:18.48
  E0207 15:12:19.368128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:20.368210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 02/07/24 15:12:20.483
  Feb  7 15:12:20.993: INFO: Successfully updated pod "adopt-release-hp8pm"
  STEP: Checking that the Job readopts the Pod @ 02/07/24 15:12:20.993
  E0207 15:12:21.369170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:22.369652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 02/07/24 15:12:23
  E0207 15:12:23.370101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:23.507: INFO: Successfully updated pod "adopt-release-hp8pm"
  STEP: Checking that the Job releases the Pod @ 02/07/24 15:12:23.507
  E0207 15:12:24.370704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:25.370935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:25.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8661" for this suite. @ 02/07/24 15:12:25.516
• [7.059 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 02/07/24 15:12:25.521
  Feb  7 15:12:25.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 15:12:25.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:25.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:25.534
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 15:12:25.537
  E0207 15:12:26.371394      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:27.371439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:12:27.549
  Feb  7 15:12:27.551: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-41c386c8-a20c-422f-beb7-05625deeaba2 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 15:12:27.556
  Feb  7 15:12:27.567: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4200" for this suite. @ 02/07/24 15:12:27.569
• [2.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 02/07/24 15:12:27.574
  Feb  7 15:12:27.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 15:12:27.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:27.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:27.586
  Feb  7 15:12:27.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: creating the pod @ 02/07/24 15:12:27.59
  STEP: submitting the pod to kubernetes @ 02/07/24 15:12:27.59
  E0207 15:12:28.372421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:29.372655      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:29.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1312" for this suite. @ 02/07/24 15:12:29.614
• [2.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 02/07/24 15:12:29.618
  Feb  7 15:12:29.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 15:12:29.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:29.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:29.63
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 15:12:29.632
  E0207 15:12:30.373001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:31.373078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:12:31.643
  Feb  7 15:12:31.645: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-63561811-40ee-43f1-b1bf-7dfa053a6abd container client-container: <nil>
  STEP: delete the pod @ 02/07/24 15:12:31.65
  Feb  7 15:12:31.659: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8184" for this suite. @ 02/07/24 15:12:31.661
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 02/07/24 15:12:31.667
  Feb  7 15:12:31.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename proxy @ 02/07/24 15:12:31.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:31.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:31.678
  Feb  7 15:12:31.682: INFO: Creating pod...
  E0207 15:12:32.373251      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:33.374103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:33.695: INFO: Creating service...
  Feb  7 15:12:33.706: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=DELETE
  Feb  7 15:12:33.716: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb  7 15:12:33.716: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=OPTIONS
  Feb  7 15:12:33.718: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb  7 15:12:33.718: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=PATCH
  Feb  7 15:12:33.721: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb  7 15:12:33.721: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=POST
  Feb  7 15:12:33.724: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb  7 15:12:33.724: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=PUT
  Feb  7 15:12:33.726: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb  7 15:12:33.726: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=DELETE
  Feb  7 15:12:33.729: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Feb  7 15:12:33.729: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Feb  7 15:12:33.733: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Feb  7 15:12:33.733: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=PATCH
  Feb  7 15:12:33.736: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Feb  7 15:12:33.736: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=POST
  Feb  7 15:12:33.739: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Feb  7 15:12:33.739: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=PUT
  Feb  7 15:12:33.742: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Feb  7 15:12:33.743: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=GET
  Feb  7 15:12:33.744: INFO: http.Client request:GET StatusCode:301
  Feb  7 15:12:33.744: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=GET
  Feb  7 15:12:33.746: INFO: http.Client request:GET StatusCode:301
  Feb  7 15:12:33.746: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/pods/agnhost/proxy?method=HEAD
  Feb  7 15:12:33.747: INFO: http.Client request:HEAD StatusCode:301
  Feb  7 15:12:33.747: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6576/services/e2e-proxy-test-service/proxy?method=HEAD
  Feb  7 15:12:33.749: INFO: http.Client request:HEAD StatusCode:301
  Feb  7 15:12:33.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-6576" for this suite. @ 02/07/24 15:12:33.752
• [2.088 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 02/07/24 15:12:33.756
  Feb  7 15:12:33.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 15:12:33.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:33.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:33.768
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 15:12:33.77
  E0207 15:12:34.375074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:35.375518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:36.375608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:37.376168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:12:37.785
  Feb  7 15:12:37.787: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-8bf1f0cf-87d2-4099-a707-77b92d9c2258 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 15:12:37.792
  Feb  7 15:12:37.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1316" for this suite. @ 02/07/24 15:12:37.805
• [4.053 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 02/07/24 15:12:37.809
  Feb  7 15:12:37.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename podtemplate @ 02/07/24 15:12:37.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:37.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:37.823
  STEP: Create set of pod templates @ 02/07/24 15:12:37.826
  Feb  7 15:12:37.830: INFO: created test-podtemplate-1
  Feb  7 15:12:37.834: INFO: created test-podtemplate-2
  Feb  7 15:12:37.839: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 02/07/24 15:12:37.839
  STEP: delete collection of pod templates @ 02/07/24 15:12:37.841
  Feb  7 15:12:37.841: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 02/07/24 15:12:37.849
  Feb  7 15:12:37.849: INFO: requesting list of pod templates to confirm quantity
  Feb  7 15:12:37.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3036" for this suite. @ 02/07/24 15:12:37.854
• [0.050 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 02/07/24 15:12:37.859
  Feb  7 15:12:37.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename controllerrevisions @ 02/07/24 15:12:37.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:37.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:37.871
  STEP: Creating DaemonSet "e2e-jcd7k-daemon-set" @ 02/07/24 15:12:37.884
  STEP: Check that daemon pods launch on every node of the cluster. @ 02/07/24 15:12:37.888
  Feb  7 15:12:37.894: INFO: Number of nodes with available pods controlled by daemonset e2e-jcd7k-daemon-set: 0
  Feb  7 15:12:37.894: INFO: Node worker-0 is running 0 daemon pod, expected 1
  E0207 15:12:38.376817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:38.893: INFO: Number of nodes with available pods controlled by daemonset e2e-jcd7k-daemon-set: 1
  Feb  7 15:12:38.893: INFO: Node worker-1 is running 0 daemon pod, expected 1
  E0207 15:12:39.377057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:39.894: INFO: Number of nodes with available pods controlled by daemonset e2e-jcd7k-daemon-set: 2
  Feb  7 15:12:39.894: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-jcd7k-daemon-set
  STEP: Confirm DaemonSet "e2e-jcd7k-daemon-set" successfully created with "daemonset-name=e2e-jcd7k-daemon-set" label @ 02/07/24 15:12:39.896
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-jcd7k-daemon-set" @ 02/07/24 15:12:39.901
  Feb  7 15:12:39.903: INFO: Located ControllerRevision: "e2e-jcd7k-daemon-set-6db4495dfb"
  STEP: Patching ControllerRevision "e2e-jcd7k-daemon-set-6db4495dfb" @ 02/07/24 15:12:39.905
  Feb  7 15:12:39.910: INFO: e2e-jcd7k-daemon-set-6db4495dfb has been patched
  STEP: Create a new ControllerRevision @ 02/07/24 15:12:39.91
  Feb  7 15:12:39.921: INFO: Created ControllerRevision: e2e-jcd7k-daemon-set-67757ccc54
  STEP: Confirm that there are two ControllerRevisions @ 02/07/24 15:12:39.921
  Feb  7 15:12:39.922: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb  7 15:12:39.924: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-jcd7k-daemon-set-6db4495dfb" @ 02/07/24 15:12:39.924
  STEP: Confirm that there is only one ControllerRevision @ 02/07/24 15:12:39.928
  Feb  7 15:12:39.928: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb  7 15:12:39.930: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-jcd7k-daemon-set-67757ccc54" @ 02/07/24 15:12:39.932
  Feb  7 15:12:39.938: INFO: e2e-jcd7k-daemon-set-67757ccc54 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 02/07/24 15:12:39.938
  W0207 15:12:39.943690      23 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 02/07/24 15:12:39.943
  Feb  7 15:12:39.943: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0207 15:12:40.377442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:40.944: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb  7 15:12:40.947: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-jcd7k-daemon-set-67757ccc54=updated" @ 02/07/24 15:12:40.947
  STEP: Confirm that there is only one ControllerRevision @ 02/07/24 15:12:40.952
  Feb  7 15:12:40.952: INFO: Requesting list of ControllerRevisions to confirm quantity
  Feb  7 15:12:40.954: INFO: Found 1 ControllerRevisions
  Feb  7 15:12:40.956: INFO: ControllerRevision "e2e-jcd7k-daemon-set-58db699ddc" has revision 3
  STEP: Deleting DaemonSet "e2e-jcd7k-daemon-set" @ 02/07/24 15:12:40.959
  STEP: deleting DaemonSet.extensions e2e-jcd7k-daemon-set in namespace controllerrevisions-1814, will wait for the garbage collector to delete the pods @ 02/07/24 15:12:40.959
  Feb  7 15:12:41.017: INFO: Deleting DaemonSet.extensions e2e-jcd7k-daemon-set took: 4.95632ms
  Feb  7 15:12:41.117: INFO: Terminating DaemonSet.extensions e2e-jcd7k-daemon-set pods took: 100.125415ms
  E0207 15:12:41.378481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:42.378901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:42.420: INFO: Number of nodes with available pods controlled by daemonset e2e-jcd7k-daemon-set: 0
  Feb  7 15:12:42.420: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-jcd7k-daemon-set
  Feb  7 15:12:42.423: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32046"},"items":null}

  Feb  7 15:12:42.425: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32046"},"items":null}

  Feb  7 15:12:42.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-1814" for this suite. @ 02/07/24 15:12:42.434
• [4.580 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 02/07/24 15:12:42.44
  Feb  7 15:12:42.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 15:12:42.44
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:42.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:42.458
  E0207 15:12:43.379331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:44.379282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:44.473: INFO: Deleting pod "var-expansion-bd67856f-a895-47ad-91aa-402c64169316" in namespace "var-expansion-3180"
  Feb  7 15:12:44.478: INFO: Wait up to 5m0s for pod "var-expansion-bd67856f-a895-47ad-91aa-402c64169316" to be fully deleted
  E0207 15:12:45.379854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:46.380040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:12:46.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3180" for this suite. @ 02/07/24 15:12:46.487
• [4.053 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 02/07/24 15:12:46.493
  Feb  7 15:12:46.493: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 15:12:46.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:46.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:46.504
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 15:12:46.507
  E0207 15:12:47.380345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:48.380550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:49.381434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:50.382129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:12:50.525
  Feb  7 15:12:50.527: INFO: Trying to get logs from node worker-0 pod downwardapi-volume-f8efbb6e-9115-4b6c-be56-c25285778ff8 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 15:12:50.532
  Feb  7 15:12:50.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9623" for this suite. @ 02/07/24 15:12:50.544
• [4.055 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 02/07/24 15:12:50.548
  Feb  7 15:12:50.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename chunking @ 02/07/24 15:12:50.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:12:50.557
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:12:50.56
  STEP: creating a large number of resources @ 02/07/24 15:12:50.562
  E0207 15:12:51.382774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:52.383286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:53.384302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:54.384927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:55.385590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:56.385629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:57.385820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:58.386213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:12:59.386561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:00.386815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:01.386862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:02.387600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:03.387681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:04.388196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:05.388635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:06.389515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:07.390483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 02/07/24 15:13:08.253
  Feb  7 15:13:08.302: INFO: Retrieved 40/40 results with rv 32593 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 02/07/24 15:13:08.302
  E0207 15:13:08.390883      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:09.391076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:10.391253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:11.391449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:12.391790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:13.391975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:14.392173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:15.392347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:16.392551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:17.393235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:18.394104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:19.394269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:20.394444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:21.394632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:22.394974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:23.395428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:24.395610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:25.395717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:26.395835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:27.396343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:13:28.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:13:28.396377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:29.396555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:30.396729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:31.396899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:32.397304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:33.398107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:34.398275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:35.398476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:36.398643      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:37.399231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:38.399413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:39.399582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:40.399779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:41.400442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:42.400808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:43.401285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:44.401398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:45.402104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:46.402285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:47.402408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:13:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:13:48.403112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:49.403287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:50.403471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:51.403647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:52.403962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:53.404071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:54.404262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:55.404447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:56.404631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:57.405223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:58.405515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:13:59.405708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:00.405894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:01.406073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:02.406402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:03.406830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:04.406952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:05.407133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:06.407326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:07.407771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:14:08.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:14:08.408565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:09.408690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:10.408868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:11.409053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:12.409464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:13.409639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:14.410117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:15.410291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:16.410467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:17.410946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:18.411234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:19.411354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:20.411471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:21.411660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:22.411989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:23.412180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:24.412353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:25.412548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:26.412675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:27.413244      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:14:28.306: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:14:28.413614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:29.413793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:30.413966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:31.414154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:32.414494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:33.414603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:34.414791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:35.414946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:36.415060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:37.415464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:38.415760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:39.415950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:40.416129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:41.416310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:42.416651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:43.417129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:44.417192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:45.417155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:46.417277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:47.417619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:14:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:14:48.417656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:49.417840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:50.418022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:51.418210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:52.418508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:53.418689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:54.418887      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:55.419071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:56.419246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:57.419640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:58.419826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:14:59.420017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:00.420209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:01.420381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:02.420701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:03.420807      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:04.421005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:05.421101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:06.421285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:07.421712      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:15:08.306: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:15:08.422661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:09.422877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:10.423055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:11.423237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:12.423434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:13.423617      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:14.423801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:15.423984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:16.424099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:17.424528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:18.424815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:19.425140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:20.425324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:21.425509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:22.425840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:23.426114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:24.426299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:25.426499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:26.426678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:27.427480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:15:28.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:15:28.428293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:29.428483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:30.428671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:31.428786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:32.429293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:33.430100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:34.430276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:35.430470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:36.430650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:37.431094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:38.431387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:39.431518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:40.431719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:41.431909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:42.432256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:43.432443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:44.432622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:45.432743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:46.432935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:47.433483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:15:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:15:48.434277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:49.434760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:50.434930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:51.435212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:52.435439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:53.435616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:54.435795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:55.435980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:56.436100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:57.436695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:58.436878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:15:59.437040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:00.437233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:01.437415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:02.437739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:03.437858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:04.438042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:05.438219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:06.438400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:07.438862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:16:08.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:16:08.439770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:09.439889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:10.440005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:11.440187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:12.440532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:13.440713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:14.440937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:15.441123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:16.441299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:17.441662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:18.441944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:19.442117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:20.442294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:21.442472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:22.442788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:23.442914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:24.443304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:25.443494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:26.443678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:27.444334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:16:28.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:16:28.445035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:29.445207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:30.445382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:31.445562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:32.445873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:33.446051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:34.446223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:35.446410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:36.446601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:37.447112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:38.447405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:39.447586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:40.447775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:41.447964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:42.448386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:43.448564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:44.449063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:45.449000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:46.448991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:47.449578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:16:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:16:48.450069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:49.450246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:50.450436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:51.450621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:52.450981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:53.451157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:54.451335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:55.451522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:56.451713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:57.452160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:58.452451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:16:59.452631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:00.452832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:01.453069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:02.453494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:03.454106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:04.454286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:05.454394      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:06.454584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:07.455137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:17:08.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:17:08.455895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:09.456021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:10.456219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:11.456418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:12.456747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:13.456942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:14.457120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:15.457304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:16.457600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:17.458148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:18.458436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:19.458613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:20.458795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:21.458978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:22.459470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:23.459643      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:24.459839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:25.460028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:26.460319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:27.460740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:17:28.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:17:28.460949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:29.461057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:30.461376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:31.461568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:32.462022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:33.462195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:34.462415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:35.462605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:36.462787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:37.463293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:38.463470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:39.463644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:40.463818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:41.464003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:42.464397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:43.464580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:44.464783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:45.464893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:46.465046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:47.465528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:17:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:17:48.466049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:49.466234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:50.466419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:51.466545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:52.466888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:53.467014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:54.467199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:55.467378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:56.467561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:57.468083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:58.469141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:17:59.469326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:00.469460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:01.469653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:02.470574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:03.470689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:04.470820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:05.471015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:06.471205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:07.471737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:18:08.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:18:08.472324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:09.472542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:10.472736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:11.472954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:12.473368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:13.473554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:14.473746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:15.473870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:16.474770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:17.475367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:18.475743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:19.475928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:20.476054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:21.476250      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:22.476510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:23.476629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:24.477324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:25.477538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:26.477726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:27.478272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:18:28.306: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:18:28.478322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:29.478523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:30.478706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:31.478885      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:32.479010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:33.479134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:34.479310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:35.479435      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:36.479614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:37.480085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:38.480394      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:39.480518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:40.480714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:41.480834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:42.481119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:43.482115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:44.482311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:45.483003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:46.482789      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:47.483573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:18:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:18:48.483733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:49.483927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:50.484123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:51.484302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:52.484511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:53.484702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:54.484825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:55.485032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:56.485215      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:57.485721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:58.486485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:18:59.486670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:00.486802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:01.486972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:02.487418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:03.487818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:04.487949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:05.488069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:06.488260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:07.489348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:19:08.306: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:19:08.489942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:09.490090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:10.490194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:11.490392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:12.490529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:13.490720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:14.490902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:15.491083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:16.491159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:17.491718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:18.491897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:19.492080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:20.492271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:21.492479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:22.492982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:23.493176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:24.493279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:25.493465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:26.493658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:27.494076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:19:28.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:19:28.495045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:29.495231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:30.495413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:31.495537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:32.495840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:33.496037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:34.496224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:35.496409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:36.496591      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:37.497123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:38.497303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:39.498123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:40.498298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:41.498419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:42.498524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:43.498638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:44.498816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:45.498997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:46.499182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:47.499679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:19:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:19:48.500258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:49.500451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:50.500668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:51.500794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:52.501047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:53.501232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:54.501361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:55.501547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:56.502112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:57.502577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:58.502695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:19:59.502898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:00.503115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:01.503295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:02.503513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:03.503710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:04.503898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:05.504074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:06.504266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:07.504482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:20:08.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:20:08.505550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:09.505741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:10.505921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:11.506042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:12.506543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:13.506763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:14.506952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:15.507070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:16.507174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:17.507665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:18.507910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:19.508340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:20.508469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:21.508636      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:22.508948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:23.509136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:24.509311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:25.509496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:26.509691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:27.510554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:20:28.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:20:28.511016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:29.511202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:30.511335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:31.511516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:32.511772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:33.511886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:34.512062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:35.512234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:36.512411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:37.512533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:38.512643      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:39.512819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:40.512973      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:41.513162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:42.513266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:43.513446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:44.514247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:45.514363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:46.514820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:47.515580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:20:48.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:20:48.516342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:49.516517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:50.516691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:51.516873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:52.517031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:53.518115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:54.518232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:55.518398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:56.519049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:57.519438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:58.520059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:20:59.520230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:00.520402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:01.520520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:02.520798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:03.521003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:04.521186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:05.521361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:06.521702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:07.521995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:08.307: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI1OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0207 15:21:08.522658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:09.522822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:10.523282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:11.523463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:12.523534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:13.523715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:14.523822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:15.523986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:16.524336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:17.524633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:18.524858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:19.525041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:20.526113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:21.526217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:22.527123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:23.527303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:24.527478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:25.527650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:26.528691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:27.528971      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:28.306: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  Feb  7 15:21:28.306: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 02/07/24 15:21:28.306
  STEP: retrieving all remaining pages @ 02/07/24 15:21:28.309
  Feb  7 15:21:28.312: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  Feb  7 15:21:28.315: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  Feb  7 15:21:28.318: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  Feb  7 15:21:28.321: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  Feb  7 15:21:28.324: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  Feb  7 15:21:28.327: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  Feb  7 15:21:28.330: INFO: Retrieved 40/40 results with rv 33595 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM1OTUsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  Feb  7 15:21:28.333: INFO: Retrieved 40/40 results with rv 33595 and continue 
  Feb  7 15:21:28.333: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6775" for this suite. @ 02/07/24 15:21:28.336
• [517.793 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 02/07/24 15:21:28.341
  Feb  7 15:21:28.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename webhook @ 02/07/24 15:21:28.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:21:28.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:21:28.354
  STEP: Setting up server cert @ 02/07/24 15:21:28.369
  E0207 15:21:28.529369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 02/07/24 15:21:28.817
  STEP: Deploying the webhook pod @ 02/07/24 15:21:28.824
  STEP: Wait for the deployment to be ready @ 02/07/24 15:21:28.832
  Feb  7 15:21:28.836: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0207 15:21:29.529478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:30.529681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:30.843: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:21:31.529775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:32.530116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:32.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:21:33.530747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:34.530819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:34.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:21:35.531542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:36.531822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:36.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.February, 7, 15, 21, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0207 15:21:37.532606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:38.532799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 15:21:38.847
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 15:21:38.856
  E0207 15:21:39.532904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:21:39.857: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 02/07/24 15:21:39.861
  STEP: create a namespace for the webhook @ 02/07/24 15:21:39.878
  STEP: create a configmap should be unconditionally rejected by the webhook @ 02/07/24 15:21:39.888
  Feb  7 15:21:39.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1296" for this suite. @ 02/07/24 15:21:39.937
  STEP: Destroying namespace "webhook-markers-2166" for this suite. @ 02/07/24 15:21:39.942
  STEP: Destroying namespace "fail-closed-namespace-3858" for this suite. @ 02/07/24 15:21:39.945
• [11.609 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 02/07/24 15:21:39.951
  Feb  7 15:21:39.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename hostport @ 02/07/24 15:21:39.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:21:39.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:21:39.962
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 02/07/24 15:21:39.967
  E0207 15:21:40.533907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:41.534091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.0.58.191 on the node which pod1 resides and expect scheduled @ 02/07/24 15:21:41.977
  E0207 15:21:42.534188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:43.534377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:44.534458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:45.534591      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:46.534885      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:47.534994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:48.535906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:49.536016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:50.536072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:51.536278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:52.537310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:53.537412      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.0.58.191 but use UDP protocol on the node which pod2 resides @ 02/07/24 15:21:54
  E0207 15:21:54.538367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:55.538461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:56.538841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:57.539118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 02/07/24 15:21:58.019
  Feb  7 15:21:58.019: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.0.58.191 http://127.0.0.1:54323/hostname] Namespace:hostport-9587 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:21:58.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:21:58.020: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:21:58.020: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-9587/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.0.58.191+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.58.191, port: 54323 @ 02/07/24 15:21:58.081
  Feb  7 15:21:58.081: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.0.58.191:54323/hostname] Namespace:hostport-9587 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:21:58.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:21:58.081: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:21:58.081: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-9587/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.0.58.191%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.58.191, port: 54323 UDP @ 02/07/24 15:21:58.155
  Feb  7 15:21:58.155: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.0.58.191 54323] Namespace:hostport-9587 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:21:58.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:21:58.155: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:21:58.155: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-9587/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.0.58.191+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0207 15:21:58.540114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:21:59.540311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:00.540500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:01.540713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:02.541036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:22:03.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-9587" for this suite. @ 02/07/24 15:22:03.227
• [23.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 02/07/24 15:22:03.232
  Feb  7 15:22:03.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 15:22:03.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:22:03.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:22:03.245
  STEP: Creating projection with secret that has name projected-secret-test-map-c8f99c88-80a0-45cb-a69a-47aafd343afb @ 02/07/24 15:22:03.248
  STEP: Creating a pod to test consume secrets @ 02/07/24 15:22:03.251
  E0207 15:22:03.541829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:04.541948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:05.542689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:06.543062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:22:07.266
  Feb  7 15:22:07.268: INFO: Trying to get logs from node worker-0 pod pod-projected-secrets-0983eac6-2690-4ac0-995d-39be39a21931 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 15:22:07.283
  Feb  7 15:22:07.293: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6689" for this suite. @ 02/07/24 15:22:07.295
• [4.067 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 02/07/24 15:22:07.299
  Feb  7 15:22:07.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replicaset @ 02/07/24 15:22:07.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:22:07.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:22:07.312
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 02/07/24 15:22:07.314
  Feb  7 15:22:07.322: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0207 15:22:07.543727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:08.544173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:09.544380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:10.544563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:11.544661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:22:12.326: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 02/07/24 15:22:12.326
  STEP: getting scale subresource @ 02/07/24 15:22:12.326
  STEP: updating a scale subresource @ 02/07/24 15:22:12.328
  STEP: verifying the replicaset Spec.Replicas was modified @ 02/07/24 15:22:12.332
  STEP: Patch a scale subresource @ 02/07/24 15:22:12.334
  Feb  7 15:22:12.340: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-637" for this suite. @ 02/07/24 15:22:12.345
• [5.052 seconds]
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 02/07/24 15:22:12.351
  Feb  7 15:22:12.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 15:22:12.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:22:12.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:22:12.369
  STEP: create the rc @ 02/07/24 15:22:12.374
  W0207 15:22:12.378289      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0207 15:22:12.546640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:13.548501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:14.550635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:15.552691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:16.553370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:17.555140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 02/07/24 15:22:18.382
  STEP: wait for the rc to be deleted @ 02/07/24 15:22:18.387
  E0207 15:22:18.556126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:19.556504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:20.556697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:21.556904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:22.557333      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 02/07/24 15:22:23.39
  E0207 15:22:23.558288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:24.558485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:25.558683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:26.558874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:27.559182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:28.559470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:29.559652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:30.559783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:31.559963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:32.560290      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:33.560469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:34.560661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:35.560845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:36.561231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:37.561498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:38.561681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:39.561874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:40.562055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:41.562187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:42.562501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:43.562696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:44.562888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:45.563078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:46.563588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:47.563562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:48.563662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:49.563757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:50.563949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:51.564177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:52.564518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/07/24 15:22:53.4
  W0207 15:22:53.404256      23 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb  7 15:22:53.404: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb  7 15:22:53.404: INFO: Deleting pod "simpletest.rc-26wnp" in namespace "gc-4502"
  Feb  7 15:22:53.412: INFO: Deleting pod "simpletest.rc-2qjgz" in namespace "gc-4502"
  Feb  7 15:22:53.420: INFO: Deleting pod "simpletest.rc-2vxfn" in namespace "gc-4502"
  Feb  7 15:22:53.427: INFO: Deleting pod "simpletest.rc-49q2q" in namespace "gc-4502"
  Feb  7 15:22:53.434: INFO: Deleting pod "simpletest.rc-595nn" in namespace "gc-4502"
  Feb  7 15:22:53.442: INFO: Deleting pod "simpletest.rc-599r7" in namespace "gc-4502"
  Feb  7 15:22:53.450: INFO: Deleting pod "simpletest.rc-5g8fj" in namespace "gc-4502"
  Feb  7 15:22:53.461: INFO: Deleting pod "simpletest.rc-5qfql" in namespace "gc-4502"
  Feb  7 15:22:53.470: INFO: Deleting pod "simpletest.rc-5qz9l" in namespace "gc-4502"
  Feb  7 15:22:53.481: INFO: Deleting pod "simpletest.rc-65qpx" in namespace "gc-4502"
  Feb  7 15:22:53.490: INFO: Deleting pod "simpletest.rc-6rphz" in namespace "gc-4502"
  Feb  7 15:22:53.499: INFO: Deleting pod "simpletest.rc-6xnc2" in namespace "gc-4502"
  Feb  7 15:22:53.509: INFO: Deleting pod "simpletest.rc-746gs" in namespace "gc-4502"
  Feb  7 15:22:53.520: INFO: Deleting pod "simpletest.rc-76v7n" in namespace "gc-4502"
  Feb  7 15:22:53.531: INFO: Deleting pod "simpletest.rc-77dh9" in namespace "gc-4502"
  Feb  7 15:22:53.542: INFO: Deleting pod "simpletest.rc-7bblx" in namespace "gc-4502"
  Feb  7 15:22:53.554: INFO: Deleting pod "simpletest.rc-7bqqn" in namespace "gc-4502"
  Feb  7 15:22:53.567: INFO: Deleting pod "simpletest.rc-7mx2c" in namespace "gc-4502"
  E0207 15:22:53.569062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:22:53.579: INFO: Deleting pod "simpletest.rc-7s674" in namespace "gc-4502"
  Feb  7 15:22:53.595: INFO: Deleting pod "simpletest.rc-8d5w2" in namespace "gc-4502"
  Feb  7 15:22:53.607: INFO: Deleting pod "simpletest.rc-8m4vr" in namespace "gc-4502"
  Feb  7 15:22:53.616: INFO: Deleting pod "simpletest.rc-8vswf" in namespace "gc-4502"
  Feb  7 15:22:53.627: INFO: Deleting pod "simpletest.rc-8zhpg" in namespace "gc-4502"
  Feb  7 15:22:53.637: INFO: Deleting pod "simpletest.rc-9bkjc" in namespace "gc-4502"
  Feb  7 15:22:53.646: INFO: Deleting pod "simpletest.rc-9p89p" in namespace "gc-4502"
  Feb  7 15:22:53.654: INFO: Deleting pod "simpletest.rc-b28v9" in namespace "gc-4502"
  Feb  7 15:22:53.661: INFO: Deleting pod "simpletest.rc-cjvgz" in namespace "gc-4502"
  Feb  7 15:22:53.670: INFO: Deleting pod "simpletest.rc-cl8q4" in namespace "gc-4502"
  Feb  7 15:22:53.684: INFO: Deleting pod "simpletest.rc-d5nz6" in namespace "gc-4502"
  Feb  7 15:22:53.693: INFO: Deleting pod "simpletest.rc-db7xn" in namespace "gc-4502"
  Feb  7 15:22:53.705: INFO: Deleting pod "simpletest.rc-dfmqw" in namespace "gc-4502"
  Feb  7 15:22:53.721: INFO: Deleting pod "simpletest.rc-dktk2" in namespace "gc-4502"
  Feb  7 15:22:53.733: INFO: Deleting pod "simpletest.rc-dt67v" in namespace "gc-4502"
  Feb  7 15:22:53.744: INFO: Deleting pod "simpletest.rc-dtgr2" in namespace "gc-4502"
  Feb  7 15:22:53.752: INFO: Deleting pod "simpletest.rc-dv6fd" in namespace "gc-4502"
  Feb  7 15:22:53.762: INFO: Deleting pod "simpletest.rc-dv6qs" in namespace "gc-4502"
  Feb  7 15:22:53.782: INFO: Deleting pod "simpletest.rc-f6lpx" in namespace "gc-4502"
  Feb  7 15:22:53.788: INFO: Deleting pod "simpletest.rc-f9vcr" in namespace "gc-4502"
  Feb  7 15:22:53.801: INFO: Deleting pod "simpletest.rc-frgsz" in namespace "gc-4502"
  Feb  7 15:22:53.813: INFO: Deleting pod "simpletest.rc-fsbmn" in namespace "gc-4502"
  Feb  7 15:22:53.825: INFO: Deleting pod "simpletest.rc-g78dc" in namespace "gc-4502"
  Feb  7 15:22:53.831: INFO: Deleting pod "simpletest.rc-ghfwz" in namespace "gc-4502"
  Feb  7 15:22:53.839: INFO: Deleting pod "simpletest.rc-glwx7" in namespace "gc-4502"
  Feb  7 15:22:53.848: INFO: Deleting pod "simpletest.rc-h54wv" in namespace "gc-4502"
  Feb  7 15:22:53.855: INFO: Deleting pod "simpletest.rc-hfxhd" in namespace "gc-4502"
  Feb  7 15:22:53.864: INFO: Deleting pod "simpletest.rc-hhcbh" in namespace "gc-4502"
  Feb  7 15:22:53.885: INFO: Deleting pod "simpletest.rc-hjthn" in namespace "gc-4502"
  Feb  7 15:22:53.897: INFO: Deleting pod "simpletest.rc-j4sd4" in namespace "gc-4502"
  Feb  7 15:22:53.909: INFO: Deleting pod "simpletest.rc-j9xnx" in namespace "gc-4502"
  Feb  7 15:22:53.925: INFO: Deleting pod "simpletest.rc-ksrws" in namespace "gc-4502"
  Feb  7 15:22:53.938: INFO: Deleting pod "simpletest.rc-kvf4w" in namespace "gc-4502"
  Feb  7 15:22:53.946: INFO: Deleting pod "simpletest.rc-kzcjk" in namespace "gc-4502"
  Feb  7 15:22:53.957: INFO: Deleting pod "simpletest.rc-lb2fb" in namespace "gc-4502"
  Feb  7 15:22:53.965: INFO: Deleting pod "simpletest.rc-lwh55" in namespace "gc-4502"
  Feb  7 15:22:53.976: INFO: Deleting pod "simpletest.rc-lzb6v" in namespace "gc-4502"
  Feb  7 15:22:53.985: INFO: Deleting pod "simpletest.rc-mb57g" in namespace "gc-4502"
  Feb  7 15:22:53.995: INFO: Deleting pod "simpletest.rc-mkk4p" in namespace "gc-4502"
  Feb  7 15:22:54.006: INFO: Deleting pod "simpletest.rc-mlwbq" in namespace "gc-4502"
  Feb  7 15:22:54.014: INFO: Deleting pod "simpletest.rc-mnswk" in namespace "gc-4502"
  Feb  7 15:22:54.021: INFO: Deleting pod "simpletest.rc-n8zfk" in namespace "gc-4502"
  Feb  7 15:22:54.033: INFO: Deleting pod "simpletest.rc-nhqs2" in namespace "gc-4502"
  Feb  7 15:22:54.055: INFO: Deleting pod "simpletest.rc-nmth8" in namespace "gc-4502"
  Feb  7 15:22:54.105: INFO: Deleting pod "simpletest.rc-nsn2l" in namespace "gc-4502"
  Feb  7 15:22:54.153: INFO: Deleting pod "simpletest.rc-nxjjx" in namespace "gc-4502"
  Feb  7 15:22:54.200: INFO: Deleting pod "simpletest.rc-p2cgq" in namespace "gc-4502"
  Feb  7 15:22:54.249: INFO: Deleting pod "simpletest.rc-ppl5p" in namespace "gc-4502"
  Feb  7 15:22:54.301: INFO: Deleting pod "simpletest.rc-pwj8q" in namespace "gc-4502"
  Feb  7 15:22:54.356: INFO: Deleting pod "simpletest.rc-px7p9" in namespace "gc-4502"
  Feb  7 15:22:54.399: INFO: Deleting pod "simpletest.rc-pzg6s" in namespace "gc-4502"
  Feb  7 15:22:54.450: INFO: Deleting pod "simpletest.rc-q52dq" in namespace "gc-4502"
  Feb  7 15:22:54.502: INFO: Deleting pod "simpletest.rc-q7l6w" in namespace "gc-4502"
  Feb  7 15:22:54.553: INFO: Deleting pod "simpletest.rc-qv7z8" in namespace "gc-4502"
  E0207 15:22:54.568808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:22:54.605: INFO: Deleting pod "simpletest.rc-qwjpz" in namespace "gc-4502"
  Feb  7 15:22:54.650: INFO: Deleting pod "simpletest.rc-qx6n2" in namespace "gc-4502"
  Feb  7 15:22:54.705: INFO: Deleting pod "simpletest.rc-r4qrz" in namespace "gc-4502"
  Feb  7 15:22:54.751: INFO: Deleting pod "simpletest.rc-r6nzl" in namespace "gc-4502"
  Feb  7 15:22:54.800: INFO: Deleting pod "simpletest.rc-r96xd" in namespace "gc-4502"
  Feb  7 15:22:54.851: INFO: Deleting pod "simpletest.rc-rc9b2" in namespace "gc-4502"
  Feb  7 15:22:54.904: INFO: Deleting pod "simpletest.rc-rfwc7" in namespace "gc-4502"
  Feb  7 15:22:54.952: INFO: Deleting pod "simpletest.rc-rsst4" in namespace "gc-4502"
  Feb  7 15:22:55.010: INFO: Deleting pod "simpletest.rc-rwb82" in namespace "gc-4502"
  Feb  7 15:22:55.056: INFO: Deleting pod "simpletest.rc-rzmpr" in namespace "gc-4502"
  Feb  7 15:22:55.099: INFO: Deleting pod "simpletest.rc-ssgkw" in namespace "gc-4502"
  Feb  7 15:22:55.153: INFO: Deleting pod "simpletest.rc-vfg9t" in namespace "gc-4502"
  Feb  7 15:22:55.209: INFO: Deleting pod "simpletest.rc-vwvn6" in namespace "gc-4502"
  Feb  7 15:22:55.249: INFO: Deleting pod "simpletest.rc-vxgxk" in namespace "gc-4502"
  Feb  7 15:22:55.305: INFO: Deleting pod "simpletest.rc-w2fl8" in namespace "gc-4502"
  Feb  7 15:22:55.350: INFO: Deleting pod "simpletest.rc-wgb7r" in namespace "gc-4502"
  Feb  7 15:22:55.411: INFO: Deleting pod "simpletest.rc-wl7hv" in namespace "gc-4502"
  Feb  7 15:22:55.451: INFO: Deleting pod "simpletest.rc-x65cn" in namespace "gc-4502"
  Feb  7 15:22:55.499: INFO: Deleting pod "simpletest.rc-x7xrf" in namespace "gc-4502"
  Feb  7 15:22:55.561: INFO: Deleting pod "simpletest.rc-xfj2x" in namespace "gc-4502"
  E0207 15:22:55.569183      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:22:55.601: INFO: Deleting pod "simpletest.rc-xhr9x" in namespace "gc-4502"
  Feb  7 15:22:55.651: INFO: Deleting pod "simpletest.rc-xllc2" in namespace "gc-4502"
  Feb  7 15:22:55.701: INFO: Deleting pod "simpletest.rc-xm9cw" in namespace "gc-4502"
  Feb  7 15:22:55.750: INFO: Deleting pod "simpletest.rc-xpt2j" in namespace "gc-4502"
  Feb  7 15:22:55.805: INFO: Deleting pod "simpletest.rc-xsxdl" in namespace "gc-4502"
  Feb  7 15:22:55.850: INFO: Deleting pod "simpletest.rc-xtzxw" in namespace "gc-4502"
  Feb  7 15:22:55.901: INFO: Deleting pod "simpletest.rc-xzslk" in namespace "gc-4502"
  Feb  7 15:22:55.955: INFO: Deleting pod "simpletest.rc-zm7rd" in namespace "gc-4502"
  Feb  7 15:22:56.000: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4502" for this suite. @ 02/07/24 15:22:56.044
• [43.747 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 02/07/24 15:22:56.098
  Feb  7 15:22:56.098: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename job @ 02/07/24 15:22:56.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:22:56.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:22:56.115
  STEP: Creating a job @ 02/07/24 15:22:56.118
  STEP: Ensuring job reaches completions @ 02/07/24 15:22:56.124
  E0207 15:22:56.569294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:57.569587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:58.570374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:22:59.570557      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:00.571058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:01.571358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:02.571998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:03.572205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:04.572889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:05.573142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:23:06.127: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5112" for this suite. @ 02/07/24 15:23:06.129
• [10.034 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 02/07/24 15:23:06.133
  Feb  7 15:23:06.133: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-probe @ 02/07/24 15:23:06.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:23:06.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:23:06.145
  E0207 15:23:06.574064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:07.575182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:08.575524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:09.576214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:10.577009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:11.577940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:12.578950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:13.579296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:14.579941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:15.580595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:16.580834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:17.581423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:18.581534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:19.581881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:20.582108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:21.583147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:22.583990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:23.584701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:24.584802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:25.584879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:26.585549      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:27.586101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:28.586864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:29.587542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:30.587682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:31.588737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:32.589540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:33.590311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:34.591092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:35.591640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:36.592396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:37.593147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:38.593908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:39.594574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:40.595114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:41.595167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:42.595817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:43.596737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:44.596866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:45.597397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:46.598220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:47.598878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:48.599631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:49.600355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:50.600443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:51.601529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:52.601861      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:53.602499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:54.603112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:55.603202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:56.603865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:57.604369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:58.605028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:23:59.605683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:00.605836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:01.606935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:02.607687      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:03.608323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:04.609040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:05.609477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:06.155: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1126" for this suite. @ 02/07/24 15:24:06.158
• [60.028 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 02/07/24 15:24:06.162
  Feb  7 15:24:06.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 15:24:06.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:06.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:06.175
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-2428 @ 02/07/24 15:24:06.178
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 02/07/24 15:24:06.19
  STEP: creating service externalsvc in namespace services-2428 @ 02/07/24 15:24:06.19
  STEP: creating replication controller externalsvc in namespace services-2428 @ 02/07/24 15:24:06.202
  I0207 15:24:06.208608      23 runners.go:197] Created replication controller with name: externalsvc, namespace: services-2428, replica count: 2
  E0207 15:24:06.610437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:07.610983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:08.611115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 15:24:09.259923      23 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 02/07/24 15:24:09.262
  Feb  7 15:24:09.277: INFO: Creating new exec pod
  E0207 15:24:09.612113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:10.612340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:11.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-2428 exec execpodhr5gw -- /bin/sh -x -c nslookup nodeport-service.services-2428.svc.cluster.local'
  Feb  7 15:24:11.424: INFO: stderr: "+ nslookup nodeport-service.services-2428.svc.cluster.local\n"
  Feb  7 15:24:11.424: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-2428.svc.cluster.local\tcanonical name = externalsvc.services-2428.svc.cluster.local.\nName:\texternalsvc.services-2428.svc.cluster.local\nAddress: 10.101.21.102\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-2428, will wait for the garbage collector to delete the pods @ 02/07/24 15:24:11.424
  Feb  7 15:24:11.482: INFO: Deleting ReplicationController externalsvc took: 4.954934ms
  Feb  7 15:24:11.582: INFO: Terminating ReplicationController externalsvc pods took: 100.100951ms
  E0207 15:24:11.613018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:12.613653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:13.614370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:14.614898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:14.797: INFO: Cleaning up the NodePort to ExternalName test service
  Feb  7 15:24:14.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2428" for this suite. @ 02/07/24 15:24:14.806
• [8.649 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 02/07/24 15:24:14.811
  Feb  7 15:24:14.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 15:24:14.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:14.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:14.822
  STEP: creating service nodeport-test with type=NodePort in namespace services-839 @ 02/07/24 15:24:14.825
  STEP: creating replication controller nodeport-test in namespace services-839 @ 02/07/24 15:24:14.838
  I0207 15:24:14.842806      23 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-839, replica count: 2
  E0207 15:24:15.615065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:16.615472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:17.615847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 15:24:17.893202      23 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 15:24:17.893: INFO: Creating new exec pod
  E0207 15:24:18.615972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:19.616187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:20.616526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:20.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  E0207 15:24:21.616828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:22.617411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:23.028: INFO: rc: 1
  Feb  7 15:24:23.028: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 nodeport-test 80
  nc: connect to nodeport-test port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 15:24:23.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Feb  7 15:24:23.141: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Feb  7 15:24:23.141: INFO: stdout: "nodeport-test-2xhp2"
  Feb  7 15:24:23.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.16.11 80'
  E0207 15:24:23.617548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:24.618497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:25.252: INFO: rc: 1
  Feb  7 15:24:25.252: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.16.11 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.108.16.11 80
  nc: connect to 10.108.16.11 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 15:24:25.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.16.11 80'
  Feb  7 15:24:25.364: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.16.11 80\nConnection to 10.108.16.11 80 port [tcp/http] succeeded!\n"
  Feb  7 15:24:25.364: INFO: stdout: "nodeport-test-2xhp2"
  Feb  7 15:24:25.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.60.182 32527'
  Feb  7 15:24:25.476: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.60.182 32527\nConnection to 10.0.60.182 32527 port [tcp/*] succeeded!\n"
  Feb  7 15:24:25.476: INFO: stdout: "nodeport-test-2xhp2"
  Feb  7 15:24:25.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 32527'
  E0207 15:24:25.619326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:26.619758      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:27.598: INFO: rc: 1
  Feb  7 15:24:27.598: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 32527:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.0.58.191 32527
  nc: connect to 10.0.58.191 port 32527 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 15:24:27.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 32527'
  E0207 15:24:27.619804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:28.620662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:29.621041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:29.717: INFO: rc: 1
  Feb  7 15:24:29.717: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 32527:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.0.58.191 32527
  nc: connect to 10.0.58.191 port 32527 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Feb  7 15:24:29.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-839 exec execpod5ds9k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 32527'
  Feb  7 15:24:29.829: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.58.191 32527\nConnection to 10.0.58.191 32527 port [tcp/*] succeeded!\n"
  Feb  7 15:24:29.829: INFO: stdout: "nodeport-test-9vw95"
  Feb  7 15:24:29.829: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-839" for this suite. @ 02/07/24 15:24:29.832
• [15.025 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 02/07/24 15:24:29.836
  Feb  7 15:24:29.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 15:24:29.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:29.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:29.85
  STEP: Creating configMap with name projected-configmap-test-volume-10f7b899-092a-48ab-8b05-3c4eaa63c85a @ 02/07/24 15:24:29.853
  STEP: Creating a pod to test consume configMaps @ 02/07/24 15:24:29.856
  E0207 15:24:30.621454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:31.621659      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:24:31.868
  Feb  7 15:24:31.870: INFO: Trying to get logs from node worker-1 pod pod-projected-configmaps-ede173df-6ccd-4dad-81d8-fd8e12a08bac container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 15:24:31.884
  Feb  7 15:24:31.894: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8718" for this suite. @ 02/07/24 15:24:31.896
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 02/07/24 15:24:31.901
  Feb  7 15:24:31.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-webhook @ 02/07/24 15:24:31.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:31.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:31.911
  STEP: Setting up server cert @ 02/07/24 15:24:31.914
  E0207 15:24:32.621944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 02/07/24 15:24:32.623
  STEP: Deploying the custom resource conversion webhook pod @ 02/07/24 15:24:32.628
  STEP: Wait for the deployment to be ready @ 02/07/24 15:24:32.638
  Feb  7 15:24:32.644: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0207 15:24:33.622611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:34.622813      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 02/07/24 15:24:34.651
  STEP: Verifying the service has paired with the endpoint @ 02/07/24 15:24:34.671
  E0207 15:24:35.622937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:35.672: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Feb  7 15:24:35.676: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 15:24:36.623814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:37.624085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 02/07/24 15:24:38.211
  STEP: Create a v2 custom resource @ 02/07/24 15:24:38.224
  STEP: List CRs in v1 @ 02/07/24 15:24:38.254
  STEP: List CRs in v2 @ 02/07/24 15:24:38.261
  E0207 15:24:38.624586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:24:38.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-6312" for this suite. @ 02/07/24 15:24:38.807
• [6.912 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 02/07/24 15:24:38.816
  Feb  7 15:24:38.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 15:24:38.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:38.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:38.829
  STEP: Create a pod @ 02/07/24 15:24:38.832
  E0207 15:24:39.624675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:40.624829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 02/07/24 15:24:40.842
  Feb  7 15:24:40.849: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Feb  7 15:24:40.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-441" for this suite. @ 02/07/24 15:24:40.852
• [2.040 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 02/07/24 15:24:40.856
  Feb  7 15:24:40.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 02/07/24 15:24:40.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:40.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:40.867
  STEP: creating a target pod @ 02/07/24 15:24:40.87
  E0207 15:24:41.624994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:42.625486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 02/07/24 15:24:42.883
  E0207 15:24:43.626225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:44.626461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 02/07/24 15:24:44.9
  Feb  7 15:24:44.900: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-59 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:24:44.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:24:44.901: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:24:44.901: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-59/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Feb  7 15:24:44.965: INFO: Exec stderr: ""
  Feb  7 15:24:44.977: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-59" for this suite. @ 02/07/24 15:24:44.979
• [4.127 seconds]
------------------------------
S
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 02/07/24 15:24:44.983
  Feb  7 15:24:44.983: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 15:24:44.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:44.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:44.996
  STEP: creating a Service @ 02/07/24 15:24:45.001
  STEP: watching for the Service to be added @ 02/07/24 15:24:45.013
  Feb  7 15:24:45.015: INFO: Found Service test-service-8xmhn in namespace services-9689 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32389}]
  Feb  7 15:24:45.015: INFO: Service test-service-8xmhn created
  STEP: Getting /status @ 02/07/24 15:24:45.015
  Feb  7 15:24:45.017: INFO: Service test-service-8xmhn has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 02/07/24 15:24:45.017
  STEP: watching for the Service to be patched @ 02/07/24 15:24:45.022
  Feb  7 15:24:45.023: INFO: observed Service test-service-8xmhn in namespace services-9689 with annotations: map[] & LoadBalancer: {[]}
  Feb  7 15:24:45.023: INFO: Found Service test-service-8xmhn in namespace services-9689 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  Feb  7 15:24:45.023: INFO: Service test-service-8xmhn has service status patched
  STEP: updating the ServiceStatus @ 02/07/24 15:24:45.023
  Feb  7 15:24:45.029: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 02/07/24 15:24:45.029
  Feb  7 15:24:45.031: INFO: Observed Service test-service-8xmhn in namespace services-9689 with annotations: map[] & Conditions: {[]}
  Feb  7 15:24:45.031: INFO: Observed event: &Service{ObjectMeta:{test-service-8xmhn  services-9689  1397d274-94b8-4213-8a0b-8ec3bc2d1e10 36879 0 2024-02-07 15:24:45 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-02-07 15:24:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-02-07 15:24:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:32389,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.104.115.248,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.104.115.248],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Feb  7 15:24:45.031: INFO: Found Service test-service-8xmhn in namespace services-9689 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Feb  7 15:24:45.031: INFO: Service test-service-8xmhn has service status updated
  STEP: patching the service @ 02/07/24 15:24:45.031
  STEP: watching for the Service to be patched @ 02/07/24 15:24:45.044
  Feb  7 15:24:45.046: INFO: observed Service test-service-8xmhn in namespace services-9689 with labels: map[test-service-static:true]
  Feb  7 15:24:45.046: INFO: observed Service test-service-8xmhn in namespace services-9689 with labels: map[test-service-static:true]
  Feb  7 15:24:45.046: INFO: observed Service test-service-8xmhn in namespace services-9689 with labels: map[test-service-static:true]
  Feb  7 15:24:45.046: INFO: Found Service test-service-8xmhn in namespace services-9689 with labels: map[test-service:patched test-service-static:true]
  Feb  7 15:24:45.046: INFO: Service test-service-8xmhn patched
  STEP: deleting the service @ 02/07/24 15:24:45.046
  STEP: watching for the Service to be deleted @ 02/07/24 15:24:45.058
  Feb  7 15:24:45.059: INFO: Observed event: ADDED
  Feb  7 15:24:45.059: INFO: Observed event: MODIFIED
  Feb  7 15:24:45.059: INFO: Observed event: MODIFIED
  Feb  7 15:24:45.059: INFO: Observed event: MODIFIED
  Feb  7 15:24:45.059: INFO: Found Service test-service-8xmhn in namespace services-9689 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Feb  7 15:24:45.059: INFO: Service test-service-8xmhn deleted
  Feb  7 15:24:45.060: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9689" for this suite. @ 02/07/24 15:24:45.062
• [0.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 02/07/24 15:24:45.067
  Feb  7 15:24:45.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename endpointslice @ 02/07/24 15:24:45.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:24:45.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:24:45.078
  E0207 15:24:45.627370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:46.627723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:47.627633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:48.627843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:49.628037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 02/07/24 15:24:50.131
  E0207 15:24:50.628671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:51.628859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:52.629123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:53.629240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:54.629423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 02/07/24 15:24:55.137
  E0207 15:24:55.630275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:56.630886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:57.631139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:58.631326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:24:59.631531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 02/07/24 15:25:00.142
  E0207 15:25:00.632552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:01.632755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:02.633027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:03.633154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:04.633354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 02/07/24 15:25:05.148
  Feb  7 15:25:05.159: INFO: EndpointSlice for Service endpointslice-1617/example-named-port not found
  E0207 15:25:05.633464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:06.633913      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:07.634444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:08.634828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:09.634946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:10.635812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:11.636016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:12.636395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:13.636594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:14.636812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:15.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1617" for this suite. @ 02/07/24 15:25:15.166
• [30.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 02/07/24 15:25:15.171
  Feb  7 15:25:15.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename projected @ 02/07/24 15:25:15.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:15.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:15.183
  STEP: Creating secret with name projected-secret-test-21306493-a150-4e1e-9abe-cc51602326a4 @ 02/07/24 15:25:15.186
  STEP: Creating a pod to test consume secrets @ 02/07/24 15:25:15.189
  E0207 15:25:15.637570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:16.637934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:25:17.2
  Feb  7 15:25:17.202: INFO: Trying to get logs from node worker-0 pod pod-projected-secrets-12ece8cf-0855-473c-87c1-52e4714dfca7 container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 15:25:17.207
  Feb  7 15:25:17.218: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6634" for this suite. @ 02/07/24 15:25:17.221
• [2.054 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 02/07/24 15:25:17.225
  Feb  7 15:25:17.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 15:25:17.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:17.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:17.237
  STEP: Creating configMap with name configmap-test-volume-6766e5a5-8cfc-4bbf-ba91-7a75244969ce @ 02/07/24 15:25:17.24
  STEP: Creating a pod to test consume configMaps @ 02/07/24 15:25:17.243
  E0207 15:25:17.638042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:18.638157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:25:19.254
  Feb  7 15:25:19.256: INFO: Trying to get logs from node worker-0 pod pod-configmaps-71ba7306-a424-42be-b46e-38fa55c11b7a container agnhost-container: <nil>
  STEP: delete the pod @ 02/07/24 15:25:19.261
  Feb  7 15:25:19.272: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4395" for this suite. @ 02/07/24 15:25:19.274
• [2.053 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 02/07/24 15:25:19.278
  Feb  7 15:25:19.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename crd-publish-openapi @ 02/07/24 15:25:19.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:19.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:19.29
  Feb  7 15:25:19.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  E0207 15:25:19.639160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 02/07/24 15:25:20.556
  Feb  7 15:25:20.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-2370 --namespace=crd-publish-openapi-2370 create -f -'
  E0207 15:25:20.639766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:21.639875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:22.637: INFO: stderr: ""
  Feb  7 15:25:22.637: INFO: stdout: "e2e-test-crd-publish-openapi-6141-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Feb  7 15:25:22.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-2370 --namespace=crd-publish-openapi-2370 delete e2e-test-crd-publish-openapi-6141-crds test-cr'
  E0207 15:25:22.640433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:22.701: INFO: stderr: ""
  Feb  7 15:25:22.701: INFO: stdout: "e2e-test-crd-publish-openapi-6141-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Feb  7 15:25:22.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-2370 --namespace=crd-publish-openapi-2370 apply -f -'
  Feb  7 15:25:22.767: INFO: stderr: ""
  Feb  7 15:25:22.767: INFO: stdout: "e2e-test-crd-publish-openapi-6141-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Feb  7 15:25:22.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-2370 --namespace=crd-publish-openapi-2370 delete e2e-test-crd-publish-openapi-6141-crds test-cr'
  Feb  7 15:25:22.828: INFO: stderr: ""
  Feb  7 15:25:22.828: INFO: stdout: "e2e-test-crd-publish-openapi-6141-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 02/07/24 15:25:22.828
  Feb  7 15:25:22.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=crd-publish-openapi-2370 explain e2e-test-crd-publish-openapi-6141-crds'
  Feb  7 15:25:22.886: INFO: stderr: ""
  Feb  7 15:25:22.886: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-6141-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0207 15:25:23.641247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:24.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2370" for this suite. @ 02/07/24 15:25:24.182
• [4.909 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 02/07/24 15:25:24.187
  Feb  7 15:25:24.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename svcaccounts @ 02/07/24 15:25:24.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:24.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:24.198
  STEP: creating a ServiceAccount @ 02/07/24 15:25:24.201
  STEP: watching for the ServiceAccount to be added @ 02/07/24 15:25:24.207
  STEP: patching the ServiceAccount @ 02/07/24 15:25:24.209
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 02/07/24 15:25:24.213
  STEP: deleting the ServiceAccount @ 02/07/24 15:25:24.215
  Feb  7 15:25:24.221: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5041" for this suite. @ 02/07/24 15:25:24.224
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 02/07/24 15:25:24.229
  Feb  7 15:25:24.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 15:25:24.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:24.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:24.239
  STEP: Creating secret with name secret-test-686931c5-dbe1-45b8-b111-649ab454fc43 @ 02/07/24 15:25:24.242
  STEP: Creating a pod to test consume secrets @ 02/07/24 15:25:24.244
  E0207 15:25:24.642165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:25.642749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:25:26.256
  Feb  7 15:25:26.258: INFO: Trying to get logs from node worker-0 pod pod-secrets-c25a0867-bb08-4aff-bcbd-d7b92c872593 container secret-env-test: <nil>
  STEP: delete the pod @ 02/07/24 15:25:26.263
  Feb  7 15:25:26.273: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6194" for this suite. @ 02/07/24 15:25:26.276
• [2.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 02/07/24 15:25:26.279
  Feb  7 15:25:26.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 02/07/24 15:25:26.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:26.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:26.291
  STEP: creating a target pod @ 02/07/24 15:25:26.293
  E0207 15:25:26.643264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:27.643964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 02/07/24 15:25:28.305
  E0207 15:25:28.644892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:29.645018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 02/07/24 15:25:30.316
  Feb  7 15:25:30.316: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5111 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:25:30.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:25:30.316: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:25:30.316: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-5111/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Feb  7 15:25:30.377: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 02/07/24 15:25:30.382
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 02/07/24 15:25:30.384
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 02/07/24 15:25:30.392
  Feb  7 15:25:30.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5111" for this suite. @ 02/07/24 15:25:30.398
• [4.124 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 02/07/24 15:25:30.404
  Feb  7 15:25:30.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename secrets @ 02/07/24 15:25:30.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:30.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:30.417
  STEP: Creating secret with name secret-test-map-e3c13c28-de8e-42bb-8fcf-0d582bfa03a1 @ 02/07/24 15:25:30.419
  STEP: Creating a pod to test consume secrets @ 02/07/24 15:25:30.422
  E0207 15:25:30.645110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:31.645574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:32.645956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:33.646149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:25:34.436
  Feb  7 15:25:34.438: INFO: Trying to get logs from node worker-0 pod pod-secrets-428fa3b9-2516-4c57-ad11-871c55a36ead container secret-volume-test: <nil>
  STEP: delete the pod @ 02/07/24 15:25:34.443
  Feb  7 15:25:34.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4222" for this suite. @ 02/07/24 15:25:34.457
• [4.057 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 02/07/24 15:25:34.461
  Feb  7 15:25:34.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 15:25:34.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:34.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:34.474
  STEP: Creating a pod to test downward API volume plugin @ 02/07/24 15:25:34.477
  E0207 15:25:34.646811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:35.647499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:36.647815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:37.648751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:25:38.492
  Feb  7 15:25:38.494: INFO: Trying to get logs from node worker-1 pod downwardapi-volume-a57e507d-8375-4f3e-9448-1c6bda2bdc60 container client-container: <nil>
  STEP: delete the pod @ 02/07/24 15:25:38.499
  Feb  7 15:25:38.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7302" for this suite. @ 02/07/24 15:25:38.511
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 02/07/24 15:25:38.515
  Feb  7 15:25:38.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename subjectreview @ 02/07/24 15:25:38.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:38.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:38.528
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-8729" @ 02/07/24 15:25:38.531
  Feb  7 15:25:38.533: INFO: saUsername: "system:serviceaccount:subjectreview-8729:e2e"
  Feb  7 15:25:38.533: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-8729"}
  Feb  7 15:25:38.533: INFO: saUID: "d39ce404-bbc2-41bb-958a-9ea7fcedca99"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-8729:e2e" @ 02/07/24 15:25:38.533
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-8729:e2e" @ 02/07/24 15:25:38.534
  Feb  7 15:25:38.535: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-8729:e2e" api 'list' configmaps in "subjectreview-8729" namespace @ 02/07/24 15:25:38.535
  Feb  7 15:25:38.537: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-8729:e2e" @ 02/07/24 15:25:38.537
  Feb  7 15:25:38.539: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Feb  7 15:25:38.539: INFO: LocalSubjectAccessReview has been verified
  Feb  7 15:25:38.539: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-8729" for this suite. @ 02/07/24 15:25:38.541
• [0.029 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 02/07/24 15:25:38.545
  Feb  7 15:25:38.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename csi-storageclass @ 02/07/24 15:25:38.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:38.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:38.556
  STEP: Creating a StorageClass @ 02/07/24 15:25:38.558
  STEP: Get StorageClass "e2e-dw6cp" @ 02/07/24 15:25:38.561
  STEP: Patching the StorageClass "e2e-dw6cp" @ 02/07/24 15:25:38.563
  STEP: Delete StorageClass "e2e-dw6cp" @ 02/07/24 15:25:38.568
  STEP: Confirm deletion of StorageClass "e2e-dw6cp" @ 02/07/24 15:25:38.571
  STEP: Create a replacement StorageClass @ 02/07/24 15:25:38.573
  STEP: Updating StorageClass "e2e-v2-ctb49" @ 02/07/24 15:25:38.577
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-ctb49=updated" @ 02/07/24 15:25:38.581
  STEP: Deleting StorageClass "e2e-v2-ctb49" via DeleteCollection @ 02/07/24 15:25:38.583
  STEP: Confirm deletion of StorageClass "e2e-v2-ctb49" @ 02/07/24 15:25:38.587
  Feb  7 15:25:38.589: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-999" for this suite. @ 02/07/24 15:25:38.591
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 02/07/24 15:25:38.595
  Feb  7 15:25:38.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename namespaces @ 02/07/24 15:25:38.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:38.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:38.607
  STEP: Creating a test namespace @ 02/07/24 15:25:38.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:38.617
  STEP: Creating a pod in the namespace @ 02/07/24 15:25:38.62
  STEP: Waiting for the pod to have running status @ 02/07/24 15:25:38.625
  E0207 15:25:38.649667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:39.649993      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 02/07/24 15:25:40.629
  STEP: Waiting for the namespace to be removed. @ 02/07/24 15:25:40.634
  E0207 15:25:40.650506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:41.651127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:42.651850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:43.652876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:44.653032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:45.654013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:46.654096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:47.654706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:48.654936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:49.655404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:50.655991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 02/07/24 15:25:51.636
  STEP: Verifying there are no pods in the namespace @ 02/07/24 15:25:51.645
  Feb  7 15:25:51.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-496" for this suite. @ 02/07/24 15:25:51.649
  STEP: Destroying namespace "nsdeletetest-8673" for this suite. @ 02/07/24 15:25:51.654
  Feb  7 15:25:51.656: INFO: Namespace nsdeletetest-8673 was already deleted
  STEP: Destroying namespace "nsdeletetest-8346" for this suite. @ 02/07/24 15:25:51.656
  E0207 15:25:51.656150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
• [13.064 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 02/07/24 15:25:51.659
  Feb  7 15:25:51.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 15:25:51.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:25:51.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:25:51.672
  STEP: creating a replication controller @ 02/07/24 15:25:51.675
  Feb  7 15:25:51.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 create -f -'
  Feb  7 15:25:51.794: INFO: stderr: ""
  Feb  7 15:25:51.794: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/07/24 15:25:51.794
  Feb  7 15:25:51.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 15:25:51.863: INFO: stderr: ""
  Feb  7 15:25:51.863: INFO: stdout: "update-demo-nautilus-bsbrv update-demo-nautilus-l269h "
  Feb  7 15:25:51.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:25:51.924: INFO: stderr: ""
  Feb  7 15:25:51.924: INFO: stdout: ""
  Feb  7 15:25:51.924: INFO: update-demo-nautilus-bsbrv is created but not running
  E0207 15:25:52.656327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:53.656810      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:54.657042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:55.657120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:25:56.657623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:56.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 15:25:56.988: INFO: stderr: ""
  Feb  7 15:25:56.988: INFO: stdout: "update-demo-nautilus-bsbrv update-demo-nautilus-l269h "
  Feb  7 15:25:56.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:25:57.052: INFO: stderr: ""
  Feb  7 15:25:57.052: INFO: stdout: "true"
  Feb  7 15:25:57.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 15:25:57.108: INFO: stderr: ""
  Feb  7 15:25:57.108: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 15:25:57.108: INFO: validating pod update-demo-nautilus-bsbrv
  Feb  7 15:25:57.114: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 15:25:57.114: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 15:25:57.114: INFO: update-demo-nautilus-bsbrv is verified up and running
  Feb  7 15:25:57.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-l269h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:25:57.170: INFO: stderr: ""
  Feb  7 15:25:57.170: INFO: stdout: "true"
  Feb  7 15:25:57.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-l269h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 15:25:57.229: INFO: stderr: ""
  Feb  7 15:25:57.229: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 15:25:57.229: INFO: validating pod update-demo-nautilus-l269h
  Feb  7 15:25:57.234: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 15:25:57.234: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 15:25:57.234: INFO: update-demo-nautilus-l269h is verified up and running
  STEP: scaling down the replication controller @ 02/07/24 15:25:57.234
  Feb  7 15:25:57.236: INFO: scanned /root for discovery docs: <nil>
  Feb  7 15:25:57.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0207 15:25:57.658336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:58.308: INFO: stderr: ""
  Feb  7 15:25:58.308: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/07/24 15:25:58.308
  Feb  7 15:25:58.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 15:25:58.368: INFO: stderr: ""
  Feb  7 15:25:58.368: INFO: stdout: "update-demo-nautilus-bsbrv "
  Feb  7 15:25:58.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:25:58.425: INFO: stderr: ""
  Feb  7 15:25:58.425: INFO: stdout: "true"
  Feb  7 15:25:58.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 15:25:58.484: INFO: stderr: ""
  Feb  7 15:25:58.484: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 15:25:58.484: INFO: validating pod update-demo-nautilus-bsbrv
  Feb  7 15:25:58.487: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 15:25:58.487: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 15:25:58.488: INFO: update-demo-nautilus-bsbrv is verified up and running
  STEP: scaling up the replication controller @ 02/07/24 15:25:58.488
  Feb  7 15:25:58.489: INFO: scanned /root for discovery docs: <nil>
  Feb  7 15:25:58.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0207 15:25:58.658823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:59.557: INFO: stderr: ""
  Feb  7 15:25:59.557: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 02/07/24 15:25:59.557
  Feb  7 15:25:59.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 15:25:59.619: INFO: stderr: ""
  Feb  7 15:25:59.619: INFO: stdout: "update-demo-nautilus-bsbrv update-demo-nautilus-gsg7g "
  Feb  7 15:25:59.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0207 15:25:59.659722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:25:59.675: INFO: stderr: ""
  Feb  7 15:25:59.675: INFO: stdout: "true"
  Feb  7 15:25:59.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 15:25:59.732: INFO: stderr: ""
  Feb  7 15:25:59.732: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 15:25:59.732: INFO: validating pod update-demo-nautilus-bsbrv
  Feb  7 15:25:59.735: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 15:25:59.735: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 15:25:59.735: INFO: update-demo-nautilus-bsbrv is verified up and running
  Feb  7 15:25:59.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-gsg7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:25:59.792: INFO: stderr: ""
  Feb  7 15:25:59.792: INFO: stdout: ""
  Feb  7 15:25:59.792: INFO: update-demo-nautilus-gsg7g is created but not running
  E0207 15:26:00.659812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:01.660002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:02.660440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:03.660653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:04.660831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:26:04.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Feb  7 15:26:04.853: INFO: stderr: ""
  Feb  7 15:26:04.853: INFO: stdout: "update-demo-nautilus-bsbrv update-demo-nautilus-gsg7g "
  Feb  7 15:26:04.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:26:04.911: INFO: stderr: ""
  Feb  7 15:26:04.911: INFO: stdout: "true"
  Feb  7 15:26:04.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-bsbrv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 15:26:04.968: INFO: stderr: ""
  Feb  7 15:26:04.968: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 15:26:04.968: INFO: validating pod update-demo-nautilus-bsbrv
  Feb  7 15:26:04.972: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 15:26:04.972: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 15:26:04.972: INFO: update-demo-nautilus-bsbrv is verified up and running
  Feb  7 15:26:04.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-gsg7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Feb  7 15:26:05.029: INFO: stderr: ""
  Feb  7 15:26:05.029: INFO: stdout: "true"
  Feb  7 15:26:05.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods update-demo-nautilus-gsg7g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Feb  7 15:26:05.087: INFO: stderr: ""
  Feb  7 15:26:05.087: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Feb  7 15:26:05.087: INFO: validating pod update-demo-nautilus-gsg7g
  Feb  7 15:26:05.092: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Feb  7 15:26:05.092: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Feb  7 15:26:05.092: INFO: update-demo-nautilus-gsg7g is verified up and running
  STEP: using delete to clean up resources @ 02/07/24 15:26:05.092
  Feb  7 15:26:05.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 delete --grace-period=0 --force -f -'
  Feb  7 15:26:05.151: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Feb  7 15:26:05.151: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Feb  7 15:26:05.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get rc,svc -l name=update-demo --no-headers'
  Feb  7 15:26:05.222: INFO: stderr: "No resources found in kubectl-9593 namespace.\n"
  Feb  7 15:26:05.222: INFO: stdout: ""
  Feb  7 15:26:05.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-9593 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Feb  7 15:26:05.295: INFO: stderr: ""
  Feb  7 15:26:05.295: INFO: stdout: ""
  Feb  7 15:26:05.295: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9593" for this suite. @ 02/07/24 15:26:05.298
• [13.643 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 02/07/24 15:26:05.305
  Feb  7 15:26:05.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename replicaset @ 02/07/24 15:26:05.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:26:05.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:26:05.317
  STEP: Create a ReplicaSet @ 02/07/24 15:26:05.32
  STEP: Verify that the required pods have come up @ 02/07/24 15:26:05.325
  Feb  7 15:26:05.327: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0207 15:26:05.660902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:06.661936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:07.662278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:08.662732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:09.662913      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:26:10.330: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 02/07/24 15:26:10.33
  Feb  7 15:26:10.332: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 02/07/24 15:26:10.333
  STEP: DeleteCollection of the ReplicaSets @ 02/07/24 15:26:10.335
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 02/07/24 15:26:10.34
  Feb  7 15:26:10.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2099" for this suite. @ 02/07/24 15:26:10.346
• [5.051 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 02/07/24 15:26:10.356
  Feb  7 15:26:10.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 15:26:10.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:26:10.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:26:10.371
  STEP: create the rc @ 02/07/24 15:26:10.374
  W0207 15:26:10.379536      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0207 15:26:10.663969      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:11.664237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:12.664559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:13.664754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:14.664994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 02/07/24 15:26:15.382
  STEP: wait for all pods to be garbage collected @ 02/07/24 15:26:15.386
  E0207 15:26:15.665480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:16.665858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:17.666168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:18.666377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:19.666585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 02/07/24 15:26:20.39
  W0207 15:26:20.393963      23 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb  7 15:26:20.393: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb  7 15:26:20.394: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4094" for this suite. @ 02/07/24 15:26:20.396
• [10.044 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 02/07/24 15:26:20.401
  Feb  7 15:26:20.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pods @ 02/07/24 15:26:20.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:26:20.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:26:20.413
  E0207 15:26:20.666657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:21.666774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:22.667645      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:23.667858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:24.668366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:25.668566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:26:26.452
  Feb  7 15:26:26.454: INFO: Trying to get logs from node worker-0 pod client-envvars-a3e8f6d5-bcf8-4923-9e42-af6192c44675 container env3cont: <nil>
  STEP: delete the pod @ 02/07/24 15:26:26.464
  Feb  7 15:26:26.475: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4893" for this suite. @ 02/07/24 15:26:26.478
• [6.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 02/07/24 15:26:26.483
  Feb  7 15:26:26.483: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sysctl @ 02/07/24 15:26:26.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:26:26.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:26:26.494
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 02/07/24 15:26:26.497
  STEP: Watching for error events or started pod @ 02/07/24 15:26:26.503
  E0207 15:26:26.669433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:27.669714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 02/07/24 15:26:28.507
  E0207 15:26:28.670812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:29.671048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 02/07/24 15:26:30.514
  STEP: Getting logs from the pod @ 02/07/24 15:26:30.514
  STEP: Checking that the sysctl is actually updated @ 02/07/24 15:26:30.518
  Feb  7 15:26:30.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7310" for this suite. @ 02/07/24 15:26:30.521
• [4.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 02/07/24 15:26:30.525
  Feb  7 15:26:30.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename pod-network-test @ 02/07/24 15:26:30.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:26:30.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:26:30.538
  STEP: Performing setup for networking test in namespace pod-network-test-8369 @ 02/07/24 15:26:30.541
  STEP: creating a selector @ 02/07/24 15:26:30.541
  STEP: Creating the service pods in kubernetes @ 02/07/24 15:26:30.541
  Feb  7 15:26:30.541: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0207 15:26:30.671396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:31.671646      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:32.672209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:33.672339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:34.672965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:35.673085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:36.673123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:37.673475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:38.674028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:39.674160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:40.675182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:41.675363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:42.675924      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:43.676121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:44.676666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:45.676878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:46.677335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:47.677631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:48.678354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:49.678459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:50.679237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:51.679438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:52.680093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:53.680298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:54.681063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:55.681274      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:56.681326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:57.681618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:58.682372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:26:59.682592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:00.683617      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:01.684668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:02.685427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:03.685753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:04.686433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:05.686697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 02/07/24 15:27:06.617
  E0207 15:27:06.686840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:07.687740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:08.633: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Feb  7 15:27:08.633: INFO: Breadth first check of 10.244.1.220 on host 10.0.60.182...
  Feb  7 15:27:08.634: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.221:9080/dial?request=hostname&protocol=http&host=10.244.1.220&port=8083&tries=1'] Namespace:pod-network-test-8369 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:27:08.634: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:27:08.635: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:27:08.635: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8369/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.221%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.220%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  E0207 15:27:08.687971      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:08.697: INFO: Waiting for responses: map[]
  Feb  7 15:27:08.697: INFO: reached 10.244.1.220 after 0/1 tries
  Feb  7 15:27:08.697: INFO: Breadth first check of 10.244.0.29 on host 10.0.58.191...
  Feb  7 15:27:08.700: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.221:9080/dial?request=hostname&protocol=http&host=10.244.0.29&port=8083&tries=1'] Namespace:pod-network-test-8369 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Feb  7 15:27:08.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  Feb  7 15:27:08.700: INFO: ExecWithOptions: Clientset creation
  Feb  7 15:27:08.700: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8369/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.221%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.29%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Feb  7 15:27:08.761: INFO: Waiting for responses: map[]
  Feb  7 15:27:08.761: INFO: reached 10.244.0.29 after 0/1 tries
  Feb  7 15:27:08.761: INFO: Going to retry 0 out of 2 pods....
  Feb  7 15:27:08.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8369" for this suite. @ 02/07/24 15:27:08.764
• [38.242 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 02/07/24 15:27:08.768
  Feb  7 15:27:08.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename downward-api @ 02/07/24 15:27:08.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:08.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:08.779
  STEP: Creating a pod to test downward api env vars @ 02/07/24 15:27:08.782
  E0207 15:27:09.688124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:10.688432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:11.688590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:12.688696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:27:12.797
  Feb  7 15:27:12.799: INFO: Trying to get logs from node worker-0 pod downward-api-78dccc84-53ee-40a7-9f31-32b92e9f8ef7 container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 15:27:12.806
  Feb  7 15:27:12.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8011" for this suite. @ 02/07/24 15:27:12.819
• [4.056 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 02/07/24 15:27:12.824
  Feb  7 15:27:12.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename var-expansion @ 02/07/24 15:27:12.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:12.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:12.836
  STEP: Creating a pod to test substitution in container's args @ 02/07/24 15:27:12.838
  E0207 15:27:13.688835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:14.688952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:15.689682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:16.690626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 02/07/24 15:27:16.851
  Feb  7 15:27:16.853: INFO: Trying to get logs from node worker-0 pod var-expansion-cef5d85b-24d1-4559-8e92-900884362225 container dapi-container: <nil>
  STEP: delete the pod @ 02/07/24 15:27:16.858
  Feb  7 15:27:16.869: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3229" for this suite. @ 02/07/24 15:27:16.871
• [4.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 02/07/24 15:27:16.876
  Feb  7 15:27:16.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 02/07/24 15:27:16.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:16.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:16.889
  STEP: create the container to handle the HTTPGet hook request. @ 02/07/24 15:27:16.895
  E0207 15:27:17.690978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:18.691252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 02/07/24 15:27:18.909
  E0207 15:27:19.691551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:20.691728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 02/07/24 15:27:20.92
  E0207 15:27:21.692023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:22.692098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 02/07/24 15:27:22.93
  Feb  7 15:27:22.942: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-628" for this suite. @ 02/07/24 15:27:22.945
• [6.074 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 02/07/24 15:27:22.95
  Feb  7 15:27:22.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename chunking @ 02/07/24 15:27:22.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:22.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:22.962
  STEP: creating a large number of resources @ 02/07/24 15:27:22.965
  E0207 15:27:23.693175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:24.694097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:25.694827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:26.695321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:27.695853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:28.695930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:29.696809      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:30.697442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:31.698517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:32.698912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:33.699441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:34.700416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:35.700459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:36.700790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:37.701164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:38.701379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:39.702228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 02/07/24 15:27:40.655
  E0207 15:27:40.702600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:40.705: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Feb  7 15:27:40.754: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Feb  7 15:27:40.804: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Feb  7 15:27:40.854: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Feb  7 15:27:40.904: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Feb  7 15:27:40.954: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Feb  7 15:27:41.005: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Feb  7 15:27:41.055: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Feb  7 15:27:41.104: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Feb  7 15:27:41.154: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Feb  7 15:27:41.204: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Feb  7 15:27:41.254: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Feb  7 15:27:41.304: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Feb  7 15:27:41.354: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Feb  7 15:27:41.404: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Feb  7 15:27:41.454: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Feb  7 15:27:41.504: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Feb  7 15:27:41.555: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Feb  7 15:27:41.605: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Feb  7 15:27:41.655: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  E0207 15:27:41.702607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:41.705: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Feb  7 15:27:41.755: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Feb  7 15:27:41.804: INFO: Retrieved 17/17 results with rv 38450 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTAsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Feb  7 15:27:41.855: INFO: Retrieved 9/17 results with rv 38450 and continue 
  Feb  7 15:27:41.905: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Feb  7 15:27:41.955: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Feb  7 15:27:42.005: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Feb  7 15:27:42.055: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Feb  7 15:27:42.104: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Feb  7 15:27:42.155: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Feb  7 15:27:42.204: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Feb  7 15:27:42.254: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Feb  7 15:27:42.304: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Feb  7 15:27:42.354: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Feb  7 15:27:42.404: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Feb  7 15:27:42.454: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Feb  7 15:27:42.504: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Feb  7 15:27:42.554: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Feb  7 15:27:42.604: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Feb  7 15:27:42.654: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  E0207 15:27:42.702669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:42.704: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Feb  7 15:27:42.754: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Feb  7 15:27:42.804: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Feb  7 15:27:42.854: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Feb  7 15:27:42.904: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Feb  7 15:27:42.954: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Feb  7 15:27:43.004: INFO: Retrieved 17/17 results with rv 38452 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTIsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Feb  7 15:27:43.054: INFO: Retrieved 9/17 results with rv 38452 and continue 
  Feb  7 15:27:43.104: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Feb  7 15:27:43.154: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Feb  7 15:27:43.204: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Feb  7 15:27:43.254: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Feb  7 15:27:43.304: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Feb  7 15:27:43.354: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Feb  7 15:27:43.404: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Feb  7 15:27:43.455: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Feb  7 15:27:43.504: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Feb  7 15:27:43.554: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Feb  7 15:27:43.604: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Feb  7 15:27:43.654: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  E0207 15:27:43.703391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:43.704: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Feb  7 15:27:43.754: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Feb  7 15:27:43.804: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Feb  7 15:27:43.854: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Feb  7 15:27:43.904: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Feb  7 15:27:43.954: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Feb  7 15:27:44.004: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Feb  7 15:27:44.054: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Feb  7 15:27:44.104: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Feb  7 15:27:44.154: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Feb  7 15:27:44.204: INFO: Retrieved 17/17 results with rv 38456 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzg0NTYsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Feb  7 15:27:44.254: INFO: Retrieved 9/17 results with rv 38456 and continue 
  STEP: retrieving those results all at once @ 02/07/24 15:27:44.254
  Feb  7 15:27:44.312: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6366" for this suite. @ 02/07/24 15:27:44.354
• [21.455 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 02/07/24 15:27:44.406
  Feb  7 15:27:44.406: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 15:27:44.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:44.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:44.419
  STEP: creating service in namespace services-5797 @ 02/07/24 15:27:44.422
  STEP: creating service affinity-nodeport in namespace services-5797 @ 02/07/24 15:27:44.422
  STEP: creating replication controller affinity-nodeport in namespace services-5797 @ 02/07/24 15:27:44.433
  I0207 15:27:44.438335      23 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-5797, replica count: 3
  E0207 15:27:44.704079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:45.704202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:46.704541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 15:27:47.489640      23 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 15:27:47.496: INFO: Creating new exec pod
  E0207 15:27:47.705144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:48.705350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:49.706087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:50.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5797 exec execpod-affinity7bmfv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Feb  7 15:27:50.628: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Feb  7 15:27:50.628: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:27:50.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5797 exec execpod-affinity7bmfv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.133.226 80'
  E0207 15:27:50.707215      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:50.738: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.133.226 80\nConnection to 10.99.133.226 80 port [tcp/http] succeeded!\n"
  Feb  7 15:27:50.738: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:27:50.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5797 exec execpod-affinity7bmfv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.60.182 30664'
  Feb  7 15:27:50.863: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.60.182 30664\nConnection to 10.0.60.182 30664 port [tcp/*] succeeded!\n"
  Feb  7 15:27:50.863: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:27:50.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5797 exec execpod-affinity7bmfv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 30664'
  Feb  7 15:27:50.990: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.58.191 30664\nConnection to 10.0.58.191 30664 port [tcp/*] succeeded!\n"
  Feb  7 15:27:50.990: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:27:50.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-5797 exec execpod-affinity7bmfv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.60.182:30664/ ; done'
  Feb  7 15:27:51.188: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:30664/\n"
  Feb  7 15:27:51.188: INFO: stdout: "\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf\naffinity-nodeport-rqfdf"
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Received response from host: affinity-nodeport-rqfdf
  Feb  7 15:27:51.188: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-5797, will wait for the garbage collector to delete the pods @ 02/07/24 15:27:51.197
  Feb  7 15:27:51.253: INFO: Deleting ReplicationController affinity-nodeport took: 3.313698ms
  Feb  7 15:27:51.354: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.740492ms
  E0207 15:27:51.707629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:52.708268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:53.709039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:27:54.269: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5797" for this suite. @ 02/07/24 15:27:54.271
• [9.869 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 02/07/24 15:27:54.275
  Feb  7 15:27:54.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename kubectl @ 02/07/24 15:27:54.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:54.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:54.287
  STEP: starting the proxy server @ 02/07/24 15:27:54.29
  Feb  7 15:27:54.290: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=kubectl-6121 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 02/07/24 15:27:54.338
  Feb  7 15:27:54.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6121" for this suite. @ 02/07/24 15:27:54.348
• [0.077 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 02/07/24 15:27:54.352
  Feb  7 15:27:54.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename dns @ 02/07/24 15:27:54.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:54.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:54.366
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3421.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3421.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 02/07/24 15:27:54.369
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3421.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3421.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 02/07/24 15:27:54.369
  STEP: creating a pod to probe /etc/hosts @ 02/07/24 15:27:54.369
  STEP: submitting the pod to kubernetes @ 02/07/24 15:27:54.369
  E0207 15:27:54.709597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:55.709787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 02/07/24 15:27:56.381
  STEP: looking for the results for each expected name from probers @ 02/07/24 15:27:56.383
  Feb  7 15:27:56.397: INFO: DNS probes using dns-3421/dns-test-d9e0a12c-0a5e-4adb-92e0-918eaa14a8ee succeeded

  STEP: deleting the pod @ 02/07/24 15:27:56.397
  Feb  7 15:27:56.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3421" for this suite. @ 02/07/24 15:27:56.406
• [2.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 02/07/24 15:27:56.411
  Feb  7 15:27:56.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename deployment @ 02/07/24 15:27:56.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:56.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:56.423
  Feb  7 15:27:56.425: INFO: Creating simple deployment test-new-deployment
  Feb  7 15:27:56.435: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0207 15:27:56.710616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:57.710640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 02/07/24 15:27:58.443
  STEP: updating a scale subresource @ 02/07/24 15:27:58.445
  STEP: verifying the deployment Spec.Replicas was modified @ 02/07/24 15:27:58.448
  STEP: Patch a scale subresource @ 02/07/24 15:27:58.45
  Feb  7 15:27:58.467: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8870",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a377b908-5a00-440e-a12c-26499216aae1",
      ResourceVersion: (string) (len=5) "39031",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842916476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Feb  7 15:27:58.472: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8870",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d2844b3b-8b93-4a33-8c90-a68b6f4c4e6e",
      ResourceVersion: (string) (len=5) "39038",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842916476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "a377b908-5a00-440e-a12c-26499216aae1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 33 37 37 62 39  30 38 2d 35 61 30 30 2d  |\"a377b908-5a00-|
              00000120  34 34 30 65 2d 61 31 32  63 2d 32 36 34 39 39 32  |440e-a12c-264992|
              00000130  31 36 61 61 65 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |16aae1\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Feb  7 15:27:58.477: INFO: Pod "test-new-deployment-557759b7c7-fn2j8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-fn2j8",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8870",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6702c267-573d-4491-97cc-de0174e424a0",
      ResourceVersion: (string) (len=5) "39023",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842916476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d2844b3b-8b93-4a33-8c90-a68b6f4c4e6e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 32  38 34 34 62 33 62 2d 38  |d\":\"d2844b3b-8|
              00000090  62 39 33 2d 34 61 33 33  2d 38 63 39 30 2d 61 36  |b93-4a33-8c90-a6|
              000000a0  38 62 36 66 34 63 34 65  36 65 5c 22 7d 22 3a 7b  |8b6f4c4e6e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 32  32 38 5c 22 7d 22 3a 7b  |.244.1.228\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2lxhp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2lxhp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.60.182",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.60.182"
        }
      },
      PodIP: (string) (len=12) "10.244.1.228",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.228"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842916476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63842916476,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://ccae8f8333a3f34ac35cfd37f07c8fd0b4fb20374a7f6161e67c05b324c4df55",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 15:27:58.480: INFO: Pod "test-new-deployment-557759b7c7-xgdwl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-xgdwl",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8870",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3d70712a-bd98-4805-8b68-5da1d0644e35",
      ResourceVersion: (string) (len=5) "39039",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842916478,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d2844b3b-8b93-4a33-8c90-a68b6f4c4e6e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 32  38 34 34 62 33 62 2d 38  |d\":\"d2844b3b-8|
              00000090  62 39 33 2d 34 61 33 33  2d 38 63 39 30 2d 61 36  |b93-4a33-8c90-a6|
              000000a0  38 62 36 66 34 63 34 65  36 65 5c 22 7d 22 3a 7b  |8b6f4c4e6e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ckvmq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ckvmq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=8) "worker-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63842916478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "10.0.58.191",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "10.0.58.191"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63842916478,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Feb  7 15:27:58.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8870" for this suite. @ 02/07/24 15:27:58.491
• [2.089 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 02/07/24 15:27:58.5
  Feb  7 15:27:58.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename services @ 02/07/24 15:27:58.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:27:58.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:27:58.516
  STEP: creating service in namespace services-9062 @ 02/07/24 15:27:58.519
  STEP: creating service affinity-nodeport-transition in namespace services-9062 @ 02/07/24 15:27:58.519
  STEP: creating replication controller affinity-nodeport-transition in namespace services-9062 @ 02/07/24 15:27:58.532
  I0207 15:27:58.537083      23 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-9062, replica count: 3
  E0207 15:27:58.710701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:27:59.710818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:00.711141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0207 15:28:01.588178      23 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Feb  7 15:28:01.594: INFO: Creating new exec pod
  E0207 15:28:01.711573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:02.711828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:03.712482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:28:04.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E0207 15:28:04.712853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:28:04.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Feb  7 15:28:04.744: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:28:04.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.203.126 80'
  Feb  7 15:28:04.858: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.203.126 80\nConnection to 10.99.203.126 80 port [tcp/http] succeeded!\n"
  Feb  7 15:28:04.858: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:28:04.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.60.182 31362'
  Feb  7 15:28:04.974: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.60.182 31362\nConnection to 10.0.60.182 31362 port [tcp/*] succeeded!\n"
  Feb  7 15:28:04.974: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:28:04.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.58.191 31362'
  Feb  7 15:28:05.102: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.58.191 31362\nConnection to 10.0.58.191 31362 port [tcp/*] succeeded!\n"
  Feb  7 15:28:05.102: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Feb  7 15:28:05.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.60.182:31362/ ; done'
  E0207 15:28:05.713167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:06.713670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:07.714106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:08.714308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:09.714365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:10.714576      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:11.714854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:12.715121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:28:13.312: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n"
  Feb  7 15:28:13.312: INFO: stdout: "\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-gcvqq\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-gcvqq\naffinity-nodeport-transition-7zhmx\n\n\naffinity-nodeport-transition-gcvqq\naffinity-nodeport-transition-gcvqq\n\n\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-gcvqq\naffinity-nodeport-transition-gcvqq"
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:13.312: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  E0207 15:28:13.715816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:14.716006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:15.716214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:16.716672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:17.717142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:18.717266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:19.717625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:20.717807      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:21.718126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:22.718457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:23.718649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:24.718824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:25.719007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:26.719354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:27.719688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:28.719796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:29.719979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:30.720092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:31.720269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:32.720395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:33.720581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:34.720891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:35.721725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:36.722058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:37.722381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:38.722601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:39.722785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:40.723105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:41.723285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:42.723665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:28:43.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.60.182:31362/ ; done'
  Feb  7 15:28:43.507: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n"
  Feb  7 15:28:43.507: INFO: stdout: "\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-gcvqq\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-gcvqq\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-7zhmx\naffinity-nodeport-transition-nxbb2"
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-gcvqq
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-7zhmx
  Feb  7 15:28:43.507: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2713282832 --namespace=services-9062 exec execpod-affinitytq7lp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.60.182:31362/ ; done'
  Feb  7 15:28:43.716: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.60.182:31362/\n"
  Feb  7 15:28:43.716: INFO: stdout: "\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2\naffinity-nodeport-transition-nxbb2"
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Received response from host: affinity-nodeport-transition-nxbb2
  Feb  7 15:28:43.717: INFO: Cleaning up the exec pod
  E0207 15:28:43.724120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-9062, will wait for the garbage collector to delete the pods @ 02/07/24 15:28:43.725
  Feb  7 15:28:43.783: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.096322ms
  Feb  7 15:28:43.884: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.305199ms
  E0207 15:28:44.725124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:45.725864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:28:46.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9062" for this suite. @ 02/07/24 15:28:46.401
• [47.906 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 02/07/24 15:28:46.407
  Feb  7 15:28:46.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename container-runtime @ 02/07/24 15:28:46.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:28:46.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:28:46.419
  STEP: create the container @ 02/07/24 15:28:46.421
  W0207 15:28:46.428175      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 02/07/24 15:28:46.428
  E0207 15:28:46.726871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:47.727632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:48.727722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 02/07/24 15:28:49.439
  STEP: the container should be terminated @ 02/07/24 15:28:49.441
  STEP: the termination message should be set @ 02/07/24 15:28:49.441
  Feb  7 15:28:49.441: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 02/07/24 15:28:49.441
  Feb  7 15:28:49.450: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2508" for this suite. @ 02/07/24 15:28:49.453
• [3.051 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 02/07/24 15:28:49.458
  Feb  7 15:28:49.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename gc @ 02/07/24 15:28:49.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:28:49.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:28:49.469
  STEP: create the deployment @ 02/07/24 15:28:49.472
  W0207 15:28:49.476674      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 02/07/24 15:28:49.476
  E0207 15:28:49.728196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 02/07/24 15:28:49.979
  STEP: wait for all rs to be garbage collected @ 02/07/24 15:28:49.983
  STEP: expected 0 rs, got 1 rs @ 02/07/24 15:28:49.987
  STEP: expected 0 pods, got 2 pods @ 02/07/24 15:28:49.989
  STEP: Gathering metrics @ 02/07/24 15:28:50.488
  W0207 15:28:50.492274      23 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Feb  7 15:28:50.492: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Feb  7 15:28:50.492: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1941" for this suite. @ 02/07/24 15:28:50.494
• [1.042 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 02/07/24 15:28:50.5
  Feb  7 15:28:50.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename sched-pred @ 02/07/24 15:28:50.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:28:50.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:28:50.512
  Feb  7 15:28:50.514: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Feb  7 15:28:50.519: INFO: Waiting for terminating namespaces to be deleted...
  Feb  7 15:28:50.521: INFO: 
  Logging pods the apiserver thinks is on node worker-0 before test
  Feb  7 15:28:50.524: INFO: coredns-555d98c87b-tdvsz from kube-system started at 2024-02-07 14:03:53 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.524: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: konnectivity-agent-x99jt from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.524: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: kube-proxy-l28q5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.524: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: kube-router-wfgm8 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.524: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: sonobuoy from sonobuoy started at 2024-02-07 13:37:03 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.524: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-2wkv5 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 15:28:50.524: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: 	Container systemd-logs ready: true, restart count 0
  Feb  7 15:28:50.524: INFO: 
  Logging pods the apiserver thinks is on node worker-1 before test
  Feb  7 15:28:50.528: INFO: coredns-555d98c87b-f8t6j from kube-system started at 2024-02-07 13:37:51 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container coredns ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: konnectivity-agent-bt2h5 from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: kube-proxy-qvgjm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container kube-proxy ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: kube-router-mqgnm from kube-system started at 2024-02-07 13:36:38 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container kube-router ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: metrics-server-7556957bb7-6kv5t from kube-system started at 2024-02-07 13:36:50 +0000 UTC (1 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container metrics-server ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: sonobuoy-e2e-job-fedf139ced3a4f30 from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container e2e ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: sonobuoy-systemd-logs-daemon-set-b9afb3918b9243fb-rq8vf from sonobuoy started at 2024-02-07 13:37:07 +0000 UTC (2 container statuses recorded)
  Feb  7 15:28:50.528: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Feb  7 15:28:50.528: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 02/07/24 15:28:50.528
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17b19e3fc8f4cbc5], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] @ 02/07/24 15:28:50.545
  E0207 15:28:50.728397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:28:51.544: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8892" for this suite. @ 02/07/24 15:28:51.547
• [1.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 02/07/24 15:28:51.552
  Feb  7 15:28:51.552: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename namespaces @ 02/07/24 15:28:51.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:28:51.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:28:51.565
  STEP: Read namespace status @ 02/07/24 15:28:51.568
  Feb  7 15:28:51.571: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 02/07/24 15:28:51.571
  Feb  7 15:28:51.574: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 02/07/24 15:28:51.574
  Feb  7 15:28:51.581: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Feb  7 15:28:51.581: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1155" for this suite. @ 02/07/24 15:28:51.584
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 02/07/24 15:28:51.599
  Feb  7 15:28:51.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename resourcequota @ 02/07/24 15:28:51.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:28:51.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:28:51.609
  STEP: Creating a ResourceQuota with best effort scope @ 02/07/24 15:28:51.611
  STEP: Ensuring ResourceQuota status is calculated @ 02/07/24 15:28:51.614
  E0207 15:28:51.728960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:52.729045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 02/07/24 15:28:53.617
  STEP: Ensuring ResourceQuota status is calculated @ 02/07/24 15:28:53.62
  E0207 15:28:53.730119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:54.730315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 02/07/24 15:28:55.623
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 02/07/24 15:28:55.633
  E0207 15:28:55.731259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:56.731590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 02/07/24 15:28:57.636
  E0207 15:28:57.732267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:28:58.732470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/07/24 15:28:59.638
  STEP: Ensuring resource quota status released the pod usage @ 02/07/24 15:28:59.646
  E0207 15:28:59.733438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:29:00.734117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 02/07/24 15:29:01.649
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 02/07/24 15:29:01.656
  E0207 15:29:01.734618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:29:02.734925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 02/07/24 15:29:03.658
  E0207 15:29:03.735202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:29:04.735299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 02/07/24 15:29:05.661
  STEP: Ensuring resource quota status released the pod usage @ 02/07/24 15:29:05.668
  E0207 15:29:05.735958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0207 15:29:06.736316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  Feb  7 15:29:07.671: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8060" for this suite. @ 02/07/24 15:29:07.674
• [16.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 02/07/24 15:29:07.679
  Feb  7 15:29:07.679: INFO: >>> kubeConfig: /tmp/kubeconfig-2713282832
  STEP: Building a namespace api object, basename configmap @ 02/07/24 15:29:07.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 02/07/24 15:29:07.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 02/07/24 15:29:07.692
  STEP: Creating configMap that has name configmap-test-emptyKey-5cd7bc35-eda5-4876-a97e-8251b266332c @ 02/07/24 15:29:07.695
  Feb  7 15:29:07.696: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8807" for this suite. @ 02/07/24 15:29:07.699
• [0.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Feb  7 15:29:07.704: INFO: Running AfterSuite actions on node 1
  Feb  7 15:29:07.704: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:621
  E0207 15:29:07.736753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
[ReportAfterSuite] PASSED [0.064 seconds]
------------------------------

Ran 388 of 7407 Specs in 6700.243 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 1h51m41.289256456s
Test Suite Passed
