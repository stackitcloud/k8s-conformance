  I1219 10:02:08.738998      13 e2e.go:117] Starting e2e run "13f7c4b6-93cb-4d70-8a59-2a33698c5e74" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1702980126 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Dec 19 10:02:09.162: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:02:09.169: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Dec 19 10:02:09.241: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Dec 19 10:02:09.250: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
  Dec 19 10:02:09.250: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Dec 19 10:02:09.250: INFO: e2e test version: v1.29.0
  Dec 19 10:02:09.252: INFO: kube-apiserver version: v1.29.0
  Dec 19 10:02:09.253: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:02:09.263: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.101 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 12/19/23 10:02:09.536
  Dec 19 10:02:09.536: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/19/23 10:02:09.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:02:09.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:02:09.578
  STEP: Cleaning up the secret @ 12/19/23 10:02:47.83
  STEP: Cleaning up the configmap @ 12/19/23 10:02:47.842
  STEP: Cleaning up the pod @ 12/19/23 10:02:47.852
  Dec 19 10:02:47.879: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4313" for this suite. @ 12/19/23 10:02:47.888
• [38.373 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 12/19/23 10:02:47.904
  Dec 19 10:02:47.904: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:02:47.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:02:47.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:02:47.943
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/19/23 10:02:47.948
  STEP: Saw pod success @ 12/19/23 10:02:52.005
  Dec 19 10:02:52.011: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-0372f52e-e225-48de-9fc1-1981f86ea0b2 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:02:52.046
  Dec 19 10:02:52.085: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5629" for this suite. @ 12/19/23 10:02:52.094
• [4.209 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 12/19/23 10:02:52.114
  Dec 19 10:02:52.114: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:02:52.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:02:52.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:02:52.146
  STEP: set up a multi version CRD @ 12/19/23 10:02:52.15
  Dec 19 10:02:52.152: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: mark a version not serverd @ 12/19/23 10:02:56.901
  STEP: check the unserved version gets removed @ 12/19/23 10:02:56.947
  STEP: check the other version is not changed @ 12/19/23 10:02:58.368
  Dec 19 10:03:01.711: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7937" for this suite. @ 12/19/23 10:03:01.734
• [9.631 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 12/19/23 10:03:01.746
  Dec 19 10:03:01.746: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:03:01.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:01.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:01.784
  Dec 19 10:03:01.812: INFO: created pod
  STEP: Saw pod success @ 12/19/23 10:03:05.836
  Dec 19 10:03:35.836: INFO: polling logs
  Dec 19 10:03:35.857: INFO: Pod logs: 
  I1219 10:03:02.547733       1 log.go:194] OK: Got token
  I1219 10:03:02.549288       1 log.go:194] validating with in-cluster discovery
  I1219 10:03:02.550356       1 log.go:194] OK: got issuer https://kubernetes.default.svc.cluster.local
  I1219 10:03:02.550406       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-880:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000042b70), NotBefore:(*jwt.NumericDate)(0xc000042ce8), IssuedAt:(*jwt.NumericDate)(0xc000042b80), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-880", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"8718249e-6d53-43ec-baf6-c6b9a68f044b"}}}
  I1219 10:03:02.589233       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I1219 10:03:02.605912       1 log.go:194] OK: Validated signature on JWT
  I1219 10:03:02.606048       1 log.go:194] OK: Got valid claims from token!
  I1219 10:03:02.606134       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-880:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0000c8ba8), NotBefore:(*jwt.NumericDate)(0xc0000c8bd0), IssuedAt:(*jwt.NumericDate)(0xc0000c8bb0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-880", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"8718249e-6d53-43ec-baf6-c6b9a68f044b"}}}

  Dec 19 10:03:35.857: INFO: completed pod
  Dec 19 10:03:35.871: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-880" for this suite. @ 12/19/23 10:03:35.879
• [34.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 12/19/23 10:03:35.897
  Dec 19 10:03:35.898: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:03:35.902
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:35.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:35.937
  STEP: creating service endpoint-test2 in namespace services-7915 @ 12/19/23 10:03:35.943
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7915 to expose endpoints map[] @ 12/19/23 10:03:35.976
  Dec 19 10:03:36.005: INFO: successfully validated that service endpoint-test2 in namespace services-7915 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7915 @ 12/19/23 10:03:36.005
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7915 to expose endpoints map[pod1:[80]] @ 12/19/23 10:03:38.053
  Dec 19 10:03:38.074: INFO: successfully validated that service endpoint-test2 in namespace services-7915 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 12/19/23 10:03:38.075
  Dec 19 10:03:38.075: INFO: Creating new exec pod
  Dec 19 10:03:41.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7915 exec execpodlfqfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec 19 10:03:41.650: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec 19 10:03:41.650: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:03:41.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7915 exec execpodlfqfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.11 80'
  Dec 19 10:03:41.940: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.11 80\nConnection to 10.233.42.11 80 port [tcp/http] succeeded!\n"
  Dec 19 10:03:41.940: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-7915 @ 12/19/23 10:03:41.941
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7915 to expose endpoints map[pod1:[80] pod2:[80]] @ 12/19/23 10:03:54.042
  Dec 19 10:03:54.075: INFO: successfully validated that service endpoint-test2 in namespace services-7915 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 12/19/23 10:03:54.075
  Dec 19 10:03:55.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7915 exec execpodlfqfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec 19 10:03:55.441: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec 19 10:03:55.441: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:03:55.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7915 exec execpodlfqfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.11 80'
  Dec 19 10:03:55.745: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.11 80\nConnection to 10.233.42.11 80 port [tcp/http] succeeded!\n"
  Dec 19 10:03:55.745: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7915 @ 12/19/23 10:03:55.745
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7915 to expose endpoints map[pod2:[80]] @ 12/19/23 10:03:55.802
  Dec 19 10:03:55.826: INFO: successfully validated that service endpoint-test2 in namespace services-7915 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 12/19/23 10:03:55.826
  Dec 19 10:03:56.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7915 exec execpodlfqfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec 19 10:03:57.181: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec 19 10:03:57.181: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:03:57.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7915 exec execpodlfqfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.11 80'
  Dec 19 10:03:57.477: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.11 80\nConnection to 10.233.42.11 80 port [tcp/http] succeeded!\n"
  Dec 19 10:03:57.477: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-7915 @ 12/19/23 10:03:57.477
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7915 to expose endpoints map[] @ 12/19/23 10:03:57.509
  Dec 19 10:03:58.579: INFO: successfully validated that service endpoint-test2 in namespace services-7915 exposes endpoints map[]
  Dec 19 10:03:58.624: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7915" for this suite. @ 12/19/23 10:03:58.635
• [22.754 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 12/19/23 10:03:58.653
  Dec 19 10:03:58.653: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:03:58.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:58.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:58.694
  STEP: Creating a pod to test substitution in container's args @ 12/19/23 10:03:58.703
  STEP: Saw pod success @ 12/19/23 10:04:04.762
  Dec 19 10:04:04.773: INFO: Trying to get logs from node uikie9pei4sh-3 pod var-expansion-de9a9672-1ce9-43bd-85f5-c4e068725019 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:04:04.791
  Dec 19 10:04:04.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3589" for this suite. @ 12/19/23 10:04:04.843
• [6.204 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 12/19/23 10:04:04.86
  Dec 19 10:04:04.861: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:04:04.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:04.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:04.899
  STEP: creating the pod @ 12/19/23 10:04:04.908
  STEP: submitting the pod to kubernetes @ 12/19/23 10:04:04.908
  STEP: verifying QOS class is set on the pod @ 12/19/23 10:04:04.926
  Dec 19 10:04:04.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2402" for this suite. @ 12/19/23 10:04:04.959
• [0.111 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 12/19/23 10:04:04.974
  Dec 19 10:04:04.975: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 10:04:04.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:05.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:05.019
  Dec 19 10:04:07.092: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1527" for this suite. @ 12/19/23 10:04:07.102
• [2.142 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 12/19/23 10:04:07.117
  Dec 19 10:04:07.117: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename containers @ 12/19/23 10:04:07.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:07.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:07.181
  STEP: Creating a pod to test override all @ 12/19/23 10:04:07.185
  STEP: Saw pod success @ 12/19/23 10:04:11.228
  Dec 19 10:04:11.236: INFO: Trying to get logs from node uikie9pei4sh-3 pod client-containers-d3b2b53a-dada-4d51-aa38-8fcb4029667a container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:04:11.248
  Dec 19 10:04:11.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4016" for this suite. @ 12/19/23 10:04:11.283
• [4.181 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 12/19/23 10:04:11.298
  Dec 19 10:04:11.298: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 10:04:11.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:11.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:11.333
  STEP: getting /apis @ 12/19/23 10:04:11.339
  STEP: getting /apis/discovery.k8s.io @ 12/19/23 10:04:11.347
  STEP: getting /apis/discovery.k8s.iov1 @ 12/19/23 10:04:11.349
  STEP: creating @ 12/19/23 10:04:11.352
  STEP: getting @ 12/19/23 10:04:11.382
  STEP: listing @ 12/19/23 10:04:11.39
  STEP: watching @ 12/19/23 10:04:11.395
  Dec 19 10:04:11.395: INFO: starting watch
  STEP: cluster-wide listing @ 12/19/23 10:04:11.399
  STEP: cluster-wide watching @ 12/19/23 10:04:11.407
  Dec 19 10:04:11.407: INFO: starting watch
  STEP: patching @ 12/19/23 10:04:11.409
  STEP: updating @ 12/19/23 10:04:11.423
  Dec 19 10:04:11.440: INFO: waiting for watch events with expected annotations
  Dec 19 10:04:11.441: INFO: saw patched and updated annotations
  STEP: deleting @ 12/19/23 10:04:11.441
  STEP: deleting a collection @ 12/19/23 10:04:11.466
  Dec 19 10:04:11.507: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6914" for this suite. @ 12/19/23 10:04:11.514
• [0.228 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 12/19/23 10:04:11.526
  Dec 19 10:04:11.526: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:04:11.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:11.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:11.568
  STEP: validating cluster-info @ 12/19/23 10:04:11.576
  Dec 19 10:04:11.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5851 cluster-info'
  Dec 19 10:04:11.757: INFO: stderr: ""
  Dec 19 10:04:11.757: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Dec 19 10:04:11.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5851" for this suite. @ 12/19/23 10:04:11.766
• [0.249 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 12/19/23 10:04:11.776
  Dec 19 10:04:11.776: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:04:11.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:11.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:11.821
  STEP: Counting existing ResourceQuota @ 12/19/23 10:04:11.825
  STEP: Creating a ResourceQuota @ 12/19/23 10:04:16.835
  STEP: Ensuring resource quota status is calculated @ 12/19/23 10:04:16.85
  STEP: Creating a ReplicaSet @ 12/19/23 10:04:18.861
  STEP: Ensuring resource quota status captures replicaset creation @ 12/19/23 10:04:18.89
  STEP: Deleting a ReplicaSet @ 12/19/23 10:04:20.902
  STEP: Ensuring resource quota status released usage @ 12/19/23 10:04:20.926
  Dec 19 10:04:22.953: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6325" for this suite. @ 12/19/23 10:04:22.97
• [11.210 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 12/19/23 10:04:22.986
  Dec 19 10:04:22.986: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:04:22.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:23.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:23.037
  Dec 19 10:04:23.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8063" for this suite. @ 12/19/23 10:04:23.155
• [0.183 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 12/19/23 10:04:23.169
  Dec 19 10:04:23.169: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename tables @ 12/19/23 10:04:23.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:23.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:23.209
  Dec 19 10:04:23.221: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-9375" for this suite. @ 12/19/23 10:04:23.229
• [0.072 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 12/19/23 10:04:23.241
  Dec 19 10:04:23.241: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename podtemplate @ 12/19/23 10:04:23.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:23.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:23.283
  STEP: Create set of pod templates @ 12/19/23 10:04:23.289
  Dec 19 10:04:23.301: INFO: created test-podtemplate-1
  Dec 19 10:04:23.310: INFO: created test-podtemplate-2
  Dec 19 10:04:23.319: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 12/19/23 10:04:23.319
  STEP: delete collection of pod templates @ 12/19/23 10:04:23.327
  Dec 19 10:04:23.327: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 12/19/23 10:04:23.355
  Dec 19 10:04:23.355: INFO: requesting list of pod templates to confirm quantity
  Dec 19 10:04:23.360: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1445" for this suite. @ 12/19/23 10:04:23.369
• [0.139 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 12/19/23 10:04:23.381
  Dec 19 10:04:23.381: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 10:04:23.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:23.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:23.436
  STEP: Creating a test namespace @ 12/19/23 10:04:23.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:23.475
  STEP: Creating a service in the namespace @ 12/19/23 10:04:23.48
  STEP: Deleting the namespace @ 12/19/23 10:04:23.521
  STEP: Waiting for the namespace to be removed. @ 12/19/23 10:04:23.555
  STEP: Recreating the namespace @ 12/19/23 10:04:29.571
  STEP: Verifying there is no service in the namespace @ 12/19/23 10:04:29.613
  Dec 19 10:04:29.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2612" for this suite. @ 12/19/23 10:04:29.63
  STEP: Destroying namespace "nsdeletetest-7114" for this suite. @ 12/19/23 10:04:29.641
  Dec 19 10:04:29.646: INFO: Namespace nsdeletetest-7114 was already deleted
  STEP: Destroying namespace "nsdeletetest-5818" for this suite. @ 12/19/23 10:04:29.646
• [6.277 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 12/19/23 10:04:29.676
  Dec 19 10:04:29.676: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:04:29.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:29.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:29.71
  STEP: Creating the pod @ 12/19/23 10:04:29.715
  Dec 19 10:04:32.306: INFO: Successfully updated pod "labelsupdatee582a97a-dd35-4d96-a85b-eaa26b103c8e"
  Dec 19 10:04:34.400: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7732" for this suite. @ 12/19/23 10:04:34.413
• [4.753 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 12/19/23 10:04:34.431
  Dec 19 10:04:34.431: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:04:34.436
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:34.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:34.465
  STEP: creating a Deployment @ 12/19/23 10:04:34.477
  Dec 19 10:04:34.477: INFO: Creating simple deployment test-deployment-shxlw
  Dec 19 10:04:34.499: INFO: new replicaset for deployment "test-deployment-shxlw" is yet to be created
  Dec 19 10:04:36.538: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:38.552: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:40.548: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:42.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:44.549: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:46.548: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:48.559: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:50.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:52.569: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:54.550: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:56.552: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:04:58.545: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:05:00.549: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:05:02.548: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:05:04.553: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec 19 10:05:06.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Getting /status @ 12/19/23 10:05:08.556
  Dec 19 10:05:08.572: INFO: Deployment test-deployment-shxlw has Conditions: [{Available True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:05:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-shxlw-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 12/19/23 10:05:08.572
  Dec 19 10:05:08.598: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 5, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 5, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 5, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 4, 34, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-shxlw-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 12/19/23 10:05:08.598
  Dec 19 10:05:08.604: INFO: Observed &Deployment event: ADDED
  Dec 19 10:05:08.604: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-shxlw-5d576bd769"}
  Dec 19 10:05:08.604: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.605: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-shxlw-5d576bd769"}
  Dec 19 10:05:08.605: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:05:08.605: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.605: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:05:08.605: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-shxlw-5d576bd769" is progressing.}
  Dec 19 10:05:08.606: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.606: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:05:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:05:08.606: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-shxlw-5d576bd769" has successfully progressed.}
  Dec 19 10:05:08.606: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.606: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:05:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:05:08.606: INFO: Observed Deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-shxlw-5d576bd769" has successfully progressed.}
  Dec 19 10:05:08.606: INFO: Found Deployment test-deployment-shxlw in namespace deployment-408 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:05:08.606: INFO: Deployment test-deployment-shxlw has an updated status
  STEP: patching the Statefulset Status @ 12/19/23 10:05:08.606
  Dec 19 10:05:08.606: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec 19 10:05:08.626: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 12/19/23 10:05:08.627
  Dec 19 10:05:08.630: INFO: Observed &Deployment event: ADDED
  Dec 19 10:05:08.630: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-shxlw-5d576bd769"}
  Dec 19 10:05:08.631: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.631: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-shxlw-5d576bd769"}
  Dec 19 10:05:08.632: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:05:08.632: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.632: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:05:08.633: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:04:34 +0000 UTC 2023-12-19 10:04:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-shxlw-5d576bd769" is progressing.}
  Dec 19 10:05:08.633: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.634: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:05:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:05:08.634: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-shxlw-5d576bd769" has successfully progressed.}
  Dec 19 10:05:08.634: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.635: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:05:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:05:08.635: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:05:07 +0000 UTC 2023-12-19 10:04:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-shxlw-5d576bd769" has successfully progressed.}
  Dec 19 10:05:08.635: INFO: Observed deployment test-deployment-shxlw in namespace deployment-408 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:05:08.636: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:05:08.636: INFO: Found deployment test-deployment-shxlw in namespace deployment-408 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Dec 19 10:05:08.636: INFO: Deployment test-deployment-shxlw has a patched status
  Dec 19 10:05:08.647: INFO: Deployment "test-deployment-shxlw":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-shxlw",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-408",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e3057be-2693-4f08-9853-5f8a1f70e861",
      ResourceVersion: (string) (len=4) "3493",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577108,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577108,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577108,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577108,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-shxlw-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 10:05:08.660: INFO: New ReplicaSet "test-deployment-shxlw-5d576bd769" of Deployment "test-deployment-shxlw":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-shxlw-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-408",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "34ab46d0-45bd-48c9-91b2-9b31e58379df",
      ResourceVersion: (string) (len=4) "3487",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-shxlw",
          UID: (types.UID) (len=36) "4e3057be-2693-4f08-9853-5f8a1f70e861",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 34 65 33  |k:{\"uid\":\"4e3|
              00000120  30 35 37 62 65 2d 32 36  39 33 2d 34 66 30 38 2d  |057be-2693-4f08-|
              00000130  39 38 35 33 2d 35 66 38  61 31 66 37 30 65 38 36  |9853-5f8a1f70e86|
              00000140  31 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |1\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577107,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:05:08.679: INFO: Pod "test-deployment-shxlw-5d576bd769-ds94w" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-shxlw-5d576bd769-ds94w",
      GenerateName: (string) (len=33) "test-deployment-shxlw-5d576bd769-",
      Namespace: (string) (len=14) "deployment-408",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "411751ad-483d-4e63-9a4e-7e093673d634",
      ResourceVersion: (string) (len=4) "3486",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-shxlw-5d576bd769",
          UID: (types.UID) (len=36) "34ab46d0-45bd-48c9-91b2-9b31e58379df",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 33 34 61 62 34 36 64  30 2d 34 35 62 64 2d 34  |"34ab46d0-45bd-4|
              000000a0  38 63 39 2d 39 31 62 32  2d 39 62 33 31 65 35 38  |8c9-91b2-9b31e58|
              000000b0  33 37 39 64 66 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |379df\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577107,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 32 5c 22 7d 22 3a 7b  |.233.66.12\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gddgm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gddgm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577107,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577107,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577107,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=12) "10.233.66.12",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.12"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838577107,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://84d2027e716348d7d59cbd25657e4862aa6ee4bf16a6d633f690516d92a41bd0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:05:08.682: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-408" for this suite. @ 12/19/23 10:05:08.695
• [34.278 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 12/19/23 10:05:08.71
  Dec 19 10:05:08.711: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:05:08.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:08.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:08.752
  STEP: Creating a pod to test downward api env vars @ 12/19/23 10:05:08.758
  STEP: Saw pod success @ 12/19/23 10:05:12.815
  Dec 19 10:05:12.821: INFO: Trying to get logs from node uikie9pei4sh-3 pod downward-api-cbbc1532-dc9c-42ec-b346-bd9cb246e1be container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:05:12.839
  Dec 19 10:05:12.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1820" for this suite. @ 12/19/23 10:05:12.874
• [4.180 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 12/19/23 10:05:12.893
  Dec 19 10:05:12.893: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:05:12.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:12.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:12.932
  STEP: Creating the pod @ 12/19/23 10:05:12.938
  Dec 19 10:05:15.523: INFO: Successfully updated pod "labelsupdate4edfb0bf-4130-4dd4-ab1a-7cbf2e5d5492"
  Dec 19 10:05:17.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1072" for this suite. @ 12/19/23 10:05:17.564
• [4.686 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 12/19/23 10:05:17.581
  Dec 19 10:05:17.581: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:05:17.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:17.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:17.616
  STEP: creating an Endpoint @ 12/19/23 10:05:17.627
  STEP: waiting for available Endpoint @ 12/19/23 10:05:17.637
  STEP: listing all Endpoints @ 12/19/23 10:05:17.639
  STEP: updating the Endpoint @ 12/19/23 10:05:17.647
  STEP: fetching the Endpoint @ 12/19/23 10:05:17.659
  STEP: patching the Endpoint @ 12/19/23 10:05:17.666
  STEP: fetching the Endpoint @ 12/19/23 10:05:17.678
  STEP: deleting the Endpoint by Collection @ 12/19/23 10:05:17.684
  STEP: waiting for Endpoint deletion @ 12/19/23 10:05:17.698
  STEP: fetching the Endpoint @ 12/19/23 10:05:17.702
  Dec 19 10:05:17.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7786" for this suite. @ 12/19/23 10:05:17.719
• [0.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 12/19/23 10:05:17.743
  Dec 19 10:05:17.743: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:05:17.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:17.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:17.775
  STEP: Creating simple DaemonSet "daemon-set" @ 12/19/23 10:05:17.824
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 10:05:17.839
  Dec 19 10:05:17.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:05:17.856: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:18.874: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:05:18.874: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:19.859: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:19.859: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:20.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:20.856: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:21.861: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:21.862: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:22.893: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:22.893: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:23.868: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:23.869: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:24.861: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:24.861: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:25.858: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:25.858: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:26.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:26.856: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:27.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:27.855: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:28.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:28.856: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:29.864: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:05:29.865: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  Dec 19 10:05:30.867: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:05:30.867: INFO: Node uikie9pei4sh-2 is running 0 daemon pod, expected 1
  Dec 19 10:05:31.861: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:05:31.861: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 12/19/23 10:05:31.867
  STEP: DeleteCollection of the DaemonSets @ 12/19/23 10:05:31.878
  STEP: Verify that ReplicaSets have been deleted @ 12/19/23 10:05:31.895
  Dec 19 10:05:31.932: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3659"},"items":null}

  Dec 19 10:05:31.945: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3659"},"items":[{"metadata":{"name":"daemon-set-469sg","generateName":"daemon-set-","namespace":"daemonsets-6925","uid":"ff571186-174e-412a-bcf4-d09db74f0003","resourceVersion":"3656","creationTimestamp":"2023-12-19T10:05:17Z","deletionTimestamp":"2023-12-19T10:06:01Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"661b4d9d-0085-4189-af2d-d73a4bd65ed9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-19T10:05:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"661b4d9d-0085-4189-af2d-d73a4bd65ed9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-19T10:05:30Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-p5pj5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-p5pj5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"uikie9pei4sh-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["uikie9pei4sh-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:30Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:30Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:30Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:17Z"}],"hostIP":"192.168.121.241","hostIPs":[{"ip":"192.168.121.241"}],"podIP":"10.233.64.6","podIPs":[{"ip":"10.233.64.6"}],"startTime":"2023-12-19T10:05:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-19T10:05:29Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089","containerID":"cri-o://1de8b93ff3c76504b0fbb8f9fd19fb55b6fa5ca0adc04cd3991fd6fed325d075","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-bm9vm","generateName":"daemon-set-","namespace":"daemonsets-6925","uid":"4f92f01a-6d04-48c4-87c0-4b457484155a","resourceVersion":"3658","creationTimestamp":"2023-12-19T10:05:17Z","deletionTimestamp":"2023-12-19T10:06:01Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"661b4d9d-0085-4189-af2d-d73a4bd65ed9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-19T10:05:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"661b4d9d-0085-4189-af2d-d73a4bd65ed9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-19T10:05:31Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bj2wf","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bj2wf","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"uikie9pei4sh-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["uikie9pei4sh-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:31Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:31Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:31Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:17Z"}],"hostIP":"192.168.121.77","hostIPs":[{"ip":"192.168.121.77"}],"podIP":"10.233.65.3","podIPs":[{"ip":"10.233.65.3"}],"startTime":"2023-12-19T10:05:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-19T10:05:30Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089","containerID":"cri-o://9a47e3c3adf0becc95d23e451b07c7373dee032d09b5011fd2da63468366614e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-sbhw7","generateName":"daemon-set-","namespace":"daemonsets-6925","uid":"3c67c612-ca46-4515-9c50-8c12d67b30fe","resourceVersion":"3657","creationTimestamp":"2023-12-19T10:05:17Z","deletionTimestamp":"2023-12-19T10:06:01Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"661b4d9d-0085-4189-af2d-d73a4bd65ed9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-19T10:05:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"661b4d9d-0085-4189-af2d-d73a4bd65ed9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-19T10:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mmc79","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mmc79","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"uikie9pei4sh-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["uikie9pei4sh-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:19Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:19Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:19Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T10:05:17Z"}],"hostIP":"192.168.121.201","hostIPs":[{"ip":"192.168.121.201"}],"podIP":"10.233.66.15","podIPs":[{"ip":"10.233.66.15"}],"startTime":"2023-12-19T10:05:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-19T10:05:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089","containerID":"cri-o://076bc6427b7b0750816368ae900379a7548506dfef4d7d49a7e7c4be5e45337b","started":true}],"qosClass":"BestEffort"}}]}

  Dec 19 10:05:31.988: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6925" for this suite. @ 12/19/23 10:05:31.994
• [14.272 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 12/19/23 10:05:32.016
  Dec 19 10:05:32.016: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:05:32.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:32.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:32.064
  STEP: Creating a ResourceQuota @ 12/19/23 10:05:32.076
  STEP: Getting a ResourceQuota @ 12/19/23 10:05:32.094
  STEP: Updating a ResourceQuota @ 12/19/23 10:05:32.106
  STEP: Verifying a ResourceQuota was modified @ 12/19/23 10:05:32.12
  STEP: Deleting a ResourceQuota @ 12/19/23 10:05:32.146
  STEP: Verifying the deleted ResourceQuota @ 12/19/23 10:05:32.18
  Dec 19 10:05:32.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4844" for this suite. @ 12/19/23 10:05:32.197
• [0.208 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 12/19/23 10:05:32.226
  Dec 19 10:05:32.226: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:05:32.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:32.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:32.296
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:05:32.304
  STEP: Saw pod success @ 12/19/23 10:05:36.359
  Dec 19 10:05:36.369: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-df411520-6767-4bcf-a699-ab68cba2a454 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:05:36.393
  Dec 19 10:05:36.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9871" for this suite. @ 12/19/23 10:05:36.451
• [4.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 12/19/23 10:05:36.486
  Dec 19 10:05:36.486: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:05:36.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:36.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:36.544
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:05:36.55
  STEP: Saw pod success @ 12/19/23 10:05:40.604
  Dec 19 10:05:40.612: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-7f167a89-b387-473d-93ce-311de14c1bf9 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:05:40.63
  Dec 19 10:05:40.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7068" for this suite. @ 12/19/23 10:05:40.68
• [4.216 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 12/19/23 10:05:40.708
  Dec 19 10:05:40.708: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:05:40.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:40.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:40.761
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-4213 @ 12/19/23 10:05:40.768
  STEP: changing the ExternalName service to type=NodePort @ 12/19/23 10:05:40.783
  STEP: creating replication controller externalname-service in namespace services-4213 @ 12/19/23 10:05:40.822
  I1219 10:05:40.849872      13 runners.go:197] Created replication controller with name: externalname-service, namespace: services-4213, replica count: 2
  I1219 10:05:43.904016      13 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:05:43.905: INFO: Creating new exec pod
  Dec 19 10:05:46.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-4213 exec execpodvxp78 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec 19 10:05:47.449: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec 19 10:05:47.449: INFO: stdout: ""
  Dec 19 10:05:47.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-4213 exec execpodvxp78 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec 19 10:05:48.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec 19 10:05:48.297: INFO: stdout: "externalname-service-wwnrg"
  Dec 19 10:05:48.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-4213 exec execpodvxp78 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.60.24 80'
  Dec 19 10:05:48.640: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.60.24 80\nConnection to 10.233.60.24 80 port [tcp/http] succeeded!\n"
  Dec 19 10:05:48.640: INFO: stdout: "externalname-service-2qg72"
  Dec 19 10:05:48.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-4213 exec execpodvxp78 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 32183'
  Dec 19 10:05:48.942: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.241 32183\nConnection to 192.168.121.241 32183 port [tcp/*] succeeded!\n"
  Dec 19 10:05:48.942: INFO: stdout: "externalname-service-wwnrg"
  Dec 19 10:05:48.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-4213 exec execpodvxp78 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.201 32183'
  Dec 19 10:05:49.177: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.201 32183\nConnection to 192.168.121.201 32183 port [tcp/*] succeeded!\n"
  Dec 19 10:05:49.177: INFO: stdout: "externalname-service-wwnrg"
  Dec 19 10:05:49.178: INFO: Cleaning up the ExternalName to NodePort test service
  Dec 19 10:05:49.217: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4213" for this suite. @ 12/19/23 10:05:49.225
• [8.533 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 12/19/23 10:05:49.243
  Dec 19 10:05:49.243: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:05:49.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:49.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:49.298
  STEP: Creating configMap with name projected-configmap-test-volume-2021f915-74d4-41df-b03e-e8d85d0a942b @ 12/19/23 10:05:49.306
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:05:49.315
  STEP: Saw pod success @ 12/19/23 10:05:53.372
  Dec 19 10:05:53.377: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-390191fb-a56b-48c5-9160-028edc34361d container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:05:53.413
  Dec 19 10:05:53.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-209" for this suite. @ 12/19/23 10:05:53.463
• [4.232 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 12/19/23 10:05:53.483
  Dec 19 10:05:53.483: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename lease-test @ 12/19/23 10:05:53.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:53.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:53.52
  Dec 19 10:05:53.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-1691" for this suite. @ 12/19/23 10:05:53.662
• [0.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 12/19/23 10:05:53.703
  Dec 19 10:05:53.703: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:05:53.722
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:53.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:53.774
  Dec 19 10:05:53.815: INFO: created pod pod-service-account-defaultsa
  Dec 19 10:05:53.816: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Dec 19 10:05:53.828: INFO: created pod pod-service-account-mountsa
  Dec 19 10:05:53.828: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Dec 19 10:05:53.842: INFO: created pod pod-service-account-nomountsa
  Dec 19 10:05:53.842: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Dec 19 10:05:53.865: INFO: created pod pod-service-account-defaultsa-mountspec
  Dec 19 10:05:53.865: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Dec 19 10:05:53.881: INFO: created pod pod-service-account-mountsa-mountspec
  Dec 19 10:05:53.881: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Dec 19 10:05:53.893: INFO: created pod pod-service-account-nomountsa-mountspec
  Dec 19 10:05:53.893: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Dec 19 10:05:53.915: INFO: created pod pod-service-account-defaultsa-nomountspec
  Dec 19 10:05:53.915: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Dec 19 10:05:53.952: INFO: created pod pod-service-account-mountsa-nomountspec
  Dec 19 10:05:53.952: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Dec 19 10:05:53.988: INFO: created pod pod-service-account-nomountsa-nomountspec
  Dec 19 10:05:53.988: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Dec 19 10:05:53.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5418" for this suite. @ 12/19/23 10:05:54.075
• [0.438 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 12/19/23 10:05:54.148
  Dec 19 10:05:54.148: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename apf @ 12/19/23 10:05:54.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:54.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:54.239
  STEP: getting /apis @ 12/19/23 10:05:54.244
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 12/19/23 10:05:54.252
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 12/19/23 10:05:54.253
  STEP: creating @ 12/19/23 10:05:54.255
  STEP: getting @ 12/19/23 10:05:54.351
  STEP: listing @ 12/19/23 10:05:54.368
  STEP: watching @ 12/19/23 10:05:54.374
  Dec 19 10:05:54.374: INFO: starting watch
  STEP: patching @ 12/19/23 10:05:54.377
  STEP: updating @ 12/19/23 10:05:54.395
  Dec 19 10:05:54.425: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 12/19/23 10:05:54.425
  STEP: patching /status @ 12/19/23 10:05:54.432
  STEP: updating /status @ 12/19/23 10:05:54.473
  STEP: deleting @ 12/19/23 10:05:54.521
  STEP: deleting a collection @ 12/19/23 10:05:54.617
  Dec 19 10:05:54.726: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-4149" for this suite. @ 12/19/23 10:05:54.736
• [0.610 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 12/19/23 10:05:54.76
  Dec 19 10:05:54.760: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:05:54.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:05:54.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:05:54.829
  Dec 19 10:05:54.835: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/19/23 10:05:56.94
  Dec 19 10:05:56.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-2321 --namespace=crd-publish-openapi-2321 create -f -'
  Dec 19 10:05:57.379: INFO: stderr: ""
  Dec 19 10:05:57.379: INFO: stdout: "e2e-test-crd-publish-openapi-54-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec 19 10:05:57.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-2321 --namespace=crd-publish-openapi-2321 delete e2e-test-crd-publish-openapi-54-crds test-cr'
  Dec 19 10:05:57.601: INFO: stderr: ""
  Dec 19 10:05:57.601: INFO: stdout: "e2e-test-crd-publish-openapi-54-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Dec 19 10:05:57.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-2321 --namespace=crd-publish-openapi-2321 apply -f -'
  Dec 19 10:05:57.779: INFO: stderr: ""
  Dec 19 10:05:57.779: INFO: stdout: "e2e-test-crd-publish-openapi-54-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec 19 10:05:57.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-2321 --namespace=crd-publish-openapi-2321 delete e2e-test-crd-publish-openapi-54-crds test-cr'
  Dec 19 10:05:57.986: INFO: stderr: ""
  Dec 19 10:05:57.986: INFO: stdout: "e2e-test-crd-publish-openapi-54-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/19/23 10:05:57.986
  Dec 19 10:05:57.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-2321 explain e2e-test-crd-publish-openapi-54-crds'
  Dec 19 10:05:58.140: INFO: stderr: ""
  Dec 19 10:05:58.140: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-54-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Dec 19 10:06:00.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2321" for this suite. @ 12/19/23 10:06:00.19
• [5.452 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 12/19/23 10:06:00.212
  Dec 19 10:06:00.212: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename server-version @ 12/19/23 10:06:00.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:06:00.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:06:00.279
  STEP: Request ServerVersion @ 12/19/23 10:06:00.283
  STEP: Confirm major version @ 12/19/23 10:06:00.285
  Dec 19 10:06:00.285: INFO: Major version: 1
  STEP: Confirm minor version @ 12/19/23 10:06:00.285
  Dec 19 10:06:00.285: INFO: cleanMinorVersion: 29
  Dec 19 10:06:00.285: INFO: Minor version: 29
  Dec 19 10:06:00.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-3982" for this suite. @ 12/19/23 10:06:00.296
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 12/19/23 10:06:00.311
  Dec 19 10:06:00.311: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename subjectreview @ 12/19/23 10:06:00.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:06:00.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:06:00.383
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-2722" @ 12/19/23 10:06:00.387
  Dec 19 10:06:00.393: INFO: saUsername: "system:serviceaccount:subjectreview-2722:e2e"
  Dec 19 10:06:00.393: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-2722"}
  Dec 19 10:06:00.393: INFO: saUID: "4baea0b0-e26b-44a2-af68-7e716eb34818"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-2722:e2e" @ 12/19/23 10:06:00.393
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-2722:e2e" @ 12/19/23 10:06:00.402
  Dec 19 10:06:00.406: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-2722:e2e" api 'list' configmaps in "subjectreview-2722" namespace @ 12/19/23 10:06:00.407
  Dec 19 10:06:00.409: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-2722:e2e" @ 12/19/23 10:06:00.409
  Dec 19 10:06:00.411: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Dec 19 10:06:00.411: INFO: LocalSubjectAccessReview has been verified
  Dec 19 10:06:00.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-2722" for this suite. @ 12/19/23 10:06:00.42
• [0.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 12/19/23 10:06:00.432
  Dec 19 10:06:00.432: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 10:06:00.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:06:00.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:06:00.475
  Dec 19 10:06:00.506: INFO: Waiting up to 1m0s for all nodes to be ready
  Dec 19 10:07:00.520: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/19/23 10:07:00.531
  Dec 19 10:07:00.532: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/19/23 10:07:00.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:00.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:00.587
  STEP: Finding an available node @ 12/19/23 10:07:00.597
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/19/23 10:07:00.597
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/19/23 10:07:02.635
  Dec 19 10:07:02.657: INFO: found a healthy node: uikie9pei4sh-3
  Dec 19 10:07:08.795: INFO: pods created so far: [1 1 1]
  Dec 19 10:07:08.795: INFO: length of pods created so far: 3
  Dec 19 10:07:10.815: INFO: pods created so far: [2 2 1]
  Dec 19 10:07:17.953: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-3306" for this suite. @ 12/19/23 10:07:17.961
  Dec 19 10:07:17.974: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5105" for this suite. @ 12/19/23 10:07:17.984
• [77.574 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 12/19/23 10:07:18.007
  Dec 19 10:07:18.007: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 10:07:18.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:18.04
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:18.047
  STEP: Creating a test namespace @ 12/19/23 10:07:18.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:18.09
  STEP: Creating a pod in the namespace @ 12/19/23 10:07:18.095
  STEP: Waiting for the pod to have running status @ 12/19/23 10:07:18.112
  STEP: Deleting the namespace @ 12/19/23 10:07:20.131
  STEP: Waiting for the namespace to be removed. @ 12/19/23 10:07:20.144
  STEP: Recreating the namespace @ 12/19/23 10:07:31.151
  STEP: Verifying there are no pods in the namespace @ 12/19/23 10:07:31.186
  Dec 19 10:07:31.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6938" for this suite. @ 12/19/23 10:07:31.203
  STEP: Destroying namespace "nsdeletetest-4894" for this suite. @ 12/19/23 10:07:31.215
  Dec 19 10:07:31.221: INFO: Namespace nsdeletetest-4894 was already deleted
  STEP: Destroying namespace "nsdeletetest-6397" for this suite. @ 12/19/23 10:07:31.221
• [13.225 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 12/19/23 10:07:31.234
  Dec 19 10:07:31.234: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:07:31.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:31.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:31.269
  STEP: Creating configMap with name configmap-test-volume-map-e90ce754-4e67-4673-8a9c-060730fbad93 @ 12/19/23 10:07:31.273
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:07:31.281
  STEP: Saw pod success @ 12/19/23 10:07:35.334
  Dec 19 10:07:35.340: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-d240dc73-6dd7-4b54-921b-b483f6b0a3aa container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:07:35.373
  Dec 19 10:07:35.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2148" for this suite. @ 12/19/23 10:07:35.413
• [4.195 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 12/19/23 10:07:35.43
  Dec 19 10:07:35.430: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 10:07:35.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:35.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:35.473
  Dec 19 10:07:35.479: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 10:07:35.495: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:07:35.502: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-1 before test
  Dec 19 10:07:35.521: INFO: coredns-76f75df574-4529k from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.522: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 10:07:35.523: INFO: coredns-76f75df574-kjr7r from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.523: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 10:07:35.523: INFO: kube-addon-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.524: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:07:35.524: INFO: kube-apiserver-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.525: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:07:35.525: INFO: kube-controller-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.525: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:07:35.526: INFO: kube-flannel-ds-qldcz from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.526: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:07:35.528: INFO: kube-proxy-wp7g9 from kube-system started at 2023-12-19 09:44:36 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.528: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:07:35.528: INFO: kube-scheduler-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.528: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:07:35.528: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qgn7f from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:07:35.528: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:07:35.528: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:07:35.528: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-2 before test
  Dec 19 10:07:35.547: INFO: kube-addon-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:07:35.547: INFO: kube-apiserver-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:07:35.547: INFO: kube-controller-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:07:35.547: INFO: kube-flannel-ds-znfxv from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:07:35.547: INFO: kube-proxy-q4vm6 from kube-system started at 2023-12-19 09:45:19 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:07:35.547: INFO: kube-scheduler-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:07:35.547: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qvrr8 from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:07:35.547: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:07:35.547: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:07:35.547: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-3 before test
  Dec 19 10:07:35.579: INFO: kube-flannel-ds-z2w96 from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.580: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:07:35.580: INFO: kube-proxy-lh685 from kube-system started at 2023-12-19 09:45:40 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.580: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:07:35.581: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:56 +0000 UTC (1 container statuses recorded)
  Dec 19 10:07:35.581: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 10:07:35.581: INFO: sonobuoy-e2e-job-b395aad1bffb4cbc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:07:35.582: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 10:07:35.582: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:07:35.582: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-8llvc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:07:35.582: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:07:35.582: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/19/23 10:07:35.583
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/19/23 10:07:37.641
  STEP: Trying to apply a random label on the found node. @ 12/19/23 10:07:37.68
  STEP: verifying the node has the label kubernetes.io/e2e-eb88b531-a9a0-4191-8e6a-bfd1e37b966f 95 @ 12/19/23 10:07:37.7
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 12/19/23 10:07:37.712
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.201 on the node which pod4 resides and expect not scheduled @ 12/19/23 10:07:39.744
  STEP: removing the label kubernetes.io/e2e-eb88b531-a9a0-4191-8e6a-bfd1e37b966f off the node uikie9pei4sh-3 @ 12/19/23 10:12:39.76
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-eb88b531-a9a0-4191-8e6a-bfd1e37b966f @ 12/19/23 10:12:39.789
  Dec 19 10:12:39.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2851" for this suite. @ 12/19/23 10:12:39.815
• [304.403 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 12/19/23 10:12:39.839
  Dec 19 10:12:39.839: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename conformance-tests @ 12/19/23 10:12:39.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:39.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:39.906
  STEP: Getting node addresses @ 12/19/23 10:12:39.921
  Dec 19 10:12:39.922: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Dec 19 10:12:39.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-3838" for this suite. @ 12/19/23 10:12:39.963
• [0.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 12/19/23 10:12:39.996
  Dec 19 10:12:39.996: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 10:12:40.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:40.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:40.091
  STEP: Creating pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939 @ 12/19/23 10:12:40.099
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 10:12:42.154
  Dec 19 10:12:42.161: INFO: Initial restart count of pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec is 0
  Dec 19 10:12:42.167: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:44.181: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:46.190: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:48.198: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:50.209: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:52.217: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:54.227: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:56.234: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:12:58.241: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:00.250: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:02.258: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:04.267: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:06.274: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:08.282: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:10.290: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:12.298: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:14.316: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:16.327: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:18.334: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:20.343: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:22.360: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:24.370: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:26.384: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:28.391: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:30.404: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:32.411: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:34.418: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:36.427: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:38.446: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:40.459: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:42.466: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:44.481: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:46.496: INFO: Get pod test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec in namespace container-probe-3939
  Dec 19 10:13:46.496: INFO: Restart count of pod container-probe-3939/test-grpc-7d6c90d9-e033-4b41-8326-db38fa4c66ec is now 1 (1m4.334634841s elapsed)
  STEP: deleting the pod @ 12/19/23 10:13:46.497
  Dec 19 10:13:46.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3939" for this suite. @ 12/19/23 10:13:46.53
• [66.547 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 12/19/23 10:13:46.546
  Dec 19 10:13:46.546: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:13:46.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:13:46.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:13:46.602
  STEP: creating Agnhost RC @ 12/19/23 10:13:46.609
  Dec 19 10:13:46.609: INFO: namespace kubectl-6083
  Dec 19 10:13:46.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-6083 create -f -'
  Dec 19 10:13:47.088: INFO: stderr: ""
  Dec 19 10:13:47.089: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/19/23 10:13:47.089
  Dec 19 10:13:48.096: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:13:48.096: INFO: Found 1 / 1
  Dec 19 10:13:48.096: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec 19 10:13:48.102: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:13:48.102: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 10:13:48.102: INFO: wait on agnhost-primary startup in kubectl-6083 
  Dec 19 10:13:48.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-6083 logs agnhost-primary-cdq99 agnhost-primary'
  Dec 19 10:13:48.302: INFO: stderr: ""
  Dec 19 10:13:48.302: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 12/19/23 10:13:48.302
  Dec 19 10:13:48.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-6083 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Dec 19 10:13:48.498: INFO: stderr: ""
  Dec 19 10:13:48.498: INFO: stdout: "service/rm2 exposed\n"
  Dec 19 10:13:48.511: INFO: Service rm2 in namespace kubectl-6083 found.
  STEP: exposing service @ 12/19/23 10:13:50.53
  Dec 19 10:13:50.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-6083 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Dec 19 10:13:50.750: INFO: stderr: ""
  Dec 19 10:13:50.750: INFO: stdout: "service/rm3 exposed\n"
  Dec 19 10:13:50.759: INFO: Service rm3 in namespace kubectl-6083 found.
  Dec 19 10:13:52.780: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6083" for this suite. @ 12/19/23 10:13:52.794
• [6.262 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 12/19/23 10:13:52.814
  Dec 19 10:13:52.814: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:13:52.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:13:52.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:13:52.865
  STEP: Setting up server cert @ 12/19/23 10:13:52.911
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:13:54.455
  STEP: Deploying the webhook pod @ 12/19/23 10:13:54.473
  STEP: Wait for the deployment to be ready @ 12/19/23 10:13:54.495
  Dec 19 10:13:54.518: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/19/23 10:13:56.557
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:13:56.595
  Dec 19 10:13:57.596: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 12/19/23 10:13:57.611
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 10:13:57.646
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 12/19/23 10:13:57.662
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 10:13:57.681
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 12/19/23 10:13:57.701
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 10:13:57.712
  Dec 19 10:13:57.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4722" for this suite. @ 12/19/23 10:13:57.827
  STEP: Destroying namespace "webhook-markers-2985" for this suite. @ 12/19/23 10:13:57.846
• [5.051 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 12/19/23 10:13:57.868
  Dec 19 10:13:57.870: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:13:57.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:13:57.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:13:57.912
  Dec 19 10:13:57.928: INFO: Got root ca configmap in namespace "svcaccounts-1425"
  Dec 19 10:13:57.938: INFO: Deleted root ca configmap in namespace "svcaccounts-1425"
  STEP: waiting for a new root ca configmap created @ 12/19/23 10:13:58.439
  Dec 19 10:13:58.448: INFO: Recreated root ca configmap in namespace "svcaccounts-1425"
  Dec 19 10:13:58.463: INFO: Updated root ca configmap in namespace "svcaccounts-1425"
  STEP: waiting for the root ca configmap reconciled @ 12/19/23 10:13:58.964
  Dec 19 10:13:58.973: INFO: Reconciled root ca configmap in namespace "svcaccounts-1425"
  Dec 19 10:13:58.973: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1425" for this suite. @ 12/19/23 10:13:58.983
• [1.126 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 12/19/23 10:13:58.996
  Dec 19 10:13:58.996: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:13:58.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:13:59.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:13:59.067
  STEP: Creating a kubernetes client @ 12/19/23 10:13:59.072
  Dec 19 10:13:59.072: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename disruption-2 @ 12/19/23 10:13:59.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:13:59.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:13:59.123
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:13:59.149
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:14:01.168
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:14:03.188
  STEP: listing a collection of PDBs across all namespaces @ 12/19/23 10:14:05.197
  STEP: listing a collection of PDBs in namespace disruption-8442 @ 12/19/23 10:14:05.207
  STEP: deleting a collection of PDBs @ 12/19/23 10:14:05.213
  STEP: Waiting for the PDB collection to be deleted @ 12/19/23 10:14:05.253
  Dec 19 10:14:05.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-7699" for this suite. @ 12/19/23 10:14:05.271
  Dec 19 10:14:05.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8442" for this suite. @ 12/19/23 10:14:05.301
• [6.316 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 12/19/23 10:14:05.313
  Dec 19 10:14:05.313: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename ingress @ 12/19/23 10:14:05.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:05.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:05.354
  STEP: getting /apis @ 12/19/23 10:14:05.359
  STEP: getting /apis/networking.k8s.io @ 12/19/23 10:14:05.366
  STEP: getting /apis/networking.k8s.iov1 @ 12/19/23 10:14:05.368
  STEP: creating @ 12/19/23 10:14:05.37
  STEP: getting @ 12/19/23 10:14:05.4
  STEP: listing @ 12/19/23 10:14:05.406
  STEP: watching @ 12/19/23 10:14:05.414
  Dec 19 10:14:05.414: INFO: starting watch
  STEP: cluster-wide listing @ 12/19/23 10:14:05.417
  STEP: cluster-wide watching @ 12/19/23 10:14:05.425
  Dec 19 10:14:05.425: INFO: starting watch
  STEP: patching @ 12/19/23 10:14:05.429
  STEP: updating @ 12/19/23 10:14:05.441
  Dec 19 10:14:05.456: INFO: waiting for watch events with expected annotations
  Dec 19 10:14:05.456: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/19/23 10:14:05.456
  STEP: updating /status @ 12/19/23 10:14:05.467
  STEP: get /status @ 12/19/23 10:14:05.487
  STEP: deleting @ 12/19/23 10:14:05.492
  STEP: deleting a collection @ 12/19/23 10:14:05.515
  Dec 19 10:14:05.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-4666" for this suite. @ 12/19/23 10:14:05.574
• [0.282 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 12/19/23 10:14:05.597
  Dec 19 10:14:05.597: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:14:05.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:05.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:05.641
  STEP: creating a secret @ 12/19/23 10:14:05.651
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 12/19/23 10:14:05.663
  STEP: patching the secret @ 12/19/23 10:14:05.67
  STEP: deleting the secret using a LabelSelector @ 12/19/23 10:14:05.689
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 12/19/23 10:14:05.703
  Dec 19 10:14:05.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7042" for this suite. @ 12/19/23 10:14:05.718
• [0.132 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 12/19/23 10:14:05.732
  Dec 19 10:14:05.732: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:14:05.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:05.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:05.77
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/19/23 10:14:05.777
  STEP: Saw pod success @ 12/19/23 10:14:09.82
  Dec 19 10:14:09.828: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-dded8153-d806-408e-9d26-dea0fef2fe9c container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:14:09.86
  Dec 19 10:14:09.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1474" for this suite. @ 12/19/23 10:14:09.911
• [4.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 12/19/23 10:14:09.935
  Dec 19 10:14:09.935: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:14:09.938
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:09.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:09.979
  Dec 19 10:14:09.986: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/19/23 10:14:12.15
  Dec 19 10:14:12.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9588 --namespace=crd-publish-openapi-9588 create -f -'
  Dec 19 10:14:12.384: INFO: stderr: ""
  Dec 19 10:14:12.384: INFO: stdout: "e2e-test-crd-publish-openapi-3958-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec 19 10:14:12.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9588 --namespace=crd-publish-openapi-9588 delete e2e-test-crd-publish-openapi-3958-crds test-cr'
  Dec 19 10:14:12.657: INFO: stderr: ""
  Dec 19 10:14:12.657: INFO: stdout: "e2e-test-crd-publish-openapi-3958-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Dec 19 10:14:12.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9588 --namespace=crd-publish-openapi-9588 apply -f -'
  Dec 19 10:14:12.818: INFO: stderr: ""
  Dec 19 10:14:12.818: INFO: stdout: "e2e-test-crd-publish-openapi-3958-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec 19 10:14:12.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9588 --namespace=crd-publish-openapi-9588 delete e2e-test-crd-publish-openapi-3958-crds test-cr'
  Dec 19 10:14:12.998: INFO: stderr: ""
  Dec 19 10:14:12.999: INFO: stdout: "e2e-test-crd-publish-openapi-3958-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/19/23 10:14:12.999
  Dec 19 10:14:12.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9588 explain e2e-test-crd-publish-openapi-3958-crds'
  Dec 19 10:14:13.152: INFO: stderr: ""
  Dec 19 10:14:13.152: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-3958-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Dec 19 10:14:14.882: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9588" for this suite. @ 12/19/23 10:14:14.899
• [4.977 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 12/19/23 10:14:14.914
  Dec 19 10:14:14.914: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:14:14.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:14.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:14.978
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:14:14.986
  STEP: Saw pod success @ 12/19/23 10:14:19.036
  Dec 19 10:14:19.047: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-593fd78e-ba0a-40e1-ac18-8632133b3249 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:14:19.069
  Dec 19 10:14:19.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2313" for this suite. @ 12/19/23 10:14:19.105
• [4.206 seconds]
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 12/19/23 10:14:19.12
  Dec 19 10:14:19.120: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:14:19.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:19.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:19.161
  Dec 19 10:14:19.169: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: creating the pod @ 12/19/23 10:14:19.173
  STEP: submitting the pod to kubernetes @ 12/19/23 10:14:19.174
  Dec 19 10:14:21.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6932" for this suite. @ 12/19/23 10:14:21.322
• [2.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 12/19/23 10:14:21.342
  Dec 19 10:14:21.343: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:14:21.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:21.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:21.378
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:14:21.383
  STEP: Saw pod success @ 12/19/23 10:14:23.423
  Dec 19 10:14:23.429: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-7f64c5ab-9c40-4c9c-a4c6-687d6c74d5d8 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:14:23.444
  Dec 19 10:14:23.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2635" for this suite. @ 12/19/23 10:14:23.478
• [2.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 12/19/23 10:14:23.508
  Dec 19 10:14:23.508: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:14:23.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:23.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:23.543
  STEP: Creating secret with name secret-test-748d6eae-f035-42a1-95e1-8d3a57dc3445 @ 12/19/23 10:14:23.642
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:14:23.657
  STEP: Saw pod success @ 12/19/23 10:14:27.719
  Dec 19 10:14:27.727: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-aa91dcb8-d2f4-4416-ac38-58f19e2a63de container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:14:27.752
  Dec 19 10:14:27.794: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2090" for this suite. @ 12/19/23 10:14:27.806
  STEP: Destroying namespace "secret-namespace-5008" for this suite. @ 12/19/23 10:14:27.82
• [4.330 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 12/19/23 10:14:27.84
  Dec 19 10:14:27.840: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:14:27.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:27.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:27.881
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 12/19/23 10:14:27.887
  Dec 19 10:14:27.905: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6896  5a6e8ef4-416a-4a56-b47f-11a232714974 5595 0 2023-12-19 10:14:27 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-12-19 10:14:27 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-djbfj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-djbfj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 12/19/23 10:14:29.934
  Dec 19 10:14:29.935: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6896 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:14:29.936: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:14:29.941: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:14:29.942: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-6896/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 12/19/23 10:14:30.117
  Dec 19 10:14:30.117: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6896 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:14:30.117: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:14:30.120: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:14:30.120: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-6896/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec 19 10:14:30.278: INFO: Deleting pod test-dns-nameservers...
  Dec 19 10:14:30.332: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6896" for this suite. @ 12/19/23 10:14:30.356
• [2.530 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 12/19/23 10:14:30.374
  Dec 19 10:14:30.374: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:14:30.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:30.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:30.416
  Dec 19 10:14:30.421: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/19/23 10:14:32.349
  Dec 19 10:14:32.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 create -f -'
  Dec 19 10:14:32.728: INFO: stderr: ""
  Dec 19 10:14:32.728: INFO: stdout: "e2e-test-crd-publish-openapi-1815-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec 19 10:14:32.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 delete e2e-test-crd-publish-openapi-1815-crds test-cr'
  Dec 19 10:14:32.892: INFO: stderr: ""
  Dec 19 10:14:32.892: INFO: stdout: "e2e-test-crd-publish-openapi-1815-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Dec 19 10:14:32.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 apply -f -'
  Dec 19 10:14:33.098: INFO: stderr: ""
  Dec 19 10:14:33.098: INFO: stdout: "e2e-test-crd-publish-openapi-1815-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec 19 10:14:33.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 delete e2e-test-crd-publish-openapi-1815-crds test-cr'
  Dec 19 10:14:33.309: INFO: stderr: ""
  Dec 19 10:14:33.309: INFO: stdout: "e2e-test-crd-publish-openapi-1815-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 12/19/23 10:14:33.309
  Dec 19 10:14:33.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-9929 explain e2e-test-crd-publish-openapi-1815-crds'
  Dec 19 10:14:33.470: INFO: stderr: ""
  Dec 19 10:14:33.470: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-1815-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  Dec 19 10:14:35.209: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9929" for this suite. @ 12/19/23 10:14:35.24
• [4.887 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 12/19/23 10:14:35.264
  Dec 19 10:14:35.264: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:14:35.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:35.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:35.32
  STEP: Setting up server cert @ 12/19/23 10:14:35.362
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:14:36.233
  STEP: Deploying the webhook pod @ 12/19/23 10:14:36.252
  STEP: Wait for the deployment to be ready @ 12/19/23 10:14:36.277
  Dec 19 10:14:36.294: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/19/23 10:14:38.319
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:14:38.344
  Dec 19 10:14:39.344: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 12/19/23 10:14:39.362
  STEP: create a configmap that should be updated by the webhook @ 12/19/23 10:14:39.418
  Dec 19 10:14:39.637: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2847" for this suite. @ 12/19/23 10:14:39.652
  STEP: Destroying namespace "webhook-markers-4024" for this suite. @ 12/19/23 10:14:39.666
• [4.414 seconds]
------------------------------
SS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 12/19/23 10:14:39.681
  Dec 19 10:14:39.681: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/19/23 10:14:39.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:39.715
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:39.719
  STEP: Creating two CSIDrivers @ 12/19/23 10:14:39.726
  STEP: Getting "inline-driver-d6af1b47-496d-454e-b87d-e5ca1adaa0fa" & "inline-driver-39125563-e582-48de-a695-0d32457e2fbb" @ 12/19/23 10:14:39.756
  STEP: Patching the CSIDriver "inline-driver-39125563-e582-48de-a695-0d32457e2fbb" @ 12/19/23 10:14:39.769
  STEP: Updating the CSIDriver "inline-driver-39125563-e582-48de-a695-0d32457e2fbb" @ 12/19/23 10:14:39.783
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-387" @ 12/19/23 10:14:39.798
  STEP: Deleting CSIDriver "inline-driver-d6af1b47-496d-454e-b87d-e5ca1adaa0fa" @ 12/19/23 10:14:39.804
  STEP: Confirm deletion of CSIDriver "inline-driver-d6af1b47-496d-454e-b87d-e5ca1adaa0fa" @ 12/19/23 10:14:39.816
  STEP: Deleting CSIDriver "inline-driver-39125563-e582-48de-a695-0d32457e2fbb" via DeleteCollection @ 12/19/23 10:14:39.824
  STEP: Confirm deletion of CSIDriver "inline-driver-39125563-e582-48de-a695-0d32457e2fbb" @ 12/19/23 10:14:39.842
  Dec 19 10:14:39.847: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-387" for this suite. @ 12/19/23 10:14:39.859
• [0.192 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 12/19/23 10:14:39.875
  Dec 19 10:14:39.876: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 10:14:39.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:39.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:39.91
  STEP: Creating a cronjob @ 12/19/23 10:14:39.916
  STEP: creating @ 12/19/23 10:14:39.916
  STEP: getting @ 12/19/23 10:14:39.931
  STEP: listing @ 12/19/23 10:14:39.937
  STEP: watching @ 12/19/23 10:14:39.944
  Dec 19 10:14:39.944: INFO: starting watch
  STEP: cluster-wide listing @ 12/19/23 10:14:39.946
  STEP: cluster-wide watching @ 12/19/23 10:14:39.957
  Dec 19 10:14:39.957: INFO: starting watch
  STEP: patching @ 12/19/23 10:14:39.96
  STEP: updating @ 12/19/23 10:14:39.976
  Dec 19 10:14:39.996: INFO: waiting for watch events with expected annotations
  Dec 19 10:14:39.996: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/19/23 10:14:39.997
  STEP: updating /status @ 12/19/23 10:14:40.008
  STEP: get /status @ 12/19/23 10:14:40.023
  STEP: deleting @ 12/19/23 10:14:40.029
  STEP: deleting a collection @ 12/19/23 10:14:40.051
  Dec 19 10:14:40.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3210" for this suite. @ 12/19/23 10:14:40.08
• [0.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 12/19/23 10:14:40.091
  Dec 19 10:14:40.091: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 10:14:40.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:40.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:40.123
  Dec 19 10:14:40.127: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:14:41.169: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2764" for this suite. @ 12/19/23 10:14:41.182
• [1.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 12/19/23 10:14:41.2
  Dec 19 10:14:41.200: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 10:14:41.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:41.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:41.277
  STEP: Create a Replicaset @ 12/19/23 10:14:41.331
  STEP: Verify that the required pods have come up. @ 12/19/23 10:14:41.345
  Dec 19 10:14:41.351: INFO: Pod name sample-pod: Found 0 pods out of 1
  Dec 19 10:14:46.387: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 10:14:46.388
  STEP: Getting /status @ 12/19/23 10:14:46.388
  Dec 19 10:14:46.398: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 12/19/23 10:14:46.399
  Dec 19 10:14:46.420: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 12/19/23 10:14:46.421
  Dec 19 10:14:46.425: INFO: Observed &ReplicaSet event: ADDED
  Dec 19 10:14:46.426: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.426: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.426: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.426: INFO: Found replicaset test-rs in namespace replicaset-8295 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 10:14:46.426: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 12/19/23 10:14:46.426
  Dec 19 10:14:46.426: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec 19 10:14:46.440: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 12/19/23 10:14:46.44
  Dec 19 10:14:46.445: INFO: Observed &ReplicaSet event: ADDED
  Dec 19 10:14:46.445: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.445: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.446: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.446: INFO: Observed replicaset test-rs in namespace replicaset-8295 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:14:46.446: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 10:14:46.446: INFO: Found replicaset test-rs in namespace replicaset-8295 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Dec 19 10:14:46.446: INFO: Replicaset test-rs has a patched status
  Dec 19 10:14:46.446: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8295" for this suite. @ 12/19/23 10:14:46.468
• [5.284 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 12/19/23 10:14:46.485
  Dec 19 10:14:46.485: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:14:46.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:46.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:46.535
  STEP: Creating configMap with name configmap-test-volume-a9680ddd-c67e-4211-9c5b-8c9a6bb59069 @ 12/19/23 10:14:46.542
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:14:46.551
  STEP: Saw pod success @ 12/19/23 10:14:50.608
  Dec 19 10:14:50.613: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-1e702e0d-c1b6-4efe-9d0a-a61e4ad6611a container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:14:50.631
  Dec 19 10:14:50.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5202" for this suite. @ 12/19/23 10:14:50.686
• [4.221 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 12/19/23 10:14:50.709
  Dec 19 10:14:50.709: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:14:50.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:14:50.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:14:50.75
  STEP: Creating service test in namespace statefulset-1473 @ 12/19/23 10:14:50.755
  STEP: Creating a new StatefulSet @ 12/19/23 10:14:50.766
  Dec 19 10:14:50.791: INFO: Found 0 stateful pods, waiting for 3
  Dec 19 10:15:00.803: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:15:00.805: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:15:00.806: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:15:00.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1473 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 10:15:01.198: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 10:15:01.198: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 10:15:01.198: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/19/23 10:15:11.217
  Dec 19 10:15:11.255: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/19/23 10:15:11.255
  STEP: Updating Pods in reverse ordinal order @ 12/19/23 10:15:21.289
  Dec 19 10:15:21.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1473 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 10:15:21.669: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 10:15:21.669: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 10:15:21.669: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 10:15:31.711: INFO: Waiting for StatefulSet statefulset-1473/ss2 to complete update
  Dec 19 10:15:31.711: INFO: Waiting for Pod statefulset-1473/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:15:31.711: INFO: Waiting for Pod statefulset-1473/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:15:41.712: INFO: Waiting for StatefulSet statefulset-1473/ss2 to complete update
  Dec 19 10:15:41.713: INFO: Waiting for Pod statefulset-1473/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:15:51.717: INFO: Waiting for StatefulSet statefulset-1473/ss2 to complete update
  STEP: Rolling back to a previous revision @ 12/19/23 10:16:01.721
  Dec 19 10:16:01.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1473 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 10:16:02.065: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 10:16:02.065: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 10:16:02.065: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 10:16:12.124: INFO: Updating stateful set ss2
  STEP: Rolling back update in reverse ordinal order @ 12/19/23 10:16:22.158
  Dec 19 10:16:22.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1473 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 10:16:22.534: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 10:16:22.535: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 10:16:22.535: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 10:16:32.574: INFO: Deleting all statefulset in ns statefulset-1473
  Dec 19 10:16:32.586: INFO: Scaling statefulset ss2 to 0
  Dec 19 10:16:42.634: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 10:16:42.649: INFO: Deleting statefulset ss2
  Dec 19 10:16:42.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1473" for this suite. @ 12/19/23 10:16:42.713
• [112.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 12/19/23 10:16:42.742
  Dec 19 10:16:42.742: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 10:16:42.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:16:42.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:16:42.791
  STEP: apply creating a deployment @ 12/19/23 10:16:42.797
  Dec 19 10:16:42.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6182" for this suite. @ 12/19/23 10:16:42.848
• [0.122 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 12/19/23 10:16:42.866
  Dec 19 10:16:42.866: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:16:42.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:16:42.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:16:42.904
  STEP: creating secret secrets-1433/secret-test-3c5ec128-5248-4319-ae81-909a0f071905 @ 12/19/23 10:16:42.91
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:16:42.921
  STEP: Saw pod success @ 12/19/23 10:16:46.981
  Dec 19 10:16:46.988: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-49af46ba-6e91-465f-befc-2e778bdc6b8a container env-test: <nil>
  STEP: delete the pod @ 12/19/23 10:16:47.029
  Dec 19 10:16:47.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1433" for this suite. @ 12/19/23 10:16:47.067
• [4.221 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 12/19/23 10:16:47.106
  Dec 19 10:16:47.107: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:16:47.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:16:47.14
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:16:47.149
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 10:16:47.156
  Dec 19 10:16:47.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-8990 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec 19 10:16:47.373: INFO: stderr: ""
  Dec 19 10:16:47.373: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 12/19/23 10:16:47.374
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/19/23 10:16:52.427
  Dec 19 10:16:52.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-8990 get pod e2e-test-httpd-pod -o json'
  Dec 19 10:16:52.669: INFO: stderr: ""
  Dec 19 10:16:52.669: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-12-19T10:16:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8990\",\n        \"resourceVersion\": \"6528\",\n        \"uid\": \"59b4ba14-8498-4ed3-9e2b-db7c710a1f7d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tndsr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"uikie9pei4sh-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tndsr\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T10:16:48Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T10:16:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T10:16:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T10:16:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T10:16:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://b010c5fe18fc1c037b02c357b4d8dc0e4bd0bc52697259f2bd2ef5f6ccc70457\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-12-19T10:16:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.201\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.121.201\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.50\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.50\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-12-19T10:16:47Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 12/19/23 10:16:52.669
  Dec 19 10:16:52.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-8990 replace -f -'
  Dec 19 10:16:53.000: INFO: stderr: ""
  Dec 19 10:16:53.001: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 12/19/23 10:16:53.001
  Dec 19 10:16:53.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-8990 delete pods e2e-test-httpd-pod'
  Dec 19 10:16:55.047: INFO: stderr: ""
  Dec 19 10:16:55.047: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec 19 10:16:55.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8990" for this suite. @ 12/19/23 10:16:55.055
• [7.961 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 12/19/23 10:16:55.068
  Dec 19 10:16:55.068: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:16:55.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:16:55.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:16:55.104
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:16:55.126
  STEP: Updating PodDisruptionBudget status @ 12/19/23 10:16:55.133
  STEP: Waiting for all pods to be running @ 12/19/23 10:16:55.153
  Dec 19 10:16:55.175: INFO: running pods: 0 < 1
  STEP: locating a running pod @ 12/19/23 10:16:57.166
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:16:57.19
  STEP: Patching PodDisruptionBudget status @ 12/19/23 10:16:57.212
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:16:57.23
  Dec 19 10:16:57.238: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5028" for this suite. @ 12/19/23 10:16:57.251
• [2.198 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 12/19/23 10:16:57.282
  Dec 19 10:16:57.282: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:16:57.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:16:57.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:16:57.317
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:16:57.329
  STEP: Waiting for all pods to be running @ 12/19/23 10:16:59.421
  Dec 19 10:16:59.437: INFO: running pods: 0 < 3
  Dec 19 10:17:01.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9155" for this suite. @ 12/19/23 10:17:01.455
• [4.191 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 12/19/23 10:17:01.48
  Dec 19 10:17:01.480: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 10:17:01.485
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:17:01.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:17:01.517
  STEP: Creating a ForbidConcurrent cronjob @ 12/19/23 10:17:01.524
  STEP: Ensuring a job is scheduled @ 12/19/23 10:17:01.539
  STEP: Ensuring exactly one is scheduled @ 12/19/23 10:18:01.552
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/19/23 10:18:01.561
  STEP: Ensuring no more jobs are scheduled @ 12/19/23 10:18:01.571
  STEP: Removing cronjob @ 12/19/23 10:23:01.595
  Dec 19 10:23:01.616: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4192" for this suite. @ 12/19/23 10:23:01.628
• [360.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 12/19/23 10:23:01.652
  Dec 19 10:23:01.652: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:23:01.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:23:01.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:23:01.737
  STEP: Creating a pod to test substitution in volume subpath @ 12/19/23 10:23:01.749
  STEP: Saw pod success @ 12/19/23 10:23:05.823
  Dec 19 10:23:05.832: INFO: Trying to get logs from node uikie9pei4sh-3 pod var-expansion-222b3230-6652-4214-92e5-54c8b649e504 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:23:05.871
  Dec 19 10:23:05.907: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2851" for this suite. @ 12/19/23 10:23:05.917
• [4.279 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 12/19/23 10:23:05.932
  Dec 19 10:23:05.932: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:23:05.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:23:05.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:23:05.972
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:23:05.979
  STEP: Saw pod success @ 12/19/23 10:23:10.05
  Dec 19 10:23:10.059: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-709d221b-bf50-42a4-b388-327dc12faa44 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:23:10.076
  Dec 19 10:23:10.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2533" for this suite. @ 12/19/23 10:23:10.131
• [4.221 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 12/19/23 10:23:10.155
  Dec 19 10:23:10.155: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:23:10.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:23:10.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:23:10.207
  STEP: Creating resourceQuota "e2e-rq-status-8mdtr" @ 12/19/23 10:23:10.222
  Dec 19 10:23:10.240: INFO: Resource quota "e2e-rq-status-8mdtr" reports spec: hard cpu limit of 500m
  Dec 19 10:23:10.241: INFO: Resource quota "e2e-rq-status-8mdtr" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-8mdtr" /status @ 12/19/23 10:23:10.241
  STEP: Confirm /status for "e2e-rq-status-8mdtr" resourceQuota via watch @ 12/19/23 10:23:10.26
  Dec 19 10:23:10.265: INFO: observed resourceQuota "e2e-rq-status-8mdtr" in namespace "resourcequota-6957" with hard status: v1.ResourceList(nil)
  Dec 19 10:23:10.266: INFO: Found resourceQuota "e2e-rq-status-8mdtr" in namespace "resourcequota-6957" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec 19 10:23:10.266: INFO: ResourceQuota "e2e-rq-status-8mdtr" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 12/19/23 10:23:10.273
  Dec 19 10:23:10.292: INFO: Resource quota "e2e-rq-status-8mdtr" reports spec: hard cpu limit of 1
  Dec 19 10:23:10.292: INFO: Resource quota "e2e-rq-status-8mdtr" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-8mdtr" /status @ 12/19/23 10:23:10.293
  STEP: Confirm /status for "e2e-rq-status-8mdtr" resourceQuota via watch @ 12/19/23 10:23:10.315
  Dec 19 10:23:10.320: INFO: observed resourceQuota "e2e-rq-status-8mdtr" in namespace "resourcequota-6957" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec 19 10:23:10.320: INFO: Found resourceQuota "e2e-rq-status-8mdtr" in namespace "resourcequota-6957" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Dec 19 10:23:10.320: INFO: ResourceQuota "e2e-rq-status-8mdtr" /status was patched
  STEP: Get "e2e-rq-status-8mdtr" /status @ 12/19/23 10:23:10.32
  Dec 19 10:23:10.345: INFO: Resourcequota "e2e-rq-status-8mdtr" reports status: hard cpu of 1
  Dec 19 10:23:10.346: INFO: Resourcequota "e2e-rq-status-8mdtr" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-8mdtr" /status before checking Spec is unchanged @ 12/19/23 10:23:10.388
  Dec 19 10:23:10.406: INFO: Resourcequota "e2e-rq-status-8mdtr" reports status: hard cpu of 2
  Dec 19 10:23:10.406: INFO: Resourcequota "e2e-rq-status-8mdtr" reports status: hard memory of 2Gi
  Dec 19 10:23:10.409: INFO: Found resourceQuota "e2e-rq-status-8mdtr" in namespace "resourcequota-6957" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Dec 19 10:23:10.417: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ac76c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ac7770), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ac77a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:15.417: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ac7ad0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ac7b30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ac7b60), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:20.418: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0408), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0438), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0498), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:25.419: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0810), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0888), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd08b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:30.417: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a030), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a078), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a108), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:35.423: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a390), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a438), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a468), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:40.420: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a828), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a858), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453a8a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:45.418: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0e40), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0ea0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd0ed0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:50.423: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453aa98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453aaf8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453ab28), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:23:55.424: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453ad50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453adb0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453ade0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:00.428: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd12f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1338), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd13b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:05.419: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1728), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1758), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd17b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:10.418: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1ab8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1b00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1b48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:15.420: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453b308), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453b350), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453b3b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:20.422: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1d70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1da0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003dd1e00), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:25.418: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003354090), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0033540d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003354120), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:30.419: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003354318), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003354360), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0033543a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:35.421: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453bad0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453bb30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453bb60), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:40.422: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003354588), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0033545d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003354618), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:45.423: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-8mdtr", GenerateName:"", Namespace:"resourcequota-6957", SelfLink:"", UID:"9b971e08-03a6-4a3b-8554-f8706ee4180a", ResourceVersion:"7401", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-8mdtr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453bf80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00453bfe0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 23, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ca2018), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  Dec 19 10:24:50.417: INFO: ResourceQuota "e2e-rq-status-8mdtr" Spec was unchanged and /status reset
  Dec 19 10:24:50.418: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6957" for this suite. @ 12/19/23 10:24:50.433
• [100.294 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 12/19/23 10:24:50.451
  Dec 19 10:24:50.451: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:24:50.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:24:50.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:24:50.502
  STEP: creating service in namespace services-8045 @ 12/19/23 10:24:50.51
  STEP: creating service affinity-clusterip in namespace services-8045 @ 12/19/23 10:24:50.51
  STEP: creating replication controller affinity-clusterip in namespace services-8045 @ 12/19/23 10:24:50.538
  I1219 10:24:50.560711      13 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-8045, replica count: 3
  I1219 10:24:53.613247      13 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:24:53.629: INFO: Creating new exec pod
  Dec 19 10:24:56.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8045 exec execpod-affinity27rrd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Dec 19 10:24:57.067: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Dec 19 10:24:57.071: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:24:57.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8045 exec execpod-affinity27rrd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.167 80'
  Dec 19 10:24:57.369: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.167 80\nConnection to 10.233.29.167 80 port [tcp/http] succeeded!\n"
  Dec 19 10:24:57.369: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:24:57.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8045 exec execpod-affinity27rrd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.29.167:80/ ; done'
  Dec 19 10:24:57.917: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.167:80/\n"
  Dec 19 10:24:57.918: INFO: stdout: "\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d\naffinity-clusterip-xq97d"
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.918: INFO: Received response from host: affinity-clusterip-xq97d
  Dec 19 10:24:57.920: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-8045, will wait for the garbage collector to delete the pods @ 12/19/23 10:24:57.964
  Dec 19 10:24:58.049: INFO: Deleting ReplicationController affinity-clusterip took: 14.628627ms
  Dec 19 10:24:58.150: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.611715ms
  Dec 19 10:25:01.501: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8045" for this suite. @ 12/19/23 10:25:01.514
• [11.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 12/19/23 10:25:01.531
  Dec 19 10:25:01.531: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pv @ 12/19/23 10:25:01.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:01.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:01.586
  STEP: Creating initial PV and PVC @ 12/19/23 10:25:01.592
  Dec 19 10:25:01.593: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-8041" @ 12/19/23 10:25:01.627
  STEP: Listing PVCs in namespace "pv-8041" @ 12/19/23 10:25:01.637
  STEP: Patching the PV "pv-8041-8qksx" @ 12/19/23 10:25:01.648
  STEP: Patching the PVC "pvc-52c49" @ 12/19/23 10:25:01.681
  STEP: Getting PV "pv-8041-8qksx" @ 12/19/23 10:25:01.696
  STEP: Getting PVC "pvc-52c49" @ 12/19/23 10:25:01.703
  STEP: Deleting PVC "pvc-52c49" @ 12/19/23 10:25:01.719
  STEP: Confirm deletion of PVC "pvc-52c49" @ 12/19/23 10:25:01.733
  STEP: Deleting PV "pv-8041-8qksx" @ 12/19/23 10:25:03.754
  STEP: Confirm deletion of PV "pv-8041-8qksx" @ 12/19/23 10:25:03.768
  STEP: Recreating another PV & PVC @ 12/19/23 10:25:05.784
  Dec 19 10:25:05.784: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-8041-6ml2m" @ 12/19/23 10:25:05.809
  STEP: Updating the PVC "pvc-5n9mk" @ 12/19/23 10:25:05.833
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-5n9mk=updated" @ 12/19/23 10:25:05.851
  STEP: Deleting PVC "pvc-5n9mk" via DeleteCollection @ 12/19/23 10:25:05.86
  STEP: Confirm deletion of PVC "pvc-5n9mk" @ 12/19/23 10:25:05.882
  STEP: Deleting PV "pv-8041-6ml2m" via DeleteCollection @ 12/19/23 10:25:07.904
  STEP: Confirm deletion of PV "pv-8041-6ml2m" @ 12/19/23 10:25:07.932
  Dec 19 10:25:09.950: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Dec 19 10:25:09.951: INFO: Deleting PersistentVolumeClaim "pvc-5n9mk"
  Dec 19 10:25:09.958: INFO: Deleting PersistentVolume "pv-8041-6ml2m"
  Dec 19 10:25:09.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-8041" for this suite. @ 12/19/23 10:25:09.973
• [8.457 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 12/19/23 10:25:09.991
  Dec 19 10:25:09.991: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 10:25:09.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:10.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:10.025
  Dec 19 10:25:10.030: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  W1219 10:25:10.033526      13 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0013f9760 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W1219 10:25:12.786533      13 warnings.go:70] unknown field "alpha"
  W1219 10:25:12.786802      13 warnings.go:70] unknown field "beta"
  W1219 10:25:12.786828      13 warnings.go:70] unknown field "delta"
  W1219 10:25:12.786849      13 warnings.go:70] unknown field "epsilon"
  W1219 10:25:12.786878      13 warnings.go:70] unknown field "gamma"
  Dec 19 10:25:13.381: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4459" for this suite. @ 12/19/23 10:25:13.394
• [3.418 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 12/19/23 10:25:13.411
  Dec 19 10:25:13.412: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 10:25:13.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:13.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:13.455
  STEP: create the container @ 12/19/23 10:25:13.462
  W1219 10:25:13.482178      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/19/23 10:25:13.483
  STEP: get the container status @ 12/19/23 10:25:16.516
  STEP: the container should be terminated @ 12/19/23 10:25:16.521
  STEP: the termination message should be set @ 12/19/23 10:25:16.521
  Dec 19 10:25:16.521: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 12/19/23 10:25:16.521
  Dec 19 10:25:16.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4072" for this suite. @ 12/19/23 10:25:16.56
• [3.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 12/19/23 10:25:16.578
  Dec 19 10:25:16.578: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pv @ 12/19/23 10:25:16.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:16.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:16.614
  STEP: Creating initial PV and PVC @ 12/19/23 10:25:16.62
  Dec 19 10:25:16.621: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-9815" @ 12/19/23 10:25:16.654
  STEP: Listing PVCs in namespace "pv-9815" @ 12/19/23 10:25:16.662
  STEP: Reading "pvc-96ds4" Status @ 12/19/23 10:25:16.669
  STEP: Reading "pv-9815-fbz4d" Status @ 12/19/23 10:25:16.679
  STEP: Patching "pvc-96ds4" Status @ 12/19/23 10:25:16.689
  STEP: Patching "pv-9815-fbz4d" Status @ 12/19/23 10:25:16.699
  STEP: Updating "pvc-96ds4" Status @ 12/19/23 10:25:16.71
  STEP: Updating "pv-9815-fbz4d" Status @ 12/19/23 10:25:16.725
  Dec 19 10:25:16.779: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Dec 19 10:25:16.779: INFO: Deleting PersistentVolumeClaim "pvc-96ds4"
  Dec 19 10:25:16.789: INFO: Deleting PersistentVolume "pv-9815-fbz4d"
  Dec 19 10:25:16.801: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-9815" for this suite. @ 12/19/23 10:25:16.811
• [0.255 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 12/19/23 10:25:16.833
  Dec 19 10:25:16.833: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:25:16.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:16.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:16.874
  Dec 19 10:25:16.881: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 12/19/23 10:25:18.687
  Dec 19 10:25:18.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 create -f -'
  Dec 19 10:25:19.015: INFO: stderr: ""
  Dec 19 10:25:19.017: INFO: stdout: "e2e-test-crd-publish-openapi-6765-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec 19 10:25:19.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 delete e2e-test-crd-publish-openapi-6765-crds test-foo'
  Dec 19 10:25:19.237: INFO: stderr: ""
  Dec 19 10:25:19.237: INFO: stdout: "e2e-test-crd-publish-openapi-6765-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Dec 19 10:25:19.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 apply -f -'
  Dec 19 10:25:19.408: INFO: stderr: ""
  Dec 19 10:25:19.408: INFO: stdout: "e2e-test-crd-publish-openapi-6765-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec 19 10:25:19.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 delete e2e-test-crd-publish-openapi-6765-crds test-foo'
  Dec 19 10:25:19.728: INFO: stderr: ""
  Dec 19 10:25:19.728: INFO: stdout: "e2e-test-crd-publish-openapi-6765-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 12/19/23 10:25:19.728
  Dec 19 10:25:19.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 create -f -'
  Dec 19 10:25:19.880: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 12/19/23 10:25:19.881
  Dec 19 10:25:19.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 create -f -'
  Dec 19 10:25:20.049: INFO: rc: 1
  Dec 19 10:25:20.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 apply -f -'
  Dec 19 10:25:20.198: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 12/19/23 10:25:20.198
  Dec 19 10:25:20.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 create -f -'
  Dec 19 10:25:20.368: INFO: rc: 1
  Dec 19 10:25:20.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 --namespace=crd-publish-openapi-1048 apply -f -'
  Dec 19 10:25:20.560: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 12/19/23 10:25:20.56
  Dec 19 10:25:20.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 explain e2e-test-crd-publish-openapi-6765-crds'
  Dec 19 10:25:20.734: INFO: stderr: ""
  Dec 19 10:25:20.734: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6765-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 12/19/23 10:25:20.734
  Dec 19 10:25:20.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 explain e2e-test-crd-publish-openapi-6765-crds.metadata'
  Dec 19 10:25:20.889: INFO: stderr: ""
  Dec 19 10:25:20.889: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6765-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Dec 19 10:25:20.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 explain e2e-test-crd-publish-openapi-6765-crds.spec'
  Dec 19 10:25:21.074: INFO: stderr: ""
  Dec 19 10:25:21.074: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6765-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Dec 19 10:25:21.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 explain e2e-test-crd-publish-openapi-6765-crds.spec.bars'
  Dec 19 10:25:21.246: INFO: stderr: ""
  Dec 19 10:25:21.246: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6765-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 12/19/23 10:25:21.248
  Dec 19 10:25:21.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=crd-publish-openapi-1048 explain e2e-test-crd-publish-openapi-6765-crds.spec.bars2'
  Dec 19 10:25:21.417: INFO: rc: 1
  Dec 19 10:25:23.243: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1048" for this suite. @ 12/19/23 10:25:23.262
• [6.439 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 12/19/23 10:25:23.273
  Dec 19 10:25:23.274: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 10:25:23.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:23.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:23.308
  Dec 19 10:25:27.355: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6974" for this suite. @ 12/19/23 10:25:27.361
• [4.103 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 12/19/23 10:25:27.378
  Dec 19 10:25:27.378: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 10:25:27.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:27.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:27.419
  STEP: Create a ReplicaSet @ 12/19/23 10:25:27.425
  STEP: Verify that the required pods have come up @ 12/19/23 10:25:27.434
  Dec 19 10:25:27.442: INFO: Pod name sample-pod: Found 0 pods out of 3
  Dec 19 10:25:32.460: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 12/19/23 10:25:32.461
  Dec 19 10:25:32.478: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 12/19/23 10:25:32.478
  STEP: DeleteCollection of the ReplicaSets @ 12/19/23 10:25:32.487
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 12/19/23 10:25:32.505
  Dec 19 10:25:32.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2578" for this suite. @ 12/19/23 10:25:32.533
• [5.208 seconds]
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 12/19/23 10:25:32.586
  Dec 19 10:25:32.586: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:25:32.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:32.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:32.685
  STEP: creating service in namespace services-342 @ 12/19/23 10:25:32.691
  STEP: creating service affinity-nodeport in namespace services-342 @ 12/19/23 10:25:32.691
  STEP: creating replication controller affinity-nodeport in namespace services-342 @ 12/19/23 10:25:32.822
  I1219 10:25:32.867129      13 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-342, replica count: 3
  I1219 10:25:35.919717      13 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:25:35.964: INFO: Creating new exec pod
  Dec 19 10:25:39.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-342 exec execpod-affinity64wtp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Dec 19 10:25:39.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Dec 19 10:25:39.313: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:25:39.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-342 exec execpod-affinity64wtp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.6.44 80'
  Dec 19 10:25:39.541: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.6.44 80\nConnection to 10.233.6.44 80 port [tcp/http] succeeded!\n"
  Dec 19 10:25:39.541: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:25:39.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-342 exec execpod-affinity64wtp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 31981'
  Dec 19 10:25:39.797: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.241 31981\nConnection to 192.168.121.241 31981 port [tcp/*] succeeded!\n"
  Dec 19 10:25:39.798: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:25:39.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-342 exec execpod-affinity64wtp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.201 31981'
  Dec 19 10:25:40.049: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.201 31981\nConnection to 192.168.121.201 31981 port [tcp/*] succeeded!\n"
  Dec 19 10:25:40.049: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:25:40.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-342 exec execpod-affinity64wtp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:31981/ ; done'
  Dec 19 10:25:40.517: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:31981/\n"
  Dec 19 10:25:40.517: INFO: stdout: "\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h\naffinity-nodeport-6zr6h"
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Received response from host: affinity-nodeport-6zr6h
  Dec 19 10:25:40.517: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-342, will wait for the garbage collector to delete the pods @ 12/19/23 10:25:40.547
  Dec 19 10:25:40.626: INFO: Deleting ReplicationController affinity-nodeport took: 13.150298ms
  Dec 19 10:25:40.727: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.647861ms
  Dec 19 10:25:43.988: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-342" for this suite. @ 12/19/23 10:25:43.999
• [11.429 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 12/19/23 10:25:44.028
  Dec 19 10:25:44.028: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:25:44.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:44.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:44.066
  STEP: Setting up server cert @ 12/19/23 10:25:44.113
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:25:44.983
  STEP: Deploying the webhook pod @ 12/19/23 10:25:45.007
  STEP: Wait for the deployment to be ready @ 12/19/23 10:25:45.032
  Dec 19 10:25:45.051: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 12/19/23 10:25:47.077
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:25:47.096
  Dec 19 10:25:48.099: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/19/23 10:25:48.116
  STEP: create a pod that should be denied by the webhook @ 12/19/23 10:25:48.162
  STEP: create a pod that causes the webhook to hang @ 12/19/23 10:25:48.182
  STEP: create a configmap that should be denied by the webhook @ 12/19/23 10:25:58.204
  STEP: create a configmap that should be admitted by the webhook @ 12/19/23 10:25:58.283
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/19/23 10:25:58.309
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/19/23 10:25:58.334
  STEP: create a namespace that bypass the webhook @ 12/19/23 10:25:58.348
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 12/19/23 10:25:58.385
  Dec 19 10:25:58.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-241" for this suite. @ 12/19/23 10:25:58.568
  STEP: Destroying namespace "webhook-markers-9351" for this suite. @ 12/19/23 10:25:58.593
  STEP: Destroying namespace "exempted-namespace-5216" for this suite. @ 12/19/23 10:25:58.622
• [14.614 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 12/19/23 10:25:58.643
  Dec 19 10:25:58.643: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:25:58.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:25:58.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:25:58.702
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 12/19/23 10:25:58.71
  Dec 19 10:25:58.712: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:26:00.835: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:26:08.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4440" for this suite. @ 12/19/23 10:26:08.197
• [9.570 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 12/19/23 10:26:08.22
  Dec 19 10:26:08.221: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename taint-multiple-pods @ 12/19/23 10:26:08.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:26:08.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:26:08.271
  Dec 19 10:26:08.277: INFO: Waiting up to 1m0s for all nodes to be ready
  Dec 19 10:27:08.279: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:27:08.290: INFO: Starting informer...
  STEP: Starting pods... @ 12/19/23 10:27:08.29
  Dec 19 10:27:08.533: INFO: Pod1 is running on uikie9pei4sh-3. Tainting Node
  Dec 19 10:27:10.781: INFO: Pod2 is running on uikie9pei4sh-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/19/23 10:27:10.781
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 10:27:10.807
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 12/19/23 10:27:10.821
  Dec 19 10:27:16.430: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  Dec 19 10:27:36.252: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 10:27:36.279
  Dec 19 10:27:36.289: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-9678" for this suite. @ 12/19/23 10:27:36.301
• [88.102 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 12/19/23 10:27:36.328
  Dec 19 10:27:36.328: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:27:36.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:27:36.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:27:36.397
  STEP: Creating configMap that has name configmap-test-emptyKey-cfcd6d94-f44d-4829-89ce-b0a4ca0481f0 @ 12/19/23 10:27:36.41
  Dec 19 10:27:36.414: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2864" for this suite. @ 12/19/23 10:27:36.422
• [0.108 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 12/19/23 10:27:36.436
  Dec 19 10:27:36.436: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:27:36.44
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:27:36.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:27:36.48
  STEP: Creating projection with secret that has name projected-secret-test-a2f447b7-77eb-4935-8cd5-db27ad01a5a6 @ 12/19/23 10:27:36.485
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:27:36.494
  STEP: Saw pod success @ 12/19/23 10:27:40.536
  Dec 19 10:27:40.542: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-secrets-94533007-17ba-46a9-866f-ffbca84da7a4 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:27:40.577
  Dec 19 10:27:40.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6826" for this suite. @ 12/19/23 10:27:40.616
• [4.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 12/19/23 10:27:40.63
  Dec 19 10:27:40.630: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename apf @ 12/19/23 10:27:40.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:27:40.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:27:40.67
  STEP: getting /apis @ 12/19/23 10:27:40.676
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 12/19/23 10:27:40.689
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 12/19/23 10:27:40.692
  STEP: creating @ 12/19/23 10:27:40.694
  STEP: getting @ 12/19/23 10:27:40.73
  STEP: listing @ 12/19/23 10:27:40.737
  STEP: watching @ 12/19/23 10:27:40.745
  Dec 19 10:27:40.745: INFO: starting watch
  STEP: patching @ 12/19/23 10:27:40.747
  STEP: updating @ 12/19/23 10:27:40.762
  Dec 19 10:27:40.779: INFO: waiting for watch events with expected annotations
  Dec 19 10:27:40.779: INFO: missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 12/19/23 10:27:40.78
  STEP: patching /status @ 12/19/23 10:27:40.788
  STEP: updating /status @ 12/19/23 10:27:40.809
  STEP: deleting @ 12/19/23 10:27:40.854
  STEP: deleting a collection @ 12/19/23 10:27:40.881
  Dec 19 10:27:40.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-9779" for this suite. @ 12/19/23 10:27:40.931
• [0.313 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 12/19/23 10:27:40.947
  Dec 19 10:27:40.947: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:27:40.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:27:40.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:27:40.984
  STEP: Setting up server cert @ 12/19/23 10:27:41.032
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:27:42.509
  STEP: Deploying the webhook pod @ 12/19/23 10:27:42.526
  STEP: Wait for the deployment to be ready @ 12/19/23 10:27:42.542
  Dec 19 10:27:42.555: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 12/19/23 10:27:44.577
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:27:44.597
  Dec 19 10:27:45.598: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 12/19/23 10:27:45.609
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:27:45.609
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 12/19/23 10:27:45.643
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 12/19/23 10:27:46.668
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:27:46.669
  STEP: Having no error when timeout is longer than webhook latency @ 12/19/23 10:27:47.738
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:27:47.738
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 12/19/23 10:27:52.816
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:27:52.817
  Dec 19 10:27:58.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1106" for this suite. @ 12/19/23 10:27:58.032
  STEP: Destroying namespace "webhook-markers-5147" for this suite. @ 12/19/23 10:27:58.045
• [17.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 12/19/23 10:27:58.069
  Dec 19 10:27:58.069: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:27:58.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:27:58.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:27:58.13
  STEP: Creating a test headless service @ 12/19/23 10:27:58.136
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8688.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8688.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 12/19/23 10:27:58.146
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8688.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8688.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 12/19/23 10:27:58.146
  STEP: creating a pod to probe DNS @ 12/19/23 10:27:58.146
  STEP: submitting the pod to kubernetes @ 12/19/23 10:27:58.146
  STEP: retrieving the pod @ 12/19/23 10:35:18.883
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:35:18.89
  Dec 19 10:35:18.926: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-8688/dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0: the server could not find the requested resource (get pods dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0)
  Dec 19 10:35:18.926: INFO: Lookups using dns-8688/dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0 failed for: [jessie_hosts@dns-querier-2]

  Dec 19 10:35:18.939: INFO: Pod client logs for webserver: 
  Dec 19 10:35:18.951: INFO: Pod client logs for querier: 
  Dec 19 10:35:18.964: INFO: Pod client logs for jessie-querier: 
  Dec 19 10:35:23.919: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-8688/dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0: the server could not find the requested resource (get pods dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0)
  Dec 19 10:35:23.919: INFO: Lookups using dns-8688/dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0 failed for: [jessie_hosts@dns-querier-2]

  Dec 19 10:35:23.930: INFO: Pod client logs for webserver: 
  Dec 19 10:35:23.943: INFO: Pod client logs for querier: 
  Dec 19 10:35:23.956: INFO: Pod client logs for jessie-querier: 
  Dec 19 10:35:28.917: INFO: DNS probes using dns-8688/dns-test-23d84e26-e12d-4cb4-9e1e-2ef597e81ea0 succeeded

  STEP: deleting the pod @ 12/19/23 10:35:28.919
  STEP: deleting the test headless service @ 12/19/23 10:35:28.946
  Dec 19 10:35:29.000: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8688" for this suite. @ 12/19/23 10:35:29.01
• [450.954 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 12/19/23 10:35:29.024
  Dec 19 10:35:29.024: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:35:29.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:35:29.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:35:29.086
  STEP: Setting up server cert @ 12/19/23 10:35:29.15
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:35:30.233
  STEP: Deploying the webhook pod @ 12/19/23 10:35:30.251
  STEP: Wait for the deployment to be ready @ 12/19/23 10:35:30.273
  Dec 19 10:35:30.293: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 12/19/23 10:35:32.328
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:35:32.359
  Dec 19 10:35:33.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 12/19/23 10:35:33.387
  STEP: create a namespace for the webhook @ 12/19/23 10:35:33.43
  STEP: create a configmap should be unconditionally rejected by the webhook @ 12/19/23 10:35:33.471
  Dec 19 10:35:33.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8452" for this suite. @ 12/19/23 10:35:33.693
  STEP: Destroying namespace "webhook-markers-6126" for this suite. @ 12/19/23 10:35:33.717
  STEP: Destroying namespace "fail-closed-namespace-4594" for this suite. @ 12/19/23 10:35:33.736
• [4.724 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 12/19/23 10:35:33.75
  Dec 19 10:35:33.750: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename containers @ 12/19/23 10:35:33.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:35:33.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:35:33.797
  STEP: Creating a pod to test override arguments @ 12/19/23 10:35:33.803
  STEP: Saw pod success @ 12/19/23 10:35:37.857
  Dec 19 10:35:37.865: INFO: Trying to get logs from node uikie9pei4sh-3 pod client-containers-7e119179-6f75-4d0e-a3d7-8fbf5b617f58 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:35:37.879
  Dec 19 10:35:37.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5021" for this suite. @ 12/19/23 10:35:37.925
• [4.191 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 12/19/23 10:35:37.943
  Dec 19 10:35:37.943: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 10:35:37.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:35:37.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:35:37.987
  Dec 19 10:35:38.019: INFO: Pod name sample-pod: Found 0 pods out of 1
  Dec 19 10:35:43.030: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 10:35:43.031
  STEP: Scaling up "test-rs" replicaset @ 12/19/23 10:35:43.031
  Dec 19 10:35:43.053: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 12/19/23 10:35:43.053
  Dec 19 10:35:43.084: INFO: observed ReplicaSet test-rs in namespace replicaset-1505 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:35:43.149: INFO: observed ReplicaSet test-rs in namespace replicaset-1505 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:35:43.179: INFO: observed ReplicaSet test-rs in namespace replicaset-1505 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:35:43.214: INFO: observed ReplicaSet test-rs in namespace replicaset-1505 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:35:44.305: INFO: observed ReplicaSet test-rs in namespace replicaset-1505 with ReadyReplicas 2, AvailableReplicas 2
  Dec 19 10:35:45.307: INFO: observed Replicaset test-rs in namespace replicaset-1505 with ReadyReplicas 3 found true
  Dec 19 10:35:45.308: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1505" for this suite. @ 12/19/23 10:35:45.32
• [7.395 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 12/19/23 10:35:45.339
  Dec 19 10:35:45.339: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename prestop @ 12/19/23 10:35:45.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:35:45.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:35:45.392
  STEP: Creating server pod server in namespace prestop-4732 @ 12/19/23 10:35:45.403
  STEP: Waiting for pods to come up. @ 12/19/23 10:35:45.431
  STEP: Creating tester pod tester in namespace prestop-4732 @ 12/19/23 10:35:47.459
  STEP: Deleting pre-stop pod @ 12/19/23 10:35:49.495
  Dec 19 10:35:54.520: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 12/19/23 10:35:54.523
  Dec 19 10:35:54.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-4732" for this suite. @ 12/19/23 10:35:54.604
• [9.291 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 12/19/23 10:35:54.631
  Dec 19 10:35:54.631: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:35:54.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:35:54.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:35:54.675
  STEP: Creating a pod to test downward api env vars @ 12/19/23 10:35:54.681
  STEP: Saw pod success @ 12/19/23 10:35:56.719
  Dec 19 10:35:56.727: INFO: Trying to get logs from node uikie9pei4sh-3 pod downward-api-4107cf14-5059-49b9-94fd-a7c66ea461e1 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:35:56.748
  Dec 19 10:35:56.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7433" for this suite. @ 12/19/23 10:35:56.787
• [2.176 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 12/19/23 10:35:56.807
  Dec 19 10:35:56.807: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:35:56.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:35:56.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:35:56.856
  STEP: creating service in namespace services-7023 @ 12/19/23 10:35:56.862
  STEP: creating service affinity-nodeport-transition in namespace services-7023 @ 12/19/23 10:35:56.862
  STEP: creating replication controller affinity-nodeport-transition in namespace services-7023 @ 12/19/23 10:35:56.906
  I1219 10:35:56.927977      13 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-7023, replica count: 3
  I1219 10:35:59.979843      13 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:36:00.008: INFO: Creating new exec pod
  Dec 19 10:36:03.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7023 exec execpod-affinityvrbds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Dec 19 10:36:03.418: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Dec 19 10:36:03.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:36:03.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7023 exec execpod-affinityvrbds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.53.66 80'
  Dec 19 10:36:03.742: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.53.66 80\nConnection to 10.233.53.66 80 port [tcp/http] succeeded!\n"
  Dec 19 10:36:03.742: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:36:03.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7023 exec execpod-affinityvrbds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.77 30376'
  Dec 19 10:36:03.998: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.77 30376\nConnection to 192.168.121.77 30376 port [tcp/*] succeeded!\n"
  Dec 19 10:36:03.998: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:36:03.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7023 exec execpod-affinityvrbds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.201 30376'
  Dec 19 10:36:04.310: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.201 30376\nConnection to 192.168.121.201 30376 port [tcp/*] succeeded!\n"
  Dec 19 10:36:04.310: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:36:04.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7023 exec execpod-affinityvrbds -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:30376/ ; done'
  Dec 19 10:36:04.914: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n"
  Dec 19 10:36:04.914: INFO: stdout: "\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-xz4pt\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-xz4pt\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-xz4pt\naffinity-nodeport-transition-xz4pt\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-r7kzw\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z"
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-xz4pt
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.914: INFO: Received response from host: affinity-nodeport-transition-xz4pt
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-xz4pt
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-xz4pt
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-r7kzw
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:04.915: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:04.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7023 exec execpod-affinityvrbds -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:30376/ ; done'
  Dec 19 10:36:05.571: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30376/\n"
  Dec 19 10:36:05.571: INFO: stdout: "\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z\naffinity-nodeport-transition-zfs7z"
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.571: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.572: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.572: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.572: INFO: Received response from host: affinity-nodeport-transition-zfs7z
  Dec 19 10:36:05.572: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7023, will wait for the garbage collector to delete the pods @ 12/19/23 10:36:05.595
  Dec 19 10:36:05.668: INFO: Deleting ReplicationController affinity-nodeport-transition took: 12.721976ms
  Dec 19 10:36:05.769: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.852631ms
  Dec 19 10:36:08.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7023" for this suite. @ 12/19/23 10:36:08.755
• [11.967 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 12/19/23 10:36:08.789
  Dec 19 10:36:08.789: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:36:08.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:36:08.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:36:08.843
  STEP: creating a ServiceAccount @ 12/19/23 10:36:08.85
  STEP: watching for the ServiceAccount to be added @ 12/19/23 10:36:08.87
  STEP: patching the ServiceAccount @ 12/19/23 10:36:08.879
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 12/19/23 10:36:08.904
  STEP: deleting the ServiceAccount @ 12/19/23 10:36:08.914
  Dec 19 10:36:08.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5063" for this suite. @ 12/19/23 10:36:08.953
• [0.173 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 12/19/23 10:36:08.974
  Dec 19 10:36:08.974: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:36:08.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:36:09.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:36:09.01
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-7067 @ 12/19/23 10:36:09.015
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/19/23 10:36:09.049
  STEP: creating service externalsvc in namespace services-7067 @ 12/19/23 10:36:09.049
  STEP: creating replication controller externalsvc in namespace services-7067 @ 12/19/23 10:36:09.075
  I1219 10:36:09.091410      13 runners.go:197] Created replication controller with name: externalsvc, namespace: services-7067, replica count: 2
  I1219 10:36:12.144799      13 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 12/19/23 10:36:12.153
  Dec 19 10:36:12.190: INFO: Creating new exec pod
  Dec 19 10:36:14.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7067 exec execpod2wg28 -- /bin/sh -x -c nslookup nodeport-service.services-7067.svc.cluster.local'
  Dec 19 10:36:14.735: INFO: stderr: "+ nslookup nodeport-service.services-7067.svc.cluster.local\n"
  Dec 19 10:36:14.736: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-7067.svc.cluster.local\tcanonical name = externalsvc.services-7067.svc.cluster.local.\nName:\texternalsvc.services-7067.svc.cluster.local\nAddress: 10.233.56.38\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-7067, will wait for the garbage collector to delete the pods @ 12/19/23 10:36:14.736
  Dec 19 10:36:14.805: INFO: Deleting ReplicationController externalsvc took: 11.866287ms
  Dec 19 10:36:14.906: INFO: Terminating ReplicationController externalsvc pods took: 101.045874ms
  Dec 19 10:36:17.759: INFO: Cleaning up the NodePort to ExternalName test service
  Dec 19 10:36:17.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7067" for this suite. @ 12/19/23 10:36:17.807
• [8.845 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 12/19/23 10:36:17.832
  Dec 19 10:36:17.832: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename events @ 12/19/23 10:36:17.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:36:17.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:36:17.874
  STEP: Create set of events @ 12/19/23 10:36:17.881
  Dec 19 10:36:17.893: INFO: created test-event-1
  Dec 19 10:36:17.905: INFO: created test-event-2
  Dec 19 10:36:17.919: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 12/19/23 10:36:17.919
  STEP: delete collection of events @ 12/19/23 10:36:17.928
  Dec 19 10:36:17.928: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/19/23 10:36:17.972
  Dec 19 10:36:17.973: INFO: requesting list of events to confirm quantity
  Dec 19 10:36:17.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3129" for this suite. @ 12/19/23 10:36:17.99
• [0.173 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 12/19/23 10:36:18.007
  Dec 19 10:36:18.007: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 10:36:18.01
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:36:18.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:36:18.051
  STEP: create the container @ 12/19/23 10:36:18.059
  W1219 10:36:18.077065      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/19/23 10:36:18.077
  STEP: get the container status @ 12/19/23 10:36:21.109
  STEP: the container should be terminated @ 12/19/23 10:36:21.119
  STEP: the termination message should be set @ 12/19/23 10:36:21.119
  Dec 19 10:36:21.120: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/19/23 10:36:21.12
  Dec 19 10:36:21.156: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3788" for this suite. @ 12/19/23 10:36:21.169
• [3.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 12/19/23 10:36:21.19
  Dec 19 10:36:21.190: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 10:36:21.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:36:21.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:36:21.244
  STEP: Creating a cronjob @ 12/19/23 10:36:21.251
  STEP: Ensuring more than one job is running at a time @ 12/19/23 10:36:21.265
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 12/19/23 10:38:01.272
  STEP: Removing cronjob @ 12/19/23 10:38:01.284
  Dec 19 10:38:01.301: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7439" for this suite. @ 12/19/23 10:38:01.314
• [100.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 12/19/23 10:38:01.331
  Dec 19 10:38:01.331: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 10:38:01.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:01.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:01.407
  STEP: Waiting for pod completion @ 12/19/23 10:38:01.434
  Dec 19 10:38:05.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2529" for this suite. @ 12/19/23 10:38:05.504
• [4.184 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 12/19/23 10:38:05.519
  Dec 19 10:38:05.519: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename limitrange @ 12/19/23 10:38:05.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:05.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:05.564
  STEP: Creating a LimitRange @ 12/19/23 10:38:05.572
  STEP: Setting up watch @ 12/19/23 10:38:05.573
  STEP: Submitting a LimitRange @ 12/19/23 10:38:05.683
  STEP: Verifying LimitRange creation was observed @ 12/19/23 10:38:05.697
  STEP: Fetching the LimitRange to ensure it has proper values @ 12/19/23 10:38:05.697
  Dec 19 10:38:05.704: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec 19 10:38:05.705: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 12/19/23 10:38:05.705
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 12/19/23 10:38:05.717
  Dec 19 10:38:05.725: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec 19 10:38:05.725: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 12/19/23 10:38:05.726
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 12/19/23 10:38:05.739
  Dec 19 10:38:05.746: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Dec 19 10:38:05.746: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 12/19/23 10:38:05.746
  STEP: Failing to create a Pod with more than max resources @ 12/19/23 10:38:05.756
  STEP: Updating a LimitRange @ 12/19/23 10:38:05.766
  STEP: Verifying LimitRange updating is effective @ 12/19/23 10:38:05.779
  STEP: Creating a Pod with less than former min resources @ 12/19/23 10:38:07.786
  STEP: Failing to create a Pod with more than max resources @ 12/19/23 10:38:07.801
  STEP: Deleting a LimitRange @ 12/19/23 10:38:07.804
  STEP: Verifying the LimitRange was deleted @ 12/19/23 10:38:07.834
  Dec 19 10:38:12.847: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 12/19/23 10:38:12.849
  Dec 19 10:38:12.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3474" for this suite. @ 12/19/23 10:38:12.884
• [7.378 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 12/19/23 10:38:12.902
  Dec 19 10:38:12.902: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 10:38:12.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:12.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:12.946
  Dec 19 10:38:12.951: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:38:19.473: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-952" for this suite. @ 12/19/23 10:38:19.483
• [6.596 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 12/19/23 10:38:19.501
  Dec 19 10:38:19.501: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/19/23 10:38:19.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:19.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:19.548
  STEP: creating a target pod @ 12/19/23 10:38:19.566
  STEP: adding an ephemeral container @ 12/19/23 10:38:21.65
  STEP: checking pod container endpoints @ 12/19/23 10:38:25.708
  Dec 19 10:38:25.708: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3644 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:38:25.708: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:38:25.710: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:38:25.710: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-3644/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec 19 10:38:25.844: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 12/19/23 10:38:25.864
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 12/19/23 10:38:25.874
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 12/19/23 10:38:25.897
  Dec 19 10:38:25.907: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-3644" for this suite. @ 12/19/23 10:38:25.925
• [6.451 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 12/19/23 10:38:25.953
  Dec 19 10:38:25.953: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:38:25.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:26.004
  STEP: Creating configMap with name projected-configmap-test-volume-map-d6e45a2b-d364-46ba-94bc-dae1b9990b04 @ 12/19/23 10:38:26.009
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:38:26.018
  STEP: Saw pod success @ 12/19/23 10:38:30.068
  Dec 19 10:38:30.074: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-611554ff-a397-405e-8a7c-f529375dcbf3 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:38:30.097
  Dec 19 10:38:30.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5654" for this suite. @ 12/19/23 10:38:30.167
• [4.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 12/19/23 10:38:30.191
  Dec 19 10:38:30.191: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:38:30.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:30.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:30.247
  STEP: Creating secret with name secret-test-8b5e6a40-b9cd-4af4-8ccf-16ed8e884b0a @ 12/19/23 10:38:30.252
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:38:30.268
  STEP: Saw pod success @ 12/19/23 10:38:34.332
  Dec 19 10:38:34.346: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-e4ec25e8-9db5-4b4b-92c6-11ec96d0cacf container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:38:34.365
  Dec 19 10:38:34.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8816" for this suite. @ 12/19/23 10:38:34.424
• [4.249 seconds]
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 12/19/23 10:38:34.441
  Dec 19 10:38:34.442: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename job @ 12/19/23 10:38:34.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:34.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:34.499
  STEP: Creating Indexed job @ 12/19/23 10:38:34.505
  STEP: Ensuring job reaches completions @ 12/19/23 10:38:34.521
  STEP: Ensuring pods with index for job exist @ 12/19/23 10:38:42.53
  Dec 19 10:38:42.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8853" for this suite. @ 12/19/23 10:38:42.549
• [8.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 12/19/23 10:38:42.569
  Dec 19 10:38:42.570: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:38:42.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:42.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:42.635
  STEP: Setting up server cert @ 12/19/23 10:38:42.694
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:38:44.772
  STEP: Deploying the webhook pod @ 12/19/23 10:38:44.791
  STEP: Wait for the deployment to be ready @ 12/19/23 10:38:44.821
  Dec 19 10:38:44.843: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/19/23 10:38:46.866
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:38:46.888
  Dec 19 10:38:47.888: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 12/19/23 10:38:47.903
  STEP: create a pod that should be updated by the webhook @ 12/19/23 10:38:47.947
  Dec 19 10:38:48.171: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4055" for this suite. @ 12/19/23 10:38:48.194
  STEP: Destroying namespace "webhook-markers-6046" for this suite. @ 12/19/23 10:38:48.208
• [5.654 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 12/19/23 10:38:48.227
  Dec 19 10:38:48.227: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:38:48.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:48.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:48.291
  STEP: Creating secret with name secret-test-8e3ec618-b3ce-40c7-819c-19a1f2c75d19 @ 12/19/23 10:38:48.312
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:38:48.327
  STEP: Saw pod success @ 12/19/23 10:38:52.456
  Dec 19 10:38:52.465: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-9c6f3f7b-a317-4e7d-bf80-7a0c86093c51 container secret-env-test: <nil>
  STEP: delete the pod @ 12/19/23 10:38:52.486
  Dec 19 10:38:52.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8914" for this suite. @ 12/19/23 10:38:52.527
• [4.316 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 12/19/23 10:38:52.543
  Dec 19 10:38:52.543: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:38:52.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:52.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:52.592
  STEP: Create a pod @ 12/19/23 10:38:52.597
  STEP: patching /status @ 12/19/23 10:38:54.637
  Dec 19 10:38:54.654: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Dec 19 10:38:54.655: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7917" for this suite. @ 12/19/23 10:38:54.667
• [2.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 12/19/23 10:38:54.68
  Dec 19 10:38:54.680: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:38:54.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:54.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:54.734
  STEP: Creating a ResourceQuota @ 12/19/23 10:38:54.741
  STEP: Getting a ResourceQuota @ 12/19/23 10:38:54.754
  STEP: Listing all ResourceQuotas with LabelSelector @ 12/19/23 10:38:54.764
  STEP: Patching the ResourceQuota @ 12/19/23 10:38:54.77
  STEP: Deleting a Collection of ResourceQuotas @ 12/19/23 10:38:54.786
  STEP: Verifying the deleted ResourceQuota @ 12/19/23 10:38:54.809
  Dec 19 10:38:54.815: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6466" for this suite. @ 12/19/23 10:38:54.827
• [0.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 12/19/23 10:38:54.844
  Dec 19 10:38:54.844: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename discovery @ 12/19/23 10:38:54.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:54.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:54.889
  STEP: Setting up server cert @ 12/19/23 10:38:54.898
  STEP: Requesting APIResourceList from "/api/v1" @ 12/19/23 10:38:55.332
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 12/19/23 10:38:55.336
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 12/19/23 10:38:55.34
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 12/19/23 10:38:55.343
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 12/19/23 10:38:55.345
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 12/19/23 10:38:55.348
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 12/19/23 10:38:55.35
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 12/19/23 10:38:55.353
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 12/19/23 10:38:55.355
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 12/19/23 10:38:55.36
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 12/19/23 10:38:55.365
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 12/19/23 10:38:55.37
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 12/19/23 10:38:55.375
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 12/19/23 10:38:55.377
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 12/19/23 10:38:55.379
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 12/19/23 10:38:55.383
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 12/19/23 10:38:55.385
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 12/19/23 10:38:55.391
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 12/19/23 10:38:55.393
  Dec 19 10:38:55.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1963" for this suite. @ 12/19/23 10:38:55.409
• [0.580 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 12/19/23 10:38:55.425
  Dec 19 10:38:55.425: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:38:55.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:55.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:55.477
  Dec 19 10:38:55.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8498" for this suite. @ 12/19/23 10:38:55.805
• [0.402 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 12/19/23 10:38:55.828
  Dec 19 10:38:55.828: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:38:55.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:55.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:55.895
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/19/23 10:38:55.903
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/19/23 10:38:55.904
  STEP: creating a pod to probe DNS @ 12/19/23 10:38:55.904
  STEP: submitting the pod to kubernetes @ 12/19/23 10:38:55.904
  STEP: retrieving the pod @ 12/19/23 10:38:57.954
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:38:57.962
  Dec 19 10:38:58.008: INFO: DNS probes using dns-7013/dns-test-e2e95cc9-d8af-4f8b-99c9-a98edb26449a succeeded

  STEP: deleting the pod @ 12/19/23 10:38:58.009
  Dec 19 10:38:58.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7013" for this suite. @ 12/19/23 10:38:58.066
• [2.252 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 12/19/23 10:38:58.083
  Dec 19 10:38:58.083: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename init-container @ 12/19/23 10:38:58.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:38:58.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:38:58.137
  STEP: creating the pod @ 12/19/23 10:38:58.148
  Dec 19 10:38:58.148: INFO: PodSpec: initContainers in spec.initContainers
  Dec 19 10:39:42.882: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-808c0aa7-d920-456d-aa02-d7bf2d4928b0", GenerateName:"", Namespace:"init-container-5530", SelfLink:"", UID:"cf465d6c-0c9b-456e-8dae-a52920f48dde", ResourceVersion:"11030", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"148863051"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00141b638), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 39, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00141b6b0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-9vb8g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0010707a0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9vb8g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9vb8g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9vb8g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002cd8978), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"uikie9pei4sh-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0000d9650), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002cd8a00)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002cd8a20)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002cd8a28), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002cd8a2c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003da57c0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 38, 59, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.201", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.121.201"}}, PodIP:"10.233.66.98", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.98"}}, StartTime:time.Date(2023, time.December, 19, 10, 38, 58, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000d9730)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000d97a0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"3e0d9138669908f438c06993e9a6815bbd8c05411b8e9acfc297b3c8b017c28c", ContainerID:"cri-o://32c8cbb6b10f9afea345a3b461e4fdec1932fa957274134dec93e4d2ff60983b", Started:(*bool)(0xc002cd8aca), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001070800), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc002cd8adf), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010707e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc002cd8aaf), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Dec 19 10:39:42.887: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5530" for this suite. @ 12/19/23 10:39:42.898
• [44.833 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 12/19/23 10:39:42.92
  Dec 19 10:39:42.920: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:39:42.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:39:42.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:39:42.997
  STEP: Creating a pod to test emptydir volume type on node default medium @ 12/19/23 10:39:43.004
  STEP: Saw pod success @ 12/19/23 10:39:47.068
  Dec 19 10:39:47.075: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-15774754-eac7-43c5-b1d8-c530d50269cf container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:39:47.093
  Dec 19 10:39:47.139: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8446" for this suite. @ 12/19/23 10:39:47.151
• [4.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 12/19/23 10:39:47.183
  Dec 19 10:39:47.183: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 10:39:47.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:39:47.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:39:47.234
  STEP: creating a ReplicationController @ 12/19/23 10:39:47.256
  STEP: waiting for RC to be added @ 12/19/23 10:39:47.27
  STEP: waiting for available Replicas @ 12/19/23 10:39:47.272
  STEP: patching ReplicationController @ 12/19/23 10:39:51.951
  STEP: waiting for RC to be modified @ 12/19/23 10:39:51.971
  STEP: patching ReplicationController status @ 12/19/23 10:39:51.971
  STEP: waiting for RC to be modified @ 12/19/23 10:39:51.991
  STEP: waiting for available Replicas @ 12/19/23 10:39:51.991
  STEP: fetching ReplicationController status @ 12/19/23 10:39:52.001
  STEP: patching ReplicationController scale @ 12/19/23 10:39:52.01
  STEP: waiting for RC to be modified @ 12/19/23 10:39:52.033
  STEP: waiting for ReplicationController's scale to be the max amount @ 12/19/23 10:39:52.033
  STEP: fetching ReplicationController; ensuring that it's patched @ 12/19/23 10:39:56.459
  STEP: updating ReplicationController status @ 12/19/23 10:39:56.467
  STEP: waiting for RC to be modified @ 12/19/23 10:39:56.486
  STEP: listing all ReplicationControllers @ 12/19/23 10:39:56.486
  STEP: checking that ReplicationController has expected values @ 12/19/23 10:39:56.5
  STEP: deleting ReplicationControllers by collection @ 12/19/23 10:39:56.5
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 12/19/23 10:39:56.522
  Dec 19 10:39:56.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:39:56.662523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-8134" for this suite. @ 12/19/23 10:39:56.669
• [9.502 seconds]
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 12/19/23 10:39:56.688
  Dec 19 10:39:56.689: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename proxy @ 12/19/23 10:39:56.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:39:56.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:39:56.748
  Dec 19 10:39:56.753: INFO: Creating pod...
  E1219 10:39:57.661990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:58.662193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:58.791: INFO: Creating service...
  Dec 19 10:39:58.819: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=DELETE
  Dec 19 10:39:58.842: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 10:39:58.842: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=OPTIONS
  Dec 19 10:39:58.851: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 10:39:58.852: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=PATCH
  Dec 19 10:39:58.860: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 10:39:58.861: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=POST
  Dec 19 10:39:58.869: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 10:39:58.869: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=PUT
  Dec 19 10:39:58.881: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 10:39:58.882: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=DELETE
  Dec 19 10:39:58.897: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 10:39:58.897: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Dec 19 10:39:58.910: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 10:39:58.910: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=PATCH
  Dec 19 10:39:58.921: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 10:39:58.921: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=POST
  Dec 19 10:39:58.932: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 10:39:58.932: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=PUT
  Dec 19 10:39:58.944: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 10:39:58.945: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=GET
  Dec 19 10:39:58.951: INFO: http.Client request:GET StatusCode:301
  Dec 19 10:39:58.951: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=GET
  Dec 19 10:39:58.958: INFO: http.Client request:GET StatusCode:301
  Dec 19 10:39:58.958: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/pods/agnhost/proxy?method=HEAD
  Dec 19 10:39:58.963: INFO: http.Client request:HEAD StatusCode:301
  Dec 19 10:39:58.963: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3793/services/e2e-proxy-test-service/proxy?method=HEAD
  Dec 19 10:39:58.972: INFO: http.Client request:HEAD StatusCode:301
  Dec 19 10:39:58.972: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3793" for this suite. @ 12/19/23 10:39:58.984
• [2.345 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 12/19/23 10:39:59.051
  Dec 19 10:39:59.051: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 10:39:59.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:39:59.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:39:59.1
  Dec 19 10:39:59.107: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E1219 10:39:59.662800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 12/19/23 10:40:00.142
  STEP: Checking rc "condition-test" has the desired failure condition set @ 12/19/23 10:40:00.153
  E1219 10:40:00.662707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 12/19/23 10:40:01.175
  Dec 19 10:40:01.199: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 12/19/23 10:40:01.199
  E1219 10:40:01.663532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:02.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1977" for this suite. @ 12/19/23 10:40:02.24
• [3.204 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 12/19/23 10:40:02.258
  Dec 19 10:40:02.258: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 10:40:02.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:40:02.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:40:02.315
  STEP: Creating pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920 @ 12/19/23 10:40:02.324
  E1219 10:40:02.664528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:03.665195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 10:40:04.362
  Dec 19 10:40:04.371: INFO: Initial restart count of pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 is 0
  Dec 19 10:40:04.381: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:04.666387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:05.666582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:06.394: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:06.666893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:07.667910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:08.403: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:08.668434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:09.669109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:10.410: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:10.670160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:11.671124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:12.420: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:12.671128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:13.672177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:14.431: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:14.672440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:15.673057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:16.445: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:16.673392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:17.674643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:18.455: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:18.674368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:19.674627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:20.466: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:20.675675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:21.675973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:22.474: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  E1219 10:40:22.675721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:23.677471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:24.487: INFO: Get pod liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 in namespace container-probe-6920
  Dec 19 10:40:24.487: INFO: Restart count of pod container-probe-6920/liveness-5e66c739-103d-4c75-b02f-c0bb095e0e80 is now 1 (20.115187639s elapsed)
  STEP: deleting the pod @ 12/19/23 10:40:24.489
  Dec 19 10:40:24.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6920" for this suite. @ 12/19/23 10:40:24.571
• [22.329 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 12/19/23 10:40:24.593
  Dec 19 10:40:24.593: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 10:40:24.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:40:24.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:40:24.652
  STEP: getting /apis @ 12/19/23 10:40:24.662
  STEP: getting /apis/node.k8s.io @ 12/19/23 10:40:24.674
  STEP: getting /apis/node.k8s.io/v1 @ 12/19/23 10:40:24.677
  E1219 10:40:24.678207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating @ 12/19/23 10:40:24.68
  STEP: watching @ 12/19/23 10:40:24.729
  Dec 19 10:40:24.729: INFO: starting watch
  STEP: getting @ 12/19/23 10:40:24.746
  STEP: listing @ 12/19/23 10:40:24.774
  STEP: patching @ 12/19/23 10:40:24.786
  STEP: updating @ 12/19/23 10:40:24.797
  Dec 19 10:40:24.826: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 12/19/23 10:40:24.827
  STEP: deleting a collection @ 12/19/23 10:40:24.876
  Dec 19 10:40:24.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3796" for this suite. @ 12/19/23 10:40:24.923
• [0.355 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 12/19/23 10:40:24.95
  Dec 19 10:40:24.952: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:40:24.955
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:40:24.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:40:24.993
  Dec 19 10:40:25.038: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 10:40:25.057
  Dec 19 10:40:25.084: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:40:25.084: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 10:40:25.678452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:26.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:40:26.082: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 10:40:26.678749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:27.075: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:40:27.075: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 10:40:27.679139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:28.079: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:40:28.079: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 10:40:28.679543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:29.088: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:40:29.088: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 12/19/23 10:40:29.127
  STEP: Check that daemon pods images are updated. @ 12/19/23 10:40:29.164
  Dec 19 10:40:29.180: INFO: Wrong image for pod: daemon-set-4pdvm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:29.180: INFO: Wrong image for pod: daemon-set-6g7hh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:29.181: INFO: Wrong image for pod: daemon-set-nkd4t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E1219 10:40:29.679937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:30.173: INFO: Wrong image for pod: daemon-set-4pdvm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:30.173: INFO: Wrong image for pod: daemon-set-nkd4t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E1219 10:40:30.680996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:31.175: INFO: Wrong image for pod: daemon-set-4pdvm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:31.176: INFO: Wrong image for pod: daemon-set-nkd4t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:31.176: INFO: Pod daemon-set-qtjvv is not available
  E1219 10:40:31.681275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:32.174: INFO: Wrong image for pod: daemon-set-4pdvm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:32.174: INFO: Wrong image for pod: daemon-set-nkd4t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:40:32.174: INFO: Pod daemon-set-qtjvv is not available
  E1219 10:40:32.682214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:33.181: INFO: Pod daemon-set-4k5d5 is not available
  Dec 19 10:40:33.181: INFO: Wrong image for pod: daemon-set-nkd4t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E1219 10:40:33.683034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:34.177: INFO: Pod daemon-set-4k5d5 is not available
  Dec 19 10:40:34.177: INFO: Wrong image for pod: daemon-set-nkd4t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E1219 10:40:34.684256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:35.187: INFO: Pod daemon-set-rp7rs is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 12/19/23 10:40:35.197
  Dec 19 10:40:35.224: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:40:35.224: INFO: Node uikie9pei4sh-2 is running 0 daemon pod, expected 1
  E1219 10:40:35.684615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:36.217: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:40:36.217: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 10:40:36.268
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1810, will wait for the garbage collector to delete the pods @ 12/19/23 10:40:36.268
  Dec 19 10:40:36.341: INFO: Deleting DaemonSet.extensions daemon-set took: 13.595088ms
  Dec 19 10:40:36.442: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.989171ms
  E1219 10:40:36.685536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:37.686441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:37.750: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:40:37.750: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 10:40:37.760: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11514"},"items":null}

  Dec 19 10:40:37.768: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11514"},"items":null}

  Dec 19 10:40:37.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1810" for this suite. @ 12/19/23 10:40:37.815
• [12.881 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 12/19/23 10:40:37.831
  Dec 19 10:40:37.831: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 10:40:37.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:40:37.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:40:37.881
  Dec 19 10:40:37.887: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 10:40:38.687029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:39.687147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:40.687329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 10:40:40.742096      13 warnings.go:70] unknown field "alpha"
  W1219 10:40:40.742399      13 warnings.go:70] unknown field "beta"
  W1219 10:40:40.742673      13 warnings.go:70] unknown field "delta"
  W1219 10:40:40.743063      13 warnings.go:70] unknown field "epsilon"
  W1219 10:40:40.743348      13 warnings.go:70] unknown field "gamma"
  Dec 19 10:40:41.348: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2733" for this suite. @ 12/19/23 10:40:41.358
• [3.544 seconds]
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 12/19/23 10:40:41.376
  Dec 19 10:40:41.376: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:40:41.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:40:41.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:40:41.43
  STEP: create the rc @ 12/19/23 10:40:41.452
  W1219 10:40:41.470992      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1219 10:40:41.688031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:42.688330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:43.688959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:44.690157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:45.691203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:46.691138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/19/23 10:40:47.546
  E1219 10:40:47.691588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 12/19/23 10:40:47.996
  E1219 10:40:48.692071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:49.692252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:50.693420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:51.695661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:52.694300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 12/19/23 10:40:53.02
  E1219 10:40:53.694939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:54.695314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:55.696711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:56.697671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:57.698011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:58.698295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:59.699226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:00.700046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:01.701198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:02.701174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:03.701481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:04.701634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:05.701863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:06.702196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:07.703273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:08.703453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:09.703703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:10.703944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:11.704163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:12.705042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:13.705234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:14.705369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:15.705738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:16.706060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:17.707033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:18.707289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:19.707449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:20.707657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:21.707865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:22.708797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 10:41:23.062
  Dec 19 10:41:23.315: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:41:23.324: INFO: Deleting pod "simpletest.rc-28x29" in namespace "gc-4371"
  Dec 19 10:41:23.372: INFO: Deleting pod "simpletest.rc-2r7qp" in namespace "gc-4371"
  Dec 19 10:41:23.415: INFO: Deleting pod "simpletest.rc-2w4zf" in namespace "gc-4371"
  Dec 19 10:41:23.476: INFO: Deleting pod "simpletest.rc-4cwv2" in namespace "gc-4371"
  Dec 19 10:41:23.510: INFO: Deleting pod "simpletest.rc-4lkf6" in namespace "gc-4371"
  Dec 19 10:41:23.639: INFO: Deleting pod "simpletest.rc-4md6l" in namespace "gc-4371"
  E1219 10:41:23.709523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:23.744: INFO: Deleting pod "simpletest.rc-4tjs5" in namespace "gc-4371"
  Dec 19 10:41:23.825: INFO: Deleting pod "simpletest.rc-558zm" in namespace "gc-4371"
  Dec 19 10:41:24.002: INFO: Deleting pod "simpletest.rc-5r8zm" in namespace "gc-4371"
  Dec 19 10:41:24.092: INFO: Deleting pod "simpletest.rc-5txmb" in namespace "gc-4371"
  Dec 19 10:41:24.161: INFO: Deleting pod "simpletest.rc-5xvn4" in namespace "gc-4371"
  Dec 19 10:41:24.277: INFO: Deleting pod "simpletest.rc-6lktj" in namespace "gc-4371"
  Dec 19 10:41:24.320: INFO: Deleting pod "simpletest.rc-6wld8" in namespace "gc-4371"
  Dec 19 10:41:24.362: INFO: Deleting pod "simpletest.rc-6z5bz" in namespace "gc-4371"
  Dec 19 10:41:24.445: INFO: Deleting pod "simpletest.rc-75d2x" in namespace "gc-4371"
  Dec 19 10:41:24.497: INFO: Deleting pod "simpletest.rc-77hfs" in namespace "gc-4371"
  Dec 19 10:41:24.631: INFO: Deleting pod "simpletest.rc-77jnj" in namespace "gc-4371"
  E1219 10:41:24.710174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:24.746: INFO: Deleting pod "simpletest.rc-7f52x" in namespace "gc-4371"
  Dec 19 10:41:24.835: INFO: Deleting pod "simpletest.rc-7k2x8" in namespace "gc-4371"
  Dec 19 10:41:24.910: INFO: Deleting pod "simpletest.rc-7k95m" in namespace "gc-4371"
  Dec 19 10:41:24.980: INFO: Deleting pod "simpletest.rc-878fh" in namespace "gc-4371"
  Dec 19 10:41:25.130: INFO: Deleting pod "simpletest.rc-89q2b" in namespace "gc-4371"
  Dec 19 10:41:25.157: INFO: Deleting pod "simpletest.rc-92zhq" in namespace "gc-4371"
  Dec 19 10:41:25.194: INFO: Deleting pod "simpletest.rc-98xxs" in namespace "gc-4371"
  Dec 19 10:41:25.299: INFO: Deleting pod "simpletest.rc-9c5z8" in namespace "gc-4371"
  Dec 19 10:41:25.368: INFO: Deleting pod "simpletest.rc-9d5sc" in namespace "gc-4371"
  Dec 19 10:41:25.474: INFO: Deleting pod "simpletest.rc-9f6q7" in namespace "gc-4371"
  Dec 19 10:41:25.586: INFO: Deleting pod "simpletest.rc-9hxln" in namespace "gc-4371"
  Dec 19 10:41:25.648: INFO: Deleting pod "simpletest.rc-9lm5c" in namespace "gc-4371"
  E1219 10:41:25.710996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:25.713: INFO: Deleting pod "simpletest.rc-9szs8" in namespace "gc-4371"
  Dec 19 10:41:25.843: INFO: Deleting pod "simpletest.rc-9t7pz" in namespace "gc-4371"
  Dec 19 10:41:25.892: INFO: Deleting pod "simpletest.rc-bjhrn" in namespace "gc-4371"
  Dec 19 10:41:25.952: INFO: Deleting pod "simpletest.rc-br929" in namespace "gc-4371"
  Dec 19 10:41:26.026: INFO: Deleting pod "simpletest.rc-bsxwq" in namespace "gc-4371"
  Dec 19 10:41:26.147: INFO: Deleting pod "simpletest.rc-cn88k" in namespace "gc-4371"
  Dec 19 10:41:26.311: INFO: Deleting pod "simpletest.rc-d8vzw" in namespace "gc-4371"
  Dec 19 10:41:26.420: INFO: Deleting pod "simpletest.rc-dcx8p" in namespace "gc-4371"
  Dec 19 10:41:26.554: INFO: Deleting pod "simpletest.rc-djbl7" in namespace "gc-4371"
  E1219 10:41:26.711960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:26.808: INFO: Deleting pod "simpletest.rc-dmp6t" in namespace "gc-4371"
  Dec 19 10:41:26.923: INFO: Deleting pod "simpletest.rc-dvrv7" in namespace "gc-4371"
  Dec 19 10:41:27.082: INFO: Deleting pod "simpletest.rc-fqsr2" in namespace "gc-4371"
  Dec 19 10:41:27.121: INFO: Deleting pod "simpletest.rc-frbqq" in namespace "gc-4371"
  Dec 19 10:41:27.259: INFO: Deleting pod "simpletest.rc-fzg6r" in namespace "gc-4371"
  Dec 19 10:41:27.358: INFO: Deleting pod "simpletest.rc-hgmlx" in namespace "gc-4371"
  Dec 19 10:41:27.434: INFO: Deleting pod "simpletest.rc-hphcg" in namespace "gc-4371"
  Dec 19 10:41:27.539: INFO: Deleting pod "simpletest.rc-hqh8l" in namespace "gc-4371"
  Dec 19 10:41:27.653: INFO: Deleting pod "simpletest.rc-hs66h" in namespace "gc-4371"
  E1219 10:41:27.712586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:27.874: INFO: Deleting pod "simpletest.rc-hw59q" in namespace "gc-4371"
  Dec 19 10:41:27.979: INFO: Deleting pod "simpletest.rc-hzcgv" in namespace "gc-4371"
  Dec 19 10:41:28.101: INFO: Deleting pod "simpletest.rc-hzxsf" in namespace "gc-4371"
  Dec 19 10:41:28.194: INFO: Deleting pod "simpletest.rc-jdjbs" in namespace "gc-4371"
  Dec 19 10:41:28.289: INFO: Deleting pod "simpletest.rc-jrhtm" in namespace "gc-4371"
  Dec 19 10:41:28.437: INFO: Deleting pod "simpletest.rc-jxlk8" in namespace "gc-4371"
  Dec 19 10:41:28.564: INFO: Deleting pod "simpletest.rc-jzwsn" in namespace "gc-4371"
  Dec 19 10:41:28.651: INFO: Deleting pod "simpletest.rc-k9w9b" in namespace "gc-4371"
  E1219 10:41:28.712700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:28.795: INFO: Deleting pod "simpletest.rc-kf7rq" in namespace "gc-4371"
  Dec 19 10:41:28.906: INFO: Deleting pod "simpletest.rc-kh2vd" in namespace "gc-4371"
  Dec 19 10:41:28.949: INFO: Deleting pod "simpletest.rc-kmh6x" in namespace "gc-4371"
  Dec 19 10:41:29.003: INFO: Deleting pod "simpletest.rc-ks8ld" in namespace "gc-4371"
  Dec 19 10:41:29.096: INFO: Deleting pod "simpletest.rc-l55lb" in namespace "gc-4371"
  Dec 19 10:41:29.166: INFO: Deleting pod "simpletest.rc-l7t2r" in namespace "gc-4371"
  Dec 19 10:41:29.247: INFO: Deleting pod "simpletest.rc-lctct" in namespace "gc-4371"
  Dec 19 10:41:29.344: INFO: Deleting pod "simpletest.rc-lsmqf" in namespace "gc-4371"
  Dec 19 10:41:29.534: INFO: Deleting pod "simpletest.rc-lwm96" in namespace "gc-4371"
  Dec 19 10:41:29.603: INFO: Deleting pod "simpletest.rc-m5zbd" in namespace "gc-4371"
  Dec 19 10:41:29.681: INFO: Deleting pod "simpletest.rc-mdfxv" in namespace "gc-4371"
  E1219 10:41:29.712934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:29.732: INFO: Deleting pod "simpletest.rc-mmc84" in namespace "gc-4371"
  Dec 19 10:41:29.784: INFO: Deleting pod "simpletest.rc-mrqt7" in namespace "gc-4371"
  Dec 19 10:41:29.882: INFO: Deleting pod "simpletest.rc-mxvnv" in namespace "gc-4371"
  Dec 19 10:41:29.977: INFO: Deleting pod "simpletest.rc-ns4b5" in namespace "gc-4371"
  Dec 19 10:41:30.075: INFO: Deleting pod "simpletest.rc-nt7x5" in namespace "gc-4371"
  Dec 19 10:41:30.191: INFO: Deleting pod "simpletest.rc-p6prg" in namespace "gc-4371"
  Dec 19 10:41:30.219: INFO: Deleting pod "simpletest.rc-pdhlb" in namespace "gc-4371"
  Dec 19 10:41:30.288: INFO: Deleting pod "simpletest.rc-pmmtw" in namespace "gc-4371"
  Dec 19 10:41:30.388: INFO: Deleting pod "simpletest.rc-pnl2s" in namespace "gc-4371"
  Dec 19 10:41:30.505: INFO: Deleting pod "simpletest.rc-pvbkd" in namespace "gc-4371"
  Dec 19 10:41:30.599: INFO: Deleting pod "simpletest.rc-qwttn" in namespace "gc-4371"
  Dec 19 10:41:30.684: INFO: Deleting pod "simpletest.rc-rddt8" in namespace "gc-4371"
  E1219 10:41:30.713316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:30.780: INFO: Deleting pod "simpletest.rc-rrrrm" in namespace "gc-4371"
  Dec 19 10:41:30.851: INFO: Deleting pod "simpletest.rc-rzlpc" in namespace "gc-4371"
  Dec 19 10:41:30.989: INFO: Deleting pod "simpletest.rc-s9p5v" in namespace "gc-4371"
  Dec 19 10:41:31.156: INFO: Deleting pod "simpletest.rc-snnvp" in namespace "gc-4371"
  Dec 19 10:41:31.256: INFO: Deleting pod "simpletest.rc-snz7z" in namespace "gc-4371"
  Dec 19 10:41:31.392: INFO: Deleting pod "simpletest.rc-st97w" in namespace "gc-4371"
  Dec 19 10:41:31.562: INFO: Deleting pod "simpletest.rc-szn54" in namespace "gc-4371"
  Dec 19 10:41:31.648: INFO: Deleting pod "simpletest.rc-tghgw" in namespace "gc-4371"
  Dec 19 10:41:31.712: INFO: Deleting pod "simpletest.rc-tlc9v" in namespace "gc-4371"
  E1219 10:41:31.714396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:31.774: INFO: Deleting pod "simpletest.rc-twfm4" in namespace "gc-4371"
  Dec 19 10:41:31.799: INFO: Deleting pod "simpletest.rc-v272z" in namespace "gc-4371"
  Dec 19 10:41:31.875: INFO: Deleting pod "simpletest.rc-v2vh5" in namespace "gc-4371"
  Dec 19 10:41:31.980: INFO: Deleting pod "simpletest.rc-v5shg" in namespace "gc-4371"
  Dec 19 10:41:32.013: INFO: Deleting pod "simpletest.rc-vqz8n" in namespace "gc-4371"
  Dec 19 10:41:32.063: INFO: Deleting pod "simpletest.rc-w9wjz" in namespace "gc-4371"
  Dec 19 10:41:32.182: INFO: Deleting pod "simpletest.rc-wd5zg" in namespace "gc-4371"
  Dec 19 10:41:32.274: INFO: Deleting pod "simpletest.rc-wfjw5" in namespace "gc-4371"
  Dec 19 10:41:32.359: INFO: Deleting pod "simpletest.rc-wjjrt" in namespace "gc-4371"
  Dec 19 10:41:32.575: INFO: Deleting pod "simpletest.rc-xx5lp" in namespace "gc-4371"
  Dec 19 10:41:32.687: INFO: Deleting pod "simpletest.rc-zjjn9" in namespace "gc-4371"
  E1219 10:41:32.715129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:32.739: INFO: Deleting pod "simpletest.rc-zlb8x" in namespace "gc-4371"
  Dec 19 10:41:32.823: INFO: Deleting pod "simpletest.rc-zvwzp" in namespace "gc-4371"
  Dec 19 10:41:32.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4371" for this suite. @ 12/19/23 10:41:32.949
• [51.618 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 12/19/23 10:41:32.998
  Dec 19 10:41:32.998: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:41:33.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:41:33.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:41:33.091
  STEP: Discovering how many secrets are in namespace by default @ 12/19/23 10:41:33.097
  E1219 10:41:33.714906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:34.715523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:35.716592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:36.717003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:37.717588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/19/23 10:41:38.106
  E1219 10:41:38.718269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:39.718541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:40.718930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:41.719250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:42.719616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 10:41:43.115
  STEP: Ensuring resource quota status is calculated @ 12/19/23 10:41:43.125
  E1219 10:41:43.720417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:44.721308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 12/19/23 10:41:45.134
  STEP: Ensuring resource quota status captures secret creation @ 12/19/23 10:41:45.16
  E1219 10:41:45.721450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:46.721713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 12/19/23 10:41:47.168
  STEP: Ensuring resource quota status released usage @ 12/19/23 10:41:47.18
  E1219 10:41:47.721943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:48.723077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:49.190: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5987" for this suite. @ 12/19/23 10:41:49.202
• [16.222 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 12/19/23 10:41:49.225
  Dec 19 10:41:49.225: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svc-latency @ 12/19/23 10:41:49.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:41:49.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:41:49.273
  Dec 19 10:41:49.282: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-8858 @ 12/19/23 10:41:49.285
  I1219 10:41:49.301036      13 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8858, replica count: 1
  E1219 10:41:49.723704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:41:50.351939      13 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1219 10:41:50.723913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:41:51.352976      13 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:41:51.477: INFO: Created: latency-svc-wrzks
  Dec 19 10:41:51.503: INFO: Got endpoints: latency-svc-wrzks [49.281168ms]
  Dec 19 10:41:51.550: INFO: Created: latency-svc-csdx2
  Dec 19 10:41:51.582: INFO: Created: latency-svc-bcphr
  Dec 19 10:41:51.609: INFO: Got endpoints: latency-svc-csdx2 [104.520029ms]
  Dec 19 10:41:51.666: INFO: Got endpoints: latency-svc-bcphr [161.454212ms]
  Dec 19 10:41:51.674: INFO: Created: latency-svc-trggh
  Dec 19 10:41:51.690: INFO: Got endpoints: latency-svc-trggh [182.677862ms]
  Dec 19 10:41:51.710: INFO: Created: latency-svc-wkntv
  E1219 10:41:51.724141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:51.724: INFO: Got endpoints: latency-svc-wkntv [217.7079ms]
  Dec 19 10:41:51.735: INFO: Created: latency-svc-6vwb4
  Dec 19 10:41:51.743: INFO: Got endpoints: latency-svc-6vwb4 [237.176232ms]
  Dec 19 10:41:51.763: INFO: Created: latency-svc-pcx2c
  Dec 19 10:41:51.772: INFO: Got endpoints: latency-svc-pcx2c [266.317971ms]
  Dec 19 10:41:51.784: INFO: Created: latency-svc-gvwxb
  Dec 19 10:41:51.802: INFO: Got endpoints: latency-svc-gvwxb [295.780258ms]
  Dec 19 10:41:51.803: INFO: Created: latency-svc-b48lh
  Dec 19 10:41:51.820: INFO: Got endpoints: latency-svc-b48lh [314.466645ms]
  Dec 19 10:41:51.832: INFO: Created: latency-svc-92x7v
  Dec 19 10:41:51.834: INFO: Got endpoints: latency-svc-92x7v [327.503659ms]
  Dec 19 10:41:51.855: INFO: Created: latency-svc-v8v2t
  Dec 19 10:41:51.864: INFO: Created: latency-svc-tnktt
  Dec 19 10:41:51.865: INFO: Got endpoints: latency-svc-v8v2t [358.343085ms]
  Dec 19 10:41:51.876: INFO: Got endpoints: latency-svc-tnktt [368.588196ms]
  Dec 19 10:41:51.877: INFO: Created: latency-svc-mpx26
  Dec 19 10:41:51.909: INFO: Got endpoints: latency-svc-mpx26 [402.51366ms]
  Dec 19 10:41:51.949: INFO: Created: latency-svc-xjzzs
  Dec 19 10:41:51.956: INFO: Got endpoints: latency-svc-xjzzs [449.960856ms]
  Dec 19 10:41:52.024: INFO: Created: latency-svc-mr46m
  Dec 19 10:41:52.041: INFO: Got endpoints: latency-svc-mr46m [534.789616ms]
  Dec 19 10:41:52.066: INFO: Created: latency-svc-6qcwg
  Dec 19 10:41:52.067: INFO: Created: latency-svc-wvfp7
  Dec 19 10:41:52.068: INFO: Created: latency-svc-nphbk
  Dec 19 10:41:52.068: INFO: Created: latency-svc-srvb7
  Dec 19 10:41:52.070: INFO: Created: latency-svc-xh9qk
  Dec 19 10:41:52.071: INFO: Created: latency-svc-87ctc
  Dec 19 10:41:52.073: INFO: Created: latency-svc-6sjhz
  Dec 19 10:41:52.088: INFO: Got endpoints: latency-svc-87ctc [478.620571ms]
  Dec 19 10:41:52.092: INFO: Got endpoints: latency-svc-xh9qk [271.717461ms]
  Dec 19 10:41:52.100: INFO: Created: latency-svc-mpp94
  Dec 19 10:41:52.100: INFO: Created: latency-svc-qt67b
  Dec 19 10:41:52.104: INFO: Created: latency-svc-zc67t
  Dec 19 10:41:52.105: INFO: Created: latency-svc-8528d
  Dec 19 10:41:52.105: INFO: Created: latency-svc-gwh9k
  Dec 19 10:41:52.106: INFO: Created: latency-svc-5pnkc
  Dec 19 10:41:52.107: INFO: Created: latency-svc-2spxc
  Dec 19 10:41:52.119: INFO: Created: latency-svc-2wh7b
  Dec 19 10:41:52.143: INFO: Got endpoints: latency-svc-nphbk [266.157586ms]
  Dec 19 10:41:52.144: INFO: Got endpoints: latency-svc-6sjhz [637.528388ms]
  Dec 19 10:41:52.150: INFO: Created: latency-svc-rrpkc
  Dec 19 10:41:52.151: INFO: Got endpoints: latency-svc-6qcwg [347.992776ms]
  Dec 19 10:41:52.151: INFO: Got endpoints: latency-svc-wvfp7 [316.979189ms]
  Dec 19 10:41:52.168: INFO: Created: latency-svc-rwfql
  Dec 19 10:41:52.187: INFO: Created: latency-svc-bw5qp
  Dec 19 10:41:52.193: INFO: Got endpoints: latency-svc-srvb7 [327.75473ms]
  Dec 19 10:41:52.210: INFO: Got endpoints: latency-svc-2spxc [544.0345ms]
  Dec 19 10:41:52.218: INFO: Created: latency-svc-tcmrm
  Dec 19 10:41:52.228: INFO: Got endpoints: latency-svc-zc67t [319.153011ms]
  Dec 19 10:41:52.233: INFO: Got endpoints: latency-svc-5pnkc [543.020592ms]
  Dec 19 10:41:52.235: INFO: Got endpoints: latency-svc-qt67b [462.052639ms]
  Dec 19 10:41:52.241: INFO: Got endpoints: latency-svc-mpp94 [497.849115ms]
  Dec 19 10:41:52.243: INFO: Created: latency-svc-wpg9m
  Dec 19 10:41:52.253: INFO: Created: latency-svc-z6dnr
  Dec 19 10:41:52.268: INFO: Created: latency-svc-5749v
  Dec 19 10:41:52.276: INFO: Created: latency-svc-tvtp6
  Dec 19 10:41:52.288: INFO: Created: latency-svc-bhpzj
  Dec 19 10:41:52.299: INFO: Created: latency-svc-z5lts
  Dec 19 10:41:52.321: INFO: Got endpoints: latency-svc-gwh9k [596.068831ms]
  Dec 19 10:41:52.321: INFO: Got endpoints: latency-svc-8528d [365.238979ms]
  Dec 19 10:41:52.321: INFO: Got endpoints: latency-svc-rrpkc [233.339625ms]
  Dec 19 10:41:52.330: INFO: Got endpoints: latency-svc-2wh7b [288.375432ms]
  Dec 19 10:41:52.331: INFO: Created: latency-svc-fswbm
  Dec 19 10:41:52.333: INFO: Created: latency-svc-dgtsn
  Dec 19 10:41:52.337: INFO: Got endpoints: latency-svc-rwfql [245.113721ms]
  Dec 19 10:41:52.347: INFO: Created: latency-svc-pfwqw
  Dec 19 10:41:52.366: INFO: Created: latency-svc-tzct5
  Dec 19 10:41:52.378: INFO: Created: latency-svc-74nx9
  Dec 19 10:41:52.394: INFO: Created: latency-svc-m5t5c
  Dec 19 10:41:52.405: INFO: Got endpoints: latency-svc-tcmrm [261.668206ms]
  Dec 19 10:41:52.406: INFO: Got endpoints: latency-svc-wpg9m [254.715751ms]
  Dec 19 10:41:52.419: INFO: Got endpoints: latency-svc-bw5qp [276.492357ms]
  Dec 19 10:41:52.419: INFO: Got endpoints: latency-svc-z6dnr [268.864438ms]
  Dec 19 10:41:52.420: INFO: Created: latency-svc-5r65d
  Dec 19 10:41:52.425: INFO: Got endpoints: latency-svc-5749v [230.166333ms]
  Dec 19 10:41:52.433: INFO: Created: latency-svc-fmpzv
  Dec 19 10:41:52.438: INFO: Created: latency-svc-hqp6x
  Dec 19 10:41:52.455: INFO: Got endpoints: latency-svc-tvtp6 [243.534146ms]
  Dec 19 10:41:52.459: INFO: Created: latency-svc-gdlv8
  Dec 19 10:41:52.474: INFO: Created: latency-svc-4xzkb
  Dec 19 10:41:52.478: INFO: Got endpoints: latency-svc-z5lts [242.923081ms]
  Dec 19 10:41:52.478: INFO: Got endpoints: latency-svc-bhpzj [244.008377ms]
  Dec 19 10:41:52.479: INFO: Got endpoints: latency-svc-fswbm [249.961992ms]
  Dec 19 10:41:52.491: INFO: Created: latency-svc-7k6b5
  Dec 19 10:41:52.503: INFO: Got endpoints: latency-svc-dgtsn [260.886348ms]
  Dec 19 10:41:52.517: INFO: Created: latency-svc-ksdr7
  Dec 19 10:41:52.543: INFO: Got endpoints: latency-svc-pfwqw [221.932921ms]
  Dec 19 10:41:52.550: INFO: Got endpoints: latency-svc-74nx9 [228.10113ms]
  Dec 19 10:41:52.551: INFO: Got endpoints: latency-svc-tzct5 [229.006918ms]
  Dec 19 10:41:52.554: INFO: Created: latency-svc-88p7k
  Dec 19 10:41:52.567: INFO: Got endpoints: latency-svc-m5t5c [236.805563ms]
  Dec 19 10:41:52.568: INFO: Created: latency-svc-rjfsb
  Dec 19 10:41:52.571: INFO: Got endpoints: latency-svc-5r65d [233.749671ms]
  Dec 19 10:41:52.588: INFO: Created: latency-svc-8xll8
  Dec 19 10:41:52.604: INFO: Created: latency-svc-m5trg
  Dec 19 10:41:52.626: INFO: Created: latency-svc-5b485
  Dec 19 10:41:52.645: INFO: Created: latency-svc-fsr57
  Dec 19 10:41:52.648: INFO: Created: latency-svc-7c968
  Dec 19 10:41:52.655: INFO: Got endpoints: latency-svc-fmpzv [249.360636ms]
  Dec 19 10:41:52.666: INFO: Created: latency-svc-k949j
  Dec 19 10:41:52.678: INFO: Created: latency-svc-jqvrl
  Dec 19 10:41:52.684: INFO: Created: latency-svc-l4rwp
  Dec 19 10:41:52.695: INFO: Got endpoints: latency-svc-hqp6x [287.907928ms]
  Dec 19 10:41:52.719: INFO: Created: latency-svc-t54df
  Dec 19 10:41:52.720: INFO: Got endpoints: latency-svc-4xzkb [299.555691ms]
  Dec 19 10:41:52.720: INFO: Got endpoints: latency-svc-gdlv8 [299.403772ms]
  E1219 10:41:52.724570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:52.750: INFO: Created: latency-svc-msz2t
  Dec 19 10:41:52.754: INFO: Got endpoints: latency-svc-7k6b5 [329.081929ms]
  Dec 19 10:41:52.763: INFO: Created: latency-svc-w7ntq
  Dec 19 10:41:52.777: INFO: Created: latency-svc-cngtd
  Dec 19 10:41:52.794: INFO: Got endpoints: latency-svc-88p7k [316.279584ms]
  Dec 19 10:41:52.804: INFO: Got endpoints: latency-svc-ksdr7 [349.013334ms]
  Dec 19 10:41:52.815: INFO: Got endpoints: latency-svc-rjfsb [336.221311ms]
  Dec 19 10:41:52.819: INFO: Created: latency-svc-2nq98
  Dec 19 10:41:52.831: INFO: Created: latency-svc-4l9b4
  Dec 19 10:41:52.846: INFO: Created: latency-svc-h64hc
  Dec 19 10:41:52.857: INFO: Got endpoints: latency-svc-8xll8 [377.379603ms]
  Dec 19 10:41:52.877: INFO: Created: latency-svc-mdn8n
  Dec 19 10:41:52.897: INFO: Got endpoints: latency-svc-m5trg [393.744615ms]
  Dec 19 10:41:52.922: INFO: Created: latency-svc-45k5w
  Dec 19 10:41:52.936: INFO: Got endpoints: latency-svc-5b485 [392.884099ms]
  Dec 19 10:41:52.958: INFO: Created: latency-svc-75vlp
  Dec 19 10:41:52.990: INFO: Got endpoints: latency-svc-fsr57 [439.80628ms]
  Dec 19 10:41:53.010: INFO: Created: latency-svc-pphjc
  Dec 19 10:41:53.032: INFO: Got endpoints: latency-svc-7c968 [481.100494ms]
  Dec 19 10:41:53.049: INFO: Created: latency-svc-5zx9c
  Dec 19 10:41:53.085: INFO: Got endpoints: latency-svc-k949j [516.633443ms]
  Dec 19 10:41:53.108: INFO: Created: latency-svc-v46gx
  Dec 19 10:41:53.133: INFO: Got endpoints: latency-svc-jqvrl [562.468818ms]
  Dec 19 10:41:53.154: INFO: Created: latency-svc-f28lj
  Dec 19 10:41:53.181: INFO: Got endpoints: latency-svc-l4rwp [525.870397ms]
  Dec 19 10:41:53.203: INFO: Created: latency-svc-96lns
  Dec 19 10:41:53.233: INFO: Got endpoints: latency-svc-t54df [537.515488ms]
  Dec 19 10:41:53.255: INFO: Created: latency-svc-fdcxd
  Dec 19 10:41:53.282: INFO: Got endpoints: latency-svc-msz2t [560.939074ms]
  Dec 19 10:41:53.306: INFO: Created: latency-svc-vcmsd
  Dec 19 10:41:53.333: INFO: Got endpoints: latency-svc-w7ntq [612.866081ms]
  Dec 19 10:41:53.353: INFO: Created: latency-svc-tkmn7
  Dec 19 10:41:53.384: INFO: Got endpoints: latency-svc-cngtd [629.666421ms]
  Dec 19 10:41:53.406: INFO: Created: latency-svc-ks6cx
  Dec 19 10:41:53.436: INFO: Got endpoints: latency-svc-2nq98 [641.700325ms]
  Dec 19 10:41:53.456: INFO: Created: latency-svc-6xr8x
  Dec 19 10:41:53.481: INFO: Got endpoints: latency-svc-4l9b4 [676.948422ms]
  Dec 19 10:41:53.504: INFO: Created: latency-svc-5gnjz
  Dec 19 10:41:53.533: INFO: Got endpoints: latency-svc-h64hc [717.256972ms]
  Dec 19 10:41:53.569: INFO: Created: latency-svc-bmld5
  Dec 19 10:41:53.589: INFO: Got endpoints: latency-svc-mdn8n [731.973724ms]
  Dec 19 10:41:53.611: INFO: Created: latency-svc-6sd2r
  Dec 19 10:41:53.631: INFO: Got endpoints: latency-svc-45k5w [734.139084ms]
  Dec 19 10:41:53.671: INFO: Created: latency-svc-wb2bx
  Dec 19 10:41:53.689: INFO: Got endpoints: latency-svc-75vlp [752.568994ms]
  Dec 19 10:41:53.710: INFO: Created: latency-svc-cbpnt
  E1219 10:41:53.725215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:53.734: INFO: Got endpoints: latency-svc-pphjc [743.69283ms]
  Dec 19 10:41:53.753: INFO: Created: latency-svc-lvpbx
  Dec 19 10:41:53.785: INFO: Got endpoints: latency-svc-5zx9c [752.469146ms]
  Dec 19 10:41:53.807: INFO: Created: latency-svc-mvgx5
  Dec 19 10:41:53.833: INFO: Got endpoints: latency-svc-v46gx [747.683355ms]
  Dec 19 10:41:53.856: INFO: Created: latency-svc-mx7c6
  Dec 19 10:41:53.883: INFO: Got endpoints: latency-svc-f28lj [748.842792ms]
  Dec 19 10:41:53.911: INFO: Created: latency-svc-nvgpq
  Dec 19 10:41:53.930: INFO: Got endpoints: latency-svc-96lns [748.362607ms]
  Dec 19 10:41:53.948: INFO: Created: latency-svc-8lc8f
  Dec 19 10:41:53.986: INFO: Got endpoints: latency-svc-fdcxd [753.029638ms]
  Dec 19 10:41:54.004: INFO: Created: latency-svc-vl86g
  Dec 19 10:41:54.032: INFO: Got endpoints: latency-svc-vcmsd [750.368462ms]
  Dec 19 10:41:54.065: INFO: Created: latency-svc-n6zh8
  Dec 19 10:41:54.085: INFO: Got endpoints: latency-svc-tkmn7 [751.687917ms]
  Dec 19 10:41:54.103: INFO: Created: latency-svc-d26nz
  Dec 19 10:41:54.131: INFO: Got endpoints: latency-svc-ks6cx [745.849523ms]
  Dec 19 10:41:54.159: INFO: Created: latency-svc-zsr2g
  Dec 19 10:41:54.196: INFO: Got endpoints: latency-svc-6xr8x [759.833387ms]
  Dec 19 10:41:54.219: INFO: Created: latency-svc-z6xzc
  Dec 19 10:41:54.241: INFO: Got endpoints: latency-svc-5gnjz [760.32574ms]
  Dec 19 10:41:54.265: INFO: Created: latency-svc-mvt5k
  Dec 19 10:41:54.287: INFO: Got endpoints: latency-svc-bmld5 [754.512959ms]
  Dec 19 10:41:54.316: INFO: Created: latency-svc-t4jkq
  Dec 19 10:41:54.336: INFO: Got endpoints: latency-svc-6sd2r [747.836686ms]
  Dec 19 10:41:54.363: INFO: Created: latency-svc-c8dbc
  Dec 19 10:41:54.383: INFO: Got endpoints: latency-svc-wb2bx [751.634506ms]
  Dec 19 10:41:54.408: INFO: Created: latency-svc-8sc8w
  Dec 19 10:41:54.431: INFO: Got endpoints: latency-svc-cbpnt [742.122389ms]
  Dec 19 10:41:54.463: INFO: Created: latency-svc-b7fv7
  Dec 19 10:41:54.485: INFO: Got endpoints: latency-svc-lvpbx [750.612486ms]
  Dec 19 10:41:54.517: INFO: Created: latency-svc-8gphx
  Dec 19 10:41:54.553: INFO: Got endpoints: latency-svc-mvgx5 [767.907023ms]
  Dec 19 10:41:54.574: INFO: Created: latency-svc-5l958
  Dec 19 10:41:54.615: INFO: Got endpoints: latency-svc-mx7c6 [781.799037ms]
  Dec 19 10:41:54.635: INFO: Created: latency-svc-qzmnh
  Dec 19 10:41:54.642: INFO: Got endpoints: latency-svc-nvgpq [759.154889ms]
  Dec 19 10:41:54.665: INFO: Created: latency-svc-hnkjg
  Dec 19 10:41:54.682: INFO: Got endpoints: latency-svc-8lc8f [751.970747ms]
  Dec 19 10:41:54.711: INFO: Created: latency-svc-wwjpx
  E1219 10:41:54.725951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:54.729: INFO: Got endpoints: latency-svc-vl86g [743.065143ms]
  Dec 19 10:41:54.750: INFO: Created: latency-svc-87d6r
  Dec 19 10:41:54.785: INFO: Got endpoints: latency-svc-n6zh8 [751.610164ms]
  Dec 19 10:41:54.816: INFO: Created: latency-svc-dw6w2
  Dec 19 10:41:54.837: INFO: Got endpoints: latency-svc-d26nz [751.611356ms]
  Dec 19 10:41:54.863: INFO: Created: latency-svc-t77xc
  Dec 19 10:41:54.892: INFO: Got endpoints: latency-svc-zsr2g [761.042904ms]
  Dec 19 10:41:54.914: INFO: Created: latency-svc-g9l7g
  Dec 19 10:41:54.949: INFO: Got endpoints: latency-svc-z6xzc [753.152414ms]
  Dec 19 10:41:54.981: INFO: Created: latency-svc-8dlcr
  Dec 19 10:41:54.982: INFO: Got endpoints: latency-svc-mvt5k [740.917219ms]
  Dec 19 10:41:55.010: INFO: Created: latency-svc-clds4
  Dec 19 10:41:55.032: INFO: Got endpoints: latency-svc-t4jkq [744.525075ms]
  Dec 19 10:41:55.069: INFO: Created: latency-svc-mhjd4
  Dec 19 10:41:55.086: INFO: Got endpoints: latency-svc-c8dbc [749.349318ms]
  Dec 19 10:41:55.113: INFO: Created: latency-svc-dk4mx
  Dec 19 10:41:55.134: INFO: Got endpoints: latency-svc-8sc8w [750.889294ms]
  Dec 19 10:41:55.153: INFO: Created: latency-svc-qqg8n
  Dec 19 10:41:55.181: INFO: Got endpoints: latency-svc-b7fv7 [750.116354ms]
  Dec 19 10:41:55.201: INFO: Created: latency-svc-8kvqq
  Dec 19 10:41:55.232: INFO: Got endpoints: latency-svc-8gphx [746.976249ms]
  Dec 19 10:41:55.256: INFO: Created: latency-svc-glvbg
  Dec 19 10:41:55.284: INFO: Got endpoints: latency-svc-5l958 [730.784288ms]
  Dec 19 10:41:55.301: INFO: Created: latency-svc-v6m7n
  Dec 19 10:41:55.332: INFO: Got endpoints: latency-svc-qzmnh [716.260594ms]
  Dec 19 10:41:55.358: INFO: Created: latency-svc-wr9z5
  Dec 19 10:41:55.384: INFO: Got endpoints: latency-svc-hnkjg [741.399775ms]
  Dec 19 10:41:55.407: INFO: Created: latency-svc-pdhv8
  Dec 19 10:41:55.434: INFO: Got endpoints: latency-svc-wwjpx [751.597132ms]
  Dec 19 10:41:55.453: INFO: Created: latency-svc-cn4tj
  Dec 19 10:41:55.487: INFO: Got endpoints: latency-svc-87d6r [757.249585ms]
  Dec 19 10:41:55.513: INFO: Created: latency-svc-8ssgs
  Dec 19 10:41:55.548: INFO: Got endpoints: latency-svc-dw6w2 [762.647073ms]
  Dec 19 10:41:55.574: INFO: Created: latency-svc-sdsw8
  Dec 19 10:41:55.587: INFO: Got endpoints: latency-svc-t77xc [750.189119ms]
  Dec 19 10:41:55.649: INFO: Got endpoints: latency-svc-g9l7g [756.554264ms]
  Dec 19 10:41:55.667: INFO: Created: latency-svc-7xsnj
  Dec 19 10:41:55.683: INFO: Got endpoints: latency-svc-8dlcr [733.656739ms]
  Dec 19 10:41:55.693: INFO: Created: latency-svc-9tn5w
  Dec 19 10:41:55.705: INFO: Created: latency-svc-g6tcj
  E1219 10:41:55.726279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:55.737: INFO: Got endpoints: latency-svc-clds4 [754.119666ms]
  Dec 19 10:41:55.758: INFO: Created: latency-svc-lg77p
  Dec 19 10:41:55.783: INFO: Got endpoints: latency-svc-mhjd4 [750.079176ms]
  Dec 19 10:41:55.802: INFO: Created: latency-svc-ssdxf
  Dec 19 10:41:55.832: INFO: Got endpoints: latency-svc-dk4mx [745.909594ms]
  Dec 19 10:41:55.855: INFO: Created: latency-svc-fc4c5
  Dec 19 10:41:55.882: INFO: Got endpoints: latency-svc-qqg8n [747.41062ms]
  Dec 19 10:41:55.904: INFO: Created: latency-svc-9k77w
  Dec 19 10:41:55.931: INFO: Got endpoints: latency-svc-8kvqq [749.912813ms]
  Dec 19 10:41:55.950: INFO: Created: latency-svc-tmcs2
  Dec 19 10:41:55.987: INFO: Got endpoints: latency-svc-glvbg [754.130109ms]
  Dec 19 10:41:56.013: INFO: Created: latency-svc-qhx6z
  Dec 19 10:41:56.046: INFO: Got endpoints: latency-svc-v6m7n [761.591091ms]
  Dec 19 10:41:56.070: INFO: Created: latency-svc-tl6l4
  Dec 19 10:41:56.085: INFO: Got endpoints: latency-svc-wr9z5 [753.622033ms]
  Dec 19 10:41:56.108: INFO: Created: latency-svc-9mssg
  Dec 19 10:41:56.136: INFO: Got endpoints: latency-svc-pdhv8 [751.618134ms]
  Dec 19 10:41:56.166: INFO: Created: latency-svc-tkfcx
  Dec 19 10:41:56.182: INFO: Got endpoints: latency-svc-cn4tj [748.367944ms]
  Dec 19 10:41:56.204: INFO: Created: latency-svc-znjn8
  Dec 19 10:41:56.237: INFO: Got endpoints: latency-svc-8ssgs [749.876431ms]
  Dec 19 10:41:56.263: INFO: Created: latency-svc-j8mrf
  Dec 19 10:41:56.283: INFO: Got endpoints: latency-svc-sdsw8 [735.288234ms]
  Dec 19 10:41:56.309: INFO: Created: latency-svc-cjs6v
  Dec 19 10:41:56.339: INFO: Got endpoints: latency-svc-7xsnj [751.381371ms]
  Dec 19 10:41:56.356: INFO: Created: latency-svc-7hnx7
  Dec 19 10:41:56.381: INFO: Got endpoints: latency-svc-9tn5w [731.941574ms]
  Dec 19 10:41:56.405: INFO: Created: latency-svc-mtljr
  Dec 19 10:41:56.432: INFO: Got endpoints: latency-svc-g6tcj [747.902938ms]
  Dec 19 10:41:56.451: INFO: Created: latency-svc-n9q7k
  Dec 19 10:41:56.482: INFO: Got endpoints: latency-svc-lg77p [744.983565ms]
  Dec 19 10:41:56.505: INFO: Created: latency-svc-tftqd
  Dec 19 10:41:56.532: INFO: Got endpoints: latency-svc-ssdxf [749.080276ms]
  Dec 19 10:41:56.548: INFO: Created: latency-svc-r8lsq
  Dec 19 10:41:56.588: INFO: Got endpoints: latency-svc-fc4c5 [755.120208ms]
  Dec 19 10:41:56.618: INFO: Created: latency-svc-xrgdz
  Dec 19 10:41:56.632: INFO: Got endpoints: latency-svc-9k77w [750.328699ms]
  Dec 19 10:41:56.656: INFO: Created: latency-svc-gfnn5
  Dec 19 10:41:56.686: INFO: Got endpoints: latency-svc-tmcs2 [752.729968ms]
  Dec 19 10:41:56.703: INFO: Created: latency-svc-q2vww
  E1219 10:41:56.726372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:56.743: INFO: Got endpoints: latency-svc-qhx6z [755.648784ms]
  Dec 19 10:41:56.767: INFO: Created: latency-svc-9hmxd
  Dec 19 10:41:56.780: INFO: Got endpoints: latency-svc-tl6l4 [733.453735ms]
  Dec 19 10:41:56.799: INFO: Created: latency-svc-csvcx
  Dec 19 10:41:56.842: INFO: Got endpoints: latency-svc-9mssg [755.919617ms]
  Dec 19 10:41:56.897: INFO: Created: latency-svc-4wl9x
  Dec 19 10:41:56.901: INFO: Got endpoints: latency-svc-tkfcx [763.777808ms]
  Dec 19 10:41:56.933: INFO: Created: latency-svc-8q5g5
  Dec 19 10:41:56.942: INFO: Got endpoints: latency-svc-znjn8 [759.195447ms]
  Dec 19 10:41:56.964: INFO: Created: latency-svc-cqjvd
  Dec 19 10:41:56.990: INFO: Got endpoints: latency-svc-j8mrf [752.777581ms]
  Dec 19 10:41:57.012: INFO: Created: latency-svc-25xl5
  Dec 19 10:41:57.036: INFO: Got endpoints: latency-svc-cjs6v [752.71693ms]
  Dec 19 10:41:57.065: INFO: Created: latency-svc-q6mrf
  Dec 19 10:41:57.082: INFO: Got endpoints: latency-svc-7hnx7 [743.065862ms]
  Dec 19 10:41:57.105: INFO: Created: latency-svc-qv2rv
  Dec 19 10:41:57.131: INFO: Got endpoints: latency-svc-mtljr [749.027123ms]
  Dec 19 10:41:57.152: INFO: Created: latency-svc-cdwtc
  Dec 19 10:41:57.185: INFO: Got endpoints: latency-svc-n9q7k [753.219962ms]
  Dec 19 10:41:57.213: INFO: Created: latency-svc-rcwng
  Dec 19 10:41:57.234: INFO: Got endpoints: latency-svc-tftqd [751.725138ms]
  Dec 19 10:41:57.259: INFO: Created: latency-svc-6g6v7
  Dec 19 10:41:57.280: INFO: Got endpoints: latency-svc-r8lsq [748.088844ms]
  Dec 19 10:41:57.304: INFO: Created: latency-svc-mh4fs
  Dec 19 10:41:57.336: INFO: Got endpoints: latency-svc-xrgdz [748.313896ms]
  Dec 19 10:41:57.361: INFO: Created: latency-svc-pdd8k
  Dec 19 10:41:57.384: INFO: Got endpoints: latency-svc-gfnn5 [751.506192ms]
  Dec 19 10:41:57.412: INFO: Created: latency-svc-2v2wd
  Dec 19 10:41:57.439: INFO: Got endpoints: latency-svc-q2vww [753.651949ms]
  Dec 19 10:41:57.458: INFO: Created: latency-svc-tqqt9
  Dec 19 10:41:57.482: INFO: Got endpoints: latency-svc-9hmxd [738.873291ms]
  Dec 19 10:41:57.513: INFO: Created: latency-svc-gwm6v
  Dec 19 10:41:57.535: INFO: Got endpoints: latency-svc-csvcx [754.974913ms]
  Dec 19 10:41:57.571: INFO: Created: latency-svc-66v2b
  Dec 19 10:41:57.588: INFO: Got endpoints: latency-svc-4wl9x [746.296ms]
  Dec 19 10:41:57.606: INFO: Created: latency-svc-lnhjt
  Dec 19 10:41:57.633: INFO: Got endpoints: latency-svc-8q5g5 [732.556336ms]
  Dec 19 10:41:57.653: INFO: Created: latency-svc-jdcpg
  Dec 19 10:41:57.687: INFO: Got endpoints: latency-svc-cqjvd [744.162504ms]
  Dec 19 10:41:57.707: INFO: Created: latency-svc-vjtrx
  E1219 10:41:57.727568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:57.732: INFO: Got endpoints: latency-svc-25xl5 [741.547842ms]
  Dec 19 10:41:57.750: INFO: Created: latency-svc-fflq7
  Dec 19 10:41:57.783: INFO: Got endpoints: latency-svc-q6mrf [747.145494ms]
  Dec 19 10:41:57.804: INFO: Created: latency-svc-dtxpg
  Dec 19 10:41:57.833: INFO: Got endpoints: latency-svc-qv2rv [750.788028ms]
  Dec 19 10:41:57.868: INFO: Created: latency-svc-fnk76
  Dec 19 10:41:57.882: INFO: Got endpoints: latency-svc-cdwtc [750.631962ms]
  Dec 19 10:41:57.903: INFO: Created: latency-svc-6k82d
  Dec 19 10:41:57.931: INFO: Got endpoints: latency-svc-rcwng [745.542684ms]
  Dec 19 10:41:57.952: INFO: Created: latency-svc-tm82b
  Dec 19 10:41:57.984: INFO: Got endpoints: latency-svc-6g6v7 [748.310385ms]
  Dec 19 10:41:58.006: INFO: Created: latency-svc-rph4s
  Dec 19 10:41:58.034: INFO: Got endpoints: latency-svc-mh4fs [752.934933ms]
  Dec 19 10:41:58.070: INFO: Created: latency-svc-8kjlj
  Dec 19 10:41:58.086: INFO: Got endpoints: latency-svc-pdd8k [749.18991ms]
  Dec 19 10:41:58.112: INFO: Created: latency-svc-4c9ph
  Dec 19 10:41:58.135: INFO: Got endpoints: latency-svc-2v2wd [750.993833ms]
  Dec 19 10:41:58.155: INFO: Created: latency-svc-cvw5f
  Dec 19 10:41:58.182: INFO: Got endpoints: latency-svc-tqqt9 [742.446699ms]
  Dec 19 10:41:58.202: INFO: Created: latency-svc-nfqcx
  Dec 19 10:41:58.232: INFO: Got endpoints: latency-svc-gwm6v [750.022951ms]
  Dec 19 10:41:58.250: INFO: Created: latency-svc-tjgq9
  Dec 19 10:41:58.285: INFO: Got endpoints: latency-svc-66v2b [748.970053ms]
  Dec 19 10:41:58.308: INFO: Created: latency-svc-kjc9c
  Dec 19 10:41:58.331: INFO: Got endpoints: latency-svc-lnhjt [742.009826ms]
  Dec 19 10:41:58.385: INFO: Created: latency-svc-wg6ng
  Dec 19 10:41:58.390: INFO: Got endpoints: latency-svc-jdcpg [755.816607ms]
  Dec 19 10:41:58.406: INFO: Created: latency-svc-tvt4x
  Dec 19 10:41:58.434: INFO: Got endpoints: latency-svc-vjtrx [746.298831ms]
  Dec 19 10:41:58.453: INFO: Created: latency-svc-hrz95
  Dec 19 10:41:58.479: INFO: Got endpoints: latency-svc-fflq7 [747.323392ms]
  Dec 19 10:41:58.499: INFO: Created: latency-svc-bbvph
  Dec 19 10:41:58.534: INFO: Got endpoints: latency-svc-dtxpg [750.362361ms]
  Dec 19 10:41:58.552: INFO: Created: latency-svc-kc5sq
  Dec 19 10:41:58.583: INFO: Got endpoints: latency-svc-fnk76 [749.762599ms]
  Dec 19 10:41:58.604: INFO: Created: latency-svc-dpd82
  Dec 19 10:41:58.642: INFO: Got endpoints: latency-svc-6k82d [759.510462ms]
  Dec 19 10:41:58.662: INFO: Created: latency-svc-65bn9
  Dec 19 10:41:58.683: INFO: Got endpoints: latency-svc-tm82b [751.710107ms]
  Dec 19 10:41:58.706: INFO: Created: latency-svc-96wsd
  E1219 10:41:58.727799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:58.731: INFO: Got endpoints: latency-svc-rph4s [747.095275ms]
  Dec 19 10:41:58.747: INFO: Created: latency-svc-sgdz8
  Dec 19 10:41:58.782: INFO: Got endpoints: latency-svc-8kjlj [748.704974ms]
  Dec 19 10:41:58.800: INFO: Created: latency-svc-zgrmb
  Dec 19 10:41:58.832: INFO: Got endpoints: latency-svc-4c9ph [745.487798ms]
  Dec 19 10:41:58.851: INFO: Created: latency-svc-cstrg
  Dec 19 10:41:58.884: INFO: Got endpoints: latency-svc-cvw5f [748.616322ms]
  Dec 19 10:41:58.899: INFO: Created: latency-svc-gsw2g
  Dec 19 10:41:58.977: INFO: Got endpoints: latency-svc-nfqcx [794.51647ms]
  Dec 19 10:41:59.003: INFO: Got endpoints: latency-svc-tjgq9 [770.177506ms]
  Dec 19 10:41:59.035: INFO: Got endpoints: latency-svc-kjc9c [750.150896ms]
  Dec 19 10:41:59.042: INFO: Created: latency-svc-6xswm
  Dec 19 10:41:59.072: INFO: Created: latency-svc-w62hr
  Dec 19 10:41:59.089: INFO: Got endpoints: latency-svc-wg6ng [757.611861ms]
  Dec 19 10:41:59.093: INFO: Created: latency-svc-66vdw
  Dec 19 10:41:59.110: INFO: Created: latency-svc-5znxf
  Dec 19 10:41:59.132: INFO: Got endpoints: latency-svc-tvt4x [741.420835ms]
  Dec 19 10:41:59.161: INFO: Created: latency-svc-lmlp8
  Dec 19 10:41:59.183: INFO: Got endpoints: latency-svc-hrz95 [749.727701ms]
  Dec 19 10:41:59.219: INFO: Created: latency-svc-29x4x
  Dec 19 10:41:59.238: INFO: Got endpoints: latency-svc-bbvph [759.076207ms]
  Dec 19 10:41:59.264: INFO: Created: latency-svc-5lwvf
  Dec 19 10:41:59.287: INFO: Got endpoints: latency-svc-kc5sq [752.661209ms]
  Dec 19 10:41:59.308: INFO: Created: latency-svc-64sbp
  Dec 19 10:41:59.333: INFO: Got endpoints: latency-svc-dpd82 [750.078025ms]
  Dec 19 10:41:59.354: INFO: Created: latency-svc-klrz2
  Dec 19 10:41:59.381: INFO: Got endpoints: latency-svc-65bn9 [738.907764ms]
  Dec 19 10:41:59.434: INFO: Got endpoints: latency-svc-96wsd [750.351443ms]
  Dec 19 10:41:59.480: INFO: Got endpoints: latency-svc-sgdz8 [749.292092ms]
  Dec 19 10:41:59.535: INFO: Got endpoints: latency-svc-zgrmb [752.333744ms]
  Dec 19 10:41:59.622: INFO: Got endpoints: latency-svc-cstrg [790.440825ms]
  Dec 19 10:41:59.649: INFO: Got endpoints: latency-svc-gsw2g [764.897083ms]
  Dec 19 10:41:59.683: INFO: Got endpoints: latency-svc-6xswm [705.921977ms]
  E1219 10:41:59.728575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:59.733: INFO: Got endpoints: latency-svc-w62hr [730.512317ms]
  Dec 19 10:41:59.781: INFO: Got endpoints: latency-svc-66vdw [745.915139ms]
  Dec 19 10:41:59.831: INFO: Got endpoints: latency-svc-5znxf [741.776199ms]
  Dec 19 10:41:59.882: INFO: Got endpoints: latency-svc-lmlp8 [750.393117ms]
  Dec 19 10:41:59.937: INFO: Got endpoints: latency-svc-29x4x [753.172366ms]
  Dec 19 10:41:59.981: INFO: Got endpoints: latency-svc-5lwvf [743.145601ms]
  Dec 19 10:42:00.034: INFO: Got endpoints: latency-svc-64sbp [746.686745ms]
  Dec 19 10:42:00.080: INFO: Got endpoints: latency-svc-klrz2 [746.446186ms]
  Dec 19 10:42:00.080: INFO: Latencies: [104.520029ms 161.454212ms 182.677862ms 217.7079ms 221.932921ms 228.10113ms 229.006918ms 230.166333ms 233.339625ms 233.749671ms 236.805563ms 237.176232ms 242.923081ms 243.534146ms 244.008377ms 245.113721ms 249.360636ms 249.961992ms 254.715751ms 260.886348ms 261.668206ms 266.157586ms 266.317971ms 268.864438ms 271.717461ms 276.492357ms 287.907928ms 288.375432ms 295.780258ms 299.403772ms 299.555691ms 314.466645ms 316.279584ms 316.979189ms 319.153011ms 327.503659ms 327.75473ms 329.081929ms 336.221311ms 347.992776ms 349.013334ms 358.343085ms 365.238979ms 368.588196ms 377.379603ms 392.884099ms 393.744615ms 402.51366ms 439.80628ms 449.960856ms 462.052639ms 478.620571ms 481.100494ms 497.849115ms 516.633443ms 525.870397ms 534.789616ms 537.515488ms 543.020592ms 544.0345ms 560.939074ms 562.468818ms 596.068831ms 612.866081ms 629.666421ms 637.528388ms 641.700325ms 676.948422ms 705.921977ms 716.260594ms 717.256972ms 730.512317ms 730.784288ms 731.941574ms 731.973724ms 732.556336ms 733.453735ms 733.656739ms 734.139084ms 735.288234ms 738.873291ms 738.907764ms 740.917219ms 741.399775ms 741.420835ms 741.547842ms 741.776199ms 742.009826ms 742.122389ms 742.446699ms 743.065143ms 743.065862ms 743.145601ms 743.69283ms 744.162504ms 744.525075ms 744.983565ms 745.487798ms 745.542684ms 745.849523ms 745.909594ms 745.915139ms 746.296ms 746.298831ms 746.446186ms 746.686745ms 746.976249ms 747.095275ms 747.145494ms 747.323392ms 747.41062ms 747.683355ms 747.836686ms 747.902938ms 748.088844ms 748.310385ms 748.313896ms 748.362607ms 748.367944ms 748.616322ms 748.704974ms 748.842792ms 748.970053ms 749.027123ms 749.080276ms 749.18991ms 749.292092ms 749.349318ms 749.727701ms 749.762599ms 749.876431ms 749.912813ms 750.022951ms 750.078025ms 750.079176ms 750.116354ms 750.150896ms 750.189119ms 750.328699ms 750.351443ms 750.362361ms 750.368462ms 750.393117ms 750.612486ms 750.631962ms 750.788028ms 750.889294ms 750.993833ms 751.381371ms 751.506192ms 751.597132ms 751.610164ms 751.611356ms 751.618134ms 751.634506ms 751.687917ms 751.710107ms 751.725138ms 751.970747ms 752.333744ms 752.469146ms 752.568994ms 752.661209ms 752.71693ms 752.729968ms 752.777581ms 752.934933ms 753.029638ms 753.152414ms 753.172366ms 753.219962ms 753.622033ms 753.651949ms 754.119666ms 754.130109ms 754.512959ms 754.974913ms 755.120208ms 755.648784ms 755.816607ms 755.919617ms 756.554264ms 757.249585ms 757.611861ms 759.076207ms 759.154889ms 759.195447ms 759.510462ms 759.833387ms 760.32574ms 761.042904ms 761.591091ms 762.647073ms 763.777808ms 764.897083ms 767.907023ms 770.177506ms 781.799037ms 790.440825ms 794.51647ms]
  Dec 19 10:42:00.081: INFO: 50 %ile: 745.909594ms
  Dec 19 10:42:00.081: INFO: 90 %ile: 755.919617ms
  Dec 19 10:42:00.081: INFO: 99 %ile: 790.440825ms
  Dec 19 10:42:00.081: INFO: Total sample count: 200
  Dec 19 10:42:00.082: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-8858" for this suite. @ 12/19/23 10:42:00.098
• [10.889 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 12/19/23 10:42:00.115
  Dec 19 10:42:00.116: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:42:00.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:00.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:00.162
  STEP: Counting existing ResourceQuota @ 12/19/23 10:42:00.166
  E1219 10:42:00.731202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:01.731520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:02.732141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:03.732274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:04.732560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 10:42:05.173
  STEP: Ensuring resource quota status is calculated @ 12/19/23 10:42:05.182
  E1219 10:42:05.733241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:06.733475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:07.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1261" for this suite. @ 12/19/23 10:42:07.203
• [7.103 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 12/19/23 10:42:07.219
  Dec 19 10:42:07.219: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:42:07.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:07.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:07.274
  STEP: Creating configMap with name projected-configmap-test-volume-ab396e3c-c4a5-4fa6-8a3c-4d40f5461423 @ 12/19/23 10:42:07.287
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:42:07.297
  E1219 10:42:07.733833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:08.733811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:09.734042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:10.734813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:42:11.359
  Dec 19 10:42:11.366: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-a0221638-88ac-4c04-a419-1464350d8bb2 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:42:11.397
  Dec 19 10:42:11.423: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9853" for this suite. @ 12/19/23 10:42:11.433
• [4.225 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 12/19/23 10:42:11.445
  Dec 19 10:42:11.445: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 10:42:11.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:11.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:11.505
  Dec 19 10:42:11.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-328" for this suite. @ 12/19/23 10:42:11.611
• [0.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 12/19/23 10:42:11.655
  Dec 19 10:42:11.655: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:42:11.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:11.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:11.726
  E1219 10:42:11.735223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating configMap with name cm-test-opt-del-71f47468-6a9f-4c30-b562-2242054f7806 @ 12/19/23 10:42:11.757
  STEP: Creating configMap with name cm-test-opt-upd-84c05cf8-1374-4d3d-ac3f-8478aa6c5617 @ 12/19/23 10:42:11.773
  STEP: Creating the pod @ 12/19/23 10:42:11.785
  E1219 10:42:12.735508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:13.735689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-71f47468-6a9f-4c30-b562-2242054f7806 @ 12/19/23 10:42:13.887
  STEP: Updating configmap cm-test-opt-upd-84c05cf8-1374-4d3d-ac3f-8478aa6c5617 @ 12/19/23 10:42:13.905
  STEP: Creating configMap with name cm-test-opt-create-1bc3a89a-5513-4cc0-a52d-1324968ffe76 @ 12/19/23 10:42:13.917
  STEP: waiting to observe update in volume @ 12/19/23 10:42:13.929
  E1219 10:42:14.736192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:15.737584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:16.002: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9780" for this suite. @ 12/19/23 10:42:16.01
• [4.374 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 12/19/23 10:42:16.032
  Dec 19 10:42:16.032: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:42:16.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:16.079
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:16.085
  Dec 19 10:42:16.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-3984 version'
  Dec 19 10:42:16.286: INFO: stderr: ""
  Dec 19 10:42:16.286: INFO: stdout: "Client Version: v1.29.0\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.0\n"
  Dec 19 10:42:16.286: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3984" for this suite. @ 12/19/23 10:42:16.31
• [0.304 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 12/19/23 10:42:16.335
  Dec 19 10:42:16.335: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:42:16.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:16.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:16.392
  STEP: validating api versions @ 12/19/23 10:42:16.397
  Dec 19 10:42:16.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-9546 api-versions'
  Dec 19 10:42:16.632: INFO: stderr: ""
  Dec 19 10:42:16.636: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Dec 19 10:42:16.636: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9546" for this suite. @ 12/19/23 10:42:16.661
• [0.341 seconds]
------------------------------
SSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 12/19/23 10:42:16.678
  Dec 19 10:42:16.678: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename init-container @ 12/19/23 10:42:16.683
  E1219 10:42:16.736705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:16.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:16.741
  STEP: creating the pod @ 12/19/23 10:42:16.747
  Dec 19 10:42:16.747: INFO: PodSpec: initContainers in spec.initContainers
  E1219 10:42:17.737099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:18.740047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:19.740778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:19.750: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5457" for this suite. @ 12/19/23 10:42:19.759
• [3.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 12/19/23 10:42:19.774
  Dec 19 10:42:19.774: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:42:19.777
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:19.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:19.818
  STEP: Setting up server cert @ 12/19/23 10:42:19.867
  E1219 10:42:20.741153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:42:21.152
  STEP: Deploying the webhook pod @ 12/19/23 10:42:21.179
  STEP: Wait for the deployment to be ready @ 12/19/23 10:42:21.203
  Dec 19 10:42:21.224: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 10:42:21.741630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:22.741903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:42:23.242
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:42:23.265
  E1219 10:42:23.742900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:24.266: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 10:42:24.277: INFO: Unexpected error trying to get Endpoints for e2e-test-webhook : endpoints "e2e-test-webhook" not found
  E1219 10:42:24.743667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:25.266: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 10:42:25.284: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 10:42:25.744799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4117-crds.webhook.example.com via the AdmissionRegistration API @ 12/19/23 10:42:25.808
  Dec 19 10:42:25.835: INFO: Waiting for webhook configuration to be ready...
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/19/23 10:42:25.957
  E1219 10:42:26.745785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:27.745921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:28.746260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:28.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5023" for this suite. @ 12/19/23 10:42:28.811
  STEP: Destroying namespace "webhook-markers-9510" for this suite. @ 12/19/23 10:42:28.826
• [9.063 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 12/19/23 10:42:28.863
  Dec 19 10:42:28.863: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 10:42:28.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:28.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:28.915
  STEP: Creating namespace "e2e-ns-b7gtn" @ 12/19/23 10:42:28.921
  Dec 19 10:42:28.948: INFO: Namespace "e2e-ns-b7gtn-6924" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-b7gtn-6924" @ 12/19/23 10:42:28.948
  Dec 19 10:42:28.965: INFO: Namespace "e2e-ns-b7gtn-6924" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-b7gtn-6924" @ 12/19/23 10:42:28.965
  Dec 19 10:42:28.983: INFO: Namespace "e2e-ns-b7gtn-6924" has []v1.FinalizerName{"kubernetes"}
  Dec 19 10:42:28.983: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7462" for this suite. @ 12/19/23 10:42:28.992
  STEP: Destroying namespace "e2e-ns-b7gtn-6924" for this suite. @ 12/19/23 10:42:29.006
• [0.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 12/19/23 10:42:29.019
  Dec 19 10:42:29.019: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename proxy @ 12/19/23 10:42:29.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:29.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:29.08
  Dec 19 10:42:29.084: INFO: Creating pod...
  E1219 10:42:29.747174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:30.747970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:42:31.137: INFO: Creating service...
  Dec 19 10:42:31.164: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/DELETE
  Dec 19 10:42:31.183: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 10:42:31.183: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/GET
  Dec 19 10:42:31.190: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec 19 10:42:31.190: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/HEAD
  Dec 19 10:42:31.198: INFO: http.Client request:HEAD | StatusCode:200
  Dec 19 10:42:31.198: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/OPTIONS
  Dec 19 10:42:31.211: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 10:42:31.211: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/PATCH
  Dec 19 10:42:31.217: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 10:42:31.218: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/POST
  Dec 19 10:42:31.227: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 10:42:31.227: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/pods/agnhost/proxy/some/path/with/PUT
  Dec 19 10:42:31.235: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 10:42:31.235: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/DELETE
  Dec 19 10:42:31.245: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 10:42:31.245: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/GET
  Dec 19 10:42:31.256: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec 19 10:42:31.256: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/HEAD
  Dec 19 10:42:31.265: INFO: http.Client request:HEAD | StatusCode:200
  Dec 19 10:42:31.265: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/OPTIONS
  Dec 19 10:42:31.274: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 10:42:31.274: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/PATCH
  Dec 19 10:42:31.284: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 10:42:31.284: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/POST
  Dec 19 10:42:31.294: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 10:42:31.294: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-644/services/test-service/proxy/some/path/with/PUT
  Dec 19 10:42:31.303: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 10:42:31.303: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-644" for this suite. @ 12/19/23 10:42:31.313
• [2.305 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 12/19/23 10:42:31.325
  Dec 19 10:42:31.325: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename subpath @ 12/19/23 10:42:31.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:31.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:31.359
  STEP: Setting up data @ 12/19/23 10:42:31.363
  STEP: Creating pod pod-subpath-test-secret-cw6v @ 12/19/23 10:42:31.379
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 10:42:31.379
  E1219 10:42:31.748196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:32.748671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:33.755153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:34.750196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:35.751028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:36.751394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:37.753750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:38.752921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:39.753611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:40.754021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:41.754349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:42.754556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:43.755107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:44.755583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:45.756863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:46.756587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:47.757603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:48.757757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:49.758729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:50.759678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:51.760453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:52.761110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:53.762179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:54.762478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:42:55.518
  Dec 19 10:42:55.535: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-subpath-test-secret-cw6v container test-container-subpath-secret-cw6v: <nil>
  STEP: delete the pod @ 12/19/23 10:42:55.557
  STEP: Deleting pod pod-subpath-test-secret-cw6v @ 12/19/23 10:42:55.616
  Dec 19 10:42:55.616: INFO: Deleting pod "pod-subpath-test-secret-cw6v" in namespace "subpath-3444"
  Dec 19 10:42:55.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3444" for this suite. @ 12/19/23 10:42:55.644
• [24.341 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 12/19/23 10:42:55.67
  Dec 19 10:42:55.670: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:42:55.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:42:55.757
  E1219 10:42:55.762786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:42:55.763
  STEP: creating a replication controller @ 12/19/23 10:42:55.779
  Dec 19 10:42:55.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 create -f -'
  Dec 19 10:42:56.195: INFO: stderr: ""
  Dec 19 10:42:56.195: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 10:42:56.195
  Dec 19 10:42:56.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:42:56.445: INFO: stderr: ""
  Dec 19 10:42:56.445: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:42:56.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:42:56.593: INFO: stderr: ""
  Dec 19 10:42:56.593: INFO: stdout: ""
  Dec 19 10:42:56.593: INFO: update-demo-nautilus-4zpfx is created but not running
  E1219 10:42:56.763629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:57.764166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:58.764717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:59.765145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:00.765234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:01.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1219 10:43:01.766394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:01.809: INFO: stderr: ""
  Dec 19 10:43:01.809: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:43:01.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:02.052: INFO: stderr: ""
  Dec 19 10:43:02.052: INFO: stdout: ""
  Dec 19 10:43:02.053: INFO: update-demo-nautilus-4zpfx is created but not running
  E1219 10:43:02.768298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:03.767879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:04.767842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:05.768140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:06.768242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:07.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:43:07.330: INFO: stderr: ""
  Dec 19 10:43:07.330: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:43:07.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:07.534: INFO: stderr: ""
  Dec 19 10:43:07.534: INFO: stdout: ""
  Dec 19 10:43:07.534: INFO: update-demo-nautilus-4zpfx is created but not running
  E1219 10:43:07.768896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:08.769775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:09.769934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:10.770257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:11.770743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:12.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:43:12.736: INFO: stderr: ""
  Dec 19 10:43:12.736: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:43:12.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 10:43:12.771556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:12.915: INFO: stderr: ""
  Dec 19 10:43:12.915: INFO: stdout: ""
  Dec 19 10:43:12.915: INFO: update-demo-nautilus-4zpfx is created but not running
  E1219 10:43:13.772137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:14.773026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:15.774019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:16.773002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:17.773363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:17.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:43:18.106: INFO: stderr: ""
  Dec 19 10:43:18.106: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:43:18.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:18.290: INFO: stderr: ""
  Dec 19 10:43:18.290: INFO: stdout: "true"
  Dec 19 10:43:18.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:18.486: INFO: stderr: ""
  Dec 19 10:43:18.486: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:18.486: INFO: validating pod update-demo-nautilus-4zpfx
  Dec 19 10:43:18.507: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:18.507: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:18.507: INFO: update-demo-nautilus-4zpfx is verified up and running
  Dec 19 10:43:18.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-fnl6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:18.731: INFO: stderr: ""
  Dec 19 10:43:18.731: INFO: stdout: ""
  Dec 19 10:43:18.731: INFO: update-demo-nautilus-fnl6m is created but not running
  E1219 10:43:18.774366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:19.777443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:20.777068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:21.777342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:22.777601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:23.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1219 10:43:23.778370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:23.940: INFO: stderr: ""
  Dec 19 10:43:23.940: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:43:23.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:24.135: INFO: stderr: ""
  Dec 19 10:43:24.135: INFO: stdout: "true"
  Dec 19 10:43:24.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:24.326: INFO: stderr: ""
  Dec 19 10:43:24.326: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:24.326: INFO: validating pod update-demo-nautilus-4zpfx
  Dec 19 10:43:24.336: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:24.337: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:24.337: INFO: update-demo-nautilus-4zpfx is verified up and running
  Dec 19 10:43:24.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-fnl6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:24.517: INFO: stderr: ""
  Dec 19 10:43:24.517: INFO: stdout: ""
  Dec 19 10:43:24.517: INFO: update-demo-nautilus-fnl6m is created but not running
  E1219 10:43:24.779334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:25.779476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:26.779777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:27.780419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:28.780612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:29.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:43:29.705: INFO: stderr: ""
  Dec 19 10:43:29.705: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-fnl6m "
  Dec 19 10:43:29.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 10:43:29.781599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:29.888: INFO: stderr: ""
  Dec 19 10:43:29.888: INFO: stdout: "true"
  Dec 19 10:43:29.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:30.080: INFO: stderr: ""
  Dec 19 10:43:30.080: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:30.080: INFO: validating pod update-demo-nautilus-4zpfx
  Dec 19 10:43:30.093: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:30.093: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:30.093: INFO: update-demo-nautilus-4zpfx is verified up and running
  Dec 19 10:43:30.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-fnl6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:30.262: INFO: stderr: ""
  Dec 19 10:43:30.262: INFO: stdout: "true"
  Dec 19 10:43:30.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-fnl6m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:30.484: INFO: stderr: ""
  Dec 19 10:43:30.484: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:30.484: INFO: validating pod update-demo-nautilus-fnl6m
  Dec 19 10:43:30.502: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:30.502: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:30.502: INFO: update-demo-nautilus-fnl6m is verified up and running
  STEP: scaling down the replication controller @ 12/19/23 10:43:30.503
  Dec 19 10:43:30.538: INFO: scanned /root for discovery docs: <nil>
  Dec 19 10:43:30.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E1219 10:43:30.781914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:31.783169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:31.784: INFO: stderr: ""
  Dec 19 10:43:31.784: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 10:43:31.784
  Dec 19 10:43:31.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:43:31.942: INFO: stderr: ""
  Dec 19 10:43:31.942: INFO: stdout: "update-demo-nautilus-4zpfx "
  Dec 19 10:43:31.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:32.136: INFO: stderr: ""
  Dec 19 10:43:32.136: INFO: stdout: "true"
  Dec 19 10:43:32.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:32.319: INFO: stderr: ""
  Dec 19 10:43:32.319: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:32.319: INFO: validating pod update-demo-nautilus-4zpfx
  Dec 19 10:43:32.329: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:32.329: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:32.329: INFO: update-demo-nautilus-4zpfx is verified up and running
  STEP: scaling up the replication controller @ 12/19/23 10:43:32.329
  Dec 19 10:43:32.348: INFO: scanned /root for discovery docs: <nil>
  Dec 19 10:43:32.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E1219 10:43:32.784586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:33.596: INFO: stderr: ""
  Dec 19 10:43:33.597: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 10:43:33.597
  Dec 19 10:43:33.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1219 10:43:33.785378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:33.792: INFO: stderr: ""
  Dec 19 10:43:33.792: INFO: stdout: "update-demo-nautilus-4zpfx update-demo-nautilus-sz7zl "
  Dec 19 10:43:33.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:33.963: INFO: stderr: ""
  Dec 19 10:43:33.963: INFO: stdout: "true"
  Dec 19 10:43:33.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-4zpfx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:34.136: INFO: stderr: ""
  Dec 19 10:43:34.136: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:34.136: INFO: validating pod update-demo-nautilus-4zpfx
  Dec 19 10:43:34.148: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:34.148: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:34.148: INFO: update-demo-nautilus-4zpfx is verified up and running
  Dec 19 10:43:34.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-sz7zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:43:34.334: INFO: stderr: ""
  Dec 19 10:43:34.334: INFO: stdout: "true"
  Dec 19 10:43:34.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods update-demo-nautilus-sz7zl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:43:34.507: INFO: stderr: ""
  Dec 19 10:43:34.507: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:43:34.507: INFO: validating pod update-demo-nautilus-sz7zl
  Dec 19 10:43:34.527: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:43:34.527: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:43:34.527: INFO: update-demo-nautilus-sz7zl is verified up and running
  STEP: using delete to clean up resources @ 12/19/23 10:43:34.527
  Dec 19 10:43:34.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 delete --grace-period=0 --force -f -'
  Dec 19 10:43:34.731: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:43:34.731: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec 19 10:43:34.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get rc,svc -l name=update-demo --no-headers'
  E1219 10:43:34.788354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:35.111: INFO: stderr: "No resources found in kubectl-2016 namespace.\n"
  Dec 19 10:43:35.111: INFO: stdout: ""
  Dec 19 10:43:35.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2016 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec 19 10:43:35.420: INFO: stderr: ""
  Dec 19 10:43:35.420: INFO: stdout: ""
  Dec 19 10:43:35.421: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2016" for this suite. @ 12/19/23 10:43:35.436
• [39.788 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 12/19/23 10:43:35.46
  Dec 19 10:43:35.460: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:43:35.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:43:35.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:43:35.547
  STEP: Creating a pod to test service account token:  @ 12/19/23 10:43:35.563
  E1219 10:43:35.788612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:36.789451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:37.789908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:38.790709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:43:39.656
  Dec 19 10:43:39.679: INFO: Trying to get logs from node uikie9pei4sh-3 pod test-pod-4e0bf2ac-aca2-4ba7-94f8-4273a7527d10 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:43:39.704
  Dec 19 10:43:39.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2635" for this suite. @ 12/19/23 10:43:39.744
• [4.306 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 12/19/23 10:43:39.767
  Dec 19 10:43:39.768: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:43:39.771
  E1219 10:43:39.790766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:43:39.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:43:39.819
  Dec 19 10:43:39.917: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"45c2cc68-1967-4455-b1d1-bad23d39f610", Controller:(*bool)(0xc003cfaba6), BlockOwnerDeletion:(*bool)(0xc003cfaba7)}}
  Dec 19 10:43:39.942: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e1e00ef8-3b2f-4837-b0ad-8bb5ea346fef", Controller:(*bool)(0xc002cd8836), BlockOwnerDeletion:(*bool)(0xc002cd8837)}}
  Dec 19 10:43:39.959: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"79914faa-9988-4bb6-8d80-41d2d059c56c", Controller:(*bool)(0xc003cfadf6), BlockOwnerDeletion:(*bool)(0xc003cfadf7)}}
  E1219 10:43:40.791361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:41.791048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:42.791517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:43.791847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:44.792480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:44.985: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4387" for this suite. @ 12/19/23 10:43:44.998
• [5.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 12/19/23 10:43:45.02
  Dec 19 10:43:45.020: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:43:45.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:43:45.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:43:45.079
  STEP: Creating a test headless service @ 12/19/23 10:43:45.087
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5380.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5380.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5380.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5380.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 147.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.147_udp@PTR;check="$$(dig +tcp +noall +answer +search 147.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.147_tcp@PTR;sleep 1; done
   @ 12/19/23 10:43:45.151
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5380.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5380.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5380.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5380.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5380.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 147.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.147_udp@PTR;check="$$(dig +tcp +noall +answer +search 147.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.147_tcp@PTR;sleep 1; done
   @ 12/19/23 10:43:45.152
  STEP: creating a pod to probe DNS @ 12/19/23 10:43:45.152
  STEP: submitting the pod to kubernetes @ 12/19/23 10:43:45.152
  E1219 10:43:45.792690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:46.794642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:47.794153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:48.795342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:43:49.25
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:43:49.267
  Dec 19 10:43:49.321: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:49.335: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:49.382: INFO: Unable to read jessie_udp@dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:49.410: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:49.424: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:49.501: INFO: Lookups using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_udp@dns-test-service.dns-5380.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local]

  Dec 19 10:43:49.537: INFO: Pod client logs for webserver: 
  Dec 19 10:43:49.554: INFO: Pod client logs for querier: 
  Dec 19 10:43:49.576: INFO: Pod client logs for jessie-querier: 
  E1219 10:43:49.795088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:50.796905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:51.796190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:52.797020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:53.797149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:54.304: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:54.314: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:54.410: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:54.419: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:54.455: INFO: Lookups using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local]

  Dec 19 10:43:54.471: INFO: Pod client logs for webserver: 
  Dec 19 10:43:54.487: INFO: Pod client logs for querier: 
  Dec 19 10:43:54.513: INFO: Pod client logs for jessie-querier: 
  E1219 10:43:54.798145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:55.798976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:56.799520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:57.800401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:58.800463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:43:59.296: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:59.305: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:59.369: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:59.376: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:43:59.416: INFO: Lookups using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local]

  Dec 19 10:43:59.437: INFO: Pod client logs for webserver: 
  Dec 19 10:43:59.451: INFO: Pod client logs for querier: 
  Dec 19 10:43:59.466: INFO: Pod client logs for jessie-querier: 
  E1219 10:43:59.800693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:00.801075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:01.801171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:02.801737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:03.802743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:04.299: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:04.308: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:04.378: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:04.394: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:04.426: INFO: Lookups using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local]

  Dec 19 10:44:04.444: INFO: Pod client logs for webserver: 
  Dec 19 10:44:04.461: INFO: Pod client logs for querier: 
  Dec 19 10:44:04.482: INFO: Pod client logs for jessie-querier: 
  E1219 10:44:04.803128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:05.803465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:06.803475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:07.803909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:08.804843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:09.312: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:09.323: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:09.386: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:09.395: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:09.433: INFO: Lookups using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local]

  Dec 19 10:44:09.450: INFO: Pod client logs for webserver: 
  Dec 19 10:44:09.469: INFO: Pod client logs for querier: 
  Dec 19 10:44:09.489: INFO: Pod client logs for jessie-querier: 
  E1219 10:44:09.806348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:10.806791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:11.806906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:12.807488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:13.808100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:14.312: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:14.322: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:14.455: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:14.468: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local from pod dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70: the server could not find the requested resource (get pods dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70)
  Dec 19 10:44:14.514: INFO: Lookups using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5380.svc.cluster.local]

  Dec 19 10:44:14.540: INFO: Pod client logs for webserver: 
  Dec 19 10:44:14.561: INFO: Pod client logs for querier: 
  Dec 19 10:44:14.581: INFO: Pod client logs for jessie-querier: 
  E1219 10:44:14.814843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:15.813565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:16.813896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:17.814474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:18.816308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:19.438: INFO: DNS probes using dns-5380/dns-test-79093f2e-1ac1-480b-bd7c-a078f1a54f70 succeeded

  STEP: deleting the pod @ 12/19/23 10:44:19.441
  STEP: deleting the test service @ 12/19/23 10:44:19.482
  STEP: deleting the test headless service @ 12/19/23 10:44:19.683
  Dec 19 10:44:19.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5380" for this suite. @ 12/19/23 10:44:19.754
• [34.749 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 12/19/23 10:44:19.771
  Dec 19 10:44:19.771: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename job @ 12/19/23 10:44:19.777
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:19.813
  E1219 10:44:19.817073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:19.828
  STEP: Creating a job @ 12/19/23 10:44:19.837
  STEP: Ensuring active pods == parallelism @ 12/19/23 10:44:19.86
  E1219 10:44:20.818227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:21.818991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 12/19/23 10:44:21.873
  Dec 19 10:44:22.434: INFO: Successfully updated pod "adopt-release-767tj"
  STEP: Checking that the Job readopts the Pod @ 12/19/23 10:44:22.435
  E1219 10:44:22.820031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:23.820799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 12/19/23 10:44:24.465
  E1219 10:44:24.821016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:24.992: INFO: Successfully updated pod "adopt-release-767tj"
  STEP: Checking that the Job releases the Pod @ 12/19/23 10:44:24.993
  E1219 10:44:25.821235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:26.821356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:27.011: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7011" for this suite. @ 12/19/23 10:44:27.019
• [7.259 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 12/19/23 10:44:27.031
  Dec 19 10:44:27.031: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename certificates @ 12/19/23 10:44:27.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:27.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:27.077
  E1219 10:44:27.821733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 12/19/23 10:44:28.164
  STEP: getting /apis/certificates.k8s.io @ 12/19/23 10:44:28.174
  STEP: getting /apis/certificates.k8s.io/v1 @ 12/19/23 10:44:28.177
  STEP: creating @ 12/19/23 10:44:28.179
  STEP: getting @ 12/19/23 10:44:28.234
  STEP: listing @ 12/19/23 10:44:28.24
  STEP: watching @ 12/19/23 10:44:28.247
  Dec 19 10:44:28.247: INFO: starting watch
  STEP: patching @ 12/19/23 10:44:28.249
  STEP: updating @ 12/19/23 10:44:28.261
  Dec 19 10:44:28.271: INFO: waiting for watch events with expected annotations
  Dec 19 10:44:28.272: INFO: saw patched and updated annotations
  STEP: getting /approval @ 12/19/23 10:44:28.273
  STEP: patching /approval @ 12/19/23 10:44:28.284
  STEP: updating /approval @ 12/19/23 10:44:28.3
  STEP: getting /status @ 12/19/23 10:44:28.316
  STEP: patching /status @ 12/19/23 10:44:28.322
  STEP: updating /status @ 12/19/23 10:44:28.343
  STEP: deleting @ 12/19/23 10:44:28.361
  STEP: deleting a collection @ 12/19/23 10:44:28.402
  Dec 19 10:44:28.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-7105" for this suite. @ 12/19/23 10:44:28.457
• [1.440 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 12/19/23 10:44:28.476
  Dec 19 10:44:28.476: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:44:28.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:28.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:28.53
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 10:44:28.537
  Dec 19 10:44:28.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-7980 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Dec 19 10:44:28.731: INFO: stderr: ""
  Dec 19 10:44:28.731: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/19/23 10:44:28.731
  Dec 19 10:44:28.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-7980 delete pods e2e-test-httpd-pod'
  E1219 10:44:28.822696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:29.823184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:30.577: INFO: stderr: ""
  Dec 19 10:44:30.577: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec 19 10:44:30.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7980" for this suite. @ 12/19/23 10:44:30.588
• [2.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 12/19/23 10:44:30.61
  Dec 19 10:44:30.610: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sysctl @ 12/19/23 10:44:30.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:30.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:30.659
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 12/19/23 10:44:30.668
  STEP: Watching for error events or started pod @ 12/19/23 10:44:30.685
  E1219 10:44:30.823770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:31.823837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 12/19/23 10:44:32.693
  E1219 10:44:32.824465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:33.825485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 12/19/23 10:44:34.717
  STEP: Getting logs from the pod @ 12/19/23 10:44:34.717
  STEP: Checking that the sysctl is actually updated @ 12/19/23 10:44:34.733
  Dec 19 10:44:34.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-176" for this suite. @ 12/19/23 10:44:34.745
• [4.159 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 12/19/23 10:44:34.771
  Dec 19 10:44:34.771: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:44:34.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:34.824
  E1219 10:44:34.826092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:34.833
  STEP: Setting up server cert @ 12/19/23 10:44:34.905
  E1219 10:44:35.826248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:44:35.859
  STEP: Deploying the webhook pod @ 12/19/23 10:44:35.886
  STEP: Wait for the deployment to be ready @ 12/19/23 10:44:35.911
  Dec 19 10:44:35.935: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 10:44:36.828419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:37.828038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:37.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 10, 44, 36, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 44, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 44, 36, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 44, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 10:44:38.828669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:39.828902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:44:39.999
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:44:40.034
  E1219 10:44:40.830237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:44:41.035: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 10:44:41.052: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 12/19/23 10:44:41.581
  STEP: Creating a custom resource that should be denied by the webhook @ 12/19/23 10:44:41.628
  E1219 10:44:41.831103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:42.831063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 12/19/23 10:44:43.795
  STEP: Updating the custom resource with disallowed data should be denied @ 12/19/23 10:44:43.812
  E1219 10:44:43.830889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the custom resource should be denied @ 12/19/23 10:44:43.839
  STEP: Remove the offending key and value from the custom resource data @ 12/19/23 10:44:43.858
  STEP: Deleting the updated custom resource should be successful @ 12/19/23 10:44:43.884
  Dec 19 10:44:44.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4962" for this suite. @ 12/19/23 10:44:44.606
  STEP: Destroying namespace "webhook-markers-7132" for this suite. @ 12/19/23 10:44:44.62
• [9.871 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 12/19/23 10:44:44.643
  Dec 19 10:44:44.643: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:44:44.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:44.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:44.72
  STEP: Creating a pdb that targets all three pods in a test replica set @ 12/19/23 10:44:44.728
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:44:44.741
  E1219 10:44:44.831527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:45.831940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 12/19/23 10:44:46.762
  STEP: Waiting for all pods to be running @ 12/19/23 10:44:46.762
  Dec 19 10:44:46.774: INFO: pods: 0 < 3
  E1219 10:44:46.833421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:47.834002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/19/23 10:44:48.773
  STEP: Updating the pdb to allow a pod to be evicted @ 12/19/23 10:44:48.802
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:44:48.822
  E1219 10:44:48.835795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:49.835636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/19/23 10:44:50.829
  STEP: Waiting for all pods to be running @ 12/19/23 10:44:50.829
  E1219 10:44:50.836012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to observed all healthy pods @ 12/19/23 10:44:50.839
  STEP: Patching the pdb to disallow a pod to be evicted @ 12/19/23 10:44:50.896
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:44:50.976
  E1219 10:44:51.836612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:52.836427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 12/19/23 10:44:52.993
  STEP: locating a running pod @ 12/19/23 10:44:53.003
  STEP: Deleting the pdb to allow a pod to be evicted @ 12/19/23 10:44:53.029
  STEP: Waiting for the pdb to be deleted @ 12/19/23 10:44:53.045
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/19/23 10:44:53.054
  STEP: Waiting for all pods to be running @ 12/19/23 10:44:53.054
  Dec 19 10:44:53.101: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3307" for this suite. @ 12/19/23 10:44:53.159
• [8.552 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 12/19/23 10:44:53.2
  Dec 19 10:44:53.200: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:44:53.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:44:53.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:44:53.26
  STEP: Counting existing ResourceQuota @ 12/19/23 10:44:53.267
  E1219 10:44:53.836520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:54.836923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:55.837174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:56.837585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:57.837922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 10:44:58.28
  STEP: Ensuring resource quota status is calculated @ 12/19/23 10:44:58.296
  E1219 10:44:58.839069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:59.838781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 12/19/23 10:45:00.312
  STEP: Creating a NodePort Service @ 12/19/23 10:45:00.374
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 12/19/23 10:45:00.436
  STEP: Ensuring resource quota status captures service creation @ 12/19/23 10:45:00.493
  E1219 10:45:00.839903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:01.840091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 12/19/23 10:45:02.502
  STEP: Ensuring resource quota status released usage @ 12/19/23 10:45:02.576
  E1219 10:45:02.840132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:03.840643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:04.586: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1167" for this suite. @ 12/19/23 10:45:04.605
• [11.424 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 12/19/23 10:45:04.624
  Dec 19 10:45:04.624: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 10:45:04.628
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:04.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:04.669
  STEP: fetching the /apis discovery document @ 12/19/23 10:45:04.677
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 12/19/23 10:45:04.68
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 12/19/23 10:45:04.68
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 12/19/23 10:45:04.681
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 12/19/23 10:45:04.683
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 12/19/23 10:45:04.683
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 12/19/23 10:45:04.687
  Dec 19 10:45:04.688: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3949" for this suite. @ 12/19/23 10:45:04.699
• [0.095 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 12/19/23 10:45:04.72
  Dec 19 10:45:04.720: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename proxy @ 12/19/23 10:45:04.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:04.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:04.777
  STEP: starting an echo server on multiple ports @ 12/19/23 10:45:04.809
  STEP: creating replication controller proxy-service-gdvfw in namespace proxy-7339 @ 12/19/23 10:45:04.809
  I1219 10:45:04.832401      13 runners.go:197] Created replication controller with name: proxy-service-gdvfw, namespace: proxy-7339, replica count: 1
  E1219 10:45:04.840819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:05.841243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:45:05.886935      13 runners.go:197] proxy-service-gdvfw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E1219 10:45:06.841688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:45:06.887262      13 runners.go:197] proxy-service-gdvfw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:45:06.896: INFO: setup took 2.11098901s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 12/19/23 10:45:06.896
  Dec 19 10:45:06.945: INFO: (0) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 47.720033ms)
  Dec 19 10:45:06.946: INFO: (0) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 49.767393ms)
  Dec 19 10:45:06.946: INFO: (0) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 48.381265ms)
  Dec 19 10:45:06.946: INFO: (0) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 49.879634ms)
  Dec 19 10:45:06.947: INFO: (0) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 48.271532ms)
  Dec 19 10:45:06.957: INFO: (0) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 59.186173ms)
  Dec 19 10:45:06.957: INFO: (0) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 58.577341ms)
  Dec 19 10:45:06.961: INFO: (0) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 63.934829ms)
  Dec 19 10:45:06.961: INFO: (0) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 63.602531ms)
  Dec 19 10:45:06.969: INFO: (0) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 70.28299ms)
  Dec 19 10:45:06.969: INFO: (0) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 70.099152ms)
  Dec 19 10:45:06.969: INFO: (0) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 71.844392ms)
  Dec 19 10:45:06.969: INFO: (0) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 71.243668ms)
  Dec 19 10:45:06.969: INFO: (0) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 71.142967ms)
  Dec 19 10:45:06.970: INFO: (0) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 71.839012ms)
  Dec 19 10:45:06.970: INFO: (0) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 72.510625ms)
  Dec 19 10:45:06.989: INFO: (1) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 14.848105ms)
  Dec 19 10:45:07.009: INFO: (1) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 34.079764ms)
  Dec 19 10:45:07.009: INFO: (1) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 29.649134ms)
  Dec 19 10:45:07.009: INFO: (1) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 29.549335ms)
  Dec 19 10:45:07.016: INFO: (1) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 35.993314ms)
  Dec 19 10:45:07.016: INFO: (1) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 36.870952ms)
  Dec 19 10:45:07.021: INFO: (1) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 41.740242ms)
  Dec 19 10:45:07.021: INFO: (1) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 41.380147ms)
  Dec 19 10:45:07.021: INFO: (1) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 41.543923ms)
  Dec 19 10:45:07.022: INFO: (1) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 41.785197ms)
  Dec 19 10:45:07.022: INFO: (1) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 41.973642ms)
  Dec 19 10:45:07.023: INFO: (1) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 46.993865ms)
  Dec 19 10:45:07.025: INFO: (1) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 51.122973ms)
  Dec 19 10:45:07.025: INFO: (1) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 44.637825ms)
  Dec 19 10:45:07.025: INFO: (1) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 49.936306ms)
  Dec 19 10:45:07.028: INFO: (1) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 47.374406ms)
  Dec 19 10:45:07.047: INFO: (2) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 17.679092ms)
  Dec 19 10:45:07.052: INFO: (2) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 23.496698ms)
  Dec 19 10:45:07.056: INFO: (2) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 26.70562ms)
  Dec 19 10:45:07.056: INFO: (2) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 27.761896ms)
  Dec 19 10:45:07.056: INFO: (2) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 25.550159ms)
  Dec 19 10:45:07.056: INFO: (2) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 25.055114ms)
  Dec 19 10:45:07.058: INFO: (2) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 30.047359ms)
  Dec 19 10:45:07.061: INFO: (2) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 30.634389ms)
  Dec 19 10:45:07.063: INFO: (2) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 33.596387ms)
  Dec 19 10:45:07.064: INFO: (2) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 33.556453ms)
  Dec 19 10:45:07.064: INFO: (2) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 33.186432ms)
  Dec 19 10:45:07.065: INFO: (2) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 33.849858ms)
  Dec 19 10:45:07.066: INFO: (2) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 36.749065ms)
  Dec 19 10:45:07.067: INFO: (2) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 37.261638ms)
  Dec 19 10:45:07.068: INFO: (2) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 36.773185ms)
  Dec 19 10:45:07.071: INFO: (2) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 40.026345ms)
  Dec 19 10:45:07.091: INFO: (3) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 19.825343ms)
  Dec 19 10:45:07.091: INFO: (3) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 19.693233ms)
  Dec 19 10:45:07.094: INFO: (3) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 22.608087ms)
  Dec 19 10:45:07.095: INFO: (3) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 23.510234ms)
  Dec 19 10:45:07.095: INFO: (3) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 23.051195ms)
  Dec 19 10:45:07.104: INFO: (3) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 31.342769ms)
  Dec 19 10:45:07.106: INFO: (3) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 33.664677ms)
  Dec 19 10:45:07.106: INFO: (3) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 34.626022ms)
  Dec 19 10:45:07.110: INFO: (3) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 38.437784ms)
  Dec 19 10:45:07.110: INFO: (3) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 37.110926ms)
  Dec 19 10:45:07.110: INFO: (3) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 38.09284ms)
  Dec 19 10:45:07.110: INFO: (3) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 39.161352ms)
  Dec 19 10:45:07.110: INFO: (3) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 37.631888ms)
  Dec 19 10:45:07.110: INFO: (3) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 38.45952ms)
  Dec 19 10:45:07.111: INFO: (3) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 38.513825ms)
  Dec 19 10:45:07.115: INFO: (3) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 42.393711ms)
  Dec 19 10:45:07.145: INFO: (4) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 29.427951ms)
  Dec 19 10:45:07.148: INFO: (4) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 30.510425ms)
  Dec 19 10:45:07.148: INFO: (4) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 30.708476ms)
  Dec 19 10:45:07.150: INFO: (4) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 33.99462ms)
  Dec 19 10:45:07.150: INFO: (4) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 33.004891ms)
  Dec 19 10:45:07.151: INFO: (4) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 34.501619ms)
  Dec 19 10:45:07.152: INFO: (4) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 35.491625ms)
  Dec 19 10:45:07.152: INFO: (4) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 34.963633ms)
  Dec 19 10:45:07.153: INFO: (4) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 35.730223ms)
  Dec 19 10:45:07.167: INFO: (4) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 51.400897ms)
  Dec 19 10:45:07.167: INFO: (4) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 51.88752ms)
  Dec 19 10:45:07.167: INFO: (4) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 51.107075ms)
  Dec 19 10:45:07.168: INFO: (4) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 51.372786ms)
  Dec 19 10:45:07.168: INFO: (4) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 50.814396ms)
  Dec 19 10:45:07.174: INFO: (4) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 57.413411ms)
  Dec 19 10:45:07.179: INFO: (4) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 62.070749ms)
  Dec 19 10:45:07.194: INFO: (5) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 14.199786ms)
  Dec 19 10:45:07.194: INFO: (5) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 15.374258ms)
  Dec 19 10:45:07.196: INFO: (5) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 16.049417ms)
  Dec 19 10:45:07.204: INFO: (5) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 21.948558ms)
  Dec 19 10:45:07.204: INFO: (5) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 24.59477ms)
  Dec 19 10:45:07.205: INFO: (5) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 23.486212ms)
  Dec 19 10:45:07.205: INFO: (5) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 25.425732ms)
  Dec 19 10:45:07.205: INFO: (5) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 24.355842ms)
  Dec 19 10:45:07.208: INFO: (5) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 27.347873ms)
  Dec 19 10:45:07.209: INFO: (5) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 27.285877ms)
  Dec 19 10:45:07.220: INFO: (5) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 40.610186ms)
  Dec 19 10:45:07.225: INFO: (5) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 44.096978ms)
  Dec 19 10:45:07.225: INFO: (5) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 43.362486ms)
  Dec 19 10:45:07.226: INFO: (5) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 43.85419ms)
  Dec 19 10:45:07.226: INFO: (5) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 45.570657ms)
  Dec 19 10:45:07.226: INFO: (5) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 44.374503ms)
  Dec 19 10:45:07.239: INFO: (6) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 11.469234ms)
  Dec 19 10:45:07.243: INFO: (6) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 14.013426ms)
  Dec 19 10:45:07.244: INFO: (6) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 14.538263ms)
  Dec 19 10:45:07.246: INFO: (6) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 17.339807ms)
  Dec 19 10:45:07.248: INFO: (6) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 20.06077ms)
  Dec 19 10:45:07.252: INFO: (6) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 23.723948ms)
  Dec 19 10:45:07.266: INFO: (6) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 38.790501ms)
  Dec 19 10:45:07.267: INFO: (6) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 39.510276ms)
  Dec 19 10:45:07.267: INFO: (6) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 39.231236ms)
  Dec 19 10:45:07.267: INFO: (6) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 38.939034ms)
  Dec 19 10:45:07.268: INFO: (6) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 38.948164ms)
  Dec 19 10:45:07.268: INFO: (6) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 39.030487ms)
  Dec 19 10:45:07.268: INFO: (6) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 38.666274ms)
  Dec 19 10:45:07.268: INFO: (6) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 38.61313ms)
  Dec 19 10:45:07.268: INFO: (6) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 40.658932ms)
  Dec 19 10:45:07.268: INFO: (6) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 39.043955ms)
  Dec 19 10:45:07.289: INFO: (7) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 19.71947ms)
  Dec 19 10:45:07.290: INFO: (7) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 20.442339ms)
  Dec 19 10:45:07.293: INFO: (7) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 22.182483ms)
  Dec 19 10:45:07.297: INFO: (7) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 27.86843ms)
  Dec 19 10:45:07.298: INFO: (7) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 28.942407ms)
  Dec 19 10:45:07.298: INFO: (7) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 29.770089ms)
  Dec 19 10:45:07.301: INFO: (7) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 31.742288ms)
  Dec 19 10:45:07.302: INFO: (7) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 31.960549ms)
  Dec 19 10:45:07.303: INFO: (7) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 32.613702ms)
  Dec 19 10:45:07.330: INFO: (7) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 61.573524ms)
  Dec 19 10:45:07.337: INFO: (7) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 66.546129ms)
  Dec 19 10:45:07.338: INFO: (7) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 69.15943ms)
  Dec 19 10:45:07.338: INFO: (7) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 69.270602ms)
  Dec 19 10:45:07.342: INFO: (7) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 71.815357ms)
  Dec 19 10:45:07.342: INFO: (7) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 70.848483ms)
  Dec 19 10:45:07.352: INFO: (7) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 82.013293ms)
  Dec 19 10:45:07.396: INFO: (8) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 43.269282ms)
  Dec 19 10:45:07.396: INFO: (8) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 43.79438ms)
  Dec 19 10:45:07.413: INFO: (8) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 60.952823ms)
  Dec 19 10:45:07.415: INFO: (8) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 61.264519ms)
  Dec 19 10:45:07.417: INFO: (8) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 64.661572ms)
  Dec 19 10:45:07.425: INFO: (8) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 72.844699ms)
  Dec 19 10:45:07.432: INFO: (8) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 79.058001ms)
  Dec 19 10:45:07.437: INFO: (8) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 83.879433ms)
  Dec 19 10:45:07.437: INFO: (8) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 84.42037ms)
  Dec 19 10:45:07.437: INFO: (8) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 84.562558ms)
  Dec 19 10:45:07.437: INFO: (8) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 84.169745ms)
  Dec 19 10:45:07.437: INFO: (8) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 84.398898ms)
  Dec 19 10:45:07.437: INFO: (8) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 83.988648ms)
  Dec 19 10:45:07.438: INFO: (8) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 84.174453ms)
  Dec 19 10:45:07.438: INFO: (8) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 84.628385ms)
  Dec 19 10:45:07.438: INFO: (8) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 84.937943ms)
  Dec 19 10:45:07.460: INFO: (9) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 20.652443ms)
  Dec 19 10:45:07.468: INFO: (9) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 29.126487ms)
  Dec 19 10:45:07.469: INFO: (9) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 30.251879ms)
  Dec 19 10:45:07.470: INFO: (9) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 31.016904ms)
  Dec 19 10:45:07.476: INFO: (9) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 37.585998ms)
  Dec 19 10:45:07.481: INFO: (9) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 39.341451ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 52.620928ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 51.764473ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 51.405013ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 51.301444ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 53.700076ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 52.6392ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 52.338884ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 52.135243ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 53.447947ms)
  Dec 19 10:45:07.493: INFO: (9) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 52.707194ms)
  Dec 19 10:45:07.538: INFO: (10) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 44.141338ms)
  Dec 19 10:45:07.544: INFO: (10) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 49.206539ms)
  Dec 19 10:45:07.546: INFO: (10) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 50.272652ms)
  Dec 19 10:45:07.546: INFO: (10) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 51.442418ms)
  Dec 19 10:45:07.546: INFO: (10) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 50.760588ms)
  Dec 19 10:45:07.551: INFO: (10) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 52.888537ms)
  Dec 19 10:45:07.551: INFO: (10) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 52.981641ms)
  Dec 19 10:45:07.552: INFO: (10) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 58.772879ms)
  Dec 19 10:45:07.553: INFO: (10) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 56.897024ms)
  Dec 19 10:45:07.552: INFO: (10) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 53.065594ms)
  Dec 19 10:45:07.564: INFO: (10) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 69.016741ms)
  Dec 19 10:45:07.564: INFO: (10) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 70.860055ms)
  Dec 19 10:45:07.565: INFO: (10) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 70.961718ms)
  Dec 19 10:45:07.585: INFO: (10) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 85.910588ms)
  Dec 19 10:45:07.587: INFO: (10) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 87.496143ms)
  Dec 19 10:45:07.587: INFO: (10) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 91.099396ms)
  Dec 19 10:45:07.626: INFO: (11) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 37.38605ms)
  Dec 19 10:45:07.626: INFO: (11) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 37.050081ms)
  Dec 19 10:45:07.633: INFO: (11) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 45.49783ms)
  Dec 19 10:45:07.633: INFO: (11) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 43.868141ms)
  Dec 19 10:45:07.651: INFO: (11) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 62.866102ms)
  Dec 19 10:45:07.652: INFO: (11) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 63.178547ms)
  Dec 19 10:45:07.656: INFO: (11) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 68.269538ms)
  Dec 19 10:45:07.669: INFO: (11) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 80.489137ms)
  Dec 19 10:45:07.670: INFO: (11) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 81.218918ms)
  Dec 19 10:45:07.670: INFO: (11) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 81.010593ms)
  Dec 19 10:45:07.670: INFO: (11) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 82.957294ms)
  Dec 19 10:45:07.671: INFO: (11) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 82.787071ms)
  Dec 19 10:45:07.673: INFO: (11) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 85.192231ms)
  Dec 19 10:45:07.673: INFO: (11) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 84.418692ms)
  Dec 19 10:45:07.673: INFO: (11) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 85.52072ms)
  Dec 19 10:45:07.674: INFO: (11) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 85.276967ms)
  Dec 19 10:45:07.699: INFO: (12) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 22.927762ms)
  Dec 19 10:45:07.699: INFO: (12) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 24.016769ms)
  Dec 19 10:45:07.718: INFO: (12) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 41.055556ms)
  Dec 19 10:45:07.719: INFO: (12) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 42.491364ms)
  Dec 19 10:45:07.719: INFO: (12) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 43.8468ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 45.138429ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 45.176403ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 44.461769ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 44.485645ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 44.738086ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 44.728114ms)
  Dec 19 10:45:07.721: INFO: (12) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 44.480449ms)
  Dec 19 10:45:07.722: INFO: (12) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 44.724674ms)
  Dec 19 10:45:07.722: INFO: (12) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 46.456864ms)
  Dec 19 10:45:07.722: INFO: (12) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 44.81692ms)
  Dec 19 10:45:07.730: INFO: (12) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 53.140354ms)
  Dec 19 10:45:07.754: INFO: (13) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 22.447663ms)
  Dec 19 10:45:07.755: INFO: (13) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 23.59092ms)
  Dec 19 10:45:07.757: INFO: (13) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 24.978091ms)
  Dec 19 10:45:07.762: INFO: (13) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 30.283546ms)
  Dec 19 10:45:07.764: INFO: (13) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 32.102413ms)
  Dec 19 10:45:07.766: INFO: (13) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 33.539917ms)
  Dec 19 10:45:07.769: INFO: (13) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 37.194485ms)
  Dec 19 10:45:07.771: INFO: (13) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 38.556455ms)
  Dec 19 10:45:07.773: INFO: (13) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 40.612782ms)
  Dec 19 10:45:07.773: INFO: (13) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 41.818502ms)
  Dec 19 10:45:07.781: INFO: (13) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 48.104462ms)
  Dec 19 10:45:07.783: INFO: (13) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 51.291292ms)
  Dec 19 10:45:07.784: INFO: (13) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 50.06265ms)
  Dec 19 10:45:07.785: INFO: (13) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 51.312836ms)
  Dec 19 10:45:07.791: INFO: (13) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 58.742328ms)
  Dec 19 10:45:07.792: INFO: (13) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 59.546732ms)
  Dec 19 10:45:07.819: INFO: (14) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 26.604717ms)
  Dec 19 10:45:07.829: INFO: (14) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 35.542207ms)
  Dec 19 10:45:07.829: INFO: (14) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 36.582455ms)
  Dec 19 10:45:07.832: INFO: (14) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 38.84857ms)
  Dec 19 10:45:07.832: INFO: (14) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 38.775842ms)
  Dec 19 10:45:07.832: INFO: (14) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 39.682425ms)
  Dec 19 10:45:07.839: INFO: (14) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 45.725475ms)
  Dec 19 10:45:07.840: INFO: (14) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 45.494134ms)
  Dec 19 10:45:07.840: INFO: (14) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 47.016763ms)
  Dec 19 10:45:07.840: INFO: (14) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 47.872208ms)
  Dec 19 10:45:07.841: INFO: (14) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 46.822192ms)
  Dec 19 10:45:07.841: INFO: (14) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 46.240004ms)
  Dec 19 10:45:07.841: INFO: (14) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 46.181657ms)
  Dec 19 10:45:07.841: INFO: (14) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 46.434105ms)
  Dec 19 10:45:07.841: INFO: (14) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 46.788417ms)
  Dec 19 10:45:07.842: INFO: (14) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 48.530241ms)
  E1219 10:45:07.842931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:07.854: INFO: (15) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 11.351987ms)
  Dec 19 10:45:07.864: INFO: (15) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 20.622432ms)
  Dec 19 10:45:07.867: INFO: (15) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 23.007422ms)
  Dec 19 10:45:07.867: INFO: (15) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 23.824548ms)
  Dec 19 10:45:07.867: INFO: (15) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 24.262647ms)
  Dec 19 10:45:07.868: INFO: (15) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 25.057413ms)
  Dec 19 10:45:07.868: INFO: (15) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 24.4771ms)
  Dec 19 10:45:07.871: INFO: (15) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 27.580314ms)
  Dec 19 10:45:07.872: INFO: (15) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 28.989527ms)
  Dec 19 10:45:07.872: INFO: (15) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 28.742677ms)
  Dec 19 10:45:07.872: INFO: (15) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 28.124981ms)
  Dec 19 10:45:07.872: INFO: (15) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 28.406542ms)
  Dec 19 10:45:07.872: INFO: (15) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 29.168162ms)
  Dec 19 10:45:07.872: INFO: (15) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 29.177049ms)
  Dec 19 10:45:07.876: INFO: (15) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 32.465483ms)
  Dec 19 10:45:07.877: INFO: (15) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 33.783876ms)
  Dec 19 10:45:07.899: INFO: (16) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 20.243569ms)
  Dec 19 10:45:07.900: INFO: (16) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 21.276255ms)
  Dec 19 10:45:07.900: INFO: (16) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 21.745608ms)
  Dec 19 10:45:07.902: INFO: (16) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 23.399826ms)
  Dec 19 10:45:07.907: INFO: (16) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 29.179795ms)
  Dec 19 10:45:07.908: INFO: (16) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 28.768374ms)
  Dec 19 10:45:07.908: INFO: (16) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 29.092189ms)
  Dec 19 10:45:07.908: INFO: (16) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 29.166329ms)
  Dec 19 10:45:07.909: INFO: (16) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 29.789548ms)
  Dec 19 10:45:07.910: INFO: (16) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 30.66486ms)
  Dec 19 10:45:07.912: INFO: (16) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 33.765433ms)
  Dec 19 10:45:07.914: INFO: (16) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 35.072598ms)
  Dec 19 10:45:07.916: INFO: (16) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 37.507401ms)
  Dec 19 10:45:07.917: INFO: (16) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 38.151973ms)
  Dec 19 10:45:07.918: INFO: (16) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 38.817206ms)
  Dec 19 10:45:07.918: INFO: (16) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 40.181705ms)
  Dec 19 10:45:07.928: INFO: (17) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 9.595414ms)
  Dec 19 10:45:07.931: INFO: (17) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 11.022141ms)
  Dec 19 10:45:07.934: INFO: (17) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 14.778547ms)
  Dec 19 10:45:07.934: INFO: (17) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 14.158672ms)
  Dec 19 10:45:07.946: INFO: (17) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 24.25032ms)
  Dec 19 10:45:07.947: INFO: (17) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 28.813014ms)
  Dec 19 10:45:07.951: INFO: (17) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 32.095886ms)
  Dec 19 10:45:07.954: INFO: (17) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 33.245688ms)
  Dec 19 10:45:07.954: INFO: (17) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 35.670997ms)
  Dec 19 10:45:07.955: INFO: (17) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 35.800397ms)
  Dec 19 10:45:07.955: INFO: (17) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 34.692921ms)
  Dec 19 10:45:07.956: INFO: (17) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 35.408459ms)
  Dec 19 10:45:07.956: INFO: (17) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 36.742906ms)
  Dec 19 10:45:07.957: INFO: (17) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 38.004451ms)
  Dec 19 10:45:07.959: INFO: (17) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 38.154915ms)
  Dec 19 10:45:07.962: INFO: (17) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 40.441625ms)
  Dec 19 10:45:07.981: INFO: (18) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 17.65022ms)
  Dec 19 10:45:07.982: INFO: (18) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 20.125548ms)
  Dec 19 10:45:07.988: INFO: (18) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 25.031249ms)
  Dec 19 10:45:07.988: INFO: (18) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 25.36479ms)
  Dec 19 10:45:07.990: INFO: (18) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 26.61476ms)
  Dec 19 10:45:07.991: INFO: (18) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 27.71909ms)
  Dec 19 10:45:07.991: INFO: (18) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 28.200328ms)
  Dec 19 10:45:07.992: INFO: (18) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 28.480075ms)
  Dec 19 10:45:07.992: INFO: (18) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 29.010325ms)
  Dec 19 10:45:07.992: INFO: (18) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 29.307139ms)
  Dec 19 10:45:07.993: INFO: (18) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 30.54851ms)
  Dec 19 10:45:07.993: INFO: (18) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 30.384712ms)
  Dec 19 10:45:07.994: INFO: (18) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 31.167935ms)
  Dec 19 10:45:08.003: INFO: (18) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 40.036928ms)
  Dec 19 10:45:08.003: INFO: (18) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 40.525252ms)
  Dec 19 10:45:08.007: INFO: (18) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 43.649975ms)
  Dec 19 10:45:08.029: INFO: (19) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 21.536546ms)
  Dec 19 10:45:08.030: INFO: (19) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 22.267015ms)
  Dec 19 10:45:08.034: INFO: (19) /api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/http:proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">... (200; 25.850847ms)
  Dec 19 10:45:08.036: INFO: (19) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:443/proxy/tlsrewritem... (200; 27.593582ms)
  Dec 19 10:45:08.042: INFO: (19) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2/proxy/rewriteme">test</a> (200; 33.704504ms)
  Dec 19 10:45:08.047: INFO: (19) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:462/proxy/: tls qux (200; 38.253472ms)
  Dec 19 10:45:08.047: INFO: (19) /api/v1/namespaces/proxy-7339/pods/https:proxy-service-gdvfw-llrn2:460/proxy/: tls baz (200; 38.449649ms)
  Dec 19 10:45:08.048: INFO: (19) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname1/proxy/: foo (200; 41.213196ms)
  Dec 19 10:45:08.050: INFO: (19) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:162/proxy/: bar (200; 41.437447ms)
  Dec 19 10:45:08.050: INFO: (19) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/: <a href="/api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:1080/proxy/rewriteme">test<... (200; 41.664123ms)
  Dec 19 10:45:08.051: INFO: (19) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname1/proxy/: foo (200; 43.348535ms)
  Dec 19 10:45:08.052: INFO: (19) /api/v1/namespaces/proxy-7339/services/proxy-service-gdvfw:portname2/proxy/: bar (200; 42.989526ms)
  Dec 19 10:45:08.053: INFO: (19) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname2/proxy/: tls qux (200; 44.633561ms)
  Dec 19 10:45:08.064: INFO: (19) /api/v1/namespaces/proxy-7339/pods/proxy-service-gdvfw-llrn2:160/proxy/: foo (200; 55.525822ms)
  Dec 19 10:45:08.067: INFO: (19) /api/v1/namespaces/proxy-7339/services/http:proxy-service-gdvfw:portname2/proxy/: bar (200; 57.862176ms)
  Dec 19 10:45:08.070: INFO: (19) /api/v1/namespaces/proxy-7339/services/https:proxy-service-gdvfw:tlsportname1/proxy/: tls baz (200; 60.962556ms)
  STEP: deleting ReplicationController proxy-service-gdvfw in namespace proxy-7339, will wait for the garbage collector to delete the pods @ 12/19/23 10:45:08.07
  Dec 19 10:45:08.142: INFO: Deleting ReplicationController proxy-service-gdvfw took: 13.666774ms
  Dec 19 10:45:08.243: INFO: Terminating ReplicationController proxy-service-gdvfw pods took: 101.061213ms
  E1219 10:45:08.843062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:09.843903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:09.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7339" for this suite. @ 12/19/23 10:45:09.967
• [5.266 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 12/19/23 10:45:09.99
  Dec 19 10:45:09.990: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:45:09.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:10.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:10.051
  STEP: Creating a pod to test substitution in container's command @ 12/19/23 10:45:10.061
  E1219 10:45:10.844255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:11.845793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:12.846101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:13.847152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:45:14.124
  Dec 19 10:45:14.134: INFO: Trying to get logs from node uikie9pei4sh-3 pod var-expansion-3a0e5ffb-8046-429b-852e-6fff706bbc37 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:45:14.153
  Dec 19 10:45:14.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8494" for this suite. @ 12/19/23 10:45:14.205
• [4.237 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 12/19/23 10:45:14.23
  Dec 19 10:45:14.231: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:45:14.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:14.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:14.295
  STEP: Creating a ResourceQuota with best effort scope @ 12/19/23 10:45:14.315
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 10:45:14.339
  E1219 10:45:14.848649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:15.849121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 12/19/23 10:45:16.348
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 10:45:16.361
  E1219 10:45:16.849689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:17.849920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 12/19/23 10:45:18.374
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 12/19/23 10:45:18.447
  E1219 10:45:18.850912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:19.851317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 12/19/23 10:45:20.454
  E1219 10:45:20.851110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:21.851467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 10:45:22.463
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 10:45:22.503
  E1219 10:45:22.852233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:23.852834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 12/19/23 10:45:24.512
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 12/19/23 10:45:24.538
  E1219 10:45:24.853093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:25.853838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 12/19/23 10:45:26.551
  E1219 10:45:26.853582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:27.856530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 10:45:28.573
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 10:45:28.607
  E1219 10:45:28.855822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:29.856037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:30.616: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6427" for this suite. @ 12/19/23 10:45:30.629
• [16.413 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 12/19/23 10:45:30.65
  Dec 19 10:45:30.650: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:45:30.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:30.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:30.697
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 12/19/23 10:45:30.705
  E1219 10:45:30.862684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:31.863349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:32.863307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:33.863591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:45:34.763
  Dec 19 10:45:34.770: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-1d15df80-589a-425b-95d1-b661b1b7c2aa container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:45:34.799
  Dec 19 10:45:34.839: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9780" for this suite. @ 12/19/23 10:45:34.85
  E1219 10:45:34.864113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.216 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 12/19/23 10:45:34.867
  Dec 19 10:45:34.867: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 10:45:34.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:34.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:34.931
  STEP: create the container @ 12/19/23 10:45:34.941
  W1219 10:45:34.960922      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/19/23 10:45:34.961
  E1219 10:45:35.864387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:36.864469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:37.864974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:38.865590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/19/23 10:45:39.019
  STEP: the container should be terminated @ 12/19/23 10:45:39.025
  STEP: the termination message should be set @ 12/19/23 10:45:39.026
  Dec 19 10:45:39.026: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 12/19/23 10:45:39.026
  Dec 19 10:45:39.071: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1218" for this suite. @ 12/19/23 10:45:39.084
• [4.237 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 12/19/23 10:45:39.107
  Dec 19 10:45:39.108: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 10:45:39.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:45:39.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:45:39.18
  STEP: Creating pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541 @ 12/19/23 10:45:39.189
  E1219 10:45:39.866486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:40.866543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 10:45:41.225
  Dec 19 10:45:41.232: INFO: Initial restart count of pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 is 0
  Dec 19 10:45:41.238: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:41.867100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:42.867886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:43.252: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:43.868809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:44.869694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:45.261: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:45.869884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:46.870700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:47.269: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:47.870986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:48.872051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:49.281: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:49.871970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:50.872507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:51.293: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:51.873545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:52.874002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:53.303: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:53.874771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:54.875443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:55.318: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:55.875710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:56.876292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:57.336: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:57.876883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:58.877738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:45:59.351: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:45:59.878913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:00.880243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:01.360: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:01.879847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:02.880325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:03.369: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:03.880910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:04.881721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:05.380: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:05.882339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:06.882496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:07.390: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:07.882383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:08.883320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:09.400: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:09.883160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:10.883621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:11.412: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:11.884224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:12.884982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:13.422: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:13.885039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:14.886054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:15.435: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:15.887276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:16.887109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:17.442: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:17.887480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:18.887727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:19.456: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:19.888533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:20.888866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:21.470: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:21.889441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:22.889867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:23.482: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:23.890608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:24.890969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:25.494: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:25.891705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:26.892656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:27.504: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:27.892204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:28.893212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:29.519: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:29.893374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:30.894171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:31.538: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:31.895305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:32.895851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:33.549: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:33.896489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:34.897210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:35.566: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:35.897440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:36.897821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:37.577: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:37.897941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:38.899032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:39.602: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:39.899064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:40.899200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:41.610: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:41.899987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:42.900087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:43.619: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:43.901090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:44.903432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:45.626: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:45.903381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:46.903662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:47.635: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:47.904220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:48.904471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:49.644: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:49.904469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:50.904937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:51.654: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:51.905751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:52.906235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:53.664: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:53.907699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:54.909150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:55.677: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:55.908018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:56.908389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:57.687: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:57.909386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:58.910456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:59.697: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:46:59.911471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:00.911841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:01.707: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:01.913140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:02.913369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:03.719: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:03.914235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:04.914559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:05.730: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:05.915507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:06.915446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:07.739: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:07.916314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:08.916736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:09.749: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:09.917652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:10.918058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:11.761: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:11.918555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:12.918887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:13.771: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:13.919722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:14.920072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:15.781: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:15.921499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:16.921218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:17.790: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:17.921636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:18.921852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:19.802: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:19.922915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:20.923521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:21.812: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:21.923789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:22.924978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:23.824: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:23.925645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:24.925888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:25.833: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:25.926157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:26.926401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:27.843: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:27.926421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:28.927183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:29.853: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:29.928254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:30.928333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:31.861: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:31.928728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:32.930570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:33.872: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:33.931086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:34.932461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:35.882: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:35.934086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:36.933041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:37.893: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:37.933919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:38.934217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:39.902: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:39.936372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:40.936735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:41.912: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:41.936795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:42.937079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:43.923: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:43.937215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:44.938131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:45.933: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:45.939096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:46.939664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:47.940391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:47.945: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:48.940908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:49.941724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:49.958: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:50.941979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:51.942869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:51.969: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:52.943236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:53.943773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:53.982: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:54.944398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:55.944372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:55.998: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:56.945428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:57.946305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:58.009: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:47:58.946698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:59.947331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:00.019: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:00.947250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:01.947856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:02.038: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:02.948007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:03.948930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:04.047: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:04.949539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:05.950362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:06.058: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:06.950844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:07.951578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:08.071: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:08.954089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:09.952072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:10.083: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:10.952627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:11.953622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:12.100: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:12.953262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:13.953993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:14.108: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:14.954238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:15.955101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:16.120: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:16.955708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:17.955743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:18.132: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:18.956871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:19.957385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:20.145: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:20.957579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:21.957914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:22.161: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:22.958204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:23.958885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:24.176: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:24.959131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:25.960233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:26.186: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:26.961761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:27.960935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:28.195: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:28.962529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:29.965512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:30.206: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:30.963581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:31.963868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:32.216: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:32.964223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:33.964435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:34.226: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:34.964784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:35.965577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:36.235: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:36.965803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:37.966647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:38.243: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:38.967588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:39.968298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:40.254: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:40.968874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:41.969097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:42.262: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:42.969770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:43.969710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:44.272: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:44.969948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:45.970154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:46.284: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:46.970498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:47.970517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:48.294: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:48.971654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:49.971733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:50.314: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:50.972822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:51.973704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:52.325: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:52.973948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:53.975397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:54.336: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:54.974978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:55.975167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:56.344: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:56.976248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:57.976609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:58.360: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:48:58.977361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:59.978070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:00.373: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:00.978589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:01.979232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:02.398: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:02.979264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:03.980091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:04.408: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:04.981057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:05.981508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:06.418: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:06.981878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:07.982053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:08.428: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:08.983248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:09.984013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:10.445: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:10.984198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:11.985118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:12.457: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:12.985875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:13.986027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:14.465: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:14.986194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:15.986586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:16.475: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:16.986566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:17.990486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:18.483: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:18.987864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:19.988117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:20.500: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:20.988371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:21.988441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:22.506: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:22.989076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:23.989969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:24.516: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:24.990286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:25.990572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:26.530: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:26.991464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:27.991753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:28.540: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:28.993019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:29.993856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:30.551: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:30.993554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:31.993797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:32.566: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:32.994588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:33.994631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:34.576: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:34.995623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:35.996143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:36.585: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:36.996541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:37.997089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:38.597: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:38.997226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:39.998425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:40.607: INFO: Get pod test-webserver-811aec05-6a92-4cbb-85fc-c409c288ce85 in namespace container-probe-9541
  E1219 10:49:40.999132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:41.999467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 12/19/23 10:49:42.608
  Dec 19 10:49:42.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9541" for this suite. @ 12/19/23 10:49:42.69
• [243.596 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 12/19/23 10:49:42.706
  Dec 19 10:49:42.706: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:49:42.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:42.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:42.779
  STEP: create the deployment @ 12/19/23 10:49:42.784
  W1219 10:49:42.796511      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/19/23 10:49:42.796
  E1219 10:49:43.003223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 12/19/23 10:49:43.316
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 12/19/23 10:49:43.335
  STEP: Gathering metrics @ 12/19/23 10:49:43.87
  E1219 10:49:44.002346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:44.161: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:49:44.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5394" for this suite. @ 12/19/23 10:49:44.184
• [1.494 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 12/19/23 10:49:44.201
  Dec 19 10:49:44.202: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:49:44.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:44.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:44.253
  Dec 19 10:49:44.260: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Dec 19 10:49:44.287: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1219 10:49:45.002848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:46.003927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:47.004132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:48.004531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:49.005476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:49.297: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 10:49:49.297
  Dec 19 10:49:49.297: INFO: Creating deployment "test-rolling-update-deployment"
  Dec 19 10:49:49.314: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Dec 19 10:49:49.332: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E1219 10:49:50.006370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:51.006995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:51.361: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Dec 19 10:49:51.378: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Dec 19 10:49:51.428: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6024",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ba2879e5-6d63-44ee-85ea-29e88d89f7d8",
      ResourceVersion: (string) (len=5) "17371",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579789,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=82) "ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 10:49:51.470: INFO: New ReplicaSet "test-rolling-update-deployment-7f5c55c64" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6024",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2fdce728-a387-4d93-9bb7-03f63fff0bfe",
      ResourceVersion: (string) (len=5) "17361",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579789,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "ba2879e5-6d63-44ee-85ea-29e88d89f7d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 61 32 38 37 39  65 35 2d 36 64 36 33 2d  |\"ba2879e5-6d63-|
              00000120  34 34 65 65 2d 38 35 65  61 2d 32 39 65 38 38 64  |44ee-85ea-29e88d|
              00000130  38 39 66 37 64 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |89f7d8\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:49:51.486: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Dec 19 10:49:51.487: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6024",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0940dec4-6eab-4a16-b3d3-ea15e7ee682c",
      ResourceVersion: (string) (len=5) "17370",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579784,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "ba2879e5-6d63-44ee-85ea-29e88d89f7d8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579784,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 62 61 32 38 37 39 65  |"uid\":\"ba2879e|
              000000b0  35 2d 36 64 36 33 2d 34  34 65 65 2d 38 35 65 61  |5-6d63-44ee-85ea|
              000000c0  2d 32 39 65 38 38 64 38  39 66 37 64 38 5c 22 7d  |-29e88d89f7d8\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:49:51.515: INFO: Pod "test-rolling-update-deployment-7f5c55c64-6h5xl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=46) "test-rolling-update-deployment-7f5c55c64-6h5xl",
      GenerateName: (string) (len=41) "test-rolling-update-deployment-7f5c55c64-",
      Namespace: (string) (len=15) "deployment-6024",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "02d5ab30-a663-4726-8b55-f8aa9ed09e81",
      ResourceVersion: (string) (len=5) "17360",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579789,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
          UID: (types.UID) (len=36) "2fdce728-a387-4d93-9bb7-03f63fff0bfe",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 66  64 63 65 37 32 38 2d 61  |d\":\"2fdce728-a|
              00000090  33 38 37 2d 34 64 39 33  2d 39 62 62 37 2d 30 33  |387-4d93-9bb7-03|
              000000a0  66 36 33 66 66 66 30 62  66 65 5c 22 7d 22 3a 7b  |f63fff0bfe\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 36 34 5c 22 7d 22 3a  |.233.66.164\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8t5lq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8t5lq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579791,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579789,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=13) "10.233.66.164",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.164"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579789,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579790,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=64) "077cda6b1f5995dcc056c00f92d40b5147132839f522d46d9ca84acd44ad76a7",
          ContainerID: (string) (len=72) "cri-o://e3afa4ef7eaaf6c57d230ca492317f58927e2d3a63231fd7293db77669cc6bb6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:49:51.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6024" for this suite. @ 12/19/23 10:49:51.555
• [7.370 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 12/19/23 10:49:51.574
  Dec 19 10:49:51.575: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 10:49:51.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:51.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:51.676
  E1219 10:49:52.007816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:53.008664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:54.008391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:55.009453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:55.768: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6114" for this suite. @ 12/19/23 10:49:55.78
• [4.222 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 12/19/23 10:49:55.8
  Dec 19 10:49:55.800: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:49:55.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:55.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:55.845
  STEP: create the rc @ 12/19/23 10:49:55.853
  W1219 10:49:55.869619      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1219 10:49:56.010150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:57.014925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:58.011738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:59.012137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:00.012429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/19/23 10:50:00.883
  STEP: wait for all pods to be garbage collected @ 12/19/23 10:50:00.898
  E1219 10:50:01.013310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:02.013592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:03.013920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:04.014100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:05.014401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 10:50:05.918
  E1219 10:50:06.015068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:06.162: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:50:06.162: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7763" for this suite. @ 12/19/23 10:50:06.177
• [10.392 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 12/19/23 10:50:06.194
  Dec 19 10:50:06.194: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:50:06.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:06.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:06.243
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/19/23 10:50:06.256
  E1219 10:50:07.015355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:08.016220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:09.016905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:10.017157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:50:10.315
  Dec 19 10:50:10.325: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-a31febbf-cafd-4de3-8dbf-3ca204d7fd3e container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:50:10.379
  Dec 19 10:50:10.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7721" for this suite. @ 12/19/23 10:50:10.448
• [4.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 12/19/23 10:50:10.476
  Dec 19 10:50:10.476: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:50:10.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:10.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:10.531
  STEP: creating the pod @ 12/19/23 10:50:10.538
  STEP: waiting for pod running @ 12/19/23 10:50:10.56
  E1219 10:50:11.017226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:12.018099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 12/19/23 10:50:12.58
  Dec 19 10:50:12.589: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-1260 PodName:var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:50:12.589: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:50:12.592: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:50:12.592: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-1260/pods/var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 12/19/23 10:50:12.761
  Dec 19 10:50:12.769: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-1260 PodName:var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:50:12.769: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:50:12.771: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:50:12.771: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-1260/pods/var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 12/19/23 10:50:12.895
  E1219 10:50:13.019651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:13.424: INFO: Successfully updated pod "var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876"
  STEP: waiting for annotated pod running @ 12/19/23 10:50:13.425
  STEP: deleting the pod gracefully @ 12/19/23 10:50:13.432
  Dec 19 10:50:13.432: INFO: Deleting pod "var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876" in namespace "var-expansion-1260"
  Dec 19 10:50:13.447: INFO: Wait up to 5m0s for pod "var-expansion-fbbb01ec-a347-44b7-922a-0a1b3a0ef876" to be fully deleted
  E1219 10:50:14.019986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:15.020833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:16.021278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:17.021587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:18.022624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:19.022955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:20.023370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:21.023493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:22.024475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:23.024500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:24.027211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:25.027117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:26.027264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:27.027624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:28.027969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:29.027751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:30.028030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:31.038164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:32.037683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:33.038623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:34.039934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:35.040187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:36.040670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:37.041311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:38.042607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:39.042980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:40.043491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:41.044562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:42.044927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:43.045353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:44.045744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:45.045983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:46.046296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:47.046488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:47.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1260" for this suite. @ 12/19/23 10:50:47.672
• [37.221 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 12/19/23 10:50:47.701
  Dec 19 10:50:47.701: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:50:47.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:47.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:47.762
  STEP: Creating service test in namespace statefulset-5494 @ 12/19/23 10:50:47.768
  STEP: Creating statefulset ss in namespace statefulset-5494 @ 12/19/23 10:50:47.795
  Dec 19 10:50:47.836: INFO: Found 0 stateful pods, waiting for 1
  E1219 10:50:48.047740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:49.048398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:50.049084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:51.049101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:52.050150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:53.050861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:54.051496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:55.051709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:56.052850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:57.052858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:57.839: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 12/19/23 10:50:57.858
  STEP: Getting /status @ 12/19/23 10:50:57.893
  Dec 19 10:50:57.911: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 12/19/23 10:50:57.911
  Dec 19 10:50:57.937: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 12/19/23 10:50:57.937
  Dec 19 10:50:57.942: INFO: Observed &StatefulSet event: ADDED
  Dec 19 10:50:57.943: INFO: Found Statefulset ss in namespace statefulset-5494 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:50:57.944: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 12/19/23 10:50:57.944
  Dec 19 10:50:57.945: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec 19 10:50:57.967: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 12/19/23 10:50:57.968
  Dec 19 10:50:57.972: INFO: Observed &StatefulSet event: ADDED
  Dec 19 10:50:57.973: INFO: Observed Statefulset ss in namespace statefulset-5494 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:50:57.973: INFO: Observed &StatefulSet event: MODIFIED
  Dec 19 10:50:57.974: INFO: Deleting all statefulset in ns statefulset-5494
  Dec 19 10:50:57.981: INFO: Scaling statefulset ss to 0
  E1219 10:50:58.054014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:59.055073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:00.055942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:01.056100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:02.056361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:03.056540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:04.057220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:05.057528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:06.058210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:07.058616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:08.016: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 10:51:08.021: INFO: Deleting statefulset ss
  Dec 19 10:51:08.051: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:51:08.059686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "statefulset-5494" for this suite. @ 12/19/23 10:51:08.061
• [20.378 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 12/19/23 10:51:08.08
  Dec 19 10:51:08.080: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:51:08.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:08.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:08.126
  STEP: creating pod @ 12/19/23 10:51:08.133
  E1219 10:51:09.060857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:10.061234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:10.185: INFO: Pod pod-hostip-4819653e-0fb3-4232-b827-12f541610337 has hostIP: 192.168.121.201
  Dec 19 10:51:10.186: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8064" for this suite. @ 12/19/23 10:51:10.194
• [2.133 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 12/19/23 10:51:10.217
  Dec 19 10:51:10.217: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:51:10.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:10.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:10.305
  Dec 19 10:51:10.313: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: creating the pod @ 12/19/23 10:51:10.317
  STEP: submitting the pod to kubernetes @ 12/19/23 10:51:10.318
  E1219 10:51:11.061729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:12.062828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:12.471: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2458" for this suite. @ 12/19/23 10:51:12.483
• [2.283 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 12/19/23 10:51:12.506
  Dec 19 10:51:12.507: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:51:12.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:12.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:12.568
  STEP: create the deployment @ 12/19/23 10:51:12.581
  W1219 10:51:12.603710      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/19/23 10:51:12.604
  E1219 10:51:13.062946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 12/19/23 10:51:13.16
  STEP: wait for all rs to be garbage collected @ 12/19/23 10:51:13.2
  STEP: expected 0 pods, got 2 pods @ 12/19/23 10:51:13.238
  STEP: expected 0 rs, got 1 rs @ 12/19/23 10:51:13.272
  STEP: Gathering metrics @ 12/19/23 10:51:13.735
  Dec 19 10:51:14.061: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:51:14.062: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:51:14.063243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "gc-1142" for this suite. @ 12/19/23 10:51:14.076
• [1.588 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 12/19/23 10:51:14.095
  Dec 19 10:51:14.095: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename discovery @ 12/19/23 10:51:14.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:14.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:14.142
  STEP: Setting up server cert @ 12/19/23 10:51:14.149
  Dec 19 10:51:14.751: INFO: Checking APIGroup: apiregistration.k8s.io
  Dec 19 10:51:14.753: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Dec 19 10:51:14.753: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Dec 19 10:51:14.753: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Dec 19 10:51:14.753: INFO: Checking APIGroup: apps
  Dec 19 10:51:14.755: INFO: PreferredVersion.GroupVersion: apps/v1
  Dec 19 10:51:14.755: INFO: Versions found [{apps/v1 v1}]
  Dec 19 10:51:14.755: INFO: apps/v1 matches apps/v1
  Dec 19 10:51:14.755: INFO: Checking APIGroup: events.k8s.io
  Dec 19 10:51:14.758: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Dec 19 10:51:14.758: INFO: Versions found [{events.k8s.io/v1 v1}]
  Dec 19 10:51:14.758: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Dec 19 10:51:14.758: INFO: Checking APIGroup: authentication.k8s.io
  Dec 19 10:51:14.760: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Dec 19 10:51:14.760: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Dec 19 10:51:14.760: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Dec 19 10:51:14.760: INFO: Checking APIGroup: authorization.k8s.io
  Dec 19 10:51:14.762: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Dec 19 10:51:14.762: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Dec 19 10:51:14.762: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Dec 19 10:51:14.762: INFO: Checking APIGroup: autoscaling
  Dec 19 10:51:14.764: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Dec 19 10:51:14.764: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Dec 19 10:51:14.764: INFO: autoscaling/v2 matches autoscaling/v2
  Dec 19 10:51:14.764: INFO: Checking APIGroup: batch
  Dec 19 10:51:14.766: INFO: PreferredVersion.GroupVersion: batch/v1
  Dec 19 10:51:14.766: INFO: Versions found [{batch/v1 v1}]
  Dec 19 10:51:14.766: INFO: batch/v1 matches batch/v1
  Dec 19 10:51:14.766: INFO: Checking APIGroup: certificates.k8s.io
  Dec 19 10:51:14.768: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Dec 19 10:51:14.768: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Dec 19 10:51:14.768: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Dec 19 10:51:14.768: INFO: Checking APIGroup: networking.k8s.io
  Dec 19 10:51:14.770: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Dec 19 10:51:14.770: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Dec 19 10:51:14.770: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Dec 19 10:51:14.770: INFO: Checking APIGroup: policy
  Dec 19 10:51:14.773: INFO: PreferredVersion.GroupVersion: policy/v1
  Dec 19 10:51:14.773: INFO: Versions found [{policy/v1 v1}]
  Dec 19 10:51:14.773: INFO: policy/v1 matches policy/v1
  Dec 19 10:51:14.773: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Dec 19 10:51:14.776: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Dec 19 10:51:14.776: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Dec 19 10:51:14.776: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Dec 19 10:51:14.776: INFO: Checking APIGroup: storage.k8s.io
  Dec 19 10:51:14.778: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Dec 19 10:51:14.778: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Dec 19 10:51:14.778: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Dec 19 10:51:14.778: INFO: Checking APIGroup: admissionregistration.k8s.io
  Dec 19 10:51:14.780: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Dec 19 10:51:14.780: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Dec 19 10:51:14.780: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Dec 19 10:51:14.780: INFO: Checking APIGroup: apiextensions.k8s.io
  Dec 19 10:51:14.782: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Dec 19 10:51:14.782: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Dec 19 10:51:14.782: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Dec 19 10:51:14.783: INFO: Checking APIGroup: scheduling.k8s.io
  Dec 19 10:51:14.785: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Dec 19 10:51:14.785: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Dec 19 10:51:14.785: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Dec 19 10:51:14.785: INFO: Checking APIGroup: coordination.k8s.io
  Dec 19 10:51:14.787: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Dec 19 10:51:14.787: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Dec 19 10:51:14.788: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Dec 19 10:51:14.788: INFO: Checking APIGroup: node.k8s.io
  Dec 19 10:51:14.791: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Dec 19 10:51:14.791: INFO: Versions found [{node.k8s.io/v1 v1}]
  Dec 19 10:51:14.791: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Dec 19 10:51:14.792: INFO: Checking APIGroup: discovery.k8s.io
  Dec 19 10:51:14.794: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Dec 19 10:51:14.794: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Dec 19 10:51:14.794: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Dec 19 10:51:14.794: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Dec 19 10:51:14.795: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  Dec 19 10:51:14.796: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  Dec 19 10:51:14.796: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  Dec 19 10:51:14.797: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-427" for this suite. @ 12/19/23 10:51:14.812
• [0.731 seconds]
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 12/19/23 10:51:14.827
  Dec 19 10:51:14.827: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:51:14.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:14.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:14.879
  STEP: Creating secret with name secret-test-51496149-e8e3-4cfb-90b3-f248497dc012 @ 12/19/23 10:51:14.889
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:51:14.901
  E1219 10:51:15.067480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:16.068489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:17.069297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:18.069596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:51:18.968
  Dec 19 10:51:18.976: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-fe0dd6bf-42b1-4ca1-91a6-e84202ba0125 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:51:19.006
  Dec 19 10:51:19.060: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:51:19.070597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "secrets-9439" for this suite. @ 12/19/23 10:51:19.081
• [4.266 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 12/19/23 10:51:19.097
  Dec 19 10:51:19.097: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sysctl @ 12/19/23 10:51:19.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:19.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:19.149
  STEP: Creating a pod with one valid and two invalid sysctls @ 12/19/23 10:51:19.165
  Dec 19 10:51:19.185: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7246" for this suite. @ 12/19/23 10:51:19.197
• [0.114 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 12/19/23 10:51:19.214
  Dec 19 10:51:19.215: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:51:19.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:19.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:19.285
  STEP: creating a Deployment @ 12/19/23 10:51:19.302
  STEP: waiting for Deployment to be created @ 12/19/23 10:51:19.315
  STEP: waiting for all Replicas to be Ready @ 12/19/23 10:51:19.318
  Dec 19 10:51:19.321: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.321: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.345: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.345: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.398: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.399: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.492: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:51:19.493: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E1219 10:51:20.070800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:20.529: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec 19 10:51:20.530: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec 19 10:51:20.677: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 12/19/23 10:51:20.678
  Dec 19 10:51:20.707: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 12/19/23 10:51:20.708
  Dec 19 10:51:20.712: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.712: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.713: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.714: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.714: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.715: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.715: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.715: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 0
  Dec 19 10:51:20.717: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:20.717: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:20.717: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.717: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.718: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.718: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.733: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.733: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.793: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.794: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:20.843: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:20.843: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:20.873: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:20.874: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  E1219 10:51:21.070873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:21.712: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:21.713: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:21.812: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  STEP: listing Deployments @ 12/19/23 10:51:21.812
  Dec 19 10:51:21.834: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 12/19/23 10:51:21.835
  Dec 19 10:51:21.877: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 12/19/23 10:51:21.877
  Dec 19 10:51:21.914: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:51:21.923: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:51:22.036: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E1219 10:51:22.071382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:22.115: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:51:22.163: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E1219 10:51:23.071449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:23.729: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:51:23.818: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:51:23.909: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:51:23.994: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E1219 10:51:24.071679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:25.072139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:25.638: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 12/19/23 10:51:25.756
  STEP: fetching the DeploymentStatus @ 12/19/23 10:51:25.776
  Dec 19 10:51:25.789: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:25.790: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:25.790: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:25.790: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:25.790: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 1
  Dec 19 10:51:25.791: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:25.792: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 3
  Dec 19 10:51:25.792: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:25.793: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 2
  Dec 19 10:51:25.793: INFO: observed Deployment test-deployment in namespace deployment-8819 with ReadyReplicas 3
  STEP: deleting the Deployment @ 12/19/23 10:51:25.794
  Dec 19 10:51:25.835: INFO: observed event type MODIFIED
  Dec 19 10:51:25.836: INFO: observed event type MODIFIED
  Dec 19 10:51:25.836: INFO: observed event type MODIFIED
  Dec 19 10:51:25.836: INFO: observed event type MODIFIED
  Dec 19 10:51:25.837: INFO: observed event type MODIFIED
  Dec 19 10:51:25.837: INFO: observed event type MODIFIED
  Dec 19 10:51:25.837: INFO: observed event type MODIFIED
  Dec 19 10:51:25.837: INFO: observed event type MODIFIED
  Dec 19 10:51:25.837: INFO: observed event type MODIFIED
  Dec 19 10:51:25.838: INFO: observed event type MODIFIED
  Dec 19 10:51:25.838: INFO: observed event type MODIFIED
  Dec 19 10:51:25.838: INFO: observed event type MODIFIED
  Dec 19 10:51:25.838: INFO: observed event type MODIFIED
  Dec 19 10:51:25.859: INFO: Log out all the ReplicaSets if there is no deployment created
  Dec 19 10:51:25.878: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8819" for this suite. @ 12/19/23 10:51:25.902
• [6.740 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 12/19/23 10:51:25.958
  Dec 19 10:51:25.959: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename watch @ 12/19/23 10:51:25.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:26.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:26.03
  STEP: creating a watch on configmaps @ 12/19/23 10:51:26.041
  STEP: creating a new configmap @ 12/19/23 10:51:26.046
  STEP: modifying the configmap once @ 12/19/23 10:51:26.064
  E1219 10:51:26.071908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: closing the watch once it receives two notifications @ 12/19/23 10:51:26.081
  Dec 19 10:51:26.081: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1072  5f1b6aad-0b74-43bf-bf36-367a4a6ef0dd 18048 0 2023-12-19 10:51:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 10:51:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 10:51:26.081: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1072  5f1b6aad-0b74-43bf-bf36-367a4a6ef0dd 18049 0 2023-12-19 10:51:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 10:51:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 12/19/23 10:51:26.082
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 12/19/23 10:51:26.114
  STEP: deleting the configmap @ 12/19/23 10:51:26.118
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 12/19/23 10:51:26.145
  Dec 19 10:51:26.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1072  5f1b6aad-0b74-43bf-bf36-367a4a6ef0dd 18050 0 2023-12-19 10:51:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 10:51:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 10:51:26.146: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1072  5f1b6aad-0b74-43bf-bf36-367a4a6ef0dd 18051 0 2023-12-19 10:51:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 10:51:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 10:51:26.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1072" for this suite. @ 12/19/23 10:51:26.16
• [0.219 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 12/19/23 10:51:26.178
  Dec 19 10:51:26.178: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:51:26.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:26.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:26.221
  STEP: creating service nodeport-test with type=NodePort in namespace services-2232 @ 12/19/23 10:51:26.227
  STEP: creating replication controller nodeport-test in namespace services-2232 @ 12/19/23 10:51:26.288
  I1219 10:51:26.316092      13 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-2232, replica count: 2
  E1219 10:51:27.073217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:28.074097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:29.075174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:51:29.368169      13 runners.go:197] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1219 10:51:30.075935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:31.076546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:32.079955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:51:32.369132      13 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:51:32.370: INFO: Creating new exec pod
  E1219 10:51:33.080587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:34.081226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:35.081575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:35.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-2232 exec execpod5kx67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Dec 19 10:51:35.850: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Dec 19 10:51:35.850: INFO: stdout: "nodeport-test-mvv4w"
  Dec 19 10:51:35.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-2232 exec execpod5kx67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.15.8 80'
  E1219 10:51:36.082252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:36.146: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.15.8 80\nConnection to 10.233.15.8 80 port [tcp/http] succeeded!\n"
  Dec 19 10:51:36.146: INFO: stdout: "nodeport-test-mvv4w"
  Dec 19 10:51:36.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-2232 exec execpod5kx67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.77 31231'
  Dec 19 10:51:36.462: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.77 31231\nConnection to 192.168.121.77 31231 port [tcp/*] succeeded!\n"
  Dec 19 10:51:36.462: INFO: stdout: "nodeport-test-mvv4w"
  Dec 19 10:51:36.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-2232 exec execpod5kx67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 31231'
  Dec 19 10:51:36.753: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.241 31231\nConnection to 192.168.121.241 31231 port [tcp/*] succeeded!\n"
  Dec 19 10:51:36.753: INFO: stdout: "nodeport-test-mvv4w"
  Dec 19 10:51:36.754: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2232" for this suite. @ 12/19/23 10:51:36.764
• [10.599 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 12/19/23 10:51:36.778
  Dec 19 10:51:36.778: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename events @ 12/19/23 10:51:36.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:36.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:36.835
  STEP: creating a test event @ 12/19/23 10:51:36.841
  STEP: listing events in all namespaces @ 12/19/23 10:51:36.861
  STEP: listing events in test namespace @ 12/19/23 10:51:36.887
  STEP: listing events with field selection filtering on source @ 12/19/23 10:51:36.894
  STEP: listing events with field selection filtering on reportingController @ 12/19/23 10:51:36.903
  STEP: getting the test event @ 12/19/23 10:51:36.911
  STEP: patching the test event @ 12/19/23 10:51:36.922
  STEP: getting the test event @ 12/19/23 10:51:36.949
  STEP: updating the test event @ 12/19/23 10:51:36.957
  STEP: getting the test event @ 12/19/23 10:51:36.973
  STEP: deleting the test event @ 12/19/23 10:51:36.982
  STEP: listing events in all namespaces @ 12/19/23 10:51:37.004
  STEP: listing events in test namespace @ 12/19/23 10:51:37.031
  Dec 19 10:51:37.044: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8409" for this suite. @ 12/19/23 10:51:37.055
• [0.296 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 12/19/23 10:51:37.076
  Dec 19 10:51:37.076: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:51:37.08
  E1219 10:51:37.082256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:37.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:37.122
  STEP: Creating a pod to test downward api env vars @ 12/19/23 10:51:37.129
  E1219 10:51:38.083209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:39.085702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:40.087230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:41.086478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:51:41.189
  Dec 19 10:51:41.198: INFO: Trying to get logs from node uikie9pei4sh-3 pod downward-api-c3bfe69a-65ea-4a63-b65d-bf06fee56df8 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:51:41.219
  Dec 19 10:51:41.271: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5222" for this suite. @ 12/19/23 10:51:41.288
• [4.231 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 12/19/23 10:51:41.311
  Dec 19 10:51:41.311: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 10:51:41.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:41.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:41.356
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 10:51:41.371
  E1219 10:51:42.087515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:43.087760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 10:51:43.414
  E1219 10:51:44.088689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:45.089409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 12/19/23 10:51:45.451
  E1219 10:51:46.089131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:47.089858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 12/19/23 10:51:47.486
  Dec 19 10:51:47.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4360" for this suite. @ 12/19/23 10:51:47.51
• [6.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 12/19/23 10:51:47.54
  Dec 19 10:51:47.540: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 10:51:47.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:47.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:47.688
  E1219 10:51:48.090993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:49.090864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:50.091251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:51.091752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:52.092451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 12/19/23 10:51:52.89
  E1219 10:51:53.093376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:54.093575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:55.094030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:56.094103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:57.094418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 12/19/23 10:51:57.91
  E1219 10:51:58.095416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:59.096658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:00.097218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:01.097216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:02.097533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 12/19/23 10:52:02.941
  E1219 10:52:03.097720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:04.098576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:05.098974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:06.100715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:07.100151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 12/19/23 10:52:07.962
  Dec 19 10:52:08.019: INFO: EndpointSlice for Service endpointslice-9609/example-named-port not found
  E1219 10:52:08.100795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:09.101245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:10.102277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:11.103382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:12.103630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:13.103814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:14.103724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:15.104497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:16.105242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:17.105525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:18.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9609" for this suite. @ 12/19/23 10:52:18.034
• [30.508 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 12/19/23 10:52:18.053
  Dec 19 10:52:18.054: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:52:18.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:18.107
  E1219 10:52:18.107559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:18.114
  Dec 19 10:52:18.120: INFO: Creating deployment "webserver-deployment"
  Dec 19 10:52:18.131: INFO: Waiting for observed generation 1
  E1219 10:52:19.108116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:20.108417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:20.149: INFO: Waiting for all required pods to come up
  Dec 19 10:52:20.169: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 12/19/23 10:52:20.169
  E1219 10:52:21.109251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:22.109667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:22.204: INFO: Waiting for deployment "webserver-deployment" to complete
  Dec 19 10:52:22.216: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Dec 19 10:52:22.230: INFO: Updating deployment webserver-deployment
  Dec 19 10:52:22.230: INFO: Waiting for observed generation 2
  E1219 10:52:23.110139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:24.110661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:24.247: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Dec 19 10:52:24.258: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Dec 19 10:52:24.267: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec 19 10:52:24.307: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Dec 19 10:52:24.307: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Dec 19 10:52:24.319: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec 19 10:52:24.333: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Dec 19 10:52:24.333: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Dec 19 10:52:24.357: INFO: Updating deployment webserver-deployment
  Dec 19 10:52:24.357: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Dec 19 10:52:24.374: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Dec 19 10:52:24.393: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Dec 19 10:52:24.414: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4ac4803d-46a9-46c6-b618-1c7f5ff9abc7",
      ResourceVersion: (string) (len=5) "18647",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 10:52:24.444: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
      ResourceVersion: (string) (len=5) "18651",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "4ac4803d-46a9-46c6-b618-1c7f5ff9abc7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 61 63 34 38 30  33 64 2d 34 36 61 39 2d  |\"4ac4803d-46a9-|
              00000120  34 36 63 36 2d 62 36 31  38 2d 31 63 37 66 35 66  |46c6-b618-1c7f5f|
              00000130  66 39 61 62 63 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f9abc7\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:52:24.446: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Dec 19 10:52:24.447: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
      ResourceVersion: (string) (len=5) "18648",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "4ac4803d-46a9-46c6-b618-1c7f5ff9abc7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 61 63 34 38 30  33 64 2d 34 36 61 39 2d  |\"4ac4803d-46a9-|
              00000120  34 36 63 36 2d 62 36 31  38 2d 31 63 37 66 35 66  |46c6-b618-1c7f5f|
              00000130  66 39 61 62 63 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f9abc7\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:52:24.478: INFO: Pod "webserver-deployment-557759b7c7-4995q" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-4995q",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0197772d-cf63-4f6b-b07e-80ba18d03c67",
      ResourceVersion: (string) (len=5) "18525",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  36 34 5c 22 7d 22 3a 7b  |.233.65.64\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xqrtq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xqrtq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.77",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.77"
        }
      },
      PodIP: (string) (len=12) "10.233.65.64",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.64"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://851715d5a65007d8b1348fe6ba63752cee4d3648ea0d9ded6475987a6a809455",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.492: INFO: Pod "webserver-deployment-557759b7c7-7bfrn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7bfrn",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e7c095c7-1fae-4ee8-9acd-7b7b9a89f40f",
      ResourceVersion: (string) (len=5) "18663",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mpx7k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mpx7k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.494: INFO: Pod "webserver-deployment-557759b7c7-7d2zn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7d2zn",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3cc75a13-5d84-4e61-b654-4553afd4a2d9",
      ResourceVersion: (string) (len=5) "18545",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  35 33 5c 22 7d 22 3a 7b  |.233.64.53\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hfn5v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hfn5v",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.241",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.241"
        }
      },
      PodIP: (string) (len=12) "10.233.64.53",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.53"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://814bcbc859e65bf7f5ba46b33d67a9d828bf08b558a44df8a7efe4350524dc67",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.498: INFO: Pod "webserver-deployment-557759b7c7-8g4zx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-8g4zx",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6362abad-51d0-4cc2-ac15-63fa5437f9df",
      ResourceVersion: (string) (len=5) "18536",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 38 33 5c 22 7d 22 3a  |.233.66.183\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zqw4x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zqw4x",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=13) "10.233.66.183",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.183"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://5315e4f29a345794b84c6c8359620792f5204b1b71ad54d89afbdac0d563efef",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.526: INFO: Pod "webserver-deployment-557759b7c7-cp29v" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-cp29v",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "afb1fd15-a718-498d-815f-9970d71e19e7",
      ResourceVersion: (string) (len=5) "18542",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  35 31 5c 22 7d 22 3a 7b  |.233.64.51\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lsftv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lsftv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.241",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.241"
        }
      },
      PodIP: (string) (len=12) "10.233.64.51",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.51"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://1bfcb27e176576f2241cb2a89eb9c7bd51824ec9dbadbd8e6985979c15a9bde8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.540: INFO: Pod "webserver-deployment-557759b7c7-l96jv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-l96jv",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d8f9eb3-b1d9-4bff-aa61-5e0fedc59fde",
      ResourceVersion: (string) (len=5) "18518",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  36 35 5c 22 7d 22 3a 7b  |.233.65.65\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7vcjf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7vcjf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.77",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.77"
        }
      },
      PodIP: (string) (len=12) "10.233.65.65",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.65"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://8b5046b5d2ea1088d64a44e12a11cd4b1266b6224f910adaa07933d4531d0220",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.559: INFO: Pod "webserver-deployment-557759b7c7-mmf9p" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-mmf9p",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aeef7add-e9f0-460e-9da5-5a7c9343cb82",
      ResourceVersion: (string) (len=5) "18661",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-srf8l",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-srf8l",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.565: INFO: Pod "webserver-deployment-557759b7c7-pxjkv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-pxjkv",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "37d1c6ae-1de7-4bef-9a33-806b4eab71c3",
      ResourceVersion: (string) (len=5) "18662",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wxk7p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wxk7p",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.575: INFO: Pod "webserver-deployment-557759b7c7-q7tzg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-q7tzg",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "db036cc4-1b94-484c-a26c-23009430a3f6",
      ResourceVersion: (string) (len=5) "18539",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 38 35 5c 22 7d 22 3a  |.233.66.185\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-skr4r",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-skr4r",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=13) "10.233.66.185",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.185"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://31a9ee2a2fb152ffa9b92d5f574bbbbe592a5ae8a1102142c796461c9aecca5c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.581: INFO: Pod "webserver-deployment-557759b7c7-qx7xm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-qx7xm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d154e340-3b35-495c-92f7-d24c3dcb70cd",
      ResourceVersion: (string) (len=5) "18514",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  36 36 5c 22 7d 22 3a 7b  |.233.65.66\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j82ps",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j82ps",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.77",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.77"
        }
      },
      PodIP: (string) (len=12) "10.233.65.66",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.66"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://0f2d171aba7cc0acf56ffe7e100a739050e2c8b9fa6cf1925f1bc2745c1203e5",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.591: INFO: Pod "webserver-deployment-557759b7c7-txzmp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-txzmp",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "22fc38fc-b7d3-4c11-bcd4-a7251eebe4f8",
      ResourceVersion: (string) (len=5) "18548",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  35 32 5c 22 7d 22 3a 7b  |.233.64.52\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xstm4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xstm4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579940,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579938,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.241",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.241"
        }
      },
      PodIP: (string) (len=12) "10.233.64.52",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.52"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579938,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://039cc9adbb71fb0a4f6d714bb8bc9f7a0a758f3a349f20acab03c5832b39b588",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.603: INFO: Pod "webserver-deployment-557759b7c7-whdrh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-whdrh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "99a53fef-70ac-4945-b0d4-2a3db46447f1",
      ResourceVersion: (string) (len=5) "18656",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "7babec2f-6110-4ab4-b5ac-3f66d913c642",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  61 62 65 63 32 66 2d 36  |d\":\"7babec2f-6|
              00000090  31 31 30 2d 34 61 62 34  2d 62 35 61 63 2d 33 66  |110-4ab4-b5ac-3f|
              000000a0  36 36 64 39 31 33 63 36  34 32 5c 22 7d 22 3a 7b  |66d913c642\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qwkcs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qwkcs",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.613: INFO: Pod "webserver-deployment-9b4f5bf69-5sdkl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-5sdkl",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4c44db09-00da-4631-bcd3-d4a32ca0d8d5",
      ResourceVersion: (string) (len=5) "18576",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fr2k4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fr2k4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.627: INFO: Pod "webserver-deployment-9b4f5bf69-6kqmc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-6kqmc",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "76b6d3ea-4776-4178-bc34-0c7074034911",
      ResourceVersion: (string) (len=5) "18583",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-29887",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-29887",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.241",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.241"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.633: INFO: Pod "webserver-deployment-9b4f5bf69-fz7fs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-fz7fs",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8da746d1-e592-47fe-8cc4-ae3d46fbf351",
      ResourceVersion: (string) (len=5) "18603",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jrssx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jrssx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.77",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.77"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.642: INFO: Pod "webserver-deployment-9b4f5bf69-jz7nz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-jz7nz",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e744ff9c-a9ec-4718-9734-3a85690c4fe1",
      ResourceVersion: (string) (len=5) "18659",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2mww9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2mww9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.648: INFO: Pod "webserver-deployment-9b4f5bf69-qd8jr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qd8jr",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7e99292a-9ba2-41be-b459-b31145d53771",
      ResourceVersion: (string) (len=5) "18604",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jffhf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jffhf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.659: INFO: Pod "webserver-deployment-9b4f5bf69-sr8vk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-sr8vk",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "596777c1-b45f-43de-b3a9-6240fd34201a",
      ResourceVersion: (string) (len=5) "18655",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f7nzv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f7nzv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.671: INFO: Pod "webserver-deployment-9b4f5bf69-vz7bb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-vz7bb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d66ab2bd-3550-40c8-8aa9-fdf0d7824537",
      ResourceVersion: (string) (len=5) "18660",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pz4jk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pz4jk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.691: INFO: Pod "webserver-deployment-9b4f5bf69-zg8w8" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-zg8w8",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-4082",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8c58be9d-0809-4604-bc21-7298e484c694",
      ResourceVersion: (string) (len=5) "18581",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "83c5c2ba-81bf-4324-b999-d6957d4120a5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 33  63 35 63 32 62 61 2d 38  |d\":\"83c5c2ba-8|
              00000090  31 62 66 2d 34 33 32 34  2d 62 39 39 39 2d 64 36  |1bf-4324-b999-d6|
              000000a0  39 35 37 64 34 31 32 30  61 35 5c 22 7d 22 3a 7b  |957d4120a5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zfrzz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zfrzz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579942,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.77",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.77"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579942,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:52:24.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4082" for this suite. @ 12/19/23 10:52:24.755
• [6.751 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 12/19/23 10:52:24.807
  Dec 19 10:52:24.807: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 10:52:24.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:25.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:25.032
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 12/19/23 10:52:25.062
  E1219 10:52:25.110967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:26.112151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 12/19/23 10:52:27.096
  STEP: Then the orphan pod is adopted @ 12/19/23 10:52:27.108
  E1219 10:52:27.112113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:28.112829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 12/19/23 10:52:28.127
  Dec 19 10:52:28.138: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/19/23 10:52:28.169
  E1219 10:52:29.113193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:29.190: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6405" for this suite. @ 12/19/23 10:52:29.202
• [4.408 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 12/19/23 10:52:29.218
  Dec 19 10:52:29.218: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 10:52:29.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:29.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:29.29
  Dec 19 10:52:29.351: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 10:52:30.113175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:31.117926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:32.117523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:33.118265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:34.118530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:35.118741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:36.118924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:37.119270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:38.119507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:39.120565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:40.120698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:41.121282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:42.121524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:43.122137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:44.123073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:45.123479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:46.123662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:47.123972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:48.125120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:49.125857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:50.126169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:51.126984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:52.127513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:53.127969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:54.128267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:55.129324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:56.129442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:57.130115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:58.130475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:59.130654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:00.131750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:01.132423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:02.133235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:03.133612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:04.133600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:05.133850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:06.134992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:07.135362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:08.135460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:09.136345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:10.137090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:11.137284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:12.137352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:13.137785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:14.137937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:15.138531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:16.138858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:17.138963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:18.139448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:19.139541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:20.140577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:21.141669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:22.142549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:23.142754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:24.143157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:25.143394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:26.143717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:27.144648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:28.144993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:29.146094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:29.366: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/19/23 10:53:29.374
  Dec 19 10:53:29.435: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec 19 10:53:29.457: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec 19 10:53:29.527: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec 19 10:53:29.615: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec 19 10:53:29.668: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec 19 10:53:29.689: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/19/23 10:53:29.689
  E1219 10:53:30.147321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:31.147847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:32.148189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:33.148909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 12/19/23 10:53:33.771
  E1219 10:53:34.149287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:35.149652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:36.149793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:37.150678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:38.014: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6252" for this suite. @ 12/19/23 10:53:38.026
• [68.823 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 12/19/23 10:53:38.047
  Dec 19 10:53:38.047: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:53:38.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:53:38.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:53:38.096
  STEP: Creating a test externalName service @ 12/19/23 10:53:38.105
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4416.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:53:38.12
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4416.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:53:38.121
  STEP: creating a pod to probe DNS @ 12/19/23 10:53:38.121
  STEP: submitting the pod to kubernetes @ 12/19/23 10:53:38.121
  E1219 10:53:38.150959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:39.151201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:40.151297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:53:40.16
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:53:40.171
  Dec 19 10:53:40.201: INFO: DNS probes using dns-test-c5571fdb-8450-4a45-bbd6-553a7e67c42e succeeded

  STEP: changing the externalName to bar.example.com @ 12/19/23 10:53:40.203
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4416.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:53:40.222
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4416.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:53:40.222
  STEP: creating a second pod to probe DNS @ 12/19/23 10:53:40.222
  STEP: submitting the pod to kubernetes @ 12/19/23 10:53:40.222
  E1219 10:53:41.152582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:42.153086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:53:42.275
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:53:42.286
  Dec 19 10:53:42.371: INFO: File wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains '' instead of 'bar.example.com.'
  Dec 19 10:53:42.395: INFO: Lookups using dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 failed for: [wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local]

  Dec 19 10:53:42.431: INFO: Pod client logs for webserver: 
  Dec 19 10:53:42.475: INFO: Pod client logs for querier: 
  Dec 19 10:53:42.493: INFO: Pod client logs for jessie-querier: 
  E1219 10:53:43.153655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:44.155325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:45.156504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:46.156533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:47.156546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:47.320: INFO: File jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Dec 19 10:53:47.320: INFO: Lookups using dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 failed for: [jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local]

  Dec 19 10:53:47.335: INFO: Pod client logs for webserver: 
  Dec 19 10:53:47.357: INFO: Pod client logs for querier: 
  Dec 19 10:53:47.371: INFO: Pod client logs for jessie-querier: 
  E1219 10:53:48.157282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:49.158298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:50.158706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:51.159671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:52.159635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:52.311: INFO: File wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Dec 19 10:53:52.320: INFO: File jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Dec 19 10:53:52.320: INFO: Lookups using dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 failed for: [wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local]

  Dec 19 10:53:52.336: INFO: Pod client logs for webserver: 
  Dec 19 10:53:52.356: INFO: Pod client logs for querier: 
  Dec 19 10:53:52.378: INFO: Pod client logs for jessie-querier: 
  E1219 10:53:53.160153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:54.160212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:55.161662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:56.161580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:57.161905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:57.309: INFO: File wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Dec 19 10:53:57.319: INFO: Lookups using dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 failed for: [wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local]

  Dec 19 10:53:57.335: INFO: Pod client logs for webserver: 
  Dec 19 10:53:57.350: INFO: Pod client logs for querier: 
  Dec 19 10:53:57.366: INFO: Pod client logs for jessie-querier: 
  E1219 10:53:58.162183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:59.162626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:00.163551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:01.164469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:02.165599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:02.307: INFO: File wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Dec 19 10:54:02.315: INFO: Lookups using dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 failed for: [wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local]

  Dec 19 10:54:02.327: INFO: Pod client logs for webserver: 
  Dec 19 10:54:02.341: INFO: Pod client logs for querier: 
  Dec 19 10:54:02.358: INFO: Pod client logs for jessie-querier: 
  E1219 10:54:03.166333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:04.167369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:05.168105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:06.168956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:07.169392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:07.317: INFO: File jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local from pod  dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Dec 19 10:54:07.317: INFO: Lookups using dns-4416/dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 failed for: [jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local]

  Dec 19 10:54:07.329: INFO: Pod client logs for webserver: 
  Dec 19 10:54:07.345: INFO: Pod client logs for querier: 
  Dec 19 10:54:07.362: INFO: Pod client logs for jessie-querier: 
  E1219 10:54:08.170334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:09.171299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:10.171499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:11.171704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:12.172124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:12.318: INFO: DNS probes using dns-test-168dcb71-f54e-444f-935f-4ed47a36dae5 succeeded

  STEP: changing the service to type=ClusterIP @ 12/19/23 10:54:12.319
  W1219 10:54:12.365107      13 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4416.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4416.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:54:12.365
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4416.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4416.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:54:12.365
  STEP: creating a third pod to probe DNS @ 12/19/23 10:54:12.365
  STEP: submitting the pod to kubernetes @ 12/19/23 10:54:12.373
  E1219 10:54:13.172679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:14.172683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:15.172614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:16.173300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:17.173110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:18.173078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:19.174744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:20.174996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:21.175342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:22.175619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:23.175938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:24.176992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:25.177238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:26.177515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:27.178074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:28.178370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:29.178571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:30.178865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:31.179040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:32.179247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:54:32.524
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:54:32.531
  Dec 19 10:54:32.558: INFO: DNS probes using dns-test-7c5c02b4-c439-49a2-b9a4-ddb08ee38d0a succeeded

  STEP: deleting the pod @ 12/19/23 10:54:32.559
  STEP: deleting the pod @ 12/19/23 10:54:32.596
  STEP: deleting the pod @ 12/19/23 10:54:32.649
  STEP: deleting the test externalName service @ 12/19/23 10:54:32.71
  Dec 19 10:54:32.766: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4416" for this suite. @ 12/19/23 10:54:32.779
• [54.756 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 12/19/23 10:54:32.806
  Dec 19 10:54:32.806: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:54:32.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:32.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:32.877
  Dec 19 10:54:32.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 create -f -'
  E1219 10:54:33.179377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:33.300: INFO: stderr: ""
  Dec 19 10:54:33.300: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Dec 19 10:54:33.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 create -f -'
  Dec 19 10:54:33.711: INFO: stderr: ""
  Dec 19 10:54:33.711: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/19/23 10:54:33.711
  E1219 10:54:34.181214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:34.721: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:54:34.721: INFO: Found 0 / 1
  E1219 10:54:35.182228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:35.720: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:54:35.720: INFO: Found 1 / 1
  Dec 19 10:54:35.720: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec 19 10:54:35.731: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:54:35.731: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 10:54:35.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 describe pod agnhost-primary-zszm5'
  Dec 19 10:54:35.993: INFO: stderr: ""
  Dec 19 10:54:35.994: INFO: stdout: "Name:             agnhost-primary-zszm5\nNamespace:        kubectl-2561\nPriority:         0\nService Account:  default\nNode:             uikie9pei4sh-3/192.168.121.201\nStart Time:       Tue, 19 Dec 2023 10:54:33 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.197\nIPs:\n  IP:           10.233.66.197\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://83960f4ef12222834df025023e313defc4eeecf5e3f0e5e115fe85726858748d\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.45\n    Image ID:       077cda6b1f5995dcc056c00f92d40b5147132839f522d46d9ca84acd44ad76a7\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Dec 2023 10:54:34 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jtnwv (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-jtnwv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2561/agnhost-primary-zszm5 to uikie9pei4sh-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.45\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Dec 19 10:54:35.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 describe rc agnhost-primary'
  E1219 10:54:36.182318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:36.257: INFO: stderr: ""
  Dec 19 10:54:36.257: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2561\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-zszm5\n"
  Dec 19 10:54:36.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 describe service agnhost-primary'
  Dec 19 10:54:36.465: INFO: stderr: ""
  Dec 19 10:54:36.465: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2561\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.45.213\nIPs:               10.233.45.213\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.197:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Dec 19 10:54:36.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 describe node uikie9pei4sh-1'
  Dec 19 10:54:36.806: INFO: stderr: ""
  Dec 19 10:54:36.806: INFO: stdout: "Name:               uikie9pei4sh-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=uikie9pei4sh-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"f6:b8:4c:25:e2:4a\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.241\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 19 Dec 2023 09:44:18 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  uikie9pei4sh-1\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 19 Dec 2023 10:54:32 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 19 Dec 2023 09:56:50 +0000   Tue, 19 Dec 2023 09:56:50 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 19 Dec 2023 10:51:16 +0000   Tue, 19 Dec 2023 09:56:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 19 Dec 2023 10:51:16 +0000   Tue, 19 Dec 2023 09:56:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 19 Dec 2023 10:51:16 +0000   Tue, 19 Dec 2023 09:56:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 19 Dec 2023 10:51:16 +0000   Tue, 19 Dec 2023 09:56:17 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.241\n  Hostname:    uikie9pei4sh-1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      115008636Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8123984Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    1600m\n  ephemeral-storage:      111880401014\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3274320Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 127aa00389d24294b8f61769a835c186\n  System UUID:                127aa003-89d2-4294-b8f6-1769a835c186\n  Boot ID:                    c54298eb-c1bc-46ab-b570-de86d4a9d72a\n  Kernel Version:             6.2.0-39-generic\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.29.0\n  Kubelet Version:            v1.29.0\n  Kube-Proxy Version:         v1.29.0\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-76f75df574-4529k                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     69m\n  kube-system                 coredns-76f75df574-kjr7r                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     69m\n  kube-system                 kube-addon-manager-uikie9pei4sh-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         67m\n  kube-system                 kube-apiserver-uikie9pei4sh-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                 kube-controller-manager-uikie9pei4sh-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                 kube-flannel-ds-qldcz                                      100m (6%)     0 (0%)      50Mi (1%)        0 (0%)         67m\n  kube-system                 kube-proxy-wp7g9                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                 kube-scheduler-uikie9pei4sh-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         70m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qgn7f    0 (0%)        0 (0%)      0 (0%)           0 (0%)         53m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    855m (53%)  0 (0%)\n  memory                 240Mi (7%)  340Mi (10%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type    Reason                   Age                From             Message\n  ----    ------                   ----               ----             -------\n  Normal  Starting                 69m                kube-proxy       \n  Normal  Starting                 58m                kube-proxy       \n  Normal  NodeAllocatableEnforced  70m                kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeHasNoDiskPressure    70m (x8 over 70m)  kubelet          Node uikie9pei4sh-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientMemory  70m (x8 over 70m)  kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasSufficientPID     70m (x7 over 70m)  kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientPID\n  Normal  NodeHasNoDiskPressure    70m                kubelet          Node uikie9pei4sh-1 status is now: NodeHasNoDiskPressure\n  Normal  Starting                 70m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  70m                kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasSufficientPID     70m                kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  70m                kubelet          Updated Node Allocatable limit across pods\n  Normal  RegisteredNode           70m                node-controller  Node uikie9pei4sh-1 event: Registered Node uikie9pei4sh-1 in Controller\n  Normal  NodeAllocatableEnforced  69m                kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  69m                kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientMemory\n  Normal  Starting                 69m                kubelet          Starting kubelet.\n  Normal  NodeHasNoDiskPressure    69m                kubelet          Node uikie9pei4sh-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     69m                kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientPID\n  Normal  NodeReady                66m                kubelet          Node uikie9pei4sh-1 status is now: NodeReady\n  Normal  RegisteredNode           59m                node-controller  Node uikie9pei4sh-1 event: Registered Node uikie9pei4sh-1 in Controller\n  Normal  NodeNotReady             59m                node-controller  Node uikie9pei4sh-1 status is now: NodeNotReady\n  Normal  Starting                 58m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  58m (x8 over 58m)  kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    58m (x8 over 58m)  kubelet          Node uikie9pei4sh-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     58m (x7 over 58m)  kubelet          Node uikie9pei4sh-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  58m                kubelet          Updated Node Allocatable limit across pods\n"
  Dec 19 10:54:36.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-2561 describe namespace kubectl-2561'
  Dec 19 10:54:37.006: INFO: stderr: ""
  Dec 19 10:54:37.006: INFO: stdout: "Name:         kubectl-2561\nLabels:       e2e-framework=kubectl\n              e2e-run=13f7c4b6-93cb-4d70-8a59-2a33698c5e74\n              kubernetes.io/metadata.name=kubectl-2561\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Dec 19 10:54:37.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2561" for this suite. @ 12/19/23 10:54:37.019
• [4.229 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 12/19/23 10:54:37.051
  Dec 19 10:54:37.051: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 10:54:37.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:37.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:37.102
  STEP: fetching services @ 12/19/23 10:54:37.109
  Dec 19 10:54:37.117: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2575" for this suite. @ 12/19/23 10:54:37.131
• [0.093 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 12/19/23 10:54:37.144
  Dec 19 10:54:37.144: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:54:37.147
  E1219 10:54:37.183013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:37.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:37.194
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 12/19/23 10:54:37.202
  Dec 19 10:54:37.204: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 10:54:38.183565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:39.183560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:39.348: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 10:54:40.185729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:41.185539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:42.185973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:43.186869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:44.187809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:45.188724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:46.188947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:47.189174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:47.473: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2363" for this suite. @ 12/19/23 10:54:47.496
• [10.367 seconds]
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 12/19/23 10:54:47.513
  Dec 19 10:54:47.514: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 10:54:47.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:47.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:47.58
  Dec 19 10:54:47.585: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 10:54:47.625: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:54:47.630: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-1 before test
  Dec 19 10:54:47.650: INFO: coredns-76f75df574-4529k from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: coredns-76f75df574-kjr7r from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: kube-addon-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: kube-apiserver-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: kube-controller-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: kube-flannel-ds-qldcz from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: kube-proxy-wp7g9 from kube-system started at 2023-12-19 09:44:36 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: kube-scheduler-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:54:47.651: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qgn7f from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:54:47.651: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:54:47.651: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:54:47.651: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-2 before test
  Dec 19 10:54:47.670: INFO: kube-addon-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.670: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:54:47.670: INFO: kube-apiserver-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.670: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:54:47.670: INFO: kube-controller-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.670: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:54:47.671: INFO: kube-flannel-ds-znfxv from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.671: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:54:47.671: INFO: kube-proxy-q4vm6 from kube-system started at 2023-12-19 09:45:19 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.671: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:54:47.671: INFO: kube-scheduler-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.671: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:54:47.671: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qvrr8 from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:54:47.671: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:54:47.671: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:54:47.671: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-3 before test
  Dec 19 10:54:47.687: INFO: kube-flannel-ds-z7dwl from kube-system started at 2023-12-19 10:27:36 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.688: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 10:54:47.689: INFO: kube-proxy-lh685 from kube-system started at 2023-12-19 09:45:40 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.689: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:54:47.690: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:56 +0000 UTC (1 container statuses recorded)
  Dec 19 10:54:47.690: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 10:54:47.690: INFO: sonobuoy-e2e-job-b395aad1bffb4cbc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:54:47.691: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 10:54:47.691: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:54:47.691: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-8llvc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 10:54:47.692: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:54:47.692: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node uikie9pei4sh-1 @ 12/19/23 10:54:47.737
  STEP: verifying the node has the label node uikie9pei4sh-2 @ 12/19/23 10:54:47.786
  STEP: verifying the node has the label node uikie9pei4sh-3 @ 12/19/23 10:54:47.847
  Dec 19 10:54:47.894: INFO: Pod coredns-76f75df574-4529k requesting resource cpu=100m on Node uikie9pei4sh-1
  Dec 19 10:54:47.897: INFO: Pod coredns-76f75df574-kjr7r requesting resource cpu=100m on Node uikie9pei4sh-1
  Dec 19 10:54:47.898: INFO: Pod kube-addon-manager-uikie9pei4sh-1 requesting resource cpu=5m on Node uikie9pei4sh-1
  Dec 19 10:54:47.899: INFO: Pod kube-addon-manager-uikie9pei4sh-2 requesting resource cpu=5m on Node uikie9pei4sh-2
  Dec 19 10:54:47.899: INFO: Pod kube-apiserver-uikie9pei4sh-1 requesting resource cpu=250m on Node uikie9pei4sh-1
  Dec 19 10:54:47.900: INFO: Pod kube-apiserver-uikie9pei4sh-2 requesting resource cpu=250m on Node uikie9pei4sh-2
  Dec 19 10:54:47.900: INFO: Pod kube-controller-manager-uikie9pei4sh-1 requesting resource cpu=200m on Node uikie9pei4sh-1
  Dec 19 10:54:47.901: INFO: Pod kube-controller-manager-uikie9pei4sh-2 requesting resource cpu=200m on Node uikie9pei4sh-2
  Dec 19 10:54:47.901: INFO: Pod kube-flannel-ds-qldcz requesting resource cpu=100m on Node uikie9pei4sh-1
  Dec 19 10:54:47.902: INFO: Pod kube-flannel-ds-z7dwl requesting resource cpu=100m on Node uikie9pei4sh-3
  Dec 19 10:54:47.902: INFO: Pod kube-flannel-ds-znfxv requesting resource cpu=100m on Node uikie9pei4sh-2
  Dec 19 10:54:47.903: INFO: Pod kube-proxy-lh685 requesting resource cpu=0m on Node uikie9pei4sh-3
  Dec 19 10:54:47.904: INFO: Pod kube-proxy-q4vm6 requesting resource cpu=0m on Node uikie9pei4sh-2
  Dec 19 10:54:47.905: INFO: Pod kube-proxy-wp7g9 requesting resource cpu=0m on Node uikie9pei4sh-1
  Dec 19 10:54:47.906: INFO: Pod kube-scheduler-uikie9pei4sh-1 requesting resource cpu=100m on Node uikie9pei4sh-1
  Dec 19 10:54:47.909: INFO: Pod kube-scheduler-uikie9pei4sh-2 requesting resource cpu=100m on Node uikie9pei4sh-2
  Dec 19 10:54:47.910: INFO: Pod sonobuoy requesting resource cpu=0m on Node uikie9pei4sh-3
  Dec 19 10:54:47.911: INFO: Pod sonobuoy-e2e-job-b395aad1bffb4cbc requesting resource cpu=0m on Node uikie9pei4sh-3
  Dec 19 10:54:47.912: INFO: Pod sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-8llvc requesting resource cpu=0m on Node uikie9pei4sh-3
  Dec 19 10:54:47.913: INFO: Pod sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qgn7f requesting resource cpu=0m on Node uikie9pei4sh-1
  Dec 19 10:54:47.914: INFO: Pod sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qvrr8 requesting resource cpu=0m on Node uikie9pei4sh-2
  STEP: Starting Pods to consume most of the cluster CPU. @ 12/19/23 10:54:47.914
  Dec 19 10:54:47.914: INFO: Creating a pod which consumes cpu=521m on Node uikie9pei4sh-1
  Dec 19 10:54:47.937: INFO: Creating a pod which consumes cpu=661m on Node uikie9pei4sh-2
  Dec 19 10:54:47.962: INFO: Creating a pod which consumes cpu=1050m on Node uikie9pei4sh-3
  E1219 10:54:48.190981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:49.191265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 12/19/23 10:54:50.052
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d.17a2364714c15cf9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6000/filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d to uikie9pei4sh-2] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d.17a2364743cf50a3], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d.17a2364755181e5d], Reason = [Created], Message = [Created container filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d.17a236475794b80c], Reason = [Started], Message = [Started container filler-pod-154bbac5-79c9-4da7-9ca9-baaaeca0246d] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7dfb1877-72ed-4080-abf5-d88931984271.17a2364712b5e5ec], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6000/filler-pod-7dfb1877-72ed-4080-abf5-d88931984271 to uikie9pei4sh-1] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7dfb1877-72ed-4080-abf5-d88931984271.17a2364743737715], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7dfb1877-72ed-4080-abf5-d88931984271.17a2364755585062], Reason = [Created], Message = [Created container filler-pod-7dfb1877-72ed-4080-abf5-d88931984271] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-7dfb1877-72ed-4080-abf5-d88931984271.17a236475795d9ea], Reason = [Started], Message = [Started container filler-pod-7dfb1877-72ed-4080-abf5-d88931984271] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12.17a2364716b13153], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6000/filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12 to uikie9pei4sh-3] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12.17a2364736ee9200], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12.17a2364745eb2834], Reason = [Created], Message = [Created container filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12.17a2364748714fe4], Reason = [Started], Message = [Started container filler-pod-a80c9a66-1caf-4a41-adba-fc5f7f4bcc12] @ 12/19/23 10:54:50.073
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17a2364790824fc0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] @ 12/19/23 10:54:50.107
  E1219 10:54:50.190334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node uikie9pei4sh-3 @ 12/19/23 10:54:51.109
  STEP: verifying the node doesn't have the label node @ 12/19/23 10:54:51.146
  STEP: removing the label node off the node uikie9pei4sh-1 @ 12/19/23 10:54:51.154
  E1219 10:54:51.191229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the label node @ 12/19/23 10:54:51.197
  STEP: removing the label node off the node uikie9pei4sh-2 @ 12/19/23 10:54:51.217
  STEP: verifying the node doesn't have the label node @ 12/19/23 10:54:51.269
  Dec 19 10:54:51.284: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6000" for this suite. @ 12/19/23 10:54:51.3
• [3.812 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 12/19/23 10:54:51.326
  Dec 19 10:54:51.326: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 10:54:51.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:51.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:51.398
  E1219 10:54:52.192300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:53.192711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:54.192856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:55.193657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:56.194096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:57.194400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:58.194368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:59.194671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:59.516: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3605" for this suite. @ 12/19/23 10:54:59.529
• [8.224 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 12/19/23 10:54:59.555
  Dec 19 10:54:59.555: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename events @ 12/19/23 10:54:59.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:59.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:59.654
  STEP: creating a test event @ 12/19/23 10:54:59.66
  STEP: listing all events in all namespaces @ 12/19/23 10:54:59.672
  STEP: patching the test event @ 12/19/23 10:54:59.686
  STEP: fetching the test event @ 12/19/23 10:54:59.702
  STEP: updating the test event @ 12/19/23 10:54:59.708
  STEP: getting the test event @ 12/19/23 10:54:59.74
  STEP: deleting the test event @ 12/19/23 10:54:59.751
  STEP: listing all events in all namespaces @ 12/19/23 10:54:59.768
  Dec 19 10:54:59.784: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1305" for this suite. @ 12/19/23 10:54:59.796
• [0.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 12/19/23 10:54:59.82
  Dec 19 10:54:59.820: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:54:59.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:59.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:59.871
  STEP: Creating secret with name secret-test-map-663264b2-3d67-4dd9-b7ff-a21dc0abdfe9 @ 12/19/23 10:54:59.884
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:54:59.896
  E1219 10:55:00.199707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:01.197903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:02.198471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:03.198949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:55:03.948
  Dec 19 10:55:03.956: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-bd5d45a8-e31a-48b7-9ee9-3b6f54194f87 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:55:03.973
  Dec 19 10:55:04.011: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9653" for this suite. @ 12/19/23 10:55:04.024
• [4.219 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 12/19/23 10:55:04.04
  Dec 19 10:55:04.040: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 10:55:04.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:04.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:04.083
  STEP: Creating pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378 @ 12/19/23 10:55:04.091
  E1219 10:55:04.198829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:05.202848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 10:55:06.128
  Dec 19 10:55:06.135: INFO: Initial restart count of pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 is 0
  Dec 19 10:55:06.145: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:06.200044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:07.200235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:08.154: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:08.201083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:09.202015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:10.164: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:10.202717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:11.203048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:12.174: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:12.203307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:13.203838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:14.185: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:14.204676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:15.205313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:16.194: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:16.205184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:17.206297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:18.202: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:18.206677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:19.207950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:20.207859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:20.212: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:21.209371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:22.208813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:22.223: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:23.208982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:24.208884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:24.233: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:25.209515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:26.209758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:26.242: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:27.210406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:28.210940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:28.253: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:29.211211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:30.211493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:30.261: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:31.212088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:32.213278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:32.280: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:33.212701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:34.213211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:34.290: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:35.214202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:36.214259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:36.304: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:37.215289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:38.216277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:38.327: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:39.216641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:40.217249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:40.340: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:41.217991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:42.218162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:42.356: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:43.217939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:44.219002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:44.366: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:45.219260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:46.219996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:46.375: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:47.220009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:48.220190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:48.384: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:49.220247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:50.220582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:50.391: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:51.221462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:52.221675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:52.401: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:53.222119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:54.222965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:54.415: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:55.223141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:56.223770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:56.425: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:57.224252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:58.224384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:58.435: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:55:59.225260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:00.225712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:00.444: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:01.226336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:02.226396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:02.454: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:03.227400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:04.227724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:04.462: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:05.227980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:06.228380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:06.473: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:07.229254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:08.230051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:08.487: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:09.230941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:10.233250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:10.500: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:11.233401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:12.234260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:12.511: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:13.234901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:14.235002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:14.521: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:15.235069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:16.235652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:16.532: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:17.236668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:18.237283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:18.539: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:19.237578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:20.238291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:20.550: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:21.238680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:22.238750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:22.558: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:23.239078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:24.240114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:24.568: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:25.240328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:26.240593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:26.576: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:27.241703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:28.241874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:28.591: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:29.242637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:30.242975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:30.597: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:31.243151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:32.243424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:32.605: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:33.244091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:34.243788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:34.614: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:35.243989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:36.244459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:36.622: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:37.245209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:38.245002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:38.632: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:39.245340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:40.246234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:40.640: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:41.246251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:42.249264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:42.650: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:43.247874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:44.249012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:44.668: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:45.249086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:46.249060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:46.675: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:47.249720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:48.249823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:48.684: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:49.250012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:50.250246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:50.693: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:51.250459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:52.251371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:52.703: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:53.251193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:54.252037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:54.714: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:55.252647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:56.253475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:56.724: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:57.253902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:58.254289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:58.734: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:56:59.254448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:00.254650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:00.742: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:01.255013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:02.255884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:02.754: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:03.256859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:04.257036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:04.765: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:05.257168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:06.257985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:06.772: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:07.258541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:08.258860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:08.783: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:09.259671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:10.259882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:10.791: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:11.260065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:12.260299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:12.800: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:13.260708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:14.261069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:14.810: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:15.261308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:16.261459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:16.819: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:17.261910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:18.262659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:18.826: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:19.263777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:20.264269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:20.834: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:21.264806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:22.265097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:22.843: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:23.265741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:24.265926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:24.854: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:25.266375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:26.266618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:26.862: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:27.267111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:28.267839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:28.871: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:29.269065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:30.269862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:30.881: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:31.270694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:32.271492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:32.890: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:33.272532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:34.273049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:34.902: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:35.273473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:36.274625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:36.912: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:37.275012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:38.276034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:38.923: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:39.276372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:40.278048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:40.935: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:41.277925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:42.278586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:42.946: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:43.279878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:44.280377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:44.956: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:45.280846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:46.281597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:46.964: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:47.281834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:48.282241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:48.973: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:49.282977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:50.283473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:50.984: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:51.284673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:52.284897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:52.993: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:53.284979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:54.286944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:55.003: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:55.287404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:56.287958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:57.013: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:57.288850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:58.289119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:59.026: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:57:59.289681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:00.289819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:01.036: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:01.291263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:02.291387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:03.046: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:03.292093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:04.292417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:05.057: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:05.292295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:06.293002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:07.066: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:07.293941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:08.294256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:09.076: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:09.294797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:10.295602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:11.085: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:11.296579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:12.297033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:13.095: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:13.297277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:14.297692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:15.106: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:15.297763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:16.298468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:17.118: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:17.298649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:18.298957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:19.127: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:19.299887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:20.300065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:21.139: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:21.301085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:22.302233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:23.148: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:23.302622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:24.302981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:25.161: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:25.304218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:26.304957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:27.170: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:27.305476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:28.305594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:29.184: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:29.305925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:30.309285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:31.197: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:31.310071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:32.311523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:33.206: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:33.311796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:34.312138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:35.220: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:35.312381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:36.312666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:37.228: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:37.312903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:38.313105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:39.236: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:39.313291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:40.314169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:41.247: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:41.314902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:42.315173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:43.258: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:43.315200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:44.315389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:45.267: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:45.316301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:46.316524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:47.280: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:47.322047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:48.322252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:49.292: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:49.323041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:50.323148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:51.299: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:51.323606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:52.324703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:53.310: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:53.325390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:54.325977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:55.320: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:55.326118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:56.326453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:57.327061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:57.329: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:58:58.327103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:59.327298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:59.337: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:59:00.327439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:01.328804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:01.359: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:59:02.329125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:03.329727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:03.367: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:59:04.330043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:05.331750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:05.377: INFO: Get pod busybox-0ddda5fa-3ef7-4de6-b785-5773e34378b6 in namespace container-probe-1378
  E1219 10:59:06.331082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:07.332105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 12/19/23 10:59:07.379
  Dec 19 10:59:07.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1378" for this suite. @ 12/19/23 10:59:07.423
• [243.413 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 12/19/23 10:59:07.455
  Dec 19 10:59:07.455: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename chunking @ 12/19/23 10:59:07.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:07.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:07.51
  STEP: creating a large number of resources @ 12/19/23 10:59:07.519
  E1219 10:59:08.333308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:09.333495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:10.333511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:11.334451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:12.335007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:13.335228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:14.335348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:15.336392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:16.336630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:17.336930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:18.337471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:19.337748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:20.338376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:21.339316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:22.339793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:23.340565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:24.341011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 12/19/23 10:59:25.172
  Dec 19 10:59:25.219: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Dec 19 10:59:25.269: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Dec 19 10:59:25.321: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  E1219 10:59:25.342195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:25.370: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Dec 19 10:59:25.424: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Dec 19 10:59:25.471: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Dec 19 10:59:25.520: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Dec 19 10:59:25.572: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Dec 19 10:59:25.619: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Dec 19 10:59:25.671: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Dec 19 10:59:25.719: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Dec 19 10:59:25.769: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Dec 19 10:59:25.819: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Dec 19 10:59:25.872: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Dec 19 10:59:25.917: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Dec 19 10:59:25.968: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Dec 19 10:59:26.019: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Dec 19 10:59:26.072: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Dec 19 10:59:26.121: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Dec 19 10:59:26.167: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Dec 19 10:59:26.219: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Dec 19 10:59:26.268: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Dec 19 10:59:26.331: INFO: Retrieved 17/17 results with rv 20633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzMsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  E1219 10:59:26.342624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:26.369: INFO: Retrieved 9/17 results with rv 20633 and continue 
  Dec 19 10:59:26.420: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Dec 19 10:59:26.469: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Dec 19 10:59:26.520: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Dec 19 10:59:26.575: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Dec 19 10:59:26.620: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Dec 19 10:59:26.670: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Dec 19 10:59:26.719: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Dec 19 10:59:26.768: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Dec 19 10:59:26.822: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Dec 19 10:59:26.871: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Dec 19 10:59:26.920: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Dec 19 10:59:26.986: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Dec 19 10:59:27.026: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Dec 19 10:59:27.069: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Dec 19 10:59:27.123: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Dec 19 10:59:27.173: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Dec 19 10:59:27.219: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Dec 19 10:59:27.272: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Dec 19 10:59:27.323: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  E1219 10:59:27.342725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:27.373: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Dec 19 10:59:27.423: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Dec 19 10:59:27.473: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Dec 19 10:59:27.522: INFO: Retrieved 17/17 results with rv 20634 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzQsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Dec 19 10:59:27.628: INFO: Retrieved 9/17 results with rv 20634 and continue 
  Dec 19 10:59:27.643: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Dec 19 10:59:27.670: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Dec 19 10:59:27.720: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Dec 19 10:59:27.770: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Dec 19 10:59:27.818: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Dec 19 10:59:27.871: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Dec 19 10:59:27.922: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Dec 19 10:59:27.970: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Dec 19 10:59:28.020: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Dec 19 10:59:28.072: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Dec 19 10:59:28.120: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Dec 19 10:59:28.170: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Dec 19 10:59:28.219: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Dec 19 10:59:28.273: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Dec 19 10:59:28.323: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  E1219 10:59:28.343114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:28.368: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Dec 19 10:59:28.419: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Dec 19 10:59:28.470: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Dec 19 10:59:28.522: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Dec 19 10:59:28.571: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Dec 19 10:59:28.622: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Dec 19 10:59:28.670: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Dec 19 10:59:28.719: INFO: Retrieved 17/17 results with rv 20636 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjA2MzYsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Dec 19 10:59:28.773: INFO: Retrieved 9/17 results with rv 20636 and continue 
  STEP: retrieving those results all at once @ 12/19/23 10:59:28.774
  Dec 19 10:59:28.864: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-856" for this suite. @ 12/19/23 10:59:28.877
• [21.482 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 12/19/23 10:59:28.939
  Dec 19 10:59:28.939: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 12/19/23 10:59:28.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:28.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:29.002
  STEP: Setting up the test @ 12/19/23 10:59:29.011
  STEP: Creating hostNetwork=false pod @ 12/19/23 10:59:29.011
  E1219 10:59:29.344031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:30.345025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 12/19/23 10:59:31.062
  E1219 10:59:31.345879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:32.346656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 12/19/23 10:59:33.109
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 12/19/23 10:59:33.109
  Dec 19 10:59:33.109: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.110: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.111: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.112: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec 19 10:59:33.317: INFO: Exec stderr: ""
  Dec 19 10:59:33.318: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.318: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.322: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.322: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  E1219 10:59:33.348647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:33.418: INFO: Exec stderr: ""
  Dec 19 10:59:33.419: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.419: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.421: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.422: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec 19 10:59:33.556: INFO: Exec stderr: ""
  Dec 19 10:59:33.557: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.557: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.559: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.560: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec 19 10:59:33.677: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 12/19/23 10:59:33.677
  Dec 19 10:59:33.677: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.678: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.680: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.680: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec 19 10:59:33.791: INFO: Exec stderr: ""
  Dec 19 10:59:33.791: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.792: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.794: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.795: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec 19 10:59:33.911: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 12/19/23 10:59:33.912
  Dec 19 10:59:33.912: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:33.912: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:33.915: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:33.915: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec 19 10:59:34.061: INFO: Exec stderr: ""
  Dec 19 10:59:34.063: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:34.063: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:34.069: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:34.070: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec 19 10:59:34.256: INFO: Exec stderr: ""
  Dec 19 10:59:34.256: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:34.257: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:34.259: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:34.260: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  E1219 10:59:34.348344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:34.393: INFO: Exec stderr: ""
  Dec 19 10:59:34.393: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7311 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:59:34.393: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 10:59:34.395: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:59:34.395: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7311/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec 19 10:59:34.537: INFO: Exec stderr: ""
  Dec 19 10:59:34.537: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-7311" for this suite. @ 12/19/23 10:59:34.557
• [5.638 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 12/19/23 10:59:34.583
  Dec 19 10:59:34.583: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 10:59:34.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:34.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:34.626
  STEP: Creating ReplicationController "e2e-rc-8nmnl" @ 12/19/23 10:59:34.633
  Dec 19 10:59:34.648: INFO: Get Replication Controller "e2e-rc-8nmnl" to confirm replicas
  E1219 10:59:35.348416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:35.649: INFO: Get Replication Controller "e2e-rc-8nmnl" to confirm replicas
  Dec 19 10:59:35.729: INFO: Found 1 replicas for "e2e-rc-8nmnl" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-8nmnl" @ 12/19/23 10:59:35.729
  STEP: Updating a scale subresource @ 12/19/23 10:59:35.749
  STEP: Verifying replicas where modified for replication controller "e2e-rc-8nmnl" @ 12/19/23 10:59:35.777
  Dec 19 10:59:35.777: INFO: Get Replication Controller "e2e-rc-8nmnl" to confirm replicas
  E1219 10:59:36.348877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:36.777: INFO: Get Replication Controller "e2e-rc-8nmnl" to confirm replicas
  Dec 19 10:59:36.786: INFO: Found 2 replicas for "e2e-rc-8nmnl" replication controller
  Dec 19 10:59:36.787: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1632" for this suite. @ 12/19/23 10:59:36.801
• [2.233 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 12/19/23 10:59:36.817
  Dec 19 10:59:36.817: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename init-container @ 12/19/23 10:59:36.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:36.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:36.869
  STEP: creating the pod @ 12/19/23 10:59:36.878
  Dec 19 10:59:36.878: INFO: PodSpec: initContainers in spec.initContainers
  E1219 10:59:37.349296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:38.350069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:39.350112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:40.351434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:41.351533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:42.351683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:42.475: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3836" for this suite. @ 12/19/23 10:59:42.492
• [5.694 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 12/19/23 10:59:42.513
  Dec 19 10:59:42.513: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:59:42.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:42.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:42.586
  STEP: creating a ConfigMap @ 12/19/23 10:59:42.593
  STEP: fetching the ConfigMap @ 12/19/23 10:59:42.606
  STEP: patching the ConfigMap @ 12/19/23 10:59:42.613
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 12/19/23 10:59:42.628
  STEP: deleting the ConfigMap by collection with a label selector @ 12/19/23 10:59:42.637
  STEP: listing all ConfigMaps in test namespace @ 12/19/23 10:59:42.665
  Dec 19 10:59:42.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1759" for this suite. @ 12/19/23 10:59:42.695
• [0.199 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 12/19/23 10:59:42.713
  Dec 19 10:59:42.713: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:59:42.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:42.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:42.771
  STEP: Creating configMap with name configmap-test-volume-map-8c7d24fa-4b35-453d-8797-00f5a5268efd @ 12/19/23 10:59:42.78
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:59:42.795
  E1219 10:59:43.351910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:44.352939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:45.353141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:46.353683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:59:46.845
  Dec 19 10:59:46.854: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-8738c83f-1464-4533-88ec-cc1e9f6e99f6 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:59:46.891
  Dec 19 10:59:46.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6378" for this suite. @ 12/19/23 10:59:46.943
• [4.248 seconds]
------------------------------
S
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 12/19/23 10:59:46.963
  Dec 19 10:59:46.964: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename hostport @ 12/19/23 10:59:46.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:47.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:47.015
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 12/19/23 10:59:47.034
  E1219 10:59:47.354458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:48.355395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.201 on the node which pod1 resides and expect scheduled @ 12/19/23 10:59:49.081
  E1219 10:59:49.356324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:50.356840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:51.357810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:52.358109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:53.358484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:54.358946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:55.359073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:56.359182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:57.359838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:58.360377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:59.360575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:00.361128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.201 but use UDP protocol on the node which pod2 resides @ 12/19/23 11:00:01.167
  E1219 11:00:01.365128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:02.362905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:03.363703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:04.365484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 12/19/23 11:00:05.25
  Dec 19 11:00:05.251: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.201 http://127.0.0.1:54323/hostname] Namespace:hostport-6850 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:00:05.251: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:00:05.254: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:00:05.254: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6850/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.201+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1219 11:00:05.365941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.201, port: 54323 @ 12/19/23 11:00:05.436
  Dec 19 11:00:05.436: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.201:54323/hostname] Namespace:hostport-6850 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:00:05.436: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:00:05.441: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:00:05.441: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6850/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.201%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.201, port: 54323 UDP @ 12/19/23 11:00:05.573
  Dec 19 11:00:05.573: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.201 54323] Namespace:hostport-6850 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:00:05.573: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:00:05.575: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:00:05.576: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6850/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.201+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1219 11:00:06.366447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:07.367468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:08.367561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:09.368494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:10.368471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:10.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-6850" for this suite. @ 12/19/23 11:00:10.721
• [23.773 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 12/19/23 11:00:10.737
  Dec 19 11:00:10.737: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 11:00:10.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:10.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:10.793
  E1219 11:00:11.368737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:12.370029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 12/19/23 11:00:12.861
  Dec 19 11:00:12.862: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9214 pod-service-account-4584b631-b7ad-40fd-b272-e15a7b6206b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 12/19/23 11:00:13.234
  Dec 19 11:00:13.234: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9214 pod-service-account-4584b631-b7ad-40fd-b272-e15a7b6206b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  E1219 11:00:13.370107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 12/19/23 11:00:13.56
  Dec 19 11:00:13.560: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9214 pod-service-account-4584b631-b7ad-40fd-b272-e15a7b6206b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Dec 19 11:00:13.830: INFO: Got root ca configmap in namespace "svcaccounts-9214"
  Dec 19 11:00:13.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9214" for this suite. @ 12/19/23 11:00:13.853
• [3.129 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 12/19/23 11:00:13.868
  Dec 19 11:00:13.869: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:00:13.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:13.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:13.915
  STEP: Creating secret with name secret-test-map-b5c88639-080c-444c-b30f-2d173c67f907 @ 12/19/23 11:00:13.924
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:00:13.938
  E1219 11:00:14.370641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:15.371016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:16.371128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:17.371788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:00:17.989
  Dec 19 11:00:18.006: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-c8d59762-ae2c-45a2-b75d-57a0467d4eca container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:00:18.031
  Dec 19 11:00:18.115: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3273" for this suite. @ 12/19/23 11:00:18.127
• [4.274 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 12/19/23 11:00:18.144
  Dec 19 11:00:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:00:18.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:18.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:18.206
  E1219 11:00:18.372370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:19.372577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:20.373404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:21.374247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:22.375316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:23.376092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:24.377229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:25.377394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:26.377546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:27.378177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:28.378788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:29.380005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:30.380964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:31.381468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:32.381678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:33.382478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:34.383239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:35.383337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:36.383766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:37.385063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:38.384295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:39.384830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:40.385277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:41.385308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:42.386197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:43.386356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:44.387137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:45.387458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:46.387765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:47.387850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:48.388839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:49.389809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:50.390899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:51.391098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:52.391358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:53.392442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:54.392846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:55.393130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:56.393474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:57.394020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:58.394257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:59.394418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:00.394820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:01.395024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:02.395314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:03.395787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:04.396047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:05.396294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:06.396685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:07.397315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:08.397843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:09.398650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:10.399353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:11.399798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:12.400592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:13.400639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:14.401251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:15.401363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:16.401589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:17.401642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:18.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4256" for this suite. @ 12/19/23 11:01:18.256
• [60.127 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 12/19/23 11:01:18.274
  Dec 19 11:01:18.274: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename disruption @ 12/19/23 11:01:18.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:18.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:18.333
  STEP: creating the pdb @ 12/19/23 11:01:18.339
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:01:18.381
  E1219 11:01:18.402690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:19.403608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 12/19/23 11:01:20.392
  E1219 11:01:20.405148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:01:20.416
  STEP: patching the pdb @ 12/19/23 11:01:20.428
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:01:20.448
  E1219 11:01:21.406079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:22.406435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 12/19/23 11:01:22.469
  Dec 19 11:01:22.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3688" for this suite. @ 12/19/23 11:01:22.497
• [4.244 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 12/19/23 11:01:22.519
  Dec 19 11:01:22.519: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename subpath @ 12/19/23 11:01:22.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:22.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:22.592
  STEP: Setting up data @ 12/19/23 11:01:22.601
  STEP: Creating pod pod-subpath-test-downwardapi-rjbs @ 12/19/23 11:01:22.633
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 11:01:22.633
  E1219 11:01:23.407538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:24.407908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:25.408100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:26.408832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:27.409212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:28.409332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:29.410420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:30.411264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:31.412687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:32.413180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:33.413313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:34.418056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:35.414643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:36.414647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:37.415215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:38.415827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:39.416040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:40.416981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:41.417412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:42.417525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:43.418186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:44.419187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:45.419510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:46.420034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:01:46.789
  Dec 19 11:01:46.796: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-subpath-test-downwardapi-rjbs container test-container-subpath-downwardapi-rjbs: <nil>
  STEP: delete the pod @ 12/19/23 11:01:46.819
  STEP: Deleting pod pod-subpath-test-downwardapi-rjbs @ 12/19/23 11:01:46.859
  Dec 19 11:01:46.859: INFO: Deleting pod "pod-subpath-test-downwardapi-rjbs" in namespace "subpath-6034"
  Dec 19 11:01:46.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6034" for this suite. @ 12/19/23 11:01:46.878
• [24.376 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 12/19/23 11:01:46.897
  Dec 19 11:01:46.897: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 11:01:46.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:46.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:46.949
  Dec 19 11:01:46.985: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:01:47.420940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:48.421271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:49.421443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:50.421886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:51.422827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:52.423786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:53.423993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:54.424157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:55.425248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:56.425522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:57.425894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:58.426951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:59.427360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:00.428213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:01.429050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:02.429354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:03.429839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:04.430135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:05.430180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:06.430835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:07.431062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:08.431142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:09.432018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:10.432200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:11.432641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:12.433478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:13.433727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:14.433796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:15.434117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:16.435091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:17.435794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:18.436024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:19.436462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:20.436991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:21.437035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:22.437234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:23.438254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:24.439418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:25.440267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:26.440579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:27.440868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:28.441300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:29.441458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:30.441721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:31.442101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:32.442570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:33.443062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:34.445323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:35.443355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:36.443913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:37.444162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:38.444704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:39.445703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:40.445917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:41.446961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:42.447682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:43.448538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:44.449056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:45.449513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:46.450476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:47.006: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/19/23 11:02:47.017
  Dec 19 11:02:47.017: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/19/23 11:02:47.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:47.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:47.066
  Dec 19 11:02:47.109: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Dec 19 11:02:47.117: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Dec 19 11:02:47.291: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6242" for this suite. @ 12/19/23 11:02:47.302
  Dec 19 11:02:47.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3165" for this suite. @ 12/19/23 11:02:47.331
• [60.450 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 12/19/23 11:02:47.348
  Dec 19 11:02:47.348: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:02:47.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:47.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:47.392
  STEP: Creating service test in namespace statefulset-1827 @ 12/19/23 11:02:47.399
  STEP: Creating stateful set ss in namespace statefulset-1827 @ 12/19/23 11:02:47.413
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1827 @ 12/19/23 11:02:47.431
  Dec 19 11:02:47.440: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:02:47.451239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:48.451705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:49.451744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:50.451897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:51.452193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:52.452528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:53.452530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:54.453586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:55.453929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:56.454757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:57.441: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 12/19/23 11:02:57.442
  Dec 19 11:02:57.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1219 11:02:57.454527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:57.806: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:02:57.806: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:02:57.806: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:02:57.814: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1219 11:02:58.454870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:59.456349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:00.456227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:01.456490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:02.456698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:03.456953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:04.458486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:05.457911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:06.458044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:07.458385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:07.822: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:03:07.822: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:03:07.866: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Dec 19 11:03:07.866: INFO: ss-0  uikie9pei4sh-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:48 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:47 +0000 UTC  }]
  Dec 19 11:03:07.866: INFO: 
  Dec 19 11:03:07.866: INFO: StatefulSet ss has not reached scale 3, at 1
  E1219 11:03:08.458521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:08.888: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990966349s
  E1219 11:03:09.458783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:09.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.967793793s
  E1219 11:03:10.459276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:10.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.957899146s
  E1219 11:03:11.459118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:11.934: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936654518s
  E1219 11:03:12.459334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:12.944: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.922882169s
  E1219 11:03:13.460411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:13.952: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.913392318s
  E1219 11:03:14.460724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:14.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.904951719s
  E1219 11:03:15.461445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:15.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.894135566s
  E1219 11:03:16.462564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:16.990: INFO: Verifying statefulset ss doesn't scale past 3 for another 877.74291ms
  E1219 11:03:17.462635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1827 @ 12/19/23 11:03:17.991
  Dec 19 11:03:18.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:03:18.372: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:03:18.372: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:03:18.372: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:03:18.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 11:03:18.463430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:18.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec 19 11:03:18.690: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:03:18.690: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:03:18.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:03:19.164: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec 19 11:03:19.164: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:03:19.164: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:03:19.177: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:03:19.177: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:03:19.177: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 12/19/23 11:03:19.177
  Dec 19 11:03:19.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1219 11:03:19.466827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:19.557: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:03:19.557: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:03:19.557: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:03:19.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:03:19.861: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:03:19.861: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:03:19.861: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:03:19.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-1827 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:03:20.229: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:03:20.229: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:03:20.229: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:03:20.229: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:03:20.253: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 2
  E1219 11:03:20.467578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:21.467774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:22.468070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:23.468207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:24.468538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:25.469113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:26.469358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:27.470682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:28.471331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:29.472156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:30.248: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:03:30.248: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:03:30.248: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:03:30.281: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Dec 19 11:03:30.281: INFO: ss-0  uikie9pei4sh-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:48 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:02:47 +0000 UTC  }]
  Dec 19 11:03:30.283: INFO: ss-1  uikie9pei4sh-2  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:10 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:07 +0000 UTC  }]
  Dec 19 11:03:30.284: INFO: ss-2  uikie9pei4sh-1  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:09 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:07 +0000 UTC  }]
  Dec 19 11:03:30.285: INFO: 
  Dec 19 11:03:30.285: INFO: StatefulSet ss has not reached scale 0, at 3
  E1219 11:03:30.472356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:31.299: INFO: POD   NODE            PHASE      GRACE  CONDITIONS
  Dec 19 11:03:31.299: INFO: ss-2  uikie9pei4sh-1  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:30 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:07 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:20 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:20 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:03:07 +0000 UTC  }]
  Dec 19 11:03:31.299: INFO: 
  Dec 19 11:03:31.299: INFO: StatefulSet ss has not reached scale 0, at 1
  E1219 11:03:31.473039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:32.307: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.971227771s
  E1219 11:03:32.473513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:33.316: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.962875057s
  E1219 11:03:33.474680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:34.325: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.953934497s
  E1219 11:03:34.475448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:35.335: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.944691217s
  E1219 11:03:35.476004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:36.343: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.935343731s
  E1219 11:03:36.477027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:37.355: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.92637331s
  E1219 11:03:37.478200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:38.363: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.914992s
  E1219 11:03:38.478267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:39.376: INFO: Verifying statefulset ss doesn't scale past 0 for another 906.382918ms
  E1219 11:03:39.478537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1827 @ 12/19/23 11:03:40.377
  Dec 19 11:03:40.388: INFO: Scaling statefulset ss to 0
  Dec 19 11:03:40.424: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:03:40.432: INFO: Deleting all statefulset in ns statefulset-1827
  Dec 19 11:03:40.439: INFO: Scaling statefulset ss to 0
  Dec 19 11:03:40.467: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:03:40.478: INFO: Deleting statefulset ss
  E1219 11:03:40.479189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:40.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1827" for this suite. @ 12/19/23 11:03:40.538
• [53.206 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 12/19/23 11:03:40.564
  Dec 19 11:03:40.564: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:03:40.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:40.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:40.621
  STEP: creating service in namespace services-8062 @ 12/19/23 11:03:40.635
  STEP: creating service affinity-clusterip-transition in namespace services-8062 @ 12/19/23 11:03:40.635
  STEP: creating replication controller affinity-clusterip-transition in namespace services-8062 @ 12/19/23 11:03:40.66
  I1219 11:03:40.682351      13 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-8062, replica count: 3
  E1219 11:03:41.479787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:42.480731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:43.481491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:03:43.735600      13 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:03:43.753: INFO: Creating new exec pod
  E1219 11:03:44.482199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:45.482665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:46.483500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:46.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8062 exec execpod-affinity9zlm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Dec 19 11:03:47.247: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Dec 19 11:03:47.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:03:47.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8062 exec execpod-affinity9zlm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.63.252 80'
  E1219 11:03:47.483655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:47.629: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.63.252 80\nConnection to 10.233.63.252 80 port [tcp/http] succeeded!\n"
  Dec 19 11:03:47.630: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:03:47.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8062 exec execpod-affinity9zlm9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.63.252:80/ ; done'
  Dec 19 11:03:48.238: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n"
  Dec 19 11:03:48.238: INFO: stdout: "\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-lfhcj\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-lfhcj\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-t58n9\naffinity-clusterip-transition-lfhcj\naffinity-clusterip-transition-jdf76"
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-lfhcj
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-lfhcj
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.238: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.239: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.239: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.239: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.239: INFO: Received response from host: affinity-clusterip-transition-t58n9
  Dec 19 11:03:48.239: INFO: Received response from host: affinity-clusterip-transition-lfhcj
  Dec 19 11:03:48.239: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8062 exec execpod-affinity9zlm9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.63.252:80/ ; done'
  E1219 11:03:48.485580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:48.832: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.63.252:80/\n"
  Dec 19 11:03:48.832: INFO: stdout: "\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76\naffinity-clusterip-transition-jdf76"
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.832: INFO: Received response from host: affinity-clusterip-transition-jdf76
  Dec 19 11:03:48.833: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8062, will wait for the garbage collector to delete the pods @ 12/19/23 11:03:48.86
  Dec 19 11:03:48.939: INFO: Deleting ReplicationController affinity-clusterip-transition took: 14.739177ms
  Dec 19 11:03:49.041: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 102.069063ms
  E1219 11:03:49.485639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:50.485670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:51.486436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:52.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8062" for this suite. @ 12/19/23 11:03:52.419
• [11.875 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 12/19/23 11:03:52.446
  Dec 19 11:03:52.447: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 11:03:52.452
  E1219 11:03:52.487731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:52.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:52.492
  E1219 11:03:53.488057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:54.488982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:55.489108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:56.489125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:56.544: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9969" for this suite. @ 12/19/23 11:03:56.564
• [4.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 12/19/23 11:03:56.595
  Dec 19 11:03:56.595: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:03:56.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:56.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:56.647
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:03:56.654
  E1219 11:03:57.489509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:58.489815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:59.490707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:00.491186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:04:00.714
  Dec 19 11:04:00.723: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-6f23a1a3-8f1a-4dcf-b8a7-92371f8a9604 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:04:00.771
  Dec 19 11:04:00.806: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7861" for this suite. @ 12/19/23 11:04:00.82
• [4.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 12/19/23 11:04:00.842
  Dec 19 11:04:00.842: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:04:00.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:04:00.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:04:00.908
  STEP: creating the pod @ 12/19/23 11:04:00.917
  STEP: submitting the pod to kubernetes @ 12/19/23 11:04:00.919
  W1219 11:04:00.940234      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E1219 11:04:01.492311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:02.495484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/19/23 11:04:02.968
  STEP: updating the pod @ 12/19/23 11:04:02.976
  E1219 11:04:03.493768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:03.510: INFO: Successfully updated pod "pod-update-activedeadlineseconds-47d57552-6ecb-4169-85ff-1732fefe9f75"
  E1219 11:04:04.494431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:05.495779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:06.495198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:07.495212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:07.554: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4372" for this suite. @ 12/19/23 11:04:07.666
• [6.857 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 12/19/23 11:04:07.701
  Dec 19 11:04:07.701: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 11:04:07.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:04:07.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:04:07.777
  STEP: Performing setup for networking test in namespace pod-network-test-7998 @ 12/19/23 11:04:07.792
  STEP: creating a selector @ 12/19/23 11:04:07.792
  STEP: Creating the service pods in kubernetes @ 12/19/23 11:04:07.792
  Dec 19 11:04:07.792: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 11:04:08.496234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:09.497179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:10.498340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:11.498916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:12.499189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:13.499406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:14.499672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:15.500012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:16.500336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:17.501030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:18.501328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:19.501525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 11:04:20.02
  E1219 11:04:20.502604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:21.503625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:22.110: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 11:04:22.110: INFO: Going to poll 10.233.64.62 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:04:22.120: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.62 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7998 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:04:22.120: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:04:22.123: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:04:22.124: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7998/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.62+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 11:04:22.503963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:23.452: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec 19 11:04:23.452: INFO: Going to poll 10.233.65.79 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:04:23.459: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.79 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7998 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:04:23.459: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:04:23.461: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:04:23.461: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7998/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.79+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 11:04:23.504487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:24.504605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:24.588: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec 19 11:04:24.588: INFO: Going to poll 10.233.66.217 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:04:24.598: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.217 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7998 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:04:24.598: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:04:24.600: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:04:24.600: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7998/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.217+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 11:04:25.504956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:25.715: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec 19 11:04:25.716: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7998" for this suite. @ 12/19/23 11:04:25.726
• [18.043 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 12/19/23 11:04:25.746
  Dec 19 11:04:25.746: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:04:25.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:04:25.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:04:25.795
  STEP: creating a replication controller @ 12/19/23 11:04:25.801
  Dec 19 11:04:25.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 create -f -'
  Dec 19 11:04:26.162: INFO: stderr: ""
  Dec 19 11:04:26.162: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 11:04:26.162
  Dec 19 11:04:26.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 11:04:26.406: INFO: stderr: ""
  Dec 19 11:04:26.407: INFO: stdout: "update-demo-nautilus-9r6h7 update-demo-nautilus-nlz5c "
  Dec 19 11:04:26.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods update-demo-nautilus-9r6h7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 11:04:26.506224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:26.627: INFO: stderr: ""
  Dec 19 11:04:26.627: INFO: stdout: ""
  Dec 19 11:04:26.627: INFO: update-demo-nautilus-9r6h7 is created but not running
  E1219 11:04:27.506753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:28.506665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:29.506971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:30.507551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:31.508333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:31.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 11:04:31.981: INFO: stderr: ""
  Dec 19 11:04:31.981: INFO: stdout: "update-demo-nautilus-9r6h7 update-demo-nautilus-nlz5c "
  Dec 19 11:04:31.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods update-demo-nautilus-9r6h7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 11:04:32.199: INFO: stderr: ""
  Dec 19 11:04:32.199: INFO: stdout: "true"
  Dec 19 11:04:32.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods update-demo-nautilus-9r6h7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 11:04:32.405: INFO: stderr: ""
  Dec 19 11:04:32.405: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 11:04:32.405: INFO: validating pod update-demo-nautilus-9r6h7
  Dec 19 11:04:32.422: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 11:04:32.422: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 11:04:32.422: INFO: update-demo-nautilus-9r6h7 is verified up and running
  Dec 19 11:04:32.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods update-demo-nautilus-nlz5c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 11:04:32.509348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:32.615: INFO: stderr: ""
  Dec 19 11:04:32.615: INFO: stdout: "true"
  Dec 19 11:04:32.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods update-demo-nautilus-nlz5c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 11:04:32.748: INFO: stderr: ""
  Dec 19 11:04:32.748: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 11:04:32.748: INFO: validating pod update-demo-nautilus-nlz5c
  Dec 19 11:04:32.761: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 11:04:32.761: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 11:04:32.761: INFO: update-demo-nautilus-nlz5c is verified up and running
  STEP: using delete to clean up resources @ 12/19/23 11:04:32.762
  Dec 19 11:04:32.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 delete --grace-period=0 --force -f -'
  Dec 19 11:04:32.885: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:04:32.886: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec 19 11:04:32.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get rc,svc -l name=update-demo --no-headers'
  Dec 19 11:04:33.154: INFO: stderr: "No resources found in kubectl-133 namespace.\n"
  Dec 19 11:04:33.154: INFO: stdout: ""
  Dec 19 11:04:33.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-133 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec 19 11:04:33.374: INFO: stderr: ""
  Dec 19 11:04:33.374: INFO: stdout: ""
  Dec 19 11:04:33.374: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-133" for this suite. @ 12/19/23 11:04:33.386
• [7.653 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 12/19/23 11:04:33.399
  Dec 19 11:04:33.400: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:04:33.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:04:33.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:04:33.471
  STEP: creating service multiprotocol-test in namespace services-1924 @ 12/19/23 11:04:33.477
  E1219 11:04:33.510236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating pod pod1 in namespace services-1924 @ 12/19/23 11:04:33.521
  STEP: Creating pod pod1 in namespace services-1924 @ 12/19/23 11:04:33.521
  E1219 11:04:34.514521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:35.511356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-1924 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 12/19/23 11:04:35.609
  Dec 19 11:04:35.628: INFO: successfully validated that service multiprotocol-test in namespace services-1924 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 12/19/23 11:04:35.629
  Dec 19 11:04:35.629: INFO: Creating new exec pod
  E1219 11:04:36.511439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:37.511981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:37.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80'
  Dec 19 11:04:37.951: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.49.67 80\nConnection to 10.233.49.67 80 port [tcp/http] succeeded!\n"
  Dec 19 11:04:37.951: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:04:37.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.49.67 80'
  E1219 11:04:38.512147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:39.512258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:40.512469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:41.512654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:42.230: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.49.67 80\nConnection to 10.233.49.67 80 port [udp/*] succeeded!\n"
  Dec 19 11:04:42.230: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 12/19/23 11:04:42.23
  Dec 19 11:04:42.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80'
  E1219 11:04:42.515213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:42.634: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.49.67 80\nConnection to 10.233.49.67 80 port [tcp/http] succeeded!\n"
  Dec 19 11:04:42.634: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:04:42.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.49.67 80'
  E1219 11:04:43.516106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:44.516183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:45.516584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:46.517029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:46.951: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.49.67 80\nConnection to 10.233.49.67 80 port [udp/*] succeeded!\n"
  Dec 19 11:04:46.951: INFO: stdout: ""
  Dec 19 11:04:46.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.49.67 80'
  E1219 11:04:47.517964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:48.518576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:49.521396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:50.521623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:51.293: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.49.67 80\nConnection to 10.233.49.67 80 port [udp/*] succeeded!\n"
  Dec 19 11:04:51.293: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 12/19/23 11:04:51.295
  Dec 19 11:04:51.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.49.67 80'
  E1219 11:04:51.524992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:52.525905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:53.527128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:54.528006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:55.528949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:55.647: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.49.67 80\nConnection to 10.233.49.67 80 port [udp/*] succeeded!\n"
  Dec 19 11:04:55.647: INFO: stdout: "pod1"
  Dec 19 11:04:55.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80'
  E1219 11:04:56.529243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:57.529315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:57.953: INFO: rc: 1
  Dec 19 11:04:57.953: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.49.67 80
  nc: connect to 10.233.49.67 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Dec 19 11:04:57.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80'
  E1219 11:04:58.530987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:59.530623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:00.289: INFO: rc: 1
  Dec 19 11:05:00.289: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.49.67 80
  nc: connect to 10.233.49.67 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Dec 19 11:05:00.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80'
  E1219 11:05:00.530814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:01.531348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:02.532702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:02.621: INFO: rc: 1
  Dec 19 11:05:02.621: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-1924 exec execpodr55ct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.67 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.49.67 80
  nc: connect to 10.233.49.67 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Dec 19 11:05:02.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1924" for this suite. @ 12/19/23 11:05:02.637
• [29.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 12/19/23 11:05:02.658
  Dec 19 11:05:02.658: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename security-context @ 12/19/23 11:05:02.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:02.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:02.712
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/19/23 11:05:02.721
  E1219 11:05:03.533734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:04.533797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:05.534066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:06.534698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:06.776
  Dec 19 11:05:06.794: INFO: Trying to get logs from node uikie9pei4sh-3 pod security-context-b7a5b3fc-505d-4c72-a32d-8c5b69160df4 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:05:06.823
  Dec 19 11:05:06.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-7317" for this suite. @ 12/19/23 11:05:06.878
• [4.241 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 12/19/23 11:05:06.9
  Dec 19 11:05:06.900: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:05:06.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:06.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:06.96
  Dec 19 11:05:06.984: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6121" for this suite. @ 12/19/23 11:05:07.014
• [0.129 seconds]
------------------------------
SS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 12/19/23 11:05:07.03
  Dec 19 11:05:07.031: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename endpointslicemirroring @ 12/19/23 11:05:07.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:07.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:07.089
  STEP: mirroring a new custom Endpoint @ 12/19/23 11:05:07.12
  Dec 19 11:05:07.149: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E1219 11:05:07.534309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:08.534901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 12/19/23 11:05:09.16
  Dec 19 11:05:09.186: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E1219 11:05:09.535170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:10.535174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 12/19/23 11:05:11.198
  Dec 19 11:05:11.222: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E1219 11:05:11.536318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:12.536987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:13.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-9131" for this suite. @ 12/19/23 11:05:13.243
• [6.232 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 12/19/23 11:05:13.263
  Dec 19 11:05:13.263: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:05:13.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:13.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:13.299
  STEP: creating a Pod with a static label @ 12/19/23 11:05:13.316
  STEP: watching for Pod to be ready @ 12/19/23 11:05:13.336
  Dec 19 11:05:13.340: INFO: observed Pod pod-test in namespace pods-3236 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Dec 19 11:05:13.350: INFO: observed Pod pod-test in namespace pods-3236 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC  }]
  Dec 19 11:05:13.387: INFO: observed Pod pod-test in namespace pods-3236 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC  }]
  E1219 11:05:13.536614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:14.465: INFO: Found Pod pod-test in namespace pods-3236 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:14 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:05:13 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 12/19/23 11:05:14.473
  STEP: getting the Pod and ensuring that it's patched @ 12/19/23 11:05:14.499
  STEP: replacing the Pod's status Ready condition to False @ 12/19/23 11:05:14.507
  E1219 11:05:14.537391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the Pod again to ensure its Ready conditions are False @ 12/19/23 11:05:14.541
  STEP: deleting the Pod via a Collection with a LabelSelector @ 12/19/23 11:05:14.541
  STEP: watching for the Pod to be deleted @ 12/19/23 11:05:14.563
  Dec 19 11:05:14.566: INFO: observed event type MODIFIED
  E1219 11:05:15.537666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:16.494: INFO: observed event type MODIFIED
  E1219 11:05:16.538366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:16.648: INFO: observed event type MODIFIED
  Dec 19 11:05:17.492: INFO: observed event type MODIFIED
  Dec 19 11:05:17.520: INFO: observed event type MODIFIED
  E1219 11:05:17.538486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:17.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3236" for this suite. @ 12/19/23 11:05:17.551
• [4.306 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 12/19/23 11:05:17.58
  Dec 19 11:05:17.580: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:05:17.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:17.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:17.629
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2005.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2005.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 12/19/23 11:05:17.636
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2005.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2005.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 12/19/23 11:05:17.636
  STEP: creating a pod to probe /etc/hosts @ 12/19/23 11:05:17.636
  STEP: submitting the pod to kubernetes @ 12/19/23 11:05:17.636
  E1219 11:05:18.538898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:19.539549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 11:05:19.677
  STEP: looking for the results for each expected name from probers @ 12/19/23 11:05:19.686
  Dec 19 11:05:19.747: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-2005/dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9: the server could not find the requested resource (get pods dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9)
  Dec 19 11:05:19.748: INFO: Lookups using dns-2005/dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9 failed for: [jessie_hosts@dns-querier-1]

  Dec 19 11:05:19.774: INFO: Pod client logs for webserver: 
  Dec 19 11:05:19.799: INFO: Pod client logs for querier: 
  Dec 19 11:05:19.828: INFO: Pod client logs for jessie-querier: 
  E1219 11:05:20.539128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:21.539979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:22.541425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:23.541447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:24.542329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:24.730: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-2005/dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9: the server could not find the requested resource (get pods dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9)
  Dec 19 11:05:24.731: INFO: Lookups using dns-2005/dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9 failed for: [jessie_hosts@dns-querier-1]

  Dec 19 11:05:24.749: INFO: Pod client logs for webserver: 
  Dec 19 11:05:24.766: INFO: Pod client logs for querier: 
  Dec 19 11:05:24.788: INFO: Pod client logs for jessie-querier: 
  E1219 11:05:25.543146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:26.543322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:27.543784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:28.543861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:29.544067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:29.724: INFO: DNS probes using dns-2005/dns-test-46ddbb27-e010-49f0-8b02-447e0f81e5e9 succeeded

  STEP: deleting the pod @ 12/19/23 11:05:29.725
  Dec 19 11:05:29.765: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2005" for this suite. @ 12/19/23 11:05:29.796
• [12.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 12/19/23 11:05:29.831
  Dec 19 11:05:29.831: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:05:29.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:29.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:29.903
  STEP: creating a collection of services @ 12/19/23 11:05:29.911
  Dec 19 11:05:29.913: INFO: Creating e2e-svc-a-lvkkb
  Dec 19 11:05:29.935: INFO: Creating e2e-svc-b-k5q8n
  Dec 19 11:05:29.959: INFO: Creating e2e-svc-c-d56ds
  STEP: deleting service collection @ 12/19/23 11:05:29.998
  Dec 19 11:05:30.078: INFO: Collection of services has been deleted
  Dec 19 11:05:30.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1237" for this suite. @ 12/19/23 11:05:30.089
• [0.275 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 12/19/23 11:05:30.107
  Dec 19 11:05:30.107: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:05:30.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:30.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:30.15
  STEP: Counting existing ResourceQuota @ 12/19/23 11:05:30.155
  E1219 11:05:30.544346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:31.545792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:32.545955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:33.546245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:34.546654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:05:35.167
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:05:35.179
  E1219 11:05:35.547969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:36.548244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 12/19/23 11:05:37.19
  STEP: Ensuring resource quota status captures replication controller creation @ 12/19/23 11:05:37.223
  E1219 11:05:37.549374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:38.550212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 12/19/23 11:05:39.233
  STEP: Ensuring resource quota status released usage @ 12/19/23 11:05:39.251
  E1219 11:05:39.551160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:40.551846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:41.261: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5526" for this suite. @ 12/19/23 11:05:41.271
• [11.179 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 12/19/23 11:05:41.287
  Dec 19 11:05:41.287: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:05:41.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:41.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:41.335
  STEP: Creating a simple DaemonSet "daemon-set" @ 12/19/23 11:05:41.399
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:05:41.416
  Dec 19 11:05:41.439: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:05:41.440: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:05:41.552199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:42.435: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:05:42.436: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:05:42.552386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:43.436: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:05:43.436: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 12/19/23 11:05:43.444
  Dec 19 11:05:43.505: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 11:05:43.506: INFO: Node uikie9pei4sh-3 is running 0 daemon pod, expected 1
  E1219 11:05:43.553391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:44.492: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 11:05:44.492: INFO: Node uikie9pei4sh-3 is running 0 daemon pod, expected 1
  E1219 11:05:44.553465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:45.491: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:05:45.491: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 12/19/23 11:05:45.492
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 11:05:45.507
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7502, will wait for the garbage collector to delete the pods @ 12/19/23 11:05:45.507
  E1219 11:05:45.554003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:45.592: INFO: Deleting DaemonSet.extensions daemon-set took: 27.741227ms
  Dec 19 11:05:45.694: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.796027ms
  E1219 11:05:46.554603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:46.904: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:05:46.904: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 11:05:46.912: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22935"},"items":null}

  Dec 19 11:05:46.923: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22935"},"items":null}

  Dec 19 11:05:46.952: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7502" for this suite. @ 12/19/23 11:05:46.968
• [5.701 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 12/19/23 11:05:46.99
  Dec 19 11:05:46.990: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:05:47
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:47.044
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:47.052
  E1219 11:05:47.554804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:48.555468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:49.130: INFO: Deleting pod "var-expansion-2d534ada-25e5-4fd7-bb8c-d20945370b2e" in namespace "var-expansion-6390"
  Dec 19 11:05:49.149: INFO: Wait up to 5m0s for pod "var-expansion-2d534ada-25e5-4fd7-bb8c-d20945370b2e" to be fully deleted
  E1219 11:05:49.555495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:50.555714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:51.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6390" for this suite. @ 12/19/23 11:05:51.183
• [4.209 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 12/19/23 11:05:51.201
  Dec 19 11:05:51.201: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename ingressclass @ 12/19/23 11:05:51.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:51.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:51.248
  STEP: getting /apis @ 12/19/23 11:05:51.256
  STEP: getting /apis/networking.k8s.io @ 12/19/23 11:05:51.268
  STEP: getting /apis/networking.k8s.iov1 @ 12/19/23 11:05:51.27
  STEP: creating @ 12/19/23 11:05:51.272
  STEP: getting @ 12/19/23 11:05:51.305
  STEP: listing @ 12/19/23 11:05:51.314
  STEP: watching @ 12/19/23 11:05:51.321
  Dec 19 11:05:51.321: INFO: starting watch
  STEP: patching @ 12/19/23 11:05:51.324
  STEP: updating @ 12/19/23 11:05:51.334
  Dec 19 11:05:51.344: INFO: waiting for watch events with expected annotations
  Dec 19 11:05:51.344: INFO: saw patched and updated annotations
  STEP: deleting @ 12/19/23 11:05:51.345
  STEP: deleting a collection @ 12/19/23 11:05:51.369
  Dec 19 11:05:51.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-5640" for this suite. @ 12/19/23 11:05:51.413
• [0.227 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 12/19/23 11:05:51.433
  Dec 19 11:05:51.433: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:05:51.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:51.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:51.482
  STEP: Creating the pod @ 12/19/23 11:05:51.49
  E1219 11:05:51.555839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:52.558093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:53.557229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:54.090: INFO: Successfully updated pod "annotationupdate3b9d51ea-0e8f-4ddf-8bb9-ff8701ef3dfc"
  E1219 11:05:54.557000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:55.567585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:56.119: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5907" for this suite. @ 12/19/23 11:05:56.13
• [4.709 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 12/19/23 11:05:56.155
  Dec 19 11:05:56.156: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename containers @ 12/19/23 11:05:56.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:56.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:56.197
  E1219 11:05:56.560732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:57.561108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:58.254: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4953" for this suite. @ 12/19/23 11:05:58.267
• [2.125 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 12/19/23 11:05:58.283
  Dec 19 11:05:58.283: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:05:58.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:58.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:58.331
  E1219 11:05:58.562661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:59.562466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:00.563789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:01.563929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:02.564655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:03.564854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:04.565302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:05.566050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:06.566503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:07.566887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:08.567753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:09.567808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:10.569131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:11.569997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:12.570983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:13.571066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:14.571196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/19/23 11:06:15.345
  E1219 11:06:15.572165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:16.572877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:17.573356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:18.574278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:19.575443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:06:20.354
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:06:20.362
  E1219 11:06:20.575510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:21.576396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 12/19/23 11:06:22.378
  STEP: Ensuring resource quota status captures configMap creation @ 12/19/23 11:06:22.407
  E1219 11:06:22.576964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:23.577059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 12/19/23 11:06:24.414
  STEP: Ensuring resource quota status released usage @ 12/19/23 11:06:24.426
  E1219 11:06:24.577486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:25.578123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:26.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5250" for this suite. @ 12/19/23 11:06:26.446
• [28.175 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 12/19/23 11:06:26.459
  Dec 19 11:06:26.459: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename job @ 12/19/23 11:06:26.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:06:26.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:06:26.503
  STEP: Creating a job @ 12/19/23 11:06:26.511
  STEP: Ensuring active pods == parallelism @ 12/19/23 11:06:26.526
  E1219 11:06:26.579069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:27.579341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 12/19/23 11:06:28.536
  STEP: deleting Job.batch foo in namespace job-2237, will wait for the garbage collector to delete the pods @ 12/19/23 11:06:28.536
  E1219 11:06:28.579416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:28.606: INFO: Deleting Job.batch foo took: 13.014068ms
  Dec 19 11:06:28.708: INFO: Terminating Job.batch foo pods took: 101.768836ms
  E1219 11:06:29.580900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 12/19/23 11:06:30.01
  Dec 19 11:06:30.016: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2237" for this suite. @ 12/19/23 11:06:30.026
• [3.577 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 12/19/23 11:06:30.04
  Dec 19 11:06:30.040: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:06:30.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:06:30.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:06:30.079
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 12/19/23 11:06:30.086
  Dec 19 11:06:30.107: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1219 11:06:30.581354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:31.581480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:32.582834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:33.582128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:34.582325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:35.125: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:06:35.125
  STEP: getting scale subresource @ 12/19/23 11:06:35.125
  STEP: updating a scale subresource @ 12/19/23 11:06:35.138
  STEP: verifying the replicaset Spec.Replicas was modified @ 12/19/23 11:06:35.153
  STEP: Patch a scale subresource @ 12/19/23 11:06:35.184
  Dec 19 11:06:35.252: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9888" for this suite. @ 12/19/23 11:06:35.265
• [5.260 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 12/19/23 11:06:35.301
  Dec 19 11:06:35.301: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:06:35.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:06:35.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:06:35.39
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/19/23 11:06:35.401
  E1219 11:06:35.583243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:36.583237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:37.583744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:38.583966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:06:39.474
  Dec 19 11:06:39.484: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-e92b316f-1142-48c4-b439-2ad6faeef70b container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:06:39.509
  Dec 19 11:06:39.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7583" for this suite. @ 12/19/23 11:06:39.566
  E1219 11:06:39.584605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.288 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 12/19/23 11:06:39.589
  Dec 19 11:06:39.589: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:06:39.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:06:39.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:06:39.669
  STEP: Creating pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751 @ 12/19/23 11:06:39.676
  E1219 11:06:40.587563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:41.585355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:06:41.721
  Dec 19 11:06:41.730: INFO: Initial restart count of pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 is 0
  Dec 19 11:06:41.738: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:42.586248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:43.586905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:43.747: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:44.587713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:45.588271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:45.759: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:46.588903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:47.589122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:47.767: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:48.589376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:49.589341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:49.776: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:50.589515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:51.590251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:51.788: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:52.591167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:53.591485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:53.797: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:54.592186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:55.592522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:55.810: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:56.593386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:57.594829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:57.822: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:06:58.595428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:59.596358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:06:59.834: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:00.596984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:01.597660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:01.842: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:02.598147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:03.599182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:03.852: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:04.599386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:05.600103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:05.862: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:06.601407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:07.608304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:07.872: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:08.602377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:09.603110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:09.884: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:10.603230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:11.603489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:11.893: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:12.603717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:13.603976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:13.903: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:14.604389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:15.605102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:15.914: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:16.605446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:17.606432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:17.924: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:18.606534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:19.606790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:19.933: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:20.607135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:21.607220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:21.942: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:22.607709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:23.608941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:23.950: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:24.608810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:25.609074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:25.961: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:26.610090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:27.611459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:27.971: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:28.612208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:29.612487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:29.982: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  E1219 11:07:30.612711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:31.613123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:31.992: INFO: Get pod busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 in namespace container-probe-751
  Dec 19 11:07:31.993: INFO: Restart count of pod container-probe-751/busybox-2ae08e20-0dd6-427f-9af8-8f7fd8e26e92 is now 1 (50.262056428s elapsed)
  STEP: deleting the pod @ 12/19/23 11:07:31.994
  Dec 19 11:07:32.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-751" for this suite. @ 12/19/23 11:07:32.035
• [52.461 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 12/19/23 11:07:32.051
  Dec 19 11:07:32.051: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:07:32.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:32.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:32.113
  STEP: creating a watch on configmaps with label A @ 12/19/23 11:07:32.121
  STEP: creating a watch on configmaps with label B @ 12/19/23 11:07:32.125
  STEP: creating a watch on configmaps with label A or B @ 12/19/23 11:07:32.128
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 12/19/23 11:07:32.131
  Dec 19 11:07:32.145: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23409 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:07:32.148: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23409 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 12/19/23 11:07:32.149
  Dec 19 11:07:32.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23410 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:07:32.175: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23410 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 12/19/23 11:07:32.177
  Dec 19 11:07:32.209: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23411 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:07:32.210: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23411 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 12/19/23 11:07:32.21
  Dec 19 11:07:32.229: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23412 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:07:32.229: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6727  f0080b0f-0c7c-444c-8ef8-52442abf91a1 23412 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 12/19/23 11:07:32.23
  Dec 19 11:07:32.242: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6727  ee9e3d29-ac87-4885-ba05-9c2d09dcb859 23413 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:07:32.242: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6727  ee9e3d29-ac87-4885-ba05-9c2d09dcb859 23413 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1219 11:07:32.613621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:33.614246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:34.614486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:35.614663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:36.614761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:37.615179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:38.615964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:39.616731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:40.617192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:41.617698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 12/19/23 11:07:42.243
  Dec 19 11:07:42.255: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6727  ee9e3d29-ac87-4885-ba05-9c2d09dcb859 23441 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:07:42.256: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6727  ee9e3d29-ac87-4885-ba05-9c2d09dcb859 23441 0 2023-12-19 11:07:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:07:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1219 11:07:42.619197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:43.619573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:44.619871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:45.619906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:46.620078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:47.620419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:48.621026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:49.622039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:50.622934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:51.624024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:52.258: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6727" for this suite. @ 12/19/23 11:07:52.28
• [20.249 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 12/19/23 11:07:52.302
  Dec 19 11:07:52.302: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:07:52.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:52.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:52.359
  STEP: creating the pod @ 12/19/23 11:07:52.368
  STEP: submitting the pod to kubernetes @ 12/19/23 11:07:52.369
  E1219 11:07:52.625177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:53.626469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/19/23 11:07:54.422
  STEP: updating the pod @ 12/19/23 11:07:54.433
  E1219 11:07:54.627108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:54.974: INFO: Successfully updated pod "pod-update-7a3eb144-8f1e-4099-aff1-27dca2f45c69"
  STEP: verifying the updated pod is in kubernetes @ 12/19/23 11:07:54.989
  Dec 19 11:07:54.997: INFO: Pod update OK
  Dec 19 11:07:54.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1108" for this suite. @ 12/19/23 11:07:55.008
• [2.724 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 12/19/23 11:07:55.039
  Dec 19 11:07:55.039: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:07:55.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:55.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:55.094
  STEP: Creating pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726 @ 12/19/23 11:07:55.102
  E1219 11:07:55.628229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:56.628986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:07:57.158
  Dec 19 11:07:57.168: INFO: Initial restart count of pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e is 0
  Dec 19 11:07:57.177: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:07:57.629289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:58.629643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:59.189: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:07:59.630176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:00.630361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:01.196: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:01.631253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:02.631984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:03.204: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:03.632156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:04.633149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:05.217: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:05.633312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:06.633502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:07.227: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:07.634365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:08.635228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:09.238: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:09.635237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:10.635598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:11.247: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:11.636649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:12.637069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:13.260: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:13.637159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:14.637285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:15.269: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:15.638168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:16.639123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:17.278: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:17.639381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:18.639782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:19.290: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:19.639797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:20.640226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:21.302: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:21.640254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:22.641444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:23.310: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:23.641978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:24.641748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:25.319: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:25.643417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:26.643366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:27.328: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:27.644041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:28.644072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:29.336: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:29.644637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:30.645425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:31.349: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:31.646671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:32.646506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:33.358: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:33.646866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:34.647058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:35.370: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:35.647677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:36.647469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:37.381: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:37.647700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:38.648468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:39.396: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:39.648846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:40.650127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:41.405: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:41.649983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:42.650562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:43.420: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:43.650863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:44.651085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:45.430: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:45.652003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:46.652559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:47.439: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:47.653216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:48.653521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:49.452: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:49.654623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:50.655188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:51.461: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:51.655162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:52.656107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:53.471: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:53.656805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:54.656965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:55.479: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:55.657527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:56.658169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:57.485: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:57.659185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:58.659365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:59.493: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:08:59.660440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:00.661062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:01.500: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:01.661369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:02.662238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:03.508: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:03.663034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:04.663110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:05.516: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:05.663516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:06.664905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:07.522: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:07.665052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:08.665713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:09.544: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:09.666712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:10.666930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:11.550: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:11.667036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:12.667352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:13.560: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:13.668196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:14.668438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:15.605: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:15.669057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:16.669628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:17.617: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:17.670518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:18.670792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:19.627: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:19.671339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:20.671146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:21.636: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:21.671758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:22.671681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:23.649: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:23.671892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:24.671986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:25.657: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:25.672393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:26.672484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:27.666: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:27.672946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:28.673144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:29.673703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:29.673: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:30.674802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:31.675046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:31.682: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:32.676319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:33.677768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:33.691: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:34.677710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:35.677769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:35.701: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:36.678422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:37.679284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:37.712: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:38.679595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:39.679601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:39.719: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:40.680157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:41.680727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:41.730: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:42.681172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:43.682194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:43.737: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:44.682931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:45.683213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:45.744: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:46.683511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:47.684425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:47.752: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:48.685060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:49.685579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:49.759: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:50.686457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:51.687421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:51.768: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:52.687970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:53.689072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:53.776: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:54.688688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:55.689079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:55.783: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:56.689214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:57.690169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:57.789: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:09:58.690644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:59.691011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:59.797: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:00.691112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:01.691338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:01.806: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:02.691463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:03.691730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:03.815: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:04.692937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:05.692493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:05.823: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:06.693434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:07.694740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:07.831: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:08.694672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:09.695111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:09.844: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:10.695023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:11.695267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:11.856: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:12.696334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:13.696703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:13.865: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:14.697422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:15.698919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:15.876: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:16.698604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:17.699261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:17.885: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:18.699493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:19.701496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:19.894: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:20.701472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:21.702250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:21.905: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:22.702141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:23.702729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:23.914: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:24.702777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:25.703432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:25.924: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:26.703642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:27.704345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:27.932: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:28.704462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:29.704692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:29.940: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:30.705243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:31.705191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:31.949: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:32.705857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:33.706146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:33.958: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:34.706494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:35.711130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:35.968: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:36.711468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:37.711507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:37.978: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:38.711617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:39.711997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:39.987: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:40.712170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:41.712882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:41.996: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:42.713065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:43.713277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:44.004: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:44.714311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:45.714484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:46.011: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:46.715103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:47.716033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:48.019: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:48.716204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:49.716390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:50.026: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:50.717009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:51.717212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:52.034: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:52.718103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:53.718712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:54.042: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:54.719416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:55.720078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:56.050: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:56.720847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:57.721855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:58.057: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:10:58.722108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:59.722364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:00.065: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:00.722584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:01.722804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:02.078: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:02.723254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:03.723307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:04.086: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:04.724454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:05.724549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:06.094: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:06.725041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:07.725077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:08.104: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:08.725154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:09.725652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:10.115: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:10.726611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:11.727298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:12.124: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:12.729050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:13.728943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:14.132: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:14.729724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:15.730270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:16.145: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:16.730229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:17.731373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:18.156: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:18.731561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:19.731730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:20.166: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:20.731898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:21.732206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:22.176: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:22.732260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:23.732496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:24.186: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:24.733361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:25.733989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:26.196: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:26.734820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:27.734982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:28.205: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:28.735176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:29.736227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:30.213: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:30.736502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:31.737114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:32.220: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:32.737365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:33.737493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:34.229: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:34.737913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:35.738157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:36.236: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:36.738507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:37.739372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:38.246: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:38.739951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:39.740068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:40.253: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:40.740471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:41.740588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:42.261: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:42.741436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:43.741597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:44.273: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:44.742327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:45.742511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:46.284: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:46.743740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:47.744402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:48.291: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:48.744687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:49.744990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:50.300: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:50.745086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:51.745314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:52.308: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:52.745996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:53.747203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:54.318: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:54.747272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:55.748007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:56.329: INFO: Get pod liveness-f0f9191f-5a82-480d-92c1-e7b7d63ed83e in namespace container-probe-1726
  E1219 11:11:56.747878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:57.748681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 12/19/23 11:11:58.331
  Dec 19 11:11:58.396: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1726" for this suite. @ 12/19/23 11:11:58.407
• [243.388 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 12/19/23 11:11:58.432
  Dec 19 11:11:58.432: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:11:58.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:11:58.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:11:58.482
  STEP: Creating configMap with name configmap-projected-all-test-volume-aaeefe46-21e0-4565-a71a-bcb960cace0a @ 12/19/23 11:11:58.489
  STEP: Creating secret with name secret-projected-all-test-volume-de5d9a0c-ff7c-4046-bac8-f28b272bbe9e @ 12/19/23 11:11:58.499
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 12/19/23 11:11:58.51
  E1219 11:11:58.749211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:59.749598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:00.750336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:01.750601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:12:02.555
  Dec 19 11:12:02.566: INFO: Trying to get logs from node uikie9pei4sh-3 pod projected-volume-1cd1b882-ab97-4782-8416-3fd2f41c15e2 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:12:02.596
  Dec 19 11:12:02.621: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6456" for this suite. @ 12/19/23 11:12:02.631
• [4.211 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 12/19/23 11:12:02.646
  Dec 19 11:12:02.647: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename csistoragecapacity @ 12/19/23 11:12:02.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:02.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:02.692
  STEP: getting /apis @ 12/19/23 11:12:02.697
  STEP: getting /apis/storage.k8s.io @ 12/19/23 11:12:02.703
  STEP: getting /apis/storage.k8s.io/v1 @ 12/19/23 11:12:02.705
  STEP: creating @ 12/19/23 11:12:02.708
  STEP: watching @ 12/19/23 11:12:02.737
  Dec 19 11:12:02.737: INFO: starting watch
  E1219 11:12:02.750544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting @ 12/19/23 11:12:02.753
  STEP: listing in namespace @ 12/19/23 11:12:02.759
  STEP: listing across namespaces @ 12/19/23 11:12:02.765
  STEP: patching @ 12/19/23 11:12:02.772
  STEP: updating @ 12/19/23 11:12:02.781
  Dec 19 11:12:02.791: INFO: waiting for watch events with expected annotations in namespace
  Dec 19 11:12:02.792: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 12/19/23 11:12:02.792
  STEP: deleting a collection @ 12/19/23 11:12:02.815
  Dec 19 11:12:02.845: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-9321" for this suite. @ 12/19/23 11:12:02.851
• [0.216 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 12/19/23 11:12:02.865
  Dec 19 11:12:02.865: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename job @ 12/19/23 11:12:02.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:02.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:02.903
  STEP: Creating a job @ 12/19/23 11:12:02.909
  STEP: Ensure pods equal to parallelism count is attached to the job @ 12/19/23 11:12:02.92
  E1219 11:12:03.751567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:04.751819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 12/19/23 11:12:04.932
  STEP: updating /status @ 12/19/23 11:12:04.954
  STEP: get /status @ 12/19/23 11:12:04.979
  Dec 19 11:12:04.986: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9656" for this suite. @ 12/19/23 11:12:04.995
• [2.141 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 12/19/23 11:12:05.008
  Dec 19 11:12:05.008: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 11:12:05.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:05.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:05.048
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 12/19/23 11:12:05.074
  E1219 11:12:05.751957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:06.752703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:07.753294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:08.754332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:09.755449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:10.755592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:11.756213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:12.756443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:13.757127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:14.757167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:15.757612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:16.758479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:17.758478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:18.758652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:19.759234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:20.759572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:21.760857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 12/19/23 11:12:22.231
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 12/19/23 11:12:22.24
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 12/19/23 11:12:22.259
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 12/19/23 11:12:22.259
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 12/19/23 11:12:22.325
  E1219 11:12:22.760969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:23.761580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 12/19/23 11:12:24.36
  E1219 11:12:24.761814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:25.762758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 12/19/23 11:12:26.387
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 12/19/23 11:12:26.417
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 12/19/23 11:12:26.418
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 12/19/23 11:12:26.48
  E1219 11:12:26.763610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 12/19/23 11:12:27.501
  E1219 11:12:27.763969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 12/19/23 11:12:28.519
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 12/19/23 11:12:28.532
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 12/19/23 11:12:28.532
  Dec 19 11:12:28.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5148" for this suite. @ 12/19/23 11:12:28.621
• [23.633 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 12/19/23 11:12:28.642
  Dec 19 11:12:28.643: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:12:28.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:28.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:28.698
  STEP: Creating a test headless service @ 12/19/23 11:12:28.704
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6453 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6453;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6453 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6453;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6453.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6453.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6453.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6453.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6453.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6453.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6453.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6453.svc;check="$$(dig +notcp +noall +answer +search 221.35.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.35.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.35.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.35.221_tcp@PTR;sleep 1; done
   @ 12/19/23 11:12:28.758
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6453 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6453;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6453 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6453;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6453.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6453.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6453.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6453.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6453.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6453.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6453.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6453.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6453.svc;check="$$(dig +notcp +noall +answer +search 221.35.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.35.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.35.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.35.221_tcp@PTR;sleep 1; done
   @ 12/19/23 11:12:28.759
  STEP: creating a pod to probe DNS @ 12/19/23 11:12:28.761
  STEP: submitting the pod to kubernetes @ 12/19/23 11:12:28.763
  E1219 11:12:28.764619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:29.765081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:30.766240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 11:12:30.821
  STEP: looking for the results for each expected name from probers @ 12/19/23 11:12:30.83
  Dec 19 11:12:30.842: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.849: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.860: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.868: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.876: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.887: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.896: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.903: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.961: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.973: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.983: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:30.995: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:31.002: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:31.014: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:31.027: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:31.035: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:31.081: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 wheezy_udp@dns-test-service.dns-6453.svc wheezy_tcp@dns-test-service.dns-6453.svc wheezy_udp@_http._tcp.dns-test-service.dns-6453.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6453.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc jessie_udp@_http._tcp.dns-test-service.dns-6453.svc jessie_tcp@_http._tcp.dns-test-service.dns-6453.svc]

  Dec 19 11:12:31.100: INFO: Pod client logs for webserver: 
  Dec 19 11:12:31.113: INFO: Pod client logs for querier: 
  Dec 19 11:12:31.134: INFO: Pod client logs for jessie-querier: 
  E1219 11:12:31.766749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:32.766878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:33.768231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:34.768061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:35.768259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:35.845: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.861: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.873: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.884: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.897: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.906: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.975: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.983: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.991: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:35.999: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:36.006: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:36.014: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:36.078: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 wheezy_udp@dns-test-service.dns-6453.svc wheezy_tcp@dns-test-service.dns-6453.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc]

  Dec 19 11:12:36.095: INFO: Pod client logs for webserver: 
  Dec 19 11:12:36.108: INFO: Pod client logs for querier: 
  Dec 19 11:12:36.139: INFO: Pod client logs for jessie-querier: 
  E1219 11:12:36.769222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:37.769511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:38.769852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:39.771994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:40.772283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:40.841: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.853: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.863: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.872: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.880: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.892: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.955: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.963: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.971: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.979: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:40.992: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:41.001: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:41.057: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 wheezy_udp@dns-test-service.dns-6453.svc wheezy_tcp@dns-test-service.dns-6453.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc]

  Dec 19 11:12:41.074: INFO: Pod client logs for webserver: 
  Dec 19 11:12:41.091: INFO: Pod client logs for querier: 
  Dec 19 11:12:41.109: INFO: Pod client logs for jessie-querier: 
  E1219 11:12:41.772808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:42.773790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:43.774741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:44.775515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:45.775852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:45.841: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.853: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.863: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.873: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.885: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.896: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.964: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.980: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:45.991: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:46.002: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:46.017: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:46.027: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:46.109: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 wheezy_udp@dns-test-service.dns-6453.svc wheezy_tcp@dns-test-service.dns-6453.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc]

  Dec 19 11:12:46.132: INFO: Pod client logs for webserver: 
  Dec 19 11:12:46.148: INFO: Pod client logs for querier: 
  Dec 19 11:12:46.169: INFO: Pod client logs for jessie-querier: 
  E1219 11:12:46.776420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:47.776473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:48.776675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:49.777108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:50.777770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:50.840: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.847: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.853: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.862: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.869: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.878: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.934: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.940: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.947: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.954: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.961: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:50.968: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:51.016: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 wheezy_udp@dns-test-service.dns-6453.svc wheezy_tcp@dns-test-service.dns-6453.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc]

  Dec 19 11:12:51.035: INFO: Pod client logs for webserver: 
  Dec 19 11:12:51.050: INFO: Pod client logs for querier: 
  Dec 19 11:12:51.063: INFO: Pod client logs for jessie-querier: 
  E1219 11:12:51.778290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:52.779484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:53.779869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:54.781904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:55.782685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:55.845: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.859: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.871: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.880: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.889: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.900: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.976: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.983: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.993: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:55.999: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:56.013: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:56.022: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:12:56.087: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 wheezy_udp@dns-test-service.dns-6453.svc wheezy_tcp@dns-test-service.dns-6453.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc]

  Dec 19 11:12:56.103: INFO: Pod client logs for webserver: 
  Dec 19 11:12:56.119: INFO: Pod client logs for querier: 
  Dec 19 11:12:56.141: INFO: Pod client logs for jessie-querier: 
  E1219 11:12:56.782543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:57.783596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:58.784653      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:59.787658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:00.785421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:00.840: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.849: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.858: INFO: Unable to read wheezy_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.865: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.942: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.951: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.960: INFO: Unable to read jessie_udp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.968: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453 from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.976: INFO: Unable to read jessie_udp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:00.986: INFO: Unable to read jessie_tcp@dns-test-service.dns-6453.svc from pod dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3: the server could not find the requested resource (get pods dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3)
  Dec 19 11:13:01.042: INFO: Lookups using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6453 wheezy_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6453 jessie_tcp@dns-test-service.dns-6453 jessie_udp@dns-test-service.dns-6453.svc jessie_tcp@dns-test-service.dns-6453.svc]

  Dec 19 11:13:01.056: INFO: Pod client logs for webserver: 
  Dec 19 11:13:01.074: INFO: Pod client logs for querier: 
  Dec 19 11:13:01.090: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:01.785778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:02.786699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:03.787504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:04.788408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:05.788148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:06.102: INFO: DNS probes using dns-6453/dns-test-1f7d835d-7059-41c9-890b-2a49704d9fb3 succeeded

  STEP: deleting the pod @ 12/19/23 11:13:06.103
  STEP: deleting the test service @ 12/19/23 11:13:06.148
  STEP: deleting the test headless service @ 12/19/23 11:13:06.234
  Dec 19 11:13:06.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6453" for this suite. @ 12/19/23 11:13:06.289
• [37.691 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 12/19/23 11:13:06.365
  Dec 19 11:13:06.366: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename job @ 12/19/23 11:13:06.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:06.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:06.445
  STEP: Creating a suspended job @ 12/19/23 11:13:06.463
  STEP: Patching the Job @ 12/19/23 11:13:06.481
  STEP: Watching for Job to be patched @ 12/19/23 11:13:06.53
  Dec 19 11:13:06.534: INFO: Event ADDED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d] and annotations: map[]
  Dec 19 11:13:06.534: INFO: Event MODIFIED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d] and annotations: map[]
  Dec 19 11:13:06.534: INFO: Event MODIFIED found for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[]
  STEP: Updating the job @ 12/19/23 11:13:06.535
  STEP: Watching for Job to be updated @ 12/19/23 11:13:06.555
  Dec 19 11:13:06.560: INFO: Event MODIFIED found for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  Dec 19 11:13:06.560: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 12/19/23 11:13:06.56
  Dec 19 11:13:06.572: INFO: Job: e2e-rmf2d as labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched]
  STEP: Waiting for job to complete @ 12/19/23 11:13:06.573
  E1219 11:13:06.789340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:07.789016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:08.789700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:09.789888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:10.791642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:11.791876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:12.792447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:13.792877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:14.793184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:15.793775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 12/19/23 11:13:16.586
  STEP: Watching for Job to be deleted @ 12/19/23 11:13:16.612
  Dec 19 11:13:16.618: INFO: Event MODIFIED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  Dec 19 11:13:16.620: INFO: Event MODIFIED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  Dec 19 11:13:16.620: INFO: Event MODIFIED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  Dec 19 11:13:16.620: INFO: Event MODIFIED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  Dec 19 11:13:16.620: INFO: Event MODIFIED observed for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  Dec 19 11:13:16.621: INFO: Event DELETED found for Job e2e-rmf2d in namespace job-4115 with labels: map[e2e-job-label:e2e-rmf2d e2e-rmf2d:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 12/19/23 11:13:16.621
  Dec 19 11:13:16.629: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4115" for this suite. @ 12/19/23 11:13:16.644
• [10.297 seconds]
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 12/19/23 11:13:16.663
  Dec 19 11:13:16.663: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:13:16.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:16.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:16.751
  STEP: creating the pod @ 12/19/23 11:13:16.761
  STEP: setting up watch @ 12/19/23 11:13:16.761
  E1219 11:13:16.794183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: submitting the pod to kubernetes @ 12/19/23 11:13:16.871
  STEP: verifying the pod is in kubernetes @ 12/19/23 11:13:16.891
  STEP: verifying pod creation was observed @ 12/19/23 11:13:16.904
  E1219 11:13:17.795029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:18.795150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 12/19/23 11:13:18.939
  STEP: verifying pod deletion was observed @ 12/19/23 11:13:18.955
  E1219 11:13:19.796050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:19.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-611" for this suite. @ 12/19/23 11:13:19.842
• [3.196 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 12/19/23 11:13:19.876
  Dec 19 11:13:19.876: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:13:19.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:19.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:19.935
  STEP: Creating configMap with name configmap-test-volume-01757877-259e-4609-9cad-26348d3ea7ae @ 12/19/23 11:13:19.944
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:13:19.962
  E1219 11:13:20.796434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:21.796941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:22.797049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:23.798022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:13:24.016
  Dec 19 11:13:24.026: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-7223e101-558e-4cda-b244-e68d6095ee53 container configmap-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:13:24.04
  Dec 19 11:13:24.093: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4568" for this suite. @ 12/19/23 11:13:24.103
• [4.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 12/19/23 11:13:24.124
  Dec 19 11:13:24.125: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 11:13:24.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:24.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:24.174
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 11:13:24.191
  E1219 11:13:24.798114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:25.798438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:26.798428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:27.799482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 11:13:28.248
  E1219 11:13:28.800468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:29.801544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/19/23 11:13:30.291
  STEP: delete the pod with lifecycle hook @ 12/19/23 11:13:30.343
  E1219 11:13:30.801866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:31.802079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:32.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9228" for this suite. @ 12/19/23 11:13:32.417
• [8.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 12/19/23 11:13:32.438
  Dec 19 11:13:32.438: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:13:32.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:32.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:32.493
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:13:32.502
  E1219 11:13:32.803092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:33.803802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:34.804870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:35.806859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:13:36.562
  Dec 19 11:13:36.572: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-e85211e6-034f-4252-8549-c6839d51d0bb container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:13:36.59
  Dec 19 11:13:36.625: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-966" for this suite. @ 12/19/23 11:13:36.636
• [4.218 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 12/19/23 11:13:36.661
  Dec 19 11:13:36.661: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:13:36.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:36.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:36.711
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-7405e41a-6751-422a-a11f-88b6598ff99e @ 12/19/23 11:13:36.732
  STEP: Creating the pod @ 12/19/23 11:13:36.749
  E1219 11:13:36.807563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:37.807854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:38.813245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-7405e41a-6751-422a-a11f-88b6598ff99e @ 12/19/23 11:13:38.831
  STEP: waiting to observe update in volume @ 12/19/23 11:13:38.846
  E1219 11:13:39.808445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:40.808430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:41.808829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:42.809434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:43.810015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:44.810750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:45.811383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:46.812103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:47.812161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:48.813123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:49.813370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:50.814213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:51.814621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:52.814711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:53.814771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:54.815348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:55.815700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:56.816567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:57.817605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:58.818187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:59.818476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:00.818589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:01.818737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:02.819097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:03.819903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:04.820144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:05.820293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:06.820531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:07.820798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:08.821896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:09.822982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:10.823105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:11.823854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:12.824242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:13.824618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:14.825089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:15.825329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:16.825492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:17.826248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:18.826524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:19.827391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:20.829129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:21.828937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:22.829592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:23.830482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:24.830892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:25.832167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:26.832302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:27.832271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:28.832407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:29.833263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:30.833441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:31.834117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:32.834344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:33.834718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:34.835080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:35.835195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:36.835453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:37.836642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:38.836919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:39.837649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:40.837788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:41.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2787" for this suite. @ 12/19/23 11:14:41.632
• [65.007 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 12/19/23 11:14:41.669
  Dec 19 11:14:41.669: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 11:14:41.674
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:41.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:41.735
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 11:14:41.754
  E1219 11:14:41.838690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:42.839318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 11:14:43.817
  E1219 11:14:43.839276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:44.839852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:45.840189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 12/19/23 11:14:45.86
  E1219 11:14:46.841659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:47.841992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 12/19/23 11:14:47.899
  Dec 19 11:14:47.949: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4533" for this suite. @ 12/19/23 11:14:47.961
• [6.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 12/19/23 11:14:47.983
  Dec 19 11:14:47.983: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:14:47.986
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:48.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:48.051
  STEP: creating service multi-endpoint-test in namespace services-7728 @ 12/19/23 11:14:48.057
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7728 to expose endpoints map[] @ 12/19/23 11:14:48.099
  Dec 19 11:14:48.135: INFO: successfully validated that service multi-endpoint-test in namespace services-7728 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7728 @ 12/19/23 11:14:48.136
  E1219 11:14:48.842508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:49.843345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7728 to expose endpoints map[pod1:[100]] @ 12/19/23 11:14:50.205
  Dec 19 11:14:50.231: INFO: successfully validated that service multi-endpoint-test in namespace services-7728 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-7728 @ 12/19/23 11:14:50.231
  E1219 11:14:50.843683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:51.844494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7728 to expose endpoints map[pod1:[100] pod2:[101]] @ 12/19/23 11:14:52.274
  Dec 19 11:14:52.306: INFO: successfully validated that service multi-endpoint-test in namespace services-7728 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 12/19/23 11:14:52.307
  Dec 19 11:14:52.307: INFO: Creating new exec pod
  E1219 11:14:52.845058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:53.846114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:54.847088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:55.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7728 exec execpodnrz4c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Dec 19 11:14:55.794: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Dec 19 11:14:55.794: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:14:55.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7728 exec execpodnrz4c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.14.1 80'
  E1219 11:14:55.848289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:56.155: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.14.1 80\nConnection to 10.233.14.1 80 port [tcp/http] succeeded!\n"
  Dec 19 11:14:56.155: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:14:56.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7728 exec execpodnrz4c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Dec 19 11:14:56.456: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Dec 19 11:14:56.456: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:14:56.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-7728 exec execpodnrz4c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.14.1 81'
  E1219 11:14:56.848115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:56.854: INFO: stderr: "+ nc -v -t -w 2 10.233.14.1 81\n+ echo hostName\nConnection to 10.233.14.1 81 port [tcp/*] succeeded!\n"
  Dec 19 11:14:56.854: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7728 @ 12/19/23 11:14:56.854
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7728 to expose endpoints map[pod2:[101]] @ 12/19/23 11:14:56.913
  Dec 19 11:14:56.967: INFO: successfully validated that service multi-endpoint-test in namespace services-7728 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-7728 @ 12/19/23 11:14:56.967
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7728 to expose endpoints map[] @ 12/19/23 11:14:57.063
  Dec 19 11:14:57.087: INFO: successfully validated that service multi-endpoint-test in namespace services-7728 exposes endpoints map[]
  Dec 19 11:14:57.150: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7728" for this suite. @ 12/19/23 11:14:57.163
• [9.221 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 12/19/23 11:14:57.214
  Dec 19 11:14:57.214: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:14:57.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:57.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:57.267
  STEP: Creating configMap with name configmap-test-upd-ab33989a-5538-4b30-a55d-c116156194d6 @ 12/19/23 11:14:57.289
  STEP: Creating the pod @ 12/19/23 11:14:57.305
  E1219 11:14:57.848557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:58.848331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 12/19/23 11:14:59.348
  STEP: Waiting for pod with binary data @ 12/19/23 11:14:59.363
  Dec 19 11:14:59.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7034" for this suite. @ 12/19/23 11:14:59.387
• [2.190 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 12/19/23 11:14:59.406
  Dec 19 11:14:59.406: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:14:59.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:59.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:59.455
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:14:59.462
  E1219 11:14:59.848489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:00.849075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:15:01.506
  Dec 19 11:15:01.513: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-4cadc88f-907d-4926-ad4a-a68639e81f88 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:15:01.526
  Dec 19 11:15:01.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-863" for this suite. @ 12/19/23 11:15:01.584
• [2.202 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 12/19/23 11:15:01.608
  Dec 19 11:15:01.608: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 11:15:01.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:15:01.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:15:01.655
  STEP: Creating a ReplaceConcurrent cronjob @ 12/19/23 11:15:01.661
  STEP: Ensuring a job is scheduled @ 12/19/23 11:15:01.673
  E1219 11:15:01.849112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:02.850216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:03.850777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:04.851567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:05.853043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:06.853724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:07.853609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:08.854504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:09.854274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:10.854722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:11.855564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:12.856092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:13.856023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:14.856341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:15.857176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:16.857786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:17.858113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:18.858247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:19.859248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:20.859533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:21.859923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:22.860277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:23.861604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:24.863177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:25.861914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:26.863120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:27.863153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:28.863874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:29.863899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:30.864835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:31.866593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:32.867529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:33.868835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:34.868712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:35.869829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:36.871124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:37.871373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:38.871617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:39.871963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:40.872822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:41.873519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:42.873753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:43.874708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:44.875025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:45.876164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:46.876455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:47.876647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:48.876938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:49.877320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:50.878185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:51.879761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:52.880021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:53.880213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:54.880411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:55.881335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:56.882015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:57.881980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:58.882032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:59.883141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:00.883075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 12/19/23 11:16:01.684
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/19/23 11:16:01.69
  STEP: Ensuring the job is replaced with a new one @ 12/19/23 11:16:01.698
  E1219 11:16:01.884166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:02.884646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:03.884596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:04.884893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:05.886056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:06.886440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:07.887839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:08.887666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:09.888493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:10.888665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:11.888494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:12.889011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:13.889430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:14.889727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:15.890666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:16.890706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:17.890889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:18.891798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:19.893142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:20.894410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:21.894741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:22.895825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:23.896867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:24.896946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:25.897041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:26.897710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:27.897813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:28.899002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:29.899921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:30.901000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:31.901576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:32.902177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:33.903203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:34.903460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:35.903682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:36.904338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:37.905452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:38.905389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:39.905717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:40.906414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:41.907028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:42.908060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:43.907898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:44.907831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:45.908465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:46.908844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:47.909893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:48.911444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:49.911900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:50.911729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:51.912351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:52.912355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:53.912939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:54.913207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:55.913361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:56.914163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:57.915042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:58.915184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:59.915401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:00.915718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 12/19/23 11:17:01.707
  Dec 19 11:17:01.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7993" for this suite. @ 12/19/23 11:17:01.74
• [120.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 12/19/23 11:17:01.768
  Dec 19 11:17:01.768: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:17:01.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:01.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:01.852
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:17:01.863
  E1219 11:17:01.916837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:02.916662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:03.916857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:04.917521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:05.918039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:17:05.92
  Dec 19 11:17:05.926: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-e2a33a78-768c-4d73-857e-500921b18107 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:17:05.97
  Dec 19 11:17:06.000: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8930" for this suite. @ 12/19/23 11:17:06.013
• [4.259 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 12/19/23 11:17:06.031
  Dec 19 11:17:06.031: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:17:06.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:06.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:06.084
  STEP: Creating secret with name secret-test-bea4311f-d437-49e8-bee4-87cbc62995c6 @ 12/19/23 11:17:06.093
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:17:06.112
  E1219 11:17:06.919704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:07.919393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:08.920615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:09.921454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:17:10.161
  Dec 19 11:17:10.170: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-61434f38-d321-49c2-9ee5-48fb89ad6013 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:17:10.185
  Dec 19 11:17:10.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8720" for this suite. @ 12/19/23 11:17:10.223
• [4.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 12/19/23 11:17:10.254
  Dec 19 11:17:10.255: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:17:10.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:10.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:10.312
  STEP: Creating configMap with name projected-configmap-test-volume-afaad639-23ee-4daa-ba37-e77df5f4d175 @ 12/19/23 11:17:10.321
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:17:10.337
  E1219 11:17:10.921303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:11.921415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:12.922187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:13.923323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:17:14.445
  Dec 19 11:17:14.454: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-dd11e093-1b5d-4d4d-b681-554a820bd154 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:17:14.473
  Dec 19 11:17:14.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5872" for this suite. @ 12/19/23 11:17:14.523
• [4.289 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 12/19/23 11:17:14.551
  Dec 19 11:17:14.551: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 11:17:14.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:14.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:14.604
  Dec 19 11:17:14.612: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 11:17:14.635: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 11:17:14.649: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-1 before test
  Dec 19 11:17:14.676: INFO: coredns-76f75df574-4529k from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.677: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 11:17:14.677: INFO: coredns-76f75df574-kjr7r from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.677: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 11:17:14.677: INFO: kube-addon-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.678: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 11:17:14.678: INFO: kube-apiserver-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.678: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 11:17:14.678: INFO: kube-controller-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.678: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 11:17:14.678: INFO: kube-flannel-ds-qldcz from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.678: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 11:17:14.678: INFO: kube-proxy-wp7g9 from kube-system started at 2023-12-19 09:44:36 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.679: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:17:14.679: INFO: kube-scheduler-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.679: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 11:17:14.679: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qgn7f from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:17:14.679: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:17:14.679: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 11:17:14.679: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-2 before test
  Dec 19 11:17:14.699: INFO: kube-addon-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.699: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 11:17:14.699: INFO: kube-apiserver-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.699: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 11:17:14.699: INFO: kube-controller-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.699: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 11:17:14.700: INFO: kube-flannel-ds-znfxv from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.700: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 11:17:14.700: INFO: kube-proxy-q4vm6 from kube-system started at 2023-12-19 09:45:19 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.700: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:17:14.700: INFO: kube-scheduler-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.700: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 11:17:14.700: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qvrr8 from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:17:14.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:17:14.700: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 11:17:14.700: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-3 before test
  Dec 19 11:17:14.723: INFO: replace-28383076-wxp2w from cronjob-7993 started at 2023-12-19 11:16:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.723: INFO: 	Container c ready: true, restart count 0
  Dec 19 11:17:14.724: INFO: replace-28383077-td5tp from cronjob-7993 started at 2023-12-19 11:17:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.724: INFO: 	Container c ready: true, restart count 0
  Dec 19 11:17:14.724: INFO: kube-flannel-ds-z7dwl from kube-system started at 2023-12-19 10:27:36 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.724: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 11:17:14.725: INFO: kube-proxy-lh685 from kube-system started at 2023-12-19 09:45:40 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.725: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:17:14.725: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:56 +0000 UTC (1 container statuses recorded)
  Dec 19 11:17:14.725: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 11:17:14.725: INFO: sonobuoy-e2e-job-b395aad1bffb4cbc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:17:14.725: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 11:17:14.726: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:17:14.726: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-8llvc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:17:14.726: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:17:14.726: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/19/23 11:17:14.727
  E1219 11:17:14.923995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:15.925165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/19/23 11:17:16.792
  STEP: Trying to apply a random label on the found node. @ 12/19/23 11:17:16.817
  STEP: verifying the node has the label kubernetes.io/e2e-5410dfea-8900-4318-b380-b5ec5fa787ce 42 @ 12/19/23 11:17:16.842
  STEP: Trying to relaunch the pod, now with labels. @ 12/19/23 11:17:16.853
  E1219 11:17:16.924483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:17.925604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-5410dfea-8900-4318-b380-b5ec5fa787ce off the node uikie9pei4sh-3 @ 12/19/23 11:17:18.891
  E1219 11:17:18.926136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-5410dfea-8900-4318-b380-b5ec5fa787ce @ 12/19/23 11:17:18.952
  Dec 19 11:17:18.974: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6883" for this suite. @ 12/19/23 11:17:19.001
• [4.476 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 12/19/23 11:17:19.028
  Dec 19 11:17:19.028: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:17:19.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:19.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:19.105
  Dec 19 11:17:19.110: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:17:19.926752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:20.927070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:21.928178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:22.587: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9070" for this suite. @ 12/19/23 11:17:22.603
• [3.589 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 12/19/23 11:17:22.621
  Dec 19 11:17:22.621: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:17:22.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:22.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:22.668
  STEP: Creating a test headless service @ 12/19/23 11:17:22.675
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local;sleep 1; done
   @ 12/19/23 11:17:22.69
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1623.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local;sleep 1; done
   @ 12/19/23 11:17:22.69
  STEP: creating a pod to probe DNS @ 12/19/23 11:17:22.69
  STEP: submitting the pod to kubernetes @ 12/19/23 11:17:22.69
  E1219 11:17:22.929243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:23.932192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:24.930535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:25.931236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 11:17:26.751
  STEP: looking for the results for each expected name from probers @ 12/19/23 11:17:26.759
  Dec 19 11:17:26.799: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:26.806: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:26.813: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:26.829: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:26.836: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:26.836: INFO: Lookups using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b failed for: [wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local]

  Dec 19 11:17:26.853: INFO: Pod client logs for webserver: 
  Dec 19 11:17:26.869: INFO: Pod client logs for querier: 
  Dec 19 11:17:26.884: INFO: Pod client logs for jessie-querier: 
  E1219 11:17:26.931226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:27.931468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:28.931961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:29.933058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:30.933305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:31.807: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:31.822: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:31.865: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:31.877: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:31.877: INFO: Lookups using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b failed for: [wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local]

  Dec 19 11:17:31.898: INFO: Pod client logs for webserver: 
  Dec 19 11:17:31.916: INFO: Pod client logs for querier: 
  Dec 19 11:17:31.931: INFO: Pod client logs for jessie-querier: 
  E1219 11:17:31.933549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:32.934168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:33.935107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:34.935278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:35.935614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:36.793: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:36.802: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:36.829: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:36.837: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:36.837: INFO: Lookups using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b failed for: [wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local]

  Dec 19 11:17:36.888: INFO: Pod client logs for webserver: 
  Dec 19 11:17:36.905: INFO: Pod client logs for querier: 
  Dec 19 11:17:36.920: INFO: Pod client logs for jessie-querier: 
  E1219 11:17:36.937165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:37.937198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:38.937311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:39.937535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:40.938727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:41.806: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:41.815: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:41.840: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:41.847: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:41.847: INFO: Lookups using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b failed for: [wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local]

  Dec 19 11:17:41.862: INFO: Pod client logs for webserver: 
  Dec 19 11:17:41.876: INFO: Pod client logs for querier: 
  Dec 19 11:17:41.889: INFO: Pod client logs for jessie-querier: 
  E1219 11:17:41.939163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:42.939594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:43.939953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:44.940084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:45.940975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:46.798: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:46.815: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:46.860: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:46.872: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:46.872: INFO: Lookups using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b failed for: [wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local]

  Dec 19 11:17:46.886: INFO: Pod client logs for webserver: 
  Dec 19 11:17:46.906: INFO: Pod client logs for querier: 
  Dec 19 11:17:46.919: INFO: Pod client logs for jessie-querier: 
  E1219 11:17:46.941175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:47.941815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:48.941652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:49.942412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:50.942655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:51.790: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:51.801: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:51.831: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:51.840: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local from pod dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b: the server could not find the requested resource (get pods dns-test-59163252-dac7-449e-891a-6d7f8b30394b)
  Dec 19 11:17:51.841: INFO: Lookups using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b failed for: [wheezy_udp@dns-test-service-2.dns-1623.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1623.svc.cluster.local jessie_udp@dns-test-service-2.dns-1623.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1623.svc.cluster.local]

  Dec 19 11:17:51.857: INFO: Pod client logs for webserver: 
  Dec 19 11:17:51.873: INFO: Pod client logs for querier: 
  Dec 19 11:17:51.887: INFO: Pod client logs for jessie-querier: 
  E1219 11:17:51.943160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:52.943625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:53.944548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:54.945232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:55.945426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:56.834: INFO: DNS probes using dns-1623/dns-test-59163252-dac7-449e-891a-6d7f8b30394b succeeded

  STEP: deleting the pod @ 12/19/23 11:17:56.835
  STEP: deleting the test headless service @ 12/19/23 11:17:56.866
  Dec 19 11:17:56.893: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1623" for this suite. @ 12/19/23 11:17:56.939
  E1219 11:17:56.945807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [34.345 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 12/19/23 11:17:56.985
  Dec 19 11:17:56.986: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:17:57.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:57.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:57.066
  Dec 19 11:17:57.075: INFO: Creating deployment "test-recreate-deployment"
  Dec 19 11:17:57.089: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Dec 19 11:17:57.108: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
  E1219 11:17:57.946342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:58.947829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:17:59.157: INFO: Waiting deployment "test-recreate-deployment" to complete
  Dec 19 11:17:59.166: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Dec 19 11:17:59.194: INFO: Updating deployment test-recreate-deployment
  Dec 19 11:17:59.195: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Dec 19 11:17:59.485: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c2ce9d5c-9db1-4788-a4bb-4b2b84113656",
      ResourceVersion: (string) (len=5) "25479",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:17:59.516: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "367593a7-43f7-4d10-8b23-50f71827ff56",
      ResourceVersion: (string) (len=5) "25476",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "c2ce9d5c-9db1-4788-a4bb-4b2b84113656",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 32 63 65 39 64  35 63 2d 39 64 62 31 2d  |\"c2ce9d5c-9db1-|
              00000120  34 37 38 38 2d 61 34 62  62 2d 34 62 32 62 38 34  |4788-a4bb-4b2b84|
              00000130  31 31 33 36 35 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |113656\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:17:59.521: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Dec 19 11:17:59.522: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-dd4bc9d6d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8805da1f-ca22-4de3-a1e4-924e68f01bf1",
      ResourceVersion: (string) (len=5) "25468",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "c2ce9d5c-9db1-4788-a4bb-4b2b84113656",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 32 63 65 39 64  35 63 2d 39 64 62 31 2d  |\"c2ce9d5c-9db1-|
              00000120  34 37 38 38 2d 61 34 62  62 2d 34 62 32 62 38 34  |4788-a4bb-4b2b84|
              00000130  31 31 33 36 35 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |113656\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:17:59.535: INFO: Pod "test-recreate-deployment-76fb77d45-rw9w4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-rw9w4",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-7127",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7805b906-01ae-4e62-ad81-9855e25b2773",
      ResourceVersion: (string) (len=5) "25480",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "367593a7-43f7-4d10-8b23-50f71827ff56",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 36  37 35 39 33 61 37 2d 34  |d\":\"367593a7-4|
              00000090  33 66 37 2d 34 64 31 30  2d 38 62 32 33 2d 35 30  |3f7-4d10-8b23-50|
              000000a0  66 37 31 38 32 37 66 66  35 36 5c 22 7d 22 3a 7b  |f71827ff56\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kj6ns",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kj6ns",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:17:59.553: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7127" for this suite. @ 12/19/23 11:17:59.574
• [2.633 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 12/19/23 11:17:59.622
  Dec 19 11:17:59.623: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:17:59.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:17:59.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:17:59.687
  STEP: create deployment with httpd image @ 12/19/23 11:17:59.697
  Dec 19 11:17:59.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5594 create -f -'
  E1219 11:17:59.955830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:18:00.141: INFO: stderr: ""
  Dec 19 11:18:00.141: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 12/19/23 11:18:00.141
  Dec 19 11:18:00.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5594 diff -f -'
  Dec 19 11:18:00.669: INFO: rc: 1
  Dec 19 11:18:00.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5594 delete -f -'
  Dec 19 11:18:00.922: INFO: stderr: ""
  Dec 19 11:18:00.922: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Dec 19 11:18:00.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5594" for this suite. @ 12/19/23 11:18:00.938
  E1219 11:18:00.956463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [1.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 12/19/23 11:18:00.973
  Dec 19 11:18:00.973: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:18:00.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:18:01.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:18:01.027
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/19/23 11:18:01.036
  E1219 11:18:01.957483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:02.957815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:03.958452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:04.959294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:18:05.101
  Dec 19 11:18:05.117: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-326daf36-0a65-4ce8-a03b-47e4c51923ea container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:18:05.151
  Dec 19 11:18:05.195: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6949" for this suite. @ 12/19/23 11:18:05.215
• [4.261 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 12/19/23 11:18:05.237
  Dec 19 11:18:05.237: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 11:18:05.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:18:05.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:18:05.312
  STEP: Performing setup for networking test in namespace pod-network-test-6382 @ 12/19/23 11:18:05.322
  STEP: creating a selector @ 12/19/23 11:18:05.323
  STEP: Creating the service pods in kubernetes @ 12/19/23 11:18:05.324
  Dec 19 11:18:05.324: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 11:18:05.959010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:06.959213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:07.960400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:08.960846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:09.961346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:10.962125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:11.963645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:12.963471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:13.964007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:14.963984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:15.964729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:16.965036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:17.965751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:18.965844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:19.966650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:20.967355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:21.968614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:22.969069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:23.970538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:24.970404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:25.971259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:26.971358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 11:18:27.721
  E1219 11:18:27.972096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:28.972816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:18:29.786: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 11:18:29.786: INFO: Going to poll 10.233.64.67 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:18:29.792: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.67:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6382 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:18:29.793: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:18:29.795: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:18:29.795: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6382/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.67%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec 19 11:18:29.969: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec 19 11:18:29.969: INFO: Going to poll 10.233.65.83 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  E1219 11:18:29.973349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:18:29.975: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.83:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6382 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:18:29.975: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:18:29.977: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:18:29.977: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6382/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.83%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec 19 11:18:30.083: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec 19 11:18:30.083: INFO: Going to poll 10.233.66.18 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:18:30.091: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.18:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6382 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:18:30.092: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:18:30.093: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:18:30.094: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6382/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.18%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec 19 11:18:30.205: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec 19 11:18:30.205: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6382" for this suite. @ 12/19/23 11:18:30.215
• [24.995 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 12/19/23 11:18:30.234
  Dec 19 11:18:30.234: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:18:30.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:18:30.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:18:30.28
  STEP: Creating service test in namespace statefulset-1151 @ 12/19/23 11:18:30.287
  Dec 19 11:18:30.334: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:18:30.973885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:31.973802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:32.974788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:33.975310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:34.975568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:35.976275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:36.977000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:37.979335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:38.977760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:39.978220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:18:40.323: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 12/19/23 11:18:40.336
  W1219 11:18:40.351519      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Dec 19 11:18:40.374: INFO: Found 1 stateful pods, waiting for 2
  E1219 11:18:40.978555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:41.981348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:42.980018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:43.980940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:44.981134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:45.981899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:46.981879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:47.982156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:48.982850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:49.982948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:18:50.382: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:18:50.382: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 12/19/23 11:18:50.396
  STEP: Delete all of the StatefulSets @ 12/19/23 11:18:50.405
  STEP: Verify that StatefulSets have been deleted @ 12/19/23 11:18:50.419
  Dec 19 11:18:50.427: INFO: Deleting all statefulset in ns statefulset-1151
  Dec 19 11:18:50.456: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1151" for this suite. @ 12/19/23 11:18:50.469
• [20.260 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 12/19/23 11:18:50.501
  Dec 19 11:18:50.501: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:18:50.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:18:50.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:18:50.596
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:18:50.603
  E1219 11:18:50.983666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:51.983801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:52.984671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:53.985273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:18:54.679
  Dec 19 11:18:54.688: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-08cb0532-1bf8-4a16-87f5-480cd2d06acf container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:18:54.703
  Dec 19 11:18:54.735: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7214" for this suite. @ 12/19/23 11:18:54.743
• [4.257 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 12/19/23 11:18:54.759
  Dec 19 11:18:54.759: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:18:54.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:18:54.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:18:54.803
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/19/23 11:18:54.81
  E1219 11:18:54.986546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:55.986579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:56.987524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:57.987634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:18:58.863
  Dec 19 11:18:58.872: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-529de3e3-3b52-49ce-83c5-3c0ad2d1e605 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:18:58.891
  Dec 19 11:18:58.941: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6619" for this suite. @ 12/19/23 11:18:58.95
• [4.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 12/19/23 11:18:58.976
  Dec 19 11:18:58.977: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:18:58.981
  E1219 11:18:58.988551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:18:59.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:18:59.019
  STEP: creating the pod @ 12/19/23 11:18:59.025
  Dec 19 11:18:59.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 create -f -'
  Dec 19 11:18:59.456: INFO: stderr: ""
  Dec 19 11:18:59.457: INFO: stdout: "pod/pause created\n"
  E1219 11:18:59.988641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:00.989072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 12/19/23 11:19:01.473
  Dec 19 11:19:01.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 label pods pause testing-label=testing-label-value'
  Dec 19 11:19:01.637: INFO: stderr: ""
  Dec 19 11:19:01.637: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 12/19/23 11:19:01.637
  Dec 19 11:19:01.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 get pod pause -L testing-label'
  Dec 19 11:19:01.847: INFO: stderr: ""
  Dec 19 11:19:01.847: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 12/19/23 11:19:01.848
  Dec 19 11:19:01.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 label pods pause testing-label-'
  E1219 11:19:01.989666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:02.107: INFO: stderr: ""
  Dec 19 11:19:02.107: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 12/19/23 11:19:02.107
  Dec 19 11:19:02.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 get pod pause -L testing-label'
  Dec 19 11:19:02.272: INFO: stderr: ""
  Dec 19 11:19:02.272: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 12/19/23 11:19:02.272
  Dec 19 11:19:02.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 delete --grace-period=0 --force -f -'
  Dec 19 11:19:02.426: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:19:02.426: INFO: stdout: "pod \"pause\" force deleted\n"
  Dec 19 11:19:02.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 get rc,svc -l name=pause --no-headers'
  Dec 19 11:19:02.593: INFO: stderr: "No resources found in kubectl-914 namespace.\n"
  Dec 19 11:19:02.593: INFO: stdout: ""
  Dec 19 11:19:02.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-914 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec 19 11:19:02.716: INFO: stderr: ""
  Dec 19 11:19:02.716: INFO: stdout: ""
  Dec 19 11:19:02.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-914" for this suite. @ 12/19/23 11:19:02.725
• [3.764 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 12/19/23 11:19:02.741
  Dec 19 11:19:02.741: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:19:02.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:02.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:02.783
  Dec 19 11:19:02.788: INFO: Creating simple deployment test-new-deployment
  Dec 19 11:19:02.820: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E1219 11:19:02.990637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:03.991782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 12/19/23 11:19:04.853
  STEP: updating a scale subresource @ 12/19/23 11:19:04.86
  STEP: verifying the deployment Spec.Replicas was modified @ 12/19/23 11:19:04.872
  STEP: Patch a scale subresource @ 12/19/23 11:19:04.877
  Dec 19 11:19:04.940: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9332",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3403d881-2294-4ea4-b913-3d988d9c2f94",
      ResourceVersion: (string) (len=5) "26013",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581542,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581542,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581542,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:19:04.955: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9332",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "807d3ad3-94b3-4ab3-a30e-cb06bbcfc5ab",
      ResourceVersion: (string) (len=5) "26016",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581542,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "3403d881-2294-4ea4-b913-3d988d9c2f94",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 34 30 33 64 38  38 31 2d 32 32 39 34 2d  |\"3403d881-2294-|
              00000120  34 65 61 34 2d 62 39 31  33 2d 33 64 39 38 38 64  |4ea4-b913-3d988d|
              00000130  39 63 32 66 39 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9c2f94\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:19:04.968: INFO: Pod "test-new-deployment-557759b7c7-blzlw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-blzlw",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-9332",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a7ecbc2e-a340-44a4-89b4-0545ac2be10c",
      ResourceVersion: (string) (len=5) "26014",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581544,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "807d3ad3-94b3-4ab3-a30e-cb06bbcfc5ab",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 30  37 64 33 61 64 33 2d 39  |d\":\"807d3ad3-9|
              00000090  34 62 33 2d 34 61 62 33  2d 61 33 30 65 2d 63 62  |4b3-4ab3-a30e-cb|
              000000a0  30 36 62 62 63 66 63 35  61 62 5c 22 7d 22 3a 7b  |06bbcfc5ab\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xknln",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xknln",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:19:04.973: INFO: Pod "test-new-deployment-557759b7c7-f4b74" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-f4b74",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-9332",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6a555c0e-aa81-4e79-ae9a-40a77dc29c8e",
      ResourceVersion: (string) (len=5) "25996",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581542,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "807d3ad3-94b3-4ab3-a30e-cb06bbcfc5ab",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581542,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 30  37 64 33 61 64 33 2d 39  |d\":\"807d3ad3-9|
              00000090  34 62 33 2d 34 61 62 33  2d 61 33 30 65 2d 63 62  |4b3-4ab3-a30e-cb|
              000000a0  30 36 62 62 63 66 63 35  61 62 5c 22 7d 22 3a 7b  |06bbcfc5ab\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  32 35 5c 22 7d 22 3a 7b  |.233.66.25\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j8vcw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j8vcw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581542,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581542,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=12) "10.233.66.25",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.25"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581542,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838581543,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://f553577ffaa9114a28fd2c65be93de947e3f128dd1a1880e2e6c94863d00821b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:19:04.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9332" for this suite. @ 12/19/23 11:19:04.991
  E1219 11:19:04.992129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.271 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 12/19/23 11:19:05.013
  Dec 19 11:19:05.013: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename events @ 12/19/23 11:19:05.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:05.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:05.078
  STEP: Create set of events @ 12/19/23 11:19:05.087
  STEP: get a list of Events with a label in the current namespace @ 12/19/23 11:19:05.119
  STEP: delete a list of events @ 12/19/23 11:19:05.125
  Dec 19 11:19:05.126: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/19/23 11:19:05.177
  Dec 19 11:19:05.187: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8643" for this suite. @ 12/19/23 11:19:05.2
• [0.202 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 12/19/23 11:19:05.215
  Dec 19 11:19:05.215: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:19:05.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:05.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:05.256
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8926 @ 12/19/23 11:19:05.262
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/19/23 11:19:05.289
  STEP: creating service externalsvc in namespace services-8926 @ 12/19/23 11:19:05.29
  STEP: creating replication controller externalsvc in namespace services-8926 @ 12/19/23 11:19:05.316
  I1219 11:19:05.330251      13 runners.go:197] Created replication controller with name: externalsvc, namespace: services-8926, replica count: 2
  E1219 11:19:05.995312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:06.995543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:07.996029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:19:08.384394      13 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 12/19/23 11:19:08.391
  Dec 19 11:19:08.419: INFO: Creating new exec pod
  E1219 11:19:08.995989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:09.996217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:10.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-8926 exec execpodtt9ts -- /bin/sh -x -c nslookup clusterip-service.services-8926.svc.cluster.local'
  Dec 19 11:19:10.991: INFO: stderr: "+ nslookup clusterip-service.services-8926.svc.cluster.local\n"
  Dec 19 11:19:10.991: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-8926.svc.cluster.local\tcanonical name = externalsvc.services-8926.svc.cluster.local.\nName:\texternalsvc.services-8926.svc.cluster.local\nAddress: 10.233.56.224\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8926, will wait for the garbage collector to delete the pods @ 12/19/23 11:19:10.991
  E1219 11:19:10.996399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:11.119: INFO: Deleting ReplicationController externalsvc took: 66.707394ms
  Dec 19 11:19:11.221: INFO: Terminating ReplicationController externalsvc pods took: 101.552265ms
  E1219 11:19:11.997491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:12.998098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:13.999879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:14.280: INFO: Cleaning up the ClusterIP to ExternalName test service
  Dec 19 11:19:14.315: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8926" for this suite. @ 12/19/23 11:19:14.331
• [9.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 12/19/23 11:19:14.426
  Dec 19 11:19:14.427: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:19:14.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:14.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:14.481
  STEP: Creating configMap with name configmap-test-volume-8661da88-3219-413b-b386-1954a86a7171 @ 12/19/23 11:19:14.492
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:19:14.503
  E1219 11:19:14.999568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:16.000834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:17.001073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:18.001476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:19:18.548
  Dec 19 11:19:18.556: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-fb704f93-9369-452d-b7c2-e31c0d140793 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:19:18.588
  Dec 19 11:19:18.617: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6844" for this suite. @ 12/19/23 11:19:18.628
• [4.220 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 12/19/23 11:19:18.647
  Dec 19 11:19:18.647: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:19:18.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:18.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:18.699
  STEP: Creating service test in namespace statefulset-2824 @ 12/19/23 11:19:18.706
  STEP: Creating statefulset ss in namespace statefulset-2824 @ 12/19/23 11:19:18.722
  Dec 19 11:19:18.750: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:19:19.002456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:20.003251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:21.004846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:22.004871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:23.005043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:24.006135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:25.006379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:26.006949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:27.007502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:28.008724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:28.751: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 12/19/23 11:19:28.772
  STEP: updating a scale subresource @ 12/19/23 11:19:28.781
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/19/23 11:19:28.8
  STEP: Patch a scale subresource @ 12/19/23 11:19:28.809
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/19/23 11:19:28.826
  Dec 19 11:19:28.845: INFO: Deleting all statefulset in ns statefulset-2824
  Dec 19 11:19:28.859: INFO: Scaling statefulset ss to 0
  E1219 11:19:29.009371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:30.010165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:31.010375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:32.011320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:33.011321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:34.012141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:35.012647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:36.013239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:37.013626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:38.014309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:38.929: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:19:38.939: INFO: Deleting statefulset ss
  Dec 19 11:19:38.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2824" for this suite. @ 12/19/23 11:19:38.998
  E1219 11:19:39.015384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [20.370 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 12/19/23 11:19:39.021
  Dec 19 11:19:39.022: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:19:39.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:39.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:39.08
  STEP: creating a watch on configmaps with a certain label @ 12/19/23 11:19:39.085
  STEP: creating a new configmap @ 12/19/23 11:19:39.086
  STEP: modifying the configmap once @ 12/19/23 11:19:39.098
  STEP: changing the label value of the configmap @ 12/19/23 11:19:39.119
  STEP: Expecting to observe a delete notification for the watched object @ 12/19/23 11:19:39.142
  Dec 19 11:19:39.143: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7233  1a89ad09-f8c9-45a3-b239-f95a87394c42 26311 0 2023-12-19 11:19:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:19:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:19:39.144: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7233  1a89ad09-f8c9-45a3-b239-f95a87394c42 26313 0 2023-12-19 11:19:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:19:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:19:39.145: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7233  1a89ad09-f8c9-45a3-b239-f95a87394c42 26314 0 2023-12-19 11:19:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:19:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 12/19/23 11:19:39.145
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 12/19/23 11:19:39.174
  E1219 11:19:40.017072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:41.016666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:42.017677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:43.018771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:44.019344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:45.019607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:46.019854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:47.020088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:48.020281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:49.020910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 12/19/23 11:19:49.175
  STEP: modifying the configmap a third time @ 12/19/23 11:19:49.198
  STEP: deleting the configmap @ 12/19/23 11:19:49.218
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 12/19/23 11:19:49.235
  Dec 19 11:19:49.236: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7233  1a89ad09-f8c9-45a3-b239-f95a87394c42 26349 0 2023-12-19 11:19:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:19:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:19:49.237: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7233  1a89ad09-f8c9-45a3-b239-f95a87394c42 26350 0 2023-12-19 11:19:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:19:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:19:49.238: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7233  1a89ad09-f8c9-45a3-b239-f95a87394c42 26352 0 2023-12-19 11:19:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:19:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:19:49.239: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7233" for this suite. @ 12/19/23 11:19:49.259
• [10.268 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 12/19/23 11:19:49.291
  Dec 19 11:19:49.292: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename job @ 12/19/23 11:19:49.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:49.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:49.336
  STEP: Creating a job @ 12/19/23 11:19:49.343
  STEP: Ensuring job reaches completions @ 12/19/23 11:19:49.359
  E1219 11:19:50.021060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:51.021273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:52.022299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:53.023414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:54.023605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:55.024114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:56.029007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:57.029199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:58.030323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:59.031366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:59.368: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4635" for this suite. @ 12/19/23 11:19:59.376
• [10.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 12/19/23 11:19:59.394
  Dec 19 11:19:59.394: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:19:59.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:59.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:59.442
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 11:19:59.447
  Dec 19 11:19:59.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-3843 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec 19 11:19:59.683: INFO: stderr: ""
  Dec 19 11:19:59.683: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 12/19/23 11:19:59.683
  Dec 19 11:19:59.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-3843 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  Dec 19 11:19:59.894: INFO: stderr: ""
  Dec 19 11:19:59.894: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 11:19:59.894
  Dec 19 11:19:59.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-3843 delete pods e2e-test-httpd-pod'
  E1219 11:20:00.032240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:01.032567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:02.033167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:03.033541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:04.034239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:05.034392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:06.034639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:07.035025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:08.035369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:09.035840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:10.036102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:11.036327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:12.036513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:13.037125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:14.038014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:15.038809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:16.039363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:17.039577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:18.040192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:19.040937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:20.042741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:21.042141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:22.042489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:23.043040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:24.042950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:25.043022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:26.043229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:27.043351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:28.044252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:29.045093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:30.045884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:31.046473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:31.692: INFO: stderr: ""
  Dec 19 11:20:31.692: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec 19 11:20:31.693: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3843" for this suite. @ 12/19/23 11:20:31.706
• [32.330 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 12/19/23 11:20:31.738
  Dec 19 11:20:31.739: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename subpath @ 12/19/23 11:20:31.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:20:31.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:20:31.788
  STEP: Setting up data @ 12/19/23 11:20:31.796
  STEP: Creating pod pod-subpath-test-projected-gjh6 @ 12/19/23 11:20:31.821
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 11:20:31.821
  E1219 11:20:32.048690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:33.049235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:34.049540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:35.049666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:36.050372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:37.051400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:38.054526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:39.052843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:40.053343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:41.053518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:42.054644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:43.054767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:44.055690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:45.056519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:46.056581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:47.056945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:48.058456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:49.058424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:50.059241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:51.059970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:52.060895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:53.061256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:54.062139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:55.062826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:20:55.964
  Dec 19 11:20:55.974: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-subpath-test-projected-gjh6 container test-container-subpath-projected-gjh6: <nil>
  STEP: delete the pod @ 12/19/23 11:20:56.017
  STEP: Deleting pod pod-subpath-test-projected-gjh6 @ 12/19/23 11:20:56.059
  Dec 19 11:20:56.059: INFO: Deleting pod "pod-subpath-test-projected-gjh6" in namespace "subpath-2252"
  E1219 11:20:56.062894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:56.068: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2252" for this suite. @ 12/19/23 11:20:56.083
• [24.362 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 12/19/23 11:20:56.102
  Dec 19 11:20:56.102: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:20:56.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:20:56.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:20:56.16
  STEP: Setting up server cert @ 12/19/23 11:20:56.225
  E1219 11:20:57.063449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:20:57.438
  STEP: Deploying the webhook pod @ 12/19/23 11:20:57.457
  STEP: Wait for the deployment to be ready @ 12/19/23 11:20:57.49
  Dec 19 11:20:57.517: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:20:58.065248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:59.064995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:59.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:21:00.065245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:01.065958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:01.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:21:02.066241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:03.066451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:03.573: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:21:04.066985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:05.067378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:05.559: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:21:06.069308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:07.068073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:07.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 20, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:21:08.069046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:09.068957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:21:09.561
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:21:09.601
  E1219 11:21:10.069122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:10.602: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 11:21:10.615: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:21:11.070138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5495-crds.webhook.example.com via the AdmissionRegistration API @ 12/19/23 11:21:11.148
  STEP: Creating a custom resource while v1 is storage version @ 12/19/23 11:21:11.206
  E1219 11:21:12.070312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:13.070484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 12/19/23 11:21:13.461
  STEP: Patching the custom resource while v2 is storage version @ 12/19/23 11:21:13.495
  E1219 11:21:14.071830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:14.438: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5668" for this suite. @ 12/19/23 11:21:14.451
  STEP: Destroying namespace "webhook-markers-3219" for this suite. @ 12/19/23 11:21:14.469
• [18.383 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 12/19/23 11:21:14.492
  Dec 19 11:21:14.492: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:21:14.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:14.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:14.547
  STEP: creating a new configmap @ 12/19/23 11:21:14.554
  STEP: modifying the configmap once @ 12/19/23 11:21:14.571
  STEP: modifying the configmap a second time @ 12/19/23 11:21:14.597
  STEP: deleting the configmap @ 12/19/23 11:21:14.613
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 12/19/23 11:21:14.629
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 12/19/23 11:21:14.633
  Dec 19 11:21:14.634: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9310  3bc43e5c-5fc3-4b86-891e-5d6559cdeac8 26752 0 2023-12-19 11:21:14 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-19 11:21:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:21:14.634: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9310  3bc43e5c-5fc3-4b86-891e-5d6559cdeac8 26753 0 2023-12-19 11:21:14 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-19 11:21:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:21:14.635: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9310" for this suite. @ 12/19/23 11:21:14.654
• [0.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 12/19/23 11:21:14.679
  Dec 19 11:21:14.679: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/19/23 11:21:14.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:14.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:14.73
  STEP: creating @ 12/19/23 11:21:14.743
  STEP: getting @ 12/19/23 11:21:14.82
  STEP: listing in namespace @ 12/19/23 11:21:14.832
  STEP: patching @ 12/19/23 11:21:14.841
  STEP: deleting @ 12/19/23 11:21:14.86
  Dec 19 11:21:14.882: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4739" for this suite. @ 12/19/23 11:21:14.895
• [0.232 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 12/19/23 11:21:14.914
  Dec 19 11:21:14.915: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:21:14.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:14.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:14.969
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/19/23 11:21:14.976
  E1219 11:21:15.071748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:16.071980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:17.074113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:18.074687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:21:19.027
  Dec 19 11:21:19.052: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-c9780863-bad9-4f76-adbe-6f5b5ee53a1d container test-container: <nil>
  E1219 11:21:19.075305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/19/23 11:21:19.082
  Dec 19 11:21:19.117: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4623" for this suite. @ 12/19/23 11:21:19.126
• [4.225 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 12/19/23 11:21:19.141
  Dec 19 11:21:19.141: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:21:19.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:19.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:19.187
  Dec 19 11:21:19.194: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:21:20.076049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:21.075797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 11:21:22.035579      13 warnings.go:70] unknown field "alpha"
  W1219 11:21:22.035650      13 warnings.go:70] unknown field "beta"
  W1219 11:21:22.035679      13 warnings.go:70] unknown field "delta"
  W1219 11:21:22.035716      13 warnings.go:70] unknown field "epsilon"
  W1219 11:21:22.035744      13 warnings.go:70] unknown field "gamma"
  E1219 11:21:22.076485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:22.663: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-549" for this suite. @ 12/19/23 11:21:22.677
• [3.556 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 12/19/23 11:21:22.698
  Dec 19 11:21:22.698: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:21:22.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:22.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:22.758
  Dec 19 11:21:22.763: INFO: Creating ReplicaSet my-hostname-basic-2ec9e419-0606-4ab2-be37-f58ced7b7d9b
  Dec 19 11:21:22.791: INFO: Pod name my-hostname-basic-2ec9e419-0606-4ab2-be37-f58ced7b7d9b: Found 0 pods out of 1
  E1219 11:21:23.077073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:24.077430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:25.078019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:26.077910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:27.078639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:27.800: INFO: Pod name my-hostname-basic-2ec9e419-0606-4ab2-be37-f58ced7b7d9b: Found 1 pods out of 1
  Dec 19 11:21:27.800: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2ec9e419-0606-4ab2-be37-f58ced7b7d9b" is running
  Dec 19 11:21:27.810: INFO: Pod "my-hostname-basic-2ec9e419-0606-4ab2-be37-f58ced7b7d9b-rw9r4" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:21:23 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:21:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:21:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:21:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:21:22 +0000 UTC Reason: Message:}])
  Dec 19 11:21:27.811: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/19/23 11:21:27.811
  Dec 19 11:21:27.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8487" for this suite. @ 12/19/23 11:21:27.855
• [5.174 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 12/19/23 11:21:27.872
  Dec 19 11:21:27.873: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:21:27.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:27.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:27.917
  STEP: creating Agnhost RC @ 12/19/23 11:21:27.929
  Dec 19 11:21:27.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-1761 create -f -'
  E1219 11:21:28.079324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:28.350: INFO: stderr: ""
  Dec 19 11:21:28.350: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/19/23 11:21:28.35
  E1219 11:21:29.079518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:29.363: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:21:29.363: INFO: Found 0 / 1
  E1219 11:21:30.079668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:30.358: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:21:30.358: INFO: Found 1 / 1
  Dec 19 11:21:30.358: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 12/19/23 11:21:30.358
  Dec 19 11:21:30.366: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:21:30.366: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 11:21:30.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-1761 patch pod agnhost-primary-m7lr8 -p {"metadata":{"annotations":{"x":"y"}}}'
  Dec 19 11:21:30.621: INFO: stderr: ""
  Dec 19 11:21:30.621: INFO: stdout: "pod/agnhost-primary-m7lr8 patched\n"
  STEP: checking annotations @ 12/19/23 11:21:30.621
  Dec 19 11:21:30.626: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:21:30.626: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 11:21:30.627: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1761" for this suite. @ 12/19/23 11:21:30.634
• [2.776 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 12/19/23 11:21:30.651
  Dec 19 11:21:30.652: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename containers @ 12/19/23 11:21:30.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:30.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:30.691
  STEP: Creating a pod to test override command @ 12/19/23 11:21:30.696
  E1219 11:21:31.080365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:32.080959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:33.081344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:34.081299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:21:34.735
  Dec 19 11:21:34.741: INFO: Trying to get logs from node uikie9pei4sh-3 pod client-containers-b8548cfb-6011-4702-aa12-c68a93f481e4 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:21:34.755
  Dec 19 11:21:34.782: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6954" for this suite. @ 12/19/23 11:21:34.793
• [4.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 12/19/23 11:21:34.805
  Dec 19 11:21:34.805: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 11:21:34.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:34.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:34.846
  Dec 19 11:21:34.868: INFO: Endpoints addresses: [192.168.121.241 192.168.121.77] , ports: [6443]
  Dec 19 11:21:34.869: INFO: EndpointSlices addresses: [192.168.121.241 192.168.121.77] , ports: [6443]
  Dec 19 11:21:34.870: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4579" for this suite. @ 12/19/23 11:21:34.882
• [0.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 12/19/23 11:21:34.903
  Dec 19 11:21:34.903: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:21:34.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:34.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:34.952
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:21:34.957
  E1219 11:21:35.082332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:36.082521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:37.083025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:38.083292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:21:39.025
  Dec 19 11:21:39.032: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-696f4eeb-6d02-42be-b5db-22c2e062ba14 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:21:39.047
  Dec 19 11:21:39.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:21:39.083385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "projected-5164" for this suite. @ 12/19/23 11:21:39.084
• [4.193 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 12/19/23 11:21:39.098
  Dec 19 11:21:39.099: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:21:39.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:39.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:39.133
  STEP: Creating configMap with name configmap-test-volume-map-b0ba2a67-0360-432e-87dc-a8a7e6e5f1e0 @ 12/19/23 11:21:39.137
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:21:39.143
  E1219 11:21:40.083628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:41.083674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:21:41.177
  Dec 19 11:21:41.185: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-860f8598-f146-44f9-9b04-8393e8123747 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:21:41.202
  Dec 19 11:21:41.242: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1318" for this suite. @ 12/19/23 11:21:41.258
• [2.178 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 12/19/23 11:21:41.278
  Dec 19 11:21:41.278: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:21:41.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:41.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:41.323
  STEP: Creating service test in namespace statefulset-758 @ 12/19/23 11:21:41.329
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 12/19/23 11:21:41.343
  STEP: Creating stateful set ss in namespace statefulset-758 @ 12/19/23 11:21:41.352
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-758 @ 12/19/23 11:21:41.38
  Dec 19 11:21:41.388: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:21:42.083713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:43.084482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:44.085300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:45.085659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:46.085362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:47.085852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:48.086162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:49.087525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:50.087410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:51.087709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:51.390: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 12/19/23 11:21:51.39
  Dec 19 11:21:51.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:21:51.782: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:21:51.782: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:21:51.782: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:21:51.791: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1219 11:21:52.088624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:53.089184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:54.089887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:55.090051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:56.090272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:57.090403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:58.091498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:59.092097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:00.092858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:01.092866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:01.793: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:22:01.794: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:22:01.847: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999935s
  E1219 11:22:02.093164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:02.859: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.982817702s
  E1219 11:22:03.094172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:03.870: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.96984366s
  E1219 11:22:04.094997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:04.881: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.958839361s
  E1219 11:22:05.096007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:05.891: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.948285894s
  E1219 11:22:06.096931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:06.900: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.937908599s
  E1219 11:22:07.097814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:07.911: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.929202225s
  E1219 11:22:08.097920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:08.926: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.917805733s
  E1219 11:22:09.098415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:09.937: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.902768773s
  E1219 11:22:10.099344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:10.955: INFO: Verifying statefulset ss doesn't scale past 1 for another 891.996674ms
  E1219 11:22:11.099506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-758 @ 12/19/23 11:22:11.956
  Dec 19 11:22:11.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 11:22:12.100410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:12.304: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:22:12.304: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:22:12.304: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:22:12.313: INFO: Found 1 stateful pods, waiting for 3
  E1219 11:22:13.101536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:14.101817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:15.101991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:16.102566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:17.103351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:18.103519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:19.103896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:20.104385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:21.104553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:22.104852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:22.318: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:22:22.318: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:22:22.318: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 12/19/23 11:22:22.319
  STEP: Scale down will halt with unhealthy stateful pod @ 12/19/23 11:22:22.319
  Dec 19 11:22:22.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:22:22.668: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:22:22.668: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:22:22.668: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:22:22.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:22:23.057: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:22:23.057: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:22:23.057: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:22:23.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1219 11:22:23.105785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:23.486: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:22:23.486: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:22:23.486: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:22:23.486: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:22:23.497: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 1
  E1219 11:22:24.106052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:25.106823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:26.107199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:27.107896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:28.108796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:29.109603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:30.109964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:31.110398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:32.110573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:33.110861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:33.505: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:22:33.505: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:22:33.505: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:22:33.544: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999424s
  E1219 11:22:34.111615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:34.558: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985339934s
  E1219 11:22:35.111837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:35.623: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97237636s
  E1219 11:22:36.112856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:36.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.907389255s
  E1219 11:22:37.112603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:37.640: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.899351377s
  E1219 11:22:38.112959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:38.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.89007291s
  E1219 11:22:39.113153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:39.670: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.872054056s
  E1219 11:22:40.113361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:40.681: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.859838998s
  E1219 11:22:41.113628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:41.694: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.849182464s
  E1219 11:22:42.114050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:42.714: INFO: Verifying statefulset ss doesn't scale past 3 for another 835.941834ms
  E1219 11:22:43.115168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-758 @ 12/19/23 11:22:43.715
  Dec 19 11:22:43.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:22:44.073: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:22:44.073: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:22:44.073: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:22:44.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 11:22:44.116009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:44.370: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:22:44.370: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:22:44.370: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:22:44.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=statefulset-758 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:22:44.704: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:22:44.704: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:22:44.704: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:22:44.704: INFO: Scaling statefulset ss to 0
  E1219 11:22:45.116017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:46.116402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:47.117607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:48.118136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:49.117792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:50.118095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:51.118767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:52.118696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:53.119465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:54.120104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 12/19/23 11:22:54.738
  Dec 19 11:22:54.739: INFO: Deleting all statefulset in ns statefulset-758
  Dec 19 11:22:54.749: INFO: Scaling statefulset ss to 0
  Dec 19 11:22:54.776: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:22:54.785: INFO: Deleting statefulset ss
  Dec 19 11:22:54.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-758" for this suite. @ 12/19/23 11:22:54.834
• [73.577 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 12/19/23 11:22:54.857
  Dec 19 11:22:54.857: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:22:54.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:54.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:54.903
  STEP: Setting up server cert @ 12/19/23 11:22:54.967
  E1219 11:22:55.120158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:22:55.973
  STEP: Deploying the webhook pod @ 12/19/23 11:22:55.994
  STEP: Wait for the deployment to be ready @ 12/19/23 11:22:56.019
  Dec 19 11:22:56.038: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:22:56.122128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:57.122544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:22:58.057
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:22:58.076
  E1219 11:22:58.122792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:59.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 12/19/23 11:22:59.092
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 12/19/23 11:22:59.096
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 12/19/23 11:22:59.096
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 12/19/23 11:22:59.096
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 12/19/23 11:22:59.099
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/19/23 11:22:59.099
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/19/23 11:22:59.102
  E1219 11:22:59.122864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:59.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7176" for this suite. @ 12/19/23 11:22:59.237
  STEP: Destroying namespace "webhook-markers-6471" for this suite. @ 12/19/23 11:22:59.266
• [4.433 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 12/19/23 11:22:59.291
  Dec 19 11:22:59.291: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-webhook @ 12/19/23 11:22:59.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:59.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:59.356
  STEP: Setting up server cert @ 12/19/23 11:22:59.365
  E1219 11:23:00.123824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:01.124915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/19/23 11:23:01.476
  STEP: Deploying the custom resource conversion webhook pod @ 12/19/23 11:23:01.493
  STEP: Wait for the deployment to be ready @ 12/19/23 11:23:01.518
  Dec 19 11:23:01.535: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1219 11:23:02.125804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:03.126500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:23:03.579
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:23:03.631
  E1219 11:23:04.127068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:04.632: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec 19 11:23:04.651: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:23:05.127441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:06.127570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:07.128523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 12/19/23 11:23:07.53
  STEP: v2 custom resource should be converted @ 12/19/23 11:23:07.552
  E1219 11:23:08.129541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:08.264: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-822" for this suite. @ 12/19/23 11:23:08.28
• [9.007 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 12/19/23 11:23:08.299
  Dec 19 11:23:08.299: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:23:08.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:08.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:08.401
  STEP: Creating simple DaemonSet "daemon-set" @ 12/19/23 11:23:08.501
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:23:08.525
  Dec 19 11:23:08.562: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:23:08.563: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:23:09.130803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:09.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 11:23:09.557: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:23:10.131549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:10.554: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 11:23:10.554: INFO: Node uikie9pei4sh-2 is running 0 daemon pod, expected 1
  E1219 11:23:11.131352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:11.589: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 11:23:11.589: INFO: Node uikie9pei4sh-2 is running 0 daemon pod, expected 1
  E1219 11:23:12.132950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:12.555: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:23:12.556: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 12/19/23 11:23:12.567
  Dec 19 11:23:12.579: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 12/19/23 11:23:12.579
  Dec 19 11:23:12.618: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 12/19/23 11:23:12.618
  Dec 19 11:23:12.630: INFO: Observed &DaemonSet event: ADDED
  Dec 19 11:23:12.631: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.632: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.633: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.634: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.634: INFO: Found daemon set daemon-set in namespace daemonsets-4590 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 11:23:12.634: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 12/19/23 11:23:12.635
  STEP: watching for the daemon set status to be patched @ 12/19/23 11:23:12.659
  Dec 19 11:23:12.664: INFO: Observed &DaemonSet event: ADDED
  Dec 19 11:23:12.664: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.665: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.666: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.666: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.667: INFO: Observed daemon set daemon-set in namespace daemonsets-4590 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 11:23:12.667: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 11:23:12.667: INFO: Found daemon set daemon-set in namespace daemonsets-4590 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Dec 19 11:23:12.667: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 11:23:12.678
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4590, will wait for the garbage collector to delete the pods @ 12/19/23 11:23:12.678
  Dec 19 11:23:12.753: INFO: Deleting DaemonSet.extensions daemon-set took: 16.103576ms
  Dec 19 11:23:12.853: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.20973ms
  E1219 11:23:13.133779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:14.134781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:14.261: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:23:14.261: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 11:23:14.271: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27599"},"items":null}

  Dec 19 11:23:14.282: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27600"},"items":null}

  Dec 19 11:23:14.332: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4590" for this suite. @ 12/19/23 11:23:14.347
• [6.083 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 12/19/23 11:23:14.383
  Dec 19 11:23:14.383: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/19/23 11:23:14.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:14.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:14.437
  STEP: Creating 50 configmaps @ 12/19/23 11:23:14.447
  STEP: Creating RC which spawns configmap-volume pods @ 12/19/23 11:23:15.128
  E1219 11:23:15.135884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:15.173: INFO: Pod name wrapped-volume-race-76332158-2a20-445f-a57c-90757019a810: Found 0 pods out of 5
  E1219 11:23:16.136867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:17.137483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:18.138272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:19.138397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:20.139197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:20.191: INFO: Pod name wrapped-volume-race-76332158-2a20-445f-a57c-90757019a810: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/19/23 11:23:20.191
  STEP: Creating RC which spawns configmap-volume pods @ 12/19/23 11:23:20.253
  Dec 19 11:23:20.287: INFO: Pod name wrapped-volume-race-1d1a9797-c369-42f0-8996-fdebf93d0aef: Found 0 pods out of 5
  E1219 11:23:21.139616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:22.140682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:23.141561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:24.142303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:25.142752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:25.311: INFO: Pod name wrapped-volume-race-1d1a9797-c369-42f0-8996-fdebf93d0aef: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/19/23 11:23:25.311
  STEP: Creating RC which spawns configmap-volume pods @ 12/19/23 11:23:25.382
  Dec 19 11:23:25.438: INFO: Pod name wrapped-volume-race-269d371a-9d3d-4d9a-949d-1474f9061e5a: Found 0 pods out of 5
  E1219 11:23:26.144033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:27.146983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:28.146542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:29.147119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:30.148600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:30.470: INFO: Pod name wrapped-volume-race-269d371a-9d3d-4d9a-949d-1474f9061e5a: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/19/23 11:23:30.47
  STEP: deleting ReplicationController wrapped-volume-race-269d371a-9d3d-4d9a-949d-1474f9061e5a in namespace emptydir-wrapper-974, will wait for the garbage collector to delete the pods @ 12/19/23 11:23:30.535
  Dec 19 11:23:30.620: INFO: Deleting ReplicationController wrapped-volume-race-269d371a-9d3d-4d9a-949d-1474f9061e5a took: 16.506797ms
  Dec 19 11:23:30.721: INFO: Terminating ReplicationController wrapped-volume-race-269d371a-9d3d-4d9a-949d-1474f9061e5a pods took: 101.47473ms
  E1219 11:23:31.149287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:32.149622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-1d1a9797-c369-42f0-8996-fdebf93d0aef in namespace emptydir-wrapper-974, will wait for the garbage collector to delete the pods @ 12/19/23 11:23:32.723
  Dec 19 11:23:32.806: INFO: Deleting ReplicationController wrapped-volume-race-1d1a9797-c369-42f0-8996-fdebf93d0aef took: 21.368391ms
  Dec 19 11:23:33.007: INFO: Terminating ReplicationController wrapped-volume-race-1d1a9797-c369-42f0-8996-fdebf93d0aef pods took: 201.02441ms
  E1219 11:23:33.151029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:34.151780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-76332158-2a20-445f-a57c-90757019a810 in namespace emptydir-wrapper-974, will wait for the garbage collector to delete the pods @ 12/19/23 11:23:34.81
  Dec 19 11:23:34.887: INFO: Deleting ReplicationController wrapped-volume-race-76332158-2a20-445f-a57c-90757019a810 took: 15.884714ms
  Dec 19 11:23:34.989: INFO: Terminating ReplicationController wrapped-volume-race-76332158-2a20-445f-a57c-90757019a810 pods took: 101.873597ms
  E1219 11:23:35.152299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:36.153510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 12/19/23 11:23:36.991
  E1219 11:23:37.153732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:37.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-974" for this suite. @ 12/19/23 11:23:37.744
• [23.373 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 12/19/23 11:23:37.759
  Dec 19 11:23:37.759: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:23:37.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:37.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:37.8
  STEP: Counting existing ResourceQuota @ 12/19/23 11:23:37.807
  E1219 11:23:38.153618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:39.154066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:40.155347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:41.155266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:42.156122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:23:42.819
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:23:42.829
  E1219 11:23:43.157287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:44.158355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 12/19/23 11:23:44.839
  STEP: Ensuring ResourceQuota status captures the pod usage @ 12/19/23 11:23:44.868
  E1219 11:23:45.158705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:46.160315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 12/19/23 11:23:46.878
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 12/19/23 11:23:46.885
  STEP: Ensuring a pod cannot update its resource requirements @ 12/19/23 11:23:46.891
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 12/19/23 11:23:46.9
  E1219 11:23:47.160008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:48.160614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 11:23:48.909
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 11:23:48.945
  E1219 11:23:49.161502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:50.162201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:50.960: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1953" for this suite. @ 12/19/23 11:23:50.972
• [13.233 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 12/19/23 11:23:50.995
  Dec 19 11:23:50.995: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:23:50.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:51.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:51.045
  E1219 11:23:51.162719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:52.163861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:53.163505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:54.164363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:55.165608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:56.165684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:57.166275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:58.166619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:59.167291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:00.167701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:01.169373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:02.169271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:03.169859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:04.171359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:05.171656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:06.171873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:07.172215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:08.172441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:09.172640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:10.172903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:11.173029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:12.173606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:13.173773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:13.220: INFO: Container started at 2023-12-19 11:23:51 +0000 UTC, pod became ready at 2023-12-19 11:24:11 +0000 UTC
  Dec 19 11:24:13.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8643" for this suite. @ 12/19/23 11:24:13.248
• [22.273 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 12/19/23 11:24:13.27
  Dec 19 11:24:13.271: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:24:13.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:13.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:13.333
  Dec 19 11:24:13.380: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E1219 11:24:14.173985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:15.174963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:16.175307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:17.175938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:18.176021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:18.390: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:24:18.391
  Dec 19 11:24:18.391: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E1219 11:24:19.176977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:20.176815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:20.401: INFO: Creating deployment "test-rollover-deployment"
  Dec 19 11:24:20.420: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E1219 11:24:21.177234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:22.177474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:22.438: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Dec 19 11:24:22.451: INFO: Ensure that both replica sets have 1 created replica
  Dec 19 11:24:22.464: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Dec 19 11:24:22.487: INFO: Updating deployment test-rollover-deployment
  Dec 19 11:24:22.487: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E1219 11:24:23.177592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:24.177923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:24.506: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Dec 19 11:24:24.521: INFO: Make sure deployment "test-rollover-deployment" is complete
  Dec 19 11:24:24.533: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:24:24.533: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:25.178150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:26.178166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:26.555: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:24:26.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:27.178281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:28.178757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:28.555: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:24:28.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:29.179244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:30.179223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:30.555: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:24:30.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:31.179944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:32.179948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:32.550: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:24:32.550: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 24, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:33.180427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:34.180982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:34.550: INFO: 
  Dec 19 11:24:34.551: INFO: Ensure that both old replica sets have no replicas
  Dec 19 11:24:34.579: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9784",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2cec9d91-8b93-43ee-a5dc-0719d39aa849",
      ResourceVersion: (string) (len=5) "28332",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5d484bf7f9\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:24:34.599: INFO: New ReplicaSet "test-rollover-deployment-5d484bf7f9" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9784",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7ee3fdef-a772-4bd3-8547-402539edd483",
      ResourceVersion: (string) (len=5) "28322",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "2cec9d91-8b93-43ee-a5dc-0719d39aa849",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 63 65 63 39 64  39 31 2d 38 62 39 33 2d  |\"2cec9d91-8b93-|
              00000120  34 33 65 65 2d 61 35 64  63 2d 30 37 31 39 64 33  |43ee-a5dc-0719d3|
              00000130  39 61 61 38 34 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9aa849\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:24:34.606: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Dec 19 11:24:34.606: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9784",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc5efea9-3bb6-4a3c-aae3-e58573ef083b",
      ResourceVersion: (string) (len=5) "28331",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581853,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "2cec9d91-8b93-43ee-a5dc-0719d39aa849",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581853,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  32 63 65 63 39 64 39 31  2d 38 62 39 33 2d 34 33  |2cec9d91-8b93-43|
              000000c0  65 65 2d 61 35 64 63 2d  30 37 31 39 64 33 39 61  |ee-a5dc-0719d39a|
              000000d0  61 38 34 39 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |a849\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:24:34.609: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9784",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b75a6254-80e5-41d9-899a-e870dcd4a695",
      ResourceVersion: (string) (len=5) "28284",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "2cec9d91-8b93-43ee-a5dc-0719d39aa849",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 63 65 63 39 64  39 31 2d 38 62 39 33 2d  |\"2cec9d91-8b93-|
              00000120  34 33 65 65 2d 61 35 64  63 2d 30 37 31 39 64 33  |43ee-a5dc-0719d3|
              00000130  39 61 61 38 34 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9aa849\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:24:34.619: INFO: Pod "test-rollover-deployment-5d484bf7f9-kgbxz" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5d484bf7f9-kgbxz",
      GenerateName: (string) (len=36) "test-rollover-deployment-5d484bf7f9-",
      Namespace: (string) (len=15) "deployment-9784",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "490fb453-de3a-45fa-b709-bd58b3bafa8d",
      ResourceVersion: (string) (len=5) "28300",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
          UID: (types.UID) (len=36) "7ee3fdef-a772-4bd3-8547-402539edd483",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 65  65 33 66 64 65 66 2d 61  |d\":\"7ee3fdef-a|
              00000090  37 37 32 2d 34 62 64 33  2d 38 35 34 37 2d 34 30  |772-4bd3-8547-40|
              000000a0  32 35 33 39 65 64 64 34  38 33 5c 22 7d 22 3a 7b  |2539edd483\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  36 35 5c 22 7d 22 3a 7b  |.233.66.65\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6jjw7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6jjw7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=12) "10.233.66.65",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.65"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838581863,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=64) "077cda6b1f5995dcc056c00f92d40b5147132839f522d46d9ca84acd44ad76a7",
          ContainerID: (string) (len=72) "cri-o://5a74a75b4579c42ff53e02aaa297e0d40d6a0df860f5290132b46904959eff85",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:24:34.624: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9784" for this suite. @ 12/19/23 11:24:34.639
• [21.392 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 12/19/23 11:24:34.671
  Dec 19 11:24:34.671: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:24:34.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:34.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:34.725
  STEP: Creating secret with name projected-secret-test-c6bdbd92-1b46-4a97-aaf0-7f1caf931344 @ 12/19/23 11:24:34.733
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:24:34.746
  E1219 11:24:35.181910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:36.182117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:37.182783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:38.183601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:24:38.798
  Dec 19 11:24:38.806: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-secrets-6e113435-3156-4301-8cbe-12953af26865 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:24:38.85
  Dec 19 11:24:38.881: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4789" for this suite. @ 12/19/23 11:24:38.892
• [4.238 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 12/19/23 11:24:38.925
  Dec 19 11:24:38.925: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:24:38.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:38.967
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:38.978
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/19/23 11:24:38.988
  E1219 11:24:39.183698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:40.184111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:41.184370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:42.184803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:24:43.039
  Dec 19 11:24:43.045: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-f6ad9fee-b61c-4ad4-b8ab-d91ab67b0784 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:24:43.058
  Dec 19 11:24:43.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4763" for this suite. @ 12/19/23 11:24:43.109
• [4.200 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 12/19/23 11:24:43.126
  Dec 19 11:24:43.126: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 11:24:43.129
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:43.183
  E1219 11:24:43.184575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:43.195
  E1219 11:24:44.185056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:45.185524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:45.270: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6501" for this suite. @ 12/19/23 11:24:45.282
• [2.171 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 12/19/23 11:24:45.298
  Dec 19 11:24:45.298: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:24:45.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:45.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:45.343
  STEP: Creating configMap with name projected-configmap-test-volume-914878cb-a7ee-437e-862e-f464bee12ec8 @ 12/19/23 11:24:45.348
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:24:45.359
  E1219 11:24:46.185855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:47.186236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:48.187985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:49.187965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:24:49.426
  Dec 19 11:24:49.434: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-73de8f36-1cc1-49b2-b646-75f31b30a99f container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:24:49.452
  Dec 19 11:24:49.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2363" for this suite. @ 12/19/23 11:24:49.493
• [4.210 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 12/19/23 11:24:49.51
  Dec 19 11:24:49.510: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:24:49.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:49.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:49.552
  STEP: creating the pod with failed condition @ 12/19/23 11:24:49.558
  E1219 11:24:50.188025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:51.188366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:52.189389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:53.189541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:54.189733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:55.189864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:56.190060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:57.190281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:58.191768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:59.191781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:00.192337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:01.193080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:02.194399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:03.194924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:04.195519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:05.196126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:06.196550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:07.197319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:08.198436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:09.199573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:10.201086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:11.200100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:12.200432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:13.201343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:14.201890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:15.202081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:16.203056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:17.204229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:18.204562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:19.205195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:20.205507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:21.206144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:22.206358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:23.206466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:24.206552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:25.206638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:26.207031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:27.207955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:28.208960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:29.209461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:30.210067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:31.210632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:32.211421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:33.211436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:34.211710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:35.211970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:36.212946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:37.213081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:38.213503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:39.214334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:40.215003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:41.215297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:42.216392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:43.216440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:44.217433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:45.217736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:46.218011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:47.218936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:48.219138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:49.219990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:50.221140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:51.221788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:52.222387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:53.222932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:54.223749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:55.223981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:56.225142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:57.225602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:58.226424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:59.227343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:00.228459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:01.228512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:02.229373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:03.229898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:04.231035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:05.231276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:06.231411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:07.232006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:08.233429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:09.233982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:10.234220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:11.234379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:12.234486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:13.234988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:14.235533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:15.236332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:16.237361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:17.237664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:18.237930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:19.238798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:20.239009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:21.239592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:22.240710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:23.242395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:24.242128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:25.242448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:26.243564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:27.243815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:28.245206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:29.245211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:30.245884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:31.246737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:32.247489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:33.247575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:34.247935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:35.248469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:36.248918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:37.250000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:38.250518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:39.251465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:40.252440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:41.253090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:42.254016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:43.254821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:44.255032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:45.255826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:46.256168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:47.256878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:48.257847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:49.259158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 12/19/23 11:26:49.581
  Dec 19 11:26:50.108: INFO: Successfully updated pod "var-expansion-698de760-ea62-44cc-9b9d-437fa2f7694b"
  STEP: waiting for pod running @ 12/19/23 11:26:50.109
  E1219 11:26:50.259410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:51.259643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 12/19/23 11:26:52.128
  Dec 19 11:26:52.128: INFO: Deleting pod "var-expansion-698de760-ea62-44cc-9b9d-437fa2f7694b" in namespace "var-expansion-7881"
  Dec 19 11:26:52.153: INFO: Wait up to 5m0s for pod "var-expansion-698de760-ea62-44cc-9b9d-437fa2f7694b" to be fully deleted
  E1219 11:26:52.260066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:53.260397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:54.260826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:55.261989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:56.261443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:57.261862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:58.263147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:59.263235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:00.263710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:01.263976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:02.264871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:03.266090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:04.266161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:05.267006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:06.268025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:07.268423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:08.268300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:09.269833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:10.270464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:11.270830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:12.271385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:13.272413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:14.273083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:15.273734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:16.275127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:17.275725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:18.276132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:19.277110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:20.277072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:21.277085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:22.277514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:23.277834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:24.278820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:24.321: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7881" for this suite. @ 12/19/23 11:27:24.334
• [154.842 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 12/19/23 11:27:24.353
  Dec 19 11:27:24.353: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:27:24.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:27:24.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:27:24.402
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:27:24.407
  E1219 11:27:25.279427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:26.279776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:27.279828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:28.280815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:27:28.46
  Dec 19 11:27:28.469: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-0b3d68fa-80ac-45a5-b726-ed6d226554c9 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:27:28.506
  Dec 19 11:27:28.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4514" for this suite. @ 12/19/23 11:27:28.604
• [4.269 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 12/19/23 11:27:28.631
  Dec 19 11:27:28.631: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 11:27:28.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:27:28.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:27:28.685
  Dec 19 11:27:28.694: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 11:27:28.717: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 11:27:28.725: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-1 before test
  Dec 19 11:27:28.744: INFO: coredns-76f75df574-4529k from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.745: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 11:27:28.746: INFO: coredns-76f75df574-kjr7r from kube-system started at 2023-12-19 09:47:50 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.746: INFO: 	Container coredns ready: true, restart count 1
  Dec 19 11:27:28.747: INFO: kube-addon-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.747: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 11:27:28.747: INFO: kube-apiserver-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.748: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 11:27:28.748: INFO: kube-controller-manager-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.749: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 11:27:28.749: INFO: kube-flannel-ds-qldcz from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.749: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 11:27:28.750: INFO: kube-proxy-wp7g9 from kube-system started at 2023-12-19 09:44:36 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.750: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:27:28.750: INFO: kube-scheduler-uikie9pei4sh-1 from kube-system started at 2023-12-19 09:56:00 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.751: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 11:27:28.751: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qgn7f from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:27:28.752: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:27:28.752: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 11:27:28.752: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-2 before test
  Dec 19 11:27:28.771: INFO: kube-addon-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.771: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 11:27:28.771: INFO: kube-apiserver-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.771: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 11:27:28.771: INFO: kube-controller-manager-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.771: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 11:27:28.771: INFO: kube-flannel-ds-znfxv from kube-system started at 2023-12-19 09:47:20 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.771: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 11:27:28.771: INFO: kube-proxy-q4vm6 from kube-system started at 2023-12-19 09:45:19 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.771: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:27:28.771: INFO: kube-scheduler-uikie9pei4sh-2 from kube-system started at 2023-12-19 09:50:33 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.772: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 11:27:28.772: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-qvrr8 from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:27:28.772: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:27:28.772: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 11:27:28.772: INFO: 
  Logging pods the apiserver thinks is on node uikie9pei4sh-3 before test
  Dec 19 11:27:28.790: INFO: kube-flannel-ds-z7dwl from kube-system started at 2023-12-19 10:27:36 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.790: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 11:27:28.790: INFO: kube-proxy-lh685 from kube-system started at 2023-12-19 09:45:40 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.790: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:27:28.790: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:56 +0000 UTC (1 container statuses recorded)
  Dec 19 11:27:28.790: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 11:27:28.791: INFO: sonobuoy-e2e-job-b395aad1bffb4cbc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:27:28.791: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 11:27:28.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:27:28.791: INFO: sonobuoy-systemd-logs-daemon-set-0a5f0b5a44174ff3-8llvc from sonobuoy started at 2023-12-19 10:01:08 +0000 UTC (2 container statuses recorded)
  Dec 19 11:27:28.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:27:28.791: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 12/19/23 11:27:28.792
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17a2380f9f951736], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] @ 12/19/23 11:27:28.867
  E1219 11:27:29.281149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:29.862: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6066" for this suite. @ 12/19/23 11:27:29.871
• [1.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 12/19/23 11:27:29.895
  Dec 19 11:27:29.895: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 11:27:29.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:27:29.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:27:29.941
  Dec 19 11:27:29.994: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:27:30.281364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:31.281649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:32.282412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:33.282069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:34.282383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:35.282569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:36.283542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:37.283872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:38.284584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:39.284712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:40.285495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:41.287529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:42.287578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:43.288654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:44.288589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:45.288790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:46.288981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:47.289981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:48.290316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:49.290368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:50.290589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:51.290676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:52.290888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:53.291205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:54.291786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:55.292124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:56.292242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:57.293450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:58.293616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:59.293735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:00.294806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:01.295174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:02.296163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:03.296317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:04.296488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:05.297343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:06.297474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:07.297680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:08.298165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:09.299284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:10.299969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:11.301005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:12.301170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:13.302188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:14.303423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:15.303520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:16.303883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:17.304904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:18.305679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:19.305839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:20.306537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:21.307102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:22.308037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:23.308207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:24.308897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:25.309117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:26.309622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:27.310013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:28.310543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:29.310729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:30.010: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/19/23 11:28:30.018
  Dec 19 11:28:30.069: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec 19 11:28:30.081: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec 19 11:28:30.174: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec 19 11:28:30.187: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec 19 11:28:30.262: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec 19 11:28:30.281: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/19/23 11:28:30.281
  E1219 11:28:30.315568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:31.314464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:32.314603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 12/19/23 11:28:32.405
  E1219 11:28:33.315085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:34.316068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:35.316161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:36.316903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:37.316788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:38.317564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:38.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7559" for this suite. @ 12/19/23 11:28:38.631
• [68.749 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 12/19/23 11:28:38.647
  Dec 19 11:28:38.647: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 11:28:38.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:28:38.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:28:38.698
  E1219 11:28:39.317474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:40.317914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:40.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4665" for this suite. @ 12/19/23 11:28:40.833
• [2.198 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 12/19/23 11:28:40.847
  Dec 19 11:28:40.847: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename controllerrevisions @ 12/19/23 11:28:40.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:28:40.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:28:40.897
  STEP: Creating DaemonSet "e2e-mfln4-daemon-set" @ 12/19/23 11:28:40.949
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:28:40.962
  Dec 19 11:28:40.982: INFO: Number of nodes with available pods controlled by daemonset e2e-mfln4-daemon-set: 0
  Dec 19 11:28:40.984: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:28:41.318226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:41.982: INFO: Number of nodes with available pods controlled by daemonset e2e-mfln4-daemon-set: 1
  Dec 19 11:28:41.982: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:28:42.318992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:42.986: INFO: Number of nodes with available pods controlled by daemonset e2e-mfln4-daemon-set: 3
  Dec 19 11:28:42.987: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-mfln4-daemon-set
  STEP: Confirm DaemonSet "e2e-mfln4-daemon-set" successfully created with "daemonset-name=e2e-mfln4-daemon-set" label @ 12/19/23 11:28:42.992
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-mfln4-daemon-set" @ 12/19/23 11:28:43.008
  Dec 19 11:28:43.016: INFO: Located ControllerRevision: "e2e-mfln4-daemon-set-f9988858d"
  STEP: Patching ControllerRevision "e2e-mfln4-daemon-set-f9988858d" @ 12/19/23 11:28:43.023
  Dec 19 11:28:43.039: INFO: e2e-mfln4-daemon-set-f9988858d has been patched
  STEP: Create a new ControllerRevision @ 12/19/23 11:28:43.039
  Dec 19 11:28:43.051: INFO: Created ControllerRevision: e2e-mfln4-daemon-set-849587b98b
  STEP: Confirm that there are two ControllerRevisions @ 12/19/23 11:28:43.052
  Dec 19 11:28:43.052: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:28:43.061: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-mfln4-daemon-set-f9988858d" @ 12/19/23 11:28:43.061
  STEP: Confirm that there is only one ControllerRevision @ 12/19/23 11:28:43.072
  Dec 19 11:28:43.072: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:28:43.080: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-mfln4-daemon-set-849587b98b" @ 12/19/23 11:28:43.088
  Dec 19 11:28:43.109: INFO: e2e-mfln4-daemon-set-849587b98b has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 12/19/23 11:28:43.11
  W1219 11:28:43.127516      13 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 12/19/23 11:28:43.127
  Dec 19 11:28:43.127: INFO: Requesting list of ControllerRevisions to confirm quantity
  E1219 11:28:43.319717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:44.128: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:28:44.155: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-mfln4-daemon-set-849587b98b=updated" @ 12/19/23 11:28:44.156
  STEP: Confirm that there is only one ControllerRevision @ 12/19/23 11:28:44.176
  Dec 19 11:28:44.177: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:28:44.189: INFO: Found 1 ControllerRevisions
  Dec 19 11:28:44.209: INFO: ControllerRevision "e2e-mfln4-daemon-set-76b9488d79" has revision 3
  STEP: Deleting DaemonSet "e2e-mfln4-daemon-set" @ 12/19/23 11:28:44.221
  STEP: deleting DaemonSet.extensions e2e-mfln4-daemon-set in namespace controllerrevisions-430, will wait for the garbage collector to delete the pods @ 12/19/23 11:28:44.222
  Dec 19 11:28:44.305: INFO: Deleting DaemonSet.extensions e2e-mfln4-daemon-set took: 18.542118ms
  E1219 11:28:44.319855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:44.405: INFO: Terminating DaemonSet.extensions e2e-mfln4-daemon-set pods took: 100.37394ms
  E1219 11:28:45.320441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:46.320396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:46.814: INFO: Number of nodes with available pods controlled by daemonset e2e-mfln4-daemon-set: 0
  Dec 19 11:28:46.814: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-mfln4-daemon-set
  Dec 19 11:28:46.820: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29238"},"items":null}

  Dec 19 11:28:46.825: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29238"},"items":null}

  Dec 19 11:28:46.855: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-430" for this suite. @ 12/19/23 11:28:46.865
• [6.030 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 12/19/23 11:28:46.878
  Dec 19 11:28:46.878: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:28:46.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:28:46.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:28:46.918
  STEP: Creating configMap with name cm-test-opt-del-3d06780d-441d-4ebe-85ec-615beb4b5e41 @ 12/19/23 11:28:46.941
  STEP: Creating configMap with name cm-test-opt-upd-2807cbf5-b64e-4d9f-a3c5-3622146b9875 @ 12/19/23 11:28:46.951
  STEP: Creating the pod @ 12/19/23 11:28:46.96
  E1219 11:28:47.320690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:48.321086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-3d06780d-441d-4ebe-85ec-615beb4b5e41 @ 12/19/23 11:28:49.115
  STEP: Updating configmap cm-test-opt-upd-2807cbf5-b64e-4d9f-a3c5-3622146b9875 @ 12/19/23 11:28:49.131
  STEP: Creating configMap with name cm-test-opt-create-549dd064-7b83-4eda-965a-68213cb5e822 @ 12/19/23 11:28:49.144
  STEP: waiting to observe update in volume @ 12/19/23 11:28:49.16
  E1219 11:28:49.321547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:50.322631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:51.323632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:52.324039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:53.239: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1520" for this suite. @ 12/19/23 11:28:53.247
• [6.388 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 12/19/23 11:28:53.268
  Dec 19 11:28:53.268: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:28:53.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:28:53.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:28:53.312
  E1219 11:28:53.324990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:54.326141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:55.326755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:55.355: INFO: Deleting pod "var-expansion-ffc1bf5f-bce9-4513-ad69-c7028a703ef9" in namespace "var-expansion-5230"
  Dec 19 11:28:55.372: INFO: Wait up to 5m0s for pod "var-expansion-ffc1bf5f-bce9-4513-ad69-c7028a703ef9" to be fully deleted
  E1219 11:28:56.326551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:57.327090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:57.396: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5230" for this suite. @ 12/19/23 11:28:57.409
• [4.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 12/19/23 11:28:57.434
  Dec 19 11:28:57.434: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 11:28:57.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:28:57.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:28:57.497
  Dec 19 11:28:57.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7272" for this suite. @ 12/19/23 11:28:57.533
• [0.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 12/19/23 11:28:57.553
  Dec 19 11:28:57.553: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:28:57.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:28:57.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:28:57.603
  Dec 19 11:28:57.609: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:28:58.327459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:59.327808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:00.328028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 11:29:00.405674      13 warnings.go:70] unknown field "alpha"
  W1219 11:29:00.405996      13 warnings.go:70] unknown field "beta"
  W1219 11:29:00.406234      13 warnings.go:70] unknown field "delta"
  W1219 11:29:00.406517      13 warnings.go:70] unknown field "epsilon"
  W1219 11:29:00.406811      13 warnings.go:70] unknown field "gamma"
  Dec 19 11:29:01.026: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6542" for this suite. @ 12/19/23 11:29:01.038
• [3.501 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 12/19/23 11:29:01.056
  Dec 19 11:29:01.056: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:29:01.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:01.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:01.099
  STEP: Setting up server cert @ 12/19/23 11:29:01.155
  E1219 11:29:01.328124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:29:01.738
  STEP: Deploying the webhook pod @ 12/19/23 11:29:01.755
  STEP: Wait for the deployment to be ready @ 12/19/23 11:29:01.788
  Dec 19 11:29:01.818: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:29:02.328737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:03.329119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:03.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:29:04.330053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:05.329758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:05.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:29:06.330071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:07.330842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:07.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:29:08.332346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:09.332164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:09.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:29:10.333146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:11.333573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:11.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:29:12.334643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:13.335221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:29:13.849
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:29:13.875
  E1219 11:29:14.336111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:14.875: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/19/23 11:29:15.039
  STEP: Creating a configMap that should be mutated @ 12/19/23 11:29:15.088
  STEP: Deleting the collection of validation webhooks @ 12/19/23 11:29:15.145
  STEP: Creating a configMap that should not be mutated @ 12/19/23 11:29:15.276
  E1219 11:29:15.337809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:15.415: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8095" for this suite. @ 12/19/23 11:29:15.428
  STEP: Destroying namespace "webhook-markers-4016" for this suite. @ 12/19/23 11:29:15.448
• [14.407 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 12/19/23 11:29:15.512
  Dec 19 11:29:15.512: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 11:29:15.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:15.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:15.576
  STEP: set up a multi version CRD @ 12/19/23 11:29:15.584
  Dec 19 11:29:15.588: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:29:16.338466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:17.339125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:18.339662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:19.342265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 12/19/23 11:29:20.312
  STEP: check the new version name is served @ 12/19/23 11:29:20.339
  E1219 11:29:20.342993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:21.343983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 12/19/23 11:29:21.812
  E1219 11:29:22.345835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 12/19/23 11:29:22.655
  E1219 11:29:23.346646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:24.347602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:25.348353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:26.196: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5566" for this suite. @ 12/19/23 11:29:26.216
• [10.715 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 12/19/23 11:29:26.231
  Dec 19 11:29:26.231: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 11:29:26.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:26.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:26.268
  STEP: Deleting RuntimeClass runtimeclass-8657-delete-me @ 12/19/23 11:29:26.285
  STEP: Waiting for the RuntimeClass to disappear @ 12/19/23 11:29:26.299
  Dec 19 11:29:26.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8657" for this suite. @ 12/19/23 11:29:26.326
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 12/19/23 11:29:26.339
  Dec 19 11:29:26.340: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:29:26.342
  E1219 11:29:26.349121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:26.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:26.374
  STEP: Creating secret with name s-test-opt-del-b32a7c40-d7d3-4c9f-8fac-9525bc0e1cc0 @ 12/19/23 11:29:26.391
  STEP: Creating secret with name s-test-opt-upd-307d1575-4f98-4125-995c-7fe3b27f8912 @ 12/19/23 11:29:26.402
  STEP: Creating the pod @ 12/19/23 11:29:26.411
  E1219 11:29:27.353095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:28.354179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-b32a7c40-d7d3-4c9f-8fac-9525bc0e1cc0 @ 12/19/23 11:29:28.498
  STEP: Updating secret s-test-opt-upd-307d1575-4f98-4125-995c-7fe3b27f8912 @ 12/19/23 11:29:28.51
  STEP: Creating secret with name s-test-opt-create-09a05573-280b-458b-8037-1c989febbf28 @ 12/19/23 11:29:28.521
  STEP: waiting to observe update in volume @ 12/19/23 11:29:28.531
  E1219 11:29:29.354524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:30.355178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:30.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4591" for this suite. @ 12/19/23 11:29:30.606
• [4.280 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 12/19/23 11:29:30.623
  Dec 19 11:29:30.623: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:29:30.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:30.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:30.668
  STEP: Creating configMap configmap-1115/configmap-test-31553b91-1e15-49bd-bec5-a06c36c2c0d9 @ 12/19/23 11:29:30.673
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:29:30.684
  E1219 11:29:31.356351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:32.357307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:33.357324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:34.357366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:29:34.732
  Dec 19 11:29:34.741: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-19d26792-862d-424a-88a2-377ebf29125a container env-test: <nil>
  STEP: delete the pod @ 12/19/23 11:29:34.757
  Dec 19 11:29:34.787: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1115" for this suite. @ 12/19/23 11:29:34.796
• [4.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 12/19/23 11:29:34.821
  Dec 19 11:29:34.821: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:29:34.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:34.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:34.876
  STEP: Creating a pod to test downward api env vars @ 12/19/23 11:29:34.889
  E1219 11:29:35.358217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:36.358637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:37.359645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:38.360200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:29:38.939
  Dec 19 11:29:38.945: INFO: Trying to get logs from node uikie9pei4sh-3 pod downward-api-727e9219-5076-457e-9838-9fc418134319 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:29:38.963
  Dec 19 11:29:39.015: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2431" for this suite. @ 12/19/23 11:29:39.025
• [4.229 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 12/19/23 11:29:39.052
  Dec 19 11:29:39.052: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 11:29:39.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:39.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:39.11
  STEP: Creating replication controller my-hostname-basic-3d97f7d1-1a34-433f-ad25-8f3b35e705f2 @ 12/19/23 11:29:39.114
  Dec 19 11:29:39.145: INFO: Pod name my-hostname-basic-3d97f7d1-1a34-433f-ad25-8f3b35e705f2: Found 0 pods out of 1
  E1219 11:29:39.361030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:40.361422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:41.361935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:42.362582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:43.363298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:44.157: INFO: Pod name my-hostname-basic-3d97f7d1-1a34-433f-ad25-8f3b35e705f2: Found 1 pods out of 1
  Dec 19 11:29:44.157: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3d97f7d1-1a34-433f-ad25-8f3b35e705f2" are running
  Dec 19 11:29:44.165: INFO: Pod "my-hostname-basic-3d97f7d1-1a34-433f-ad25-8f3b35e705f2-zgs7h" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:29:40 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:29:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:29:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:29:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:29:39 +0000 UTC Reason: Message:}])
  Dec 19 11:29:44.165: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/19/23 11:29:44.166
  Dec 19 11:29:44.200: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-32" for this suite. @ 12/19/23 11:29:44.215
• [5.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 12/19/23 11:29:44.24
  Dec 19 11:29:44.240: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 11:29:44.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:44.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:44.329
  E1219 11:29:44.364266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:45.364959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:46.365173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:46.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7394" for this suite. @ 12/19/23 11:29:46.414
• [2.187 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 12/19/23 11:29:46.429
  Dec 19 11:29:46.429: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-watch @ 12/19/23 11:29:46.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:29:46.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:29:46.472
  Dec 19 11:29:46.477: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:29:47.366017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:48.366759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 12/19/23 11:29:49.159
  Dec 19 11:29:49.172: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:29:49Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:29:49Z]] name:name1 resourceVersion:29732 uid:2b6393e1-545d-415d-87b7-d22e8c2ea29a] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:29:49.367693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:50.368385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:51.369638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:52.370934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:53.370868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:54.371833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:55.371985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:56.372315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:57.372926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:58.373510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 12/19/23 11:29:59.174
  Dec 19 11:29:59.185: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:29:59Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:29:59Z]] name:name2 resourceVersion:29770 uid:55379371-48aa-4df2-8b28-04d510339c0b] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:29:59.374516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:00.375707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:01.375727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:02.375997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:03.378122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:04.377356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:05.378097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:06.378251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:07.379363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:08.380448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 12/19/23 11:30:09.186
  Dec 19 11:30:09.202: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:29:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:30:09Z]] name:name1 resourceVersion:29788 uid:2b6393e1-545d-415d-87b7-d22e8c2ea29a] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:30:09.380719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:10.380900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:11.382339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:12.382422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:13.383042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:14.383648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:15.383858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:16.384099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:17.384680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:18.385081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 12/19/23 11:30:19.203
  Dec 19 11:30:19.220: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:29:59Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:30:19Z]] name:name2 resourceVersion:29806 uid:55379371-48aa-4df2-8b28-04d510339c0b] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:30:19.386071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:20.387030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:21.387576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:22.387659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:23.387920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:24.388105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:25.388869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:26.389116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:27.390146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:28.390308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 12/19/23 11:30:29.22
  Dec 19 11:30:29.241: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:29:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:30:09Z]] name:name1 resourceVersion:29828 uid:2b6393e1-545d-415d-87b7-d22e8c2ea29a] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:30:29.390499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:30.391219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:31.391909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:32.392269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:33.392281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:34.393418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:35.393574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:36.394214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:37.394987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:38.395131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 12/19/23 11:30:39.241
  Dec 19 11:30:39.260: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:29:59Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:30:19Z]] name:name2 resourceVersion:29848 uid:55379371-48aa-4df2-8b28-04d510339c0b] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:30:39.395443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:40.396240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:41.396965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:42.397078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:43.397069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:44.397168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:45.398404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:46.398843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:47.398900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:48.399344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:49.399795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:49.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-8054" for this suite. @ 12/19/23 11:30:49.824
• [63.414 seconds]
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 12/19/23 11:30:49.844
  Dec 19 11:30:49.844: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 11:30:49.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:49.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:49.896
  E1219 11:30:50.399855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:51.400694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:52.401839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:53.403009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:54.008: INFO: Got logs for pod "busybox-privileged-false-f04ca394-01af-4313-b35d-1fe2bb0359d9": "ip: RTNETLINK answers: Operation not permitted\n"
  Dec 19 11:30:54.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7914" for this suite. @ 12/19/23 11:30:54.02
• [4.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 12/19/23 11:30:54.039
  Dec 19 11:30:54.039: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:30:54.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:54.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:54.095
  STEP: Creating a pod to test downward api env vars @ 12/19/23 11:30:54.101
  E1219 11:30:54.402849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:55.403256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:56.403965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:57.404940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:30:58.164
  Dec 19 11:30:58.172: INFO: Trying to get logs from node uikie9pei4sh-3 pod downward-api-623a927d-b07d-4608-9163-134d40811029 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:30:58.19
  Dec 19 11:30:58.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5539" for this suite. @ 12/19/23 11:30:58.227
• [4.200 seconds]
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 12/19/23 11:30:58.24
  Dec 19 11:30:58.240: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:30:58.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:58.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:58.289
  STEP: Creating pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354 @ 12/19/23 11:30:58.297
  E1219 11:30:58.405850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:59.406471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:31:00.335
  Dec 19 11:31:00.344: INFO: Initial restart count of pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 is 0
  Dec 19 11:31:00.353: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:00.407652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:01.408613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:02.396: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:02.408856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:03.409061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:04.407: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:04.409437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:05.410134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:06.410206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:06.415: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:07.410453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:08.411229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:08.423: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:09.411711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:10.412283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:10.433: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:11.412500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:12.412979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:12.443: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:13.413185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:14.414348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:14.450: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:15.414395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:16.414616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:16.459: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:17.414693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:18.415001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:18.474: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:19.415823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:20.416836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:20.482: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  Dec 19 11:31:20.482: INFO: Restart count of pod container-probe-8354/liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 is now 1 (20.137573611s elapsed)
  E1219 11:31:21.416990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:22.417884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:22.490: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:23.418095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:24.419212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:24.497: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:25.419477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:26.422438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:26.505: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:27.419889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:28.420339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:28.514: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:29.421163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:30.421390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:30.524: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:31.422024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:32.422591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:32.532: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:33.422507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:34.422668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:34.541: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:35.422925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:36.423193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:36.551: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:37.424517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:38.424996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:38.568: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:39.425810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:40.425748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:40.578: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  Dec 19 11:31:40.578: INFO: Restart count of pod container-probe-8354/liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 is now 2 (40.233349276s elapsed)
  E1219 11:31:41.425885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:42.426330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:42.586: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:43.426608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:44.426555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:44.597: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:45.427053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:46.427582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:46.605: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:47.427988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:48.429247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:48.616: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:49.429119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:50.429637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:50.626: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:51.430245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:52.431079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:52.633: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:53.431612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:54.432216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:54.642: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:55.432196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:56.432933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:56.652: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:57.434719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:58.433954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:58.660: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:31:59.435355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:00.434708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:00.672: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  Dec 19 11:32:00.672: INFO: Restart count of pod container-probe-8354/liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 is now 3 (1m0.327447046s elapsed)
  E1219 11:32:01.434750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:02.435715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:02.683: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:03.436446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:04.437122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:04.693: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:05.438426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:06.438559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:06.706: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:07.439279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:08.439678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:08.717: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:09.440537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:10.440974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:10.727: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:11.441172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:12.441407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:12.738: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:13.441573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:14.441974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:14.749: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:15.442203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:16.442551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:16.761: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:17.443559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:18.443917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:18.770: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:19.444096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:20.444958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:20.779: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  Dec 19 11:32:20.779: INFO: Restart count of pod container-probe-8354/liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 is now 4 (1m20.43441405s elapsed)
  E1219 11:32:21.444799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:22.445068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:22.791: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:23.445664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:24.446335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:24.801: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:25.447468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:26.448063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:26.812: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:27.448831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:28.449465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:28.822: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:29.449671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:30.449947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:30.829: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:31.450169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:32.450548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:32.838: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:33.451061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:34.451976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:34.846: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:35.453695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:36.453293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:36.856: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:37.453865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:38.454294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:38.869: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:39.454399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:40.454648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:40.878: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:41.455784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:42.457456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:42.890: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:43.457907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:44.458074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:44.902: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:45.458079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:46.458466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:46.913: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:47.459512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:48.460593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:48.924: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:49.461098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:50.461739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:50.942: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:51.461901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:52.462278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:52.953: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:53.463215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:54.463185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:54.963: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:55.464412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:56.464547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:56.973: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:57.464885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:58.465245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:32:58.991: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:32:59.465490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:00.465449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:01.001: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:01.465665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:02.466187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:03.026: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:03.466654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:04.466788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:05.034: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:05.468021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:06.468181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:07.041: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:07.468213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:08.469277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:09.051: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:09.469006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:10.469506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:11.064: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:11.470159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:12.470308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:13.082: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:13.470676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:14.471228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:15.091: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:15.471209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:16.471533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:17.101: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:17.472593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:18.473387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:19.110: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:19.473386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:20.473547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:21.120: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  E1219 11:33:21.474265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:22.474744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:23.130: INFO: Get pod liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 in namespace container-probe-8354
  Dec 19 11:33:23.130: INFO: Restart count of pod container-probe-8354/liveness-b5e12a02-8021-45a7-8b8b-5b75240d0bb0 is now 5 (2m22.784720805s elapsed)
  STEP: deleting the pod @ 12/19/23 11:33:23.13
  Dec 19 11:33:23.162: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8354" for this suite. @ 12/19/23 11:33:23.198
• [144.997 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 12/19/23 11:33:23.242
  Dec 19 11:33:23.242: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:33:23.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:33:23.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:33:23.304
  STEP: Creating the pod @ 12/19/23 11:33:23.314
  E1219 11:33:23.475939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:24.477023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:25.476725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:25.945: INFO: Successfully updated pod "annotationupdate7db6c66c-b5a0-4064-8cde-46dc88abd0ac"
  E1219 11:33:26.477209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:27.477815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:33:27.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7208" for this suite. @ 12/19/23 11:33:27.99
• [4.764 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 12/19/23 11:33:28.007
  Dec 19 11:33:28.008: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:33:28.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:33:28.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:33:28.049
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:33:28.055
  E1219 11:33:28.477635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:29.478095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:30.478561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:31.478654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:33:32.1
  Dec 19 11:33:32.107: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-3cacd5d0-9db3-4d52-913d-fee0b9799727 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:33:32.121
  Dec 19 11:33:32.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4807" for this suite. @ 12/19/23 11:33:32.172
• [4.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 12/19/23 11:33:32.2
  Dec 19 11:33:32.200: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:33:32.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:33:32.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:33:32.255
  STEP: Creating configMap with name configmap-test-upd-b9263ca1-8e92-464a-b8cd-521ea4ad475b @ 12/19/23 11:33:32.281
  STEP: Creating the pod @ 12/19/23 11:33:32.296
  E1219 11:33:32.479380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:33.479591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:34.479616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:35.479970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-b9263ca1-8e92-464a-b8cd-521ea4ad475b @ 12/19/23 11:33:36.389
  STEP: waiting to observe update in volume @ 12/19/23 11:33:36.399
  E1219 11:33:36.480982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:37.481514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:38.482401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:39.482620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:40.483512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:41.484107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:42.484707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:43.485600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:44.486177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:45.486566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:46.487445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:47.487750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:48.487970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:49.488096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:50.489039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:51.489224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:52.490206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:53.490757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:54.491617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:55.492391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:56.492957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:57.493007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:58.493109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:59.493477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:00.494170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:01.494706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:02.495422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:03.496620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:04.496824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:05.497322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:06.498313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:07.499399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:08.499696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:09.499883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:10.500575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:11.500696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:12.501283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:13.501485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:14.502311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:15.502530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:16.503368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:17.503385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:18.503594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:19.504601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:20.505119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:21.505331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:22.505695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:23.505947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:24.507058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:25.506997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:26.507970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:27.509240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:28.508977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:29.509298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:30.510091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:31.510821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:32.511993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:33.512192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:34.512297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:35.512450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:36.512711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:37.513499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:38.513722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:39.514000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:40.514236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:41.514831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:42.514920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:43.515404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:44.515868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:45.515963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:46.516812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:47.517380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:48.517988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:49.519057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:50.519319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:51.519976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:52.520161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:53.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9633" for this suite. @ 12/19/23 11:34:53.177
• [80.993 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 12/19/23 11:34:53.203
  Dec 19 11:34:53.203: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:34:53.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:34:53.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:34:53.268
  STEP: Creating secret with name s-test-opt-del-6954dfff-d3a4-4b71-8f74-7632b0397ed0 @ 12/19/23 11:34:53.289
  STEP: Creating secret with name s-test-opt-upd-e9724a8e-2de9-4183-a644-2d3e2a0f92cd @ 12/19/23 11:34:53.306
  STEP: Creating the pod @ 12/19/23 11:34:53.318
  E1219 11:34:53.520818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:54.521759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-6954dfff-d3a4-4b71-8f74-7632b0397ed0 @ 12/19/23 11:34:55.422
  STEP: Updating secret s-test-opt-upd-e9724a8e-2de9-4183-a644-2d3e2a0f92cd @ 12/19/23 11:34:55.439
  STEP: Creating secret with name s-test-opt-create-63b74725-7ceb-4efe-8c85-20e57bce7eba @ 12/19/23 11:34:55.452
  STEP: waiting to observe update in volume @ 12/19/23 11:34:55.464
  E1219 11:34:55.522264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:56.522329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:57.523705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:58.523788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:59.524534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:00.525536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:01.526059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:02.526651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:03.527511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:04.528575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:05.528874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:06.529189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:07.530053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:08.530428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:09.530667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:10.531557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:11.531927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:12.534461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:13.533137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:14.533432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:15.534576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:16.535662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:17.536033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:18.536932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:19.538575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:20.538628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:21.538816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:22.539445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:23.539215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:24.539940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:25.541162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:26.540934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:27.541114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:28.541556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:29.541650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:30.543597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:31.543909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:32.544069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:33.544302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:34.544239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:35.547468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:36.546212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:37.547296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:38.548400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:39.548563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:40.549099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:41.549703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:42.550636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:43.550934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:44.552056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:45.552930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:46.553143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:47.554192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:48.554411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:49.555544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:50.555885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:51.556845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:52.556956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:53.557302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:54.557357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:55.558708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:56.559279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:57.559410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:58.560361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:59.560841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:00.561044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:01.561440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:02.562520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:03.563400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:04.563507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:05.563710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:06.564470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:07.565099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:08.566053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:09.566644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:10.567214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:11.567844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:12.568408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:13.569331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:14.570053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:15.570848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:16.571711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:17.572351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:18.572854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:19.573977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:20.574789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:21.575353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:22.576428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:23.577043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:24.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3423" for this suite. @ 12/19/23 11:36:24.514
• [91.329 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 12/19/23 11:36:24.535
  Dec 19 11:36:24.536: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 11:36:24.542
  E1219 11:36:24.578237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:36:24.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:36:24.6
  STEP: create the rc @ 12/19/23 11:36:24.617
  W1219 11:36:24.630885      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1219 11:36:25.579026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:26.579257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:27.580256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:28.580356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:29.580542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:30.581001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/19/23 11:36:30.7
  STEP: wait for the rc to be deleted @ 12/19/23 11:36:30.784
  E1219 11:36:31.581286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:32.254: INFO: 82 pods remaining
  Dec 19 11:36:32.255: INFO: 79 pods has nil DeletionTimestamp
  Dec 19 11:36:32.255: INFO: 
  E1219 11:36:32.581641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:32.891: INFO: 70 pods remaining
  Dec 19 11:36:32.891: INFO: 70 pods has nil DeletionTimestamp
  Dec 19 11:36:32.892: INFO: 
  E1219 11:36:33.581901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:33.831: INFO: 59 pods remaining
  Dec 19 11:36:33.831: INFO: 58 pods has nil DeletionTimestamp
  Dec 19 11:36:33.831: INFO: 
  E1219 11:36:34.582016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:34.898: INFO: 45 pods remaining
  Dec 19 11:36:34.899: INFO: 43 pods has nil DeletionTimestamp
  Dec 19 11:36:34.899: INFO: 
  E1219 11:36:35.582369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:35.949: INFO: 32 pods remaining
  Dec 19 11:36:35.950: INFO: 30 pods has nil DeletionTimestamp
  Dec 19 11:36:35.950: INFO: 
  E1219 11:36:36.582634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:36.889: INFO: 17 pods remaining
  Dec 19 11:36:36.889: INFO: 16 pods has nil DeletionTimestamp
  Dec 19 11:36:36.889: INFO: 
  E1219 11:36:37.584623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 11:36:37.847
  Dec 19 11:36:38.171: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 11:36:38.171: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7253" for this suite. @ 12/19/23 11:36:38.195
• [13.688 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 12/19/23 11:36:38.228
  Dec 19 11:36:38.228: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:36:38.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:36:38.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:36:38.354
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:36:38.362
  E1219 11:36:38.601270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:39.585649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:40.585207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:41.585420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:42.586355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:43.586803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:44.587322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:45.587289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:46.587651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:36:46.639
  Dec 19 11:36:46.648: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-58063114-3094-422a-b2b3-0c50a46d29a7 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:36:46.692
  Dec 19 11:36:46.799: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8913" for this suite. @ 12/19/23 11:36:46.826
• [8.644 seconds]
------------------------------
S
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 12/19/23 11:36:46.875
  Dec 19 11:36:46.875: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:36:46.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:36:46.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:36:46.986
  STEP: Creating projection with secret that has name secret-emptykey-test-5de92d97-fa8f-4b27-9796-6bfe04f14fbc @ 12/19/23 11:36:47.013
  Dec 19 11:36:47.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1515" for this suite. @ 12/19/23 11:36:47.096
• [0.266 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 12/19/23 11:36:47.143
  Dec 19 11:36:47.143: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 11:36:47.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:36:47.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:36:47.242
  STEP: Performing setup for networking test in namespace pod-network-test-3527 @ 12/19/23 11:36:47.252
  STEP: creating a selector @ 12/19/23 11:36:47.252
  STEP: Creating the service pods in kubernetes @ 12/19/23 11:36:47.252
  Dec 19 11:36:47.252: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 11:36:47.588375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:48.588662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:49.588828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:50.589055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:51.589434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:52.590105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:53.590708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:54.590900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:55.591408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:56.591980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:57.592960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:58.593805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:59.593915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:00.594037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:01.595170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:02.595302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:03.597161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:04.600164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:05.600590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:06.601324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:07.602359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:08.602870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:09.603110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 11:37:09.978
  E1219 11:37:10.603348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:11.603615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:12.020: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 11:37:12.020: INFO: Breadth first check of 10.233.64.106 on host 192.168.121.241...
  Dec 19 11:37:12.028: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.128:9080/dial?request=hostname&protocol=udp&host=10.233.64.106&port=8081&tries=1'] Namespace:pod-network-test-3527 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:37:12.028: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:37:12.031: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:37:12.031: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3527/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.128%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.106%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 11:37:12.200: INFO: Waiting for responses: map[]
  Dec 19 11:37:12.200: INFO: reached 10.233.64.106 after 0/1 tries
  Dec 19 11:37:12.200: INFO: Breadth first check of 10.233.65.124 on host 192.168.121.77...
  Dec 19 11:37:12.207: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.128:9080/dial?request=hostname&protocol=udp&host=10.233.65.124&port=8081&tries=1'] Namespace:pod-network-test-3527 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:37:12.208: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:37:12.210: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:37:12.211: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3527/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.128%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.124%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 11:37:12.322: INFO: Waiting for responses: map[]
  Dec 19 11:37:12.323: INFO: reached 10.233.65.124 after 0/1 tries
  Dec 19 11:37:12.323: INFO: Breadth first check of 10.233.66.127 on host 192.168.121.201...
  Dec 19 11:37:12.335: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.128:9080/dial?request=hostname&protocol=udp&host=10.233.66.127&port=8081&tries=1'] Namespace:pod-network-test-3527 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:37:12.335: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:37:12.339: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:37:12.339: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3527/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.128%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.127%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 11:37:12.452: INFO: Waiting for responses: map[]
  Dec 19 11:37:12.452: INFO: reached 10.233.66.127 after 0/1 tries
  Dec 19 11:37:12.452: INFO: Going to retry 0 out of 3 pods....
  Dec 19 11:37:12.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3527" for this suite. @ 12/19/23 11:37:12.469
• [25.341 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 12/19/23 11:37:12.494
  Dec 19 11:37:12.494: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:37:12.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:37:12.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:37:12.535
  STEP: Creating projection with secret that has name projected-secret-test-map-76e2539e-e2b5-429f-a954-86303cdfcd17 @ 12/19/23 11:37:12.542
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:37:12.552
  E1219 11:37:12.604936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:13.605735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:37:14.595
  Dec 19 11:37:14.607: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-secrets-8103b003-b555-47f5-8b93-1b1f16092b48 container projected-secret-volume-test: <nil>
  E1219 11:37:14.608157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/19/23 11:37:14.625
  Dec 19 11:37:14.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2910" for this suite. @ 12/19/23 11:37:14.674
• [2.194 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 12/19/23 11:37:14.689
  Dec 19 11:37:14.689: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:37:14.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:37:14.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:37:14.728
  STEP: Creating pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327 @ 12/19/23 11:37:14.734
  E1219 11:37:15.608169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:16.608638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:37:16.774
  Dec 19 11:37:16.781: INFO: Initial restart count of pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 is 0
  Dec 19 11:37:16.788: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:17.609876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:18.610138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:18.802: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:19.610876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:20.611070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:20.814: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:21.610818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:22.611028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:22.821: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:23.611315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:24.611987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:24.835: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:25.611881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:26.612101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:26.851: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:27.613549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:28.613328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:28.859: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:29.613650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:30.614534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:30.867: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:31.614648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:32.615249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:32.881: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:33.615523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:34.616854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:34.890: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:35.616941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:36.618049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:36.899: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:37.618890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:38.619898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:38.908: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:39.620050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:40.620364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:40.917: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:41.623724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:42.622194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:42.925: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:43.622361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:44.622597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:44.933: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:45.624023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:46.624094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:46.943: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:47.624135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:48.624202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:48.954: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:49.624499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:50.625678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:50.975: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:51.625609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:52.626571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:52.990: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:53.626388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:54.626387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:54.999: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:55.627778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:56.628043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:57.007: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:57.628881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:58.629208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:59.017: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:37:59.630116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:00.630919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:01.025: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:01.630996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:02.631664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:03.032: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:03.632999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:04.633143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:05.042: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:05.633397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:06.633380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:07.049: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:07.633619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:08.633914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:09.058: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:09.634272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:10.634584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:11.067: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:11.634711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:12.635589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:13.074: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:13.635649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:14.636599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:15.084: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:15.636697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:16.637093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:17.093: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:17.637392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:18.637512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:19.107: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:19.637909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:20.638117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:21.115: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:21.638807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:22.639059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:23.124: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:23.639266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:24.639487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:25.133: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:25.640584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:26.640798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:27.143: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:27.641674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:28.641880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:29.151: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:29.642848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:30.643087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:31.160: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:31.643200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:32.644617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:33.170: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:33.645476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:34.646182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:35.178: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:35.646772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:36.646997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:37.186: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:37.647350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:38.647561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:39.194: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:39.648528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:40.649054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:41.202: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:41.649344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:42.649685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:43.211: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:43.649722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:44.650326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:45.220: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:45.650990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:46.652875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:47.233: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:47.653166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:48.653836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:49.243: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:49.654029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:50.655484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:51.253: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:51.655249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:52.655375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:53.261: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:53.656292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:54.656674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:55.271: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:55.657261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:56.657525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:57.282: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:57.658175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:58.658921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:59.298: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:38:59.659999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:00.661081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:01.306: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:01.661893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:02.662977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:03.315: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:03.663570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:04.664224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:05.326: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:05.664329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:06.665264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:07.337: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:07.666288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:08.667021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:09.346: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:09.667063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:10.667273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:11.354: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:11.667438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:12.667720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:13.363: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:13.667878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:14.668170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:15.370: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:15.669073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:16.669670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:17.381: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:17.669784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:18.670029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:19.391: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:19.670306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:20.670430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:21.401: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:21.670754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:22.671147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:23.411: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:23.672224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:24.672682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:25.418: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:25.673137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:26.673457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:27.428: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:27.674138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:28.678253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:29.437: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:29.675519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:30.675647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:31.445: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:31.676378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:32.677519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:33.453: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:33.677298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:34.677988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:35.463: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:35.678880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:36.679311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:37.474: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:37.682169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:38.683070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:39.483: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:39.682620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:40.682786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:41.493: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:41.683787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:42.683557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:43.509: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:43.684460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:44.684662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:45.519: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:45.685415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:46.685738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:47.532: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:47.686265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:48.686648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:49.540: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:49.687492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:50.687657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:51.568: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:51.687991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:52.688392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:53.579: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:53.688646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:54.688839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:55.615: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:55.689588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:56.689499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:57.624: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:57.689654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:58.690332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:59.633: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:39:59.690619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:00.691304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:01.642: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:01.692433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:02.692565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:03.651: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:03.693453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:04.693313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:05.659: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:05.694360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:06.694575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:07.686: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:07.695492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:08.695757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:09.694: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:09.696654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:10.697028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:11.697691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:11.701: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:12.698290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:13.698398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:13.711: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:14.698741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:15.699480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:15.719: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:16.699685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:17.700908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:17.728: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:18.701024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:19.701070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:19.735: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:20.702052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:21.702033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:21.742: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:22.702589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:23.702877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:23.752: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:24.703881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:25.704042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:25.758: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:26.704217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:27.705209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:27.768: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:28.705420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:29.705540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:29.776: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:30.705849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:31.706561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:31.789: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:32.707190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:33.707344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:33.803: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:34.707438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:35.708146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:35.815: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:36.709107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:37.709583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:37.824: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:38.709580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:39.710238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:39.835: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:40.710851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:41.711675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:41.850: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:42.712338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:43.713278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:43.861: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:44.713376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:45.713269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:45.870: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:46.715177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:47.715570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:47.878: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:48.715765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:49.716914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:49.888: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:50.717068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:51.718201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:51.896: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:52.719165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:53.719815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:53.905: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:54.720457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:55.721026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:55.917: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:56.721226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:57.722344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:57.929: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:40:58.723341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:59.724534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:59.941: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:00.724727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:01.725093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:01.948: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:02.725133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:03.725353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:03.958: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:04.725640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:05.725839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:05.966: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:06.726007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:07.726379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:07.975: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:08.726493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:09.726671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:09.984: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:10.726898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:11.727720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:11.994: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:12.728591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:13.728941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:14.002: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:14.729133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:15.729939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:16.010: INFO: Get pod test-grpc-9a3dfcda-664b-4560-a04c-95e115259975 in namespace container-probe-4327
  E1219 11:41:16.730095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:17.730424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 12/19/23 11:41:18.011
  Dec 19 11:41:18.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4327" for this suite. @ 12/19/23 11:41:18.07
• [243.406 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 12/19/23 11:41:18.1
  Dec 19 11:41:18.100: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:41:18.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:18.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:18.191
  STEP: getting a starting resourceVersion @ 12/19/23 11:41:18.197
  STEP: starting a background goroutine to produce watch events @ 12/19/23 11:41:18.205
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 12/19/23 11:41:18.205
  E1219 11:41:18.731417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:19.732553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:20.732577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:20.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4113" for this suite. @ 12/19/23 11:41:20.973
• [2.924 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 12/19/23 11:41:21.026
  Dec 19 11:41:21.026: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:41:21.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:21.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:21.07
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/19/23 11:41:21.079
  E1219 11:41:21.733070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:22.733828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:23.734165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:24.735284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:41:25.125
  Dec 19 11:41:25.132: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-4ffc4f95-dcef-45a6-a68a-ec5b2d2936b3 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:41:25.171
  Dec 19 11:41:25.209: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8855" for this suite. @ 12/19/23 11:41:25.218
• [4.206 seconds]
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 12/19/23 11:41:25.233
  Dec 19 11:41:25.234: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename podtemplate @ 12/19/23 11:41:25.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:25.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:25.286
  Dec 19 11:41:25.365: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6846" for this suite. @ 12/19/23 11:41:25.373
• [0.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 12/19/23 11:41:25.394
  Dec 19 11:41:25.394: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:41:25.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:25.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:25.433
  STEP: Creating a ResourceQuota with terminating scope @ 12/19/23 11:41:25.439
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 11:41:25.45
  E1219 11:41:25.736215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:26.736539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 12/19/23 11:41:27.457
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 11:41:27.467
  E1219 11:41:27.736691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:28.737355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 12/19/23 11:41:29.478
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 12/19/23 11:41:29.51
  E1219 11:41:29.738278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:30.739386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 12/19/23 11:41:31.518
  E1219 11:41:31.739446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:32.739783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 11:41:33.527
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 11:41:33.563
  E1219 11:41:33.740812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:34.741803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 12/19/23 11:41:35.637
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 12/19/23 11:41:35.658
  E1219 11:41:35.742309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:36.742530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 12/19/23 11:41:37.668
  E1219 11:41:37.743465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:38.743805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 11:41:39.675
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 11:41:39.708
  E1219 11:41:39.744162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:40.744825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:41.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7351" for this suite. @ 12/19/23 11:41:41.728
• [16.348 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:846
  E1219 11:41:41.747394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a kubernetes client @ 12/19/23 11:41:41.747
  Dec 19 11:41:41.748: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:41:41.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:41.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:41.794
  STEP: Create set of pods @ 12/19/23 11:41:41.8
  Dec 19 11:41:41.821: INFO: created test-pod-1
  Dec 19 11:41:41.834: INFO: created test-pod-2
  Dec 19 11:41:41.846: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 12/19/23 11:41:41.847
  E1219 11:41:42.746435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:43.747443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 12/19/23 11:41:43.958
  Dec 19 11:41:43.972: INFO: Pod quantity 3 is different from expected quantity 0
  E1219 11:41:44.748211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:44.968: INFO: Pod quantity 3 is different from expected quantity 0
  E1219 11:41:45.748718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:45.970: INFO: Pod quantity 1 is different from expected quantity 0
  E1219 11:41:46.748809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:46.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2393" for this suite. @ 12/19/23 11:41:46.986
• [5.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 12/19/23 11:41:47.001
  Dec 19 11:41:47.001: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 11:41:47.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:47.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:47.05
  Dec 19 11:41:47.062: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:41:47.749911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:48.750672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:49.751503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:50.591: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1491" for this suite. @ 12/19/23 11:41:50.6
• [3.614 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 12/19/23 11:41:50.616
  Dec 19 11:41:50.616: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename limitrange @ 12/19/23 11:41:50.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:50.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:50.66
  STEP: Creating LimitRange "e2e-limitrange-mw44z" in namespace "limitrange-2274" @ 12/19/23 11:41:50.666
  STEP: Creating another limitRange in another namespace @ 12/19/23 11:41:50.674
  Dec 19 11:41:50.703: INFO: Namespace "e2e-limitrange-mw44z-4985" created
  Dec 19 11:41:50.703: INFO: Creating LimitRange "e2e-limitrange-mw44z" in namespace "e2e-limitrange-mw44z-4985"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-mw44z" @ 12/19/23 11:41:50.713
  Dec 19 11:41:50.719: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-mw44z" in "limitrange-2274" namespace @ 12/19/23 11:41:50.719
  Dec 19 11:41:50.735: INFO: LimitRange "e2e-limitrange-mw44z" has been patched
  STEP: Delete LimitRange "e2e-limitrange-mw44z" by Collection with labelSelector: "e2e-limitrange-mw44z=patched" @ 12/19/23 11:41:50.735
  E1219 11:41:50.752194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Confirm that the limitRange "e2e-limitrange-mw44z" has been deleted @ 12/19/23 11:41:50.755
  Dec 19 11:41:50.755: INFO: Requesting list of LimitRange to confirm quantity
  Dec 19 11:41:50.762: INFO: Found 0 LimitRange with label "e2e-limitrange-mw44z=patched"
  Dec 19 11:41:50.762: INFO: LimitRange "e2e-limitrange-mw44z" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-mw44z" @ 12/19/23 11:41:50.763
  Dec 19 11:41:50.769: INFO: Found 1 limitRange
  Dec 19 11:41:50.769: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2274" for this suite. @ 12/19/23 11:41:50.777
  STEP: Destroying namespace "e2e-limitrange-mw44z-4985" for this suite. @ 12/19/23 11:41:50.79
• [0.190 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 12/19/23 11:41:50.809
  Dec 19 11:41:50.809: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:41:50.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:41:50.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:41:50.865
  STEP: Creating service test in namespace statefulset-2 @ 12/19/23 11:41:50.871
  STEP: Looking for a node to schedule stateful set and pod @ 12/19/23 11:41:50.888
  STEP: Creating pod with conflicting port in namespace statefulset-2 @ 12/19/23 11:41:50.904
  STEP: Waiting until pod test-pod will start running in namespace statefulset-2 @ 12/19/23 11:41:50.939
  E1219 11:41:51.752557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:52.752831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-2 @ 12/19/23 11:41:52.966
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2 @ 12/19/23 11:41:52.977
  Dec 19 11:41:53.009: INFO: Observed stateful pod in namespace: statefulset-2, name: ss-0, uid: 780660f4-b4a6-4002-9447-51a3a42db82b, status phase: Pending. Waiting for statefulset controller to delete.
  Dec 19 11:41:53.035: INFO: Observed stateful pod in namespace: statefulset-2, name: ss-0, uid: 780660f4-b4a6-4002-9447-51a3a42db82b, status phase: Failed. Waiting for statefulset controller to delete.
  Dec 19 11:41:53.073: INFO: Observed stateful pod in namespace: statefulset-2, name: ss-0, uid: 780660f4-b4a6-4002-9447-51a3a42db82b, status phase: Failed. Waiting for statefulset controller to delete.
  Dec 19 11:41:53.088: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2
  STEP: Removing pod with conflicting port in namespace statefulset-2 @ 12/19/23 11:41:53.088
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2 and will be in running state @ 12/19/23 11:41:53.116
  E1219 11:41:53.754201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:54.754344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:55.755000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:56.755609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:57.756278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:58.756611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:59.756929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:00.757759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:01.758430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:02.758574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:03.760114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:04.760085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:05.760274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:06.761164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:07.761302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:08.763495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:09.206: INFO: Deleting all statefulset in ns statefulset-2
  Dec 19 11:42:09.216: INFO: Scaling statefulset ss to 0
  E1219 11:42:09.764281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:10.763581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:11.763530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:12.764287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:13.764580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:14.765364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:15.765366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:16.765899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:17.767104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:18.768298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:19.261: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:42:19.267: INFO: Deleting statefulset ss
  Dec 19 11:42:19.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2" for this suite. @ 12/19/23 11:42:19.312
• [28.516 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 12/19/23 11:42:19.325
  Dec 19 11:42:19.325: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:42:19.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:42:19.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:42:19.368
  E1219 11:42:19.769041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:20.769829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:21.770475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:22.770639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:23.771257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:24.771244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:42:25.497
  Dec 19 11:42:25.503: INFO: Trying to get logs from node uikie9pei4sh-3 pod client-envvars-64b5911a-5be6-4003-ad64-587962b1d31f container env3cont: <nil>
  STEP: delete the pod @ 12/19/23 11:42:25.519
  Dec 19 11:42:25.549: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5142" for this suite. @ 12/19/23 11:42:25.565
• [6.258 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 12/19/23 11:42:25.583
  Dec 19 11:42:25.583: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 11:42:25.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:42:25.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:42:25.626
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 12/19/23 11:42:25.637
  Dec 19 11:42:25.638: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:42:25.771695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:26.772398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:27.773263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:28.773320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:29.773905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:30.774689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:31.775471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:32.776486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 12/19/23 11:42:33.249
  Dec 19 11:42:33.251: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:42:33.776530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:34.777050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:35.224: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:42:35.777541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:36.778046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:37.778610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:38.779066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:39.779370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:40.780115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:41.780995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:42.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4220" for this suite. @ 12/19/23 11:42:42.363
• [16.796 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 12/19/23 11:42:42.39
  Dec 19 11:42:42.390: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:42:42.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:42:42.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:42:42.48
  STEP: Creating configMap with name projected-configmap-test-volume-map-c86fce4c-4386-489e-b2a5-c6f28cb0e579 @ 12/19/23 11:42:42.521
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:42:42.539
  E1219 11:42:42.782035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:43.782761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:44.783737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:45.784537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:42:46.587
  Dec 19 11:42:46.596: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-fb9bd2cd-335c-4964-8ec2-7bffd830453b container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:42:46.611
  Dec 19 11:42:46.642: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4197" for this suite. @ 12/19/23 11:42:46.654
• [4.281 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 12/19/23 11:42:46.674
  Dec 19 11:42:46.675: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:42:46.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:42:46.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:42:46.721
  STEP: Creating configMap with name configmap-test-volume-02d9374f-5a7b-4e8c-a3c6-97c1966096cd @ 12/19/23 11:42:46.727
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:42:46.735
  E1219 11:42:46.784827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:47.785021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:48.785581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:49.786333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:50.787391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:42:50.788
  Dec 19 11:42:50.798: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-8582395e-fffb-4632-852b-2376df6761ba container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:42:50.816
  Dec 19 11:42:50.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7015" for this suite. @ 12/19/23 11:42:50.867
• [4.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 12/19/23 11:42:50.887
  Dec 19 11:42:50.887: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:42:50.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:42:50.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:42:50.947
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/19/23 11:42:50.953
  E1219 11:42:51.787864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:52.788330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:53.789086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:54.789195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:42:55.015
  Dec 19 11:42:55.024: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-4ddb3606-779c-4c82-bd0d-31d2278e1f9e container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:42:55.038
  Dec 19 11:42:55.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-929" for this suite. @ 12/19/23 11:42:55.09
• [4.215 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 12/19/23 11:42:55.102
  Dec 19 11:42:55.102: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename aggregator @ 12/19/23 11:42:55.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:42:55.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:42:55.178
  Dec 19 11:42:55.191: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Registering the sample API server. @ 12/19/23 11:42:55.197
  E1219 11:42:55.789726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:56.518: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Dec 19 11:42:56.621: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  E1219 11:42:56.790472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:57.790799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:58.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:42:58.790865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:59.791097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:00.750: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:00.791874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:01.792305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:02.749: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:02.792632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:03.792810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:04.750: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:04.793312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:05.793367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:06.749: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:06.794580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:07.794174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:08.750: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:08.795468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:09.795612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:10.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:10.795346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:11.795709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:12.752: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:12.796222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:13.797189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:14.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:14.798381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:15.798582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:16.749: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:16.799322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:17.799817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:18.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:18.800428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:19.800968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:20.748: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:20.801214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:21.801743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:22.750: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 42, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-99565549d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:43:22.802133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:23.802238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:24.805216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:24.898: INFO: Waited 133.589508ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 12/19/23 11:43:25.002
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 12/19/23 11:43:25.011
  STEP: List APIServices @ 12/19/23 11:43:25.028
  Dec 19 11:43:25.044: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 12/19/23 11:43:25.044
  Dec 19 11:43:25.073: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 12/19/23 11:43:25.073
  Dec 19 11:43:25.104: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.December, 19, 11, 43, 24, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 12/19/23 11:43:25.104
  Dec 19 11:43:25.113: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-12-19 11:43:24 +0000 UTC Passed all checks passed}
  Dec 19 11:43:25.114: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 11:43:25.114: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 12/19/23 11:43:25.114
  Dec 19 11:43:25.144: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-214564653" @ 12/19/23 11:43:25.145
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 12/19/23 11:43:25.174
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 12/19/23 11:43:25.187
  STEP: Patch APIService Status @ 12/19/23 11:43:25.195
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 12/19/23 11:43:25.217
  Dec 19 11:43:25.235: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-12-19 11:43:24 +0000 UTC Passed all checks passed}
  Dec 19 11:43:25.237: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 11:43:25.238: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Dec 19 11:43:25.239: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 12/19/23 11:43:25.24
  STEP: Confirm that the generated APIService has been deleted @ 12/19/23 11:43:25.264
  Dec 19 11:43:25.264: INFO: Requesting list of APIServices to confirm quantity
  Dec 19 11:43:25.278: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  Dec 19 11:43:25.278: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Dec 19 11:43:25.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-6704" for this suite. @ 12/19/23 11:43:25.635
• [30.550 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 12/19/23 11:43:25.654
  Dec 19 11:43:25.655: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:43:25.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:43:25.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:43:25.715
  STEP: Setting up server cert @ 12/19/23 11:43:25.79
  E1219 11:43:25.805462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:26.806112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:43:27.251
  STEP: Deploying the webhook pod @ 12/19/23 11:43:27.261
  STEP: Wait for the deployment to be ready @ 12/19/23 11:43:27.289
  Dec 19 11:43:27.316: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:43:27.806710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:28.807593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:43:29.34
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:43:29.362
  E1219 11:43:29.807803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:30.363: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 12/19/23 11:43:30.391
  STEP: Creating a custom resource definition that should be denied by the webhook @ 12/19/23 11:43:30.433
  Dec 19 11:43:30.434: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:43:30.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8891" for this suite. @ 12/19/23 11:43:30.584
  STEP: Destroying namespace "webhook-markers-7602" for this suite. @ 12/19/23 11:43:30.601
• [4.958 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 12/19/23 11:43:30.616
  Dec 19 11:43:30.616: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:43:30.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:43:30.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:43:30.657
  STEP: creating a Namespace @ 12/19/23 11:43:30.663
  STEP: patching the Namespace @ 12/19/23 11:43:30.691
  STEP: get the Namespace and ensuring it has the label @ 12/19/23 11:43:30.704
  Dec 19 11:43:30.711: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9360" for this suite. @ 12/19/23 11:43:30.722
  STEP: Destroying namespace "nspatchtest-19930f7c-5559-432a-bf87-5321b723dba7-2434" for this suite. @ 12/19/23 11:43:30.734
• [0.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 12/19/23 11:43:30.754
  Dec 19 11:43:30.754: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename crd-webhook @ 12/19/23 11:43:30.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:43:30.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:43:30.793
  STEP: Setting up server cert @ 12/19/23 11:43:30.799
  E1219 11:43:30.808663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/19/23 11:43:31.489
  STEP: Deploying the custom resource conversion webhook pod @ 12/19/23 11:43:31.507
  STEP: Wait for the deployment to be ready @ 12/19/23 11:43:31.526
  Dec 19 11:43:31.568: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1219 11:43:31.808843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:32.809065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:43:33.591
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:43:33.619
  E1219 11:43:33.809807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:34.622: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec 19 11:43:34.637: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:43:34.810014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:35.810619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:36.811308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 12/19/23 11:43:37.555
  STEP: Create a v2 custom resource @ 12/19/23 11:43:37.605
  E1219 11:43:37.811487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: List CRs in v1 @ 12/19/23 11:43:37.928
  STEP: List CRs in v2 @ 12/19/23 11:43:37.939
  Dec 19 11:43:38.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-724" for this suite. @ 12/19/23 11:43:38.668
• [7.932 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 12/19/23 11:43:38.686
  Dec 19 11:43:38.686: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:43:38.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:43:38.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:43:38.739
  STEP: Creating configMap configmap-922/configmap-test-a8a37816-c938-4c80-a5d8-8e77e62dcd72 @ 12/19/23 11:43:38.748
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:43:38.763
  E1219 11:43:38.812390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:39.813596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:40.813681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:41.815603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:43:42.811
  E1219 11:43:42.815033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:42.817: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-configmaps-fad6ec95-afcc-4be1-ba87-f35006f54264 container env-test: <nil>
  STEP: delete the pod @ 12/19/23 11:43:42.835
  Dec 19 11:43:42.861: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-922" for this suite. @ 12/19/23 11:43:42.872
• [4.199 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 12/19/23 11:43:42.888
  Dec 19 11:43:42.888: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename security-context @ 12/19/23 11:43:42.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:43:42.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:43:42.937
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/19/23 11:43:42.943
  E1219 11:43:43.817154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:44.816867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:45.817157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:46.817526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:43:46.995
  Dec 19 11:43:47.006: INFO: Trying to get logs from node uikie9pei4sh-3 pod security-context-0ce53951-5bfc-4483-a0cf-d3d60f3aabec container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:43:47.021
  Dec 19 11:43:47.061: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6053" for this suite. @ 12/19/23 11:43:47.073
• [4.203 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 12/19/23 11:43:47.092
  Dec 19 11:43:47.092: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename gc @ 12/19/23 11:43:47.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:43:47.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:43:47.154
  STEP: create the rc1 @ 12/19/23 11:43:47.177
  STEP: create the rc2 @ 12/19/23 11:43:47.191
  E1219 11:43:47.818180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:48.818650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:49.818735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:50.819161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:51.819688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:52.820095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 12/19/23 11:43:53.275
  E1219 11:43:53.820128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:54.824683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:55.825352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 12/19/23 11:43:56.594
  STEP: wait for the rc to be deleted @ 12/19/23 11:43:56.633
  E1219 11:43:56.825762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:57.826423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:58.827247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:59.827659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:00.828313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:01.687: INFO: 72 pods remaining
  Dec 19 11:44:01.687: INFO: 72 pods has nil DeletionTimestamp
  Dec 19 11:44:01.687: INFO: 
  E1219 11:44:01.828562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:02.829360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:03.829885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:04.830528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:05.830633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 11:44:06.681
  E1219 11:44:06.831406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:07.289: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 11:44:07.289: INFO: Deleting pod "simpletest-rc-to-be-deleted-22plt" in namespace "gc-3595"
  Dec 19 11:44:07.320: INFO: Deleting pod "simpletest-rc-to-be-deleted-296m7" in namespace "gc-3595"
  Dec 19 11:44:07.376: INFO: Deleting pod "simpletest-rc-to-be-deleted-2gq4f" in namespace "gc-3595"
  Dec 19 11:44:07.478: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tbq9" in namespace "gc-3595"
  Dec 19 11:44:07.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-2vb85" in namespace "gc-3595"
  Dec 19 11:44:07.723: INFO: Deleting pod "simpletest-rc-to-be-deleted-4bsvh" in namespace "gc-3595"
  E1219 11:44:07.832554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:07.970: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jt8b" in namespace "gc-3595"
  Dec 19 11:44:08.052: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l2dl" in namespace "gc-3595"
  Dec 19 11:44:08.170: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nqs6" in namespace "gc-3595"
  Dec 19 11:44:08.239: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r86l" in namespace "gc-3595"
  Dec 19 11:44:08.302: INFO: Deleting pod "simpletest-rc-to-be-deleted-545x6" in namespace "gc-3595"
  Dec 19 11:44:08.350: INFO: Deleting pod "simpletest-rc-to-be-deleted-562jn" in namespace "gc-3595"
  Dec 19 11:44:08.415: INFO: Deleting pod "simpletest-rc-to-be-deleted-59q54" in namespace "gc-3595"
  Dec 19 11:44:08.467: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qlfh" in namespace "gc-3595"
  Dec 19 11:44:08.554: INFO: Deleting pod "simpletest-rc-to-be-deleted-5sd5f" in namespace "gc-3595"
  Dec 19 11:44:08.608: INFO: Deleting pod "simpletest-rc-to-be-deleted-5x9tr" in namespace "gc-3595"
  Dec 19 11:44:08.662: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zvld" in namespace "gc-3595"
  Dec 19 11:44:08.700: INFO: Deleting pod "simpletest-rc-to-be-deleted-66h9z" in namespace "gc-3595"
  Dec 19 11:44:08.731: INFO: Deleting pod "simpletest-rc-to-be-deleted-6966h" in namespace "gc-3595"
  Dec 19 11:44:08.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kzb4" in namespace "gc-3595"
  Dec 19 11:44:08.832: INFO: Deleting pod "simpletest-rc-to-be-deleted-6q447" in namespace "gc-3595"
  E1219 11:44:08.833436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:08.981: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jqfm" in namespace "gc-3595"
  Dec 19 11:44:09.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-7z8lp" in namespace "gc-3595"
  Dec 19 11:44:09.149: INFO: Deleting pod "simpletest-rc-to-be-deleted-844gc" in namespace "gc-3595"
  Dec 19 11:44:09.233: INFO: Deleting pod "simpletest-rc-to-be-deleted-8b8fh" in namespace "gc-3595"
  Dec 19 11:44:09.309: INFO: Deleting pod "simpletest-rc-to-be-deleted-9njkw" in namespace "gc-3595"
  Dec 19 11:44:09.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qpc9" in namespace "gc-3595"
  Dec 19 11:44:09.470: INFO: Deleting pod "simpletest-rc-to-be-deleted-9txcn" in namespace "gc-3595"
  Dec 19 11:44:09.562: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbnw5" in namespace "gc-3595"
  Dec 19 11:44:09.617: INFO: Deleting pod "simpletest-rc-to-be-deleted-bdnzv" in namespace "gc-3595"
  Dec 19 11:44:09.683: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7slw" in namespace "gc-3595"
  Dec 19 11:44:09.726: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckph9" in namespace "gc-3595"
  E1219 11:44:09.833839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:09.873: INFO: Deleting pod "simpletest-rc-to-be-deleted-cwscf" in namespace "gc-3595"
  Dec 19 11:44:09.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-d4txw" in namespace "gc-3595"
  Dec 19 11:44:10.040: INFO: Deleting pod "simpletest-rc-to-be-deleted-dg6hf" in namespace "gc-3595"
  Dec 19 11:44:10.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-drfdh" in namespace "gc-3595"
  Dec 19 11:44:10.188: INFO: Deleting pod "simpletest-rc-to-be-deleted-ds2mn" in namespace "gc-3595"
  Dec 19 11:44:10.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-f59n5" in namespace "gc-3595"
  Dec 19 11:44:10.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbsbr" in namespace "gc-3595"
  Dec 19 11:44:10.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-fh458" in namespace "gc-3595"
  Dec 19 11:44:10.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-fnp4t" in namespace "gc-3595"
  Dec 19 11:44:10.583: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpfnq" in namespace "gc-3595"
  Dec 19 11:44:10.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-gb77j" in namespace "gc-3595"
  Dec 19 11:44:10.699: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdvsx" in namespace "gc-3595"
  Dec 19 11:44:10.781: INFO: Deleting pod "simpletest-rc-to-be-deleted-gj4qt" in namespace "gc-3595"
  E1219 11:44:10.834076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:10.846: INFO: Deleting pod "simpletest-rc-to-be-deleted-gvmpb" in namespace "gc-3595"
  Dec 19 11:44:10.933: INFO: Deleting pod "simpletest-rc-to-be-deleted-gx8s7" in namespace "gc-3595"
  Dec 19 11:44:11.308: INFO: Deleting pod "simpletest-rc-to-be-deleted-hg4n5" in namespace "gc-3595"
  Dec 19 11:44:11.487: INFO: Deleting pod "simpletest-rc-to-be-deleted-j9fst" in namespace "gc-3595"
  Dec 19 11:44:11.557: INFO: Deleting pod "simpletest-rc-to-be-deleted-jpb6l" in namespace "gc-3595"
  Dec 19 11:44:11.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:44:11.834099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "gc-3595" for this suite. @ 12/19/23 11:44:11.835
• [24.765 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 12/19/23 11:44:11.858
  Dec 19 11:44:11.858: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 11:44:11.863
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:11.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:11.928
  STEP: create the container @ 12/19/23 11:44:11.937
  W1219 11:44:11.975487      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 12/19/23 11:44:11.976
  E1219 11:44:12.834230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:13.835044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/19/23 11:44:14.069
  STEP: the container should be terminated @ 12/19/23 11:44:14.076
  STEP: the termination message should be set @ 12/19/23 11:44:14.076
  Dec 19 11:44:14.076: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/19/23 11:44:14.076
  Dec 19 11:44:14.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-336" for this suite. @ 12/19/23 11:44:14.201
• [2.365 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 12/19/23 11:44:14.226
  Dec 19 11:44:14.226: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl-logs @ 12/19/23 11:44:14.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:14.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:14.503
  STEP: creating an pod @ 12/19/23 11:44:14.514
  Dec 19 11:44:14.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Dec 19 11:44:14.718: INFO: stderr: ""
  Dec 19 11:44:14.718: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 12/19/23 11:44:14.718
  Dec 19 11:44:14.718: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E1219 11:44:14.835608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:15.836336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:16.746: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 12/19/23 11:44:16.747
  Dec 19 11:44:16.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 logs logs-generator logs-generator'
  E1219 11:44:16.837257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:16.925: INFO: stderr: ""
  Dec 19 11:44:16.925: INFO: stdout: "I1219 11:44:15.398278       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/vcnw 467\nI1219 11:44:15.598284       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/5q5 588\nI1219 11:44:15.799065       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/jjr 587\nI1219 11:44:15.998638       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/xd2k 528\nI1219 11:44:16.199059       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/ng7 397\nI1219 11:44:16.398542       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/m2lv 356\nI1219 11:44:16.598800       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/jn2 266\nI1219 11:44:16.799160       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/p4m8 566\n"
  STEP: limiting log lines @ 12/19/23 11:44:16.925
  Dec 19 11:44:16.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 logs logs-generator logs-generator --tail=1'
  Dec 19 11:44:17.221: INFO: stderr: ""
  Dec 19 11:44:17.221: INFO: stdout: "I1219 11:44:17.199008       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/f78 218\n"
  Dec 19 11:44:17.221: INFO: got output "I1219 11:44:17.199008       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/f78 218\n"
  STEP: limiting log bytes @ 12/19/23 11:44:17.221
  Dec 19 11:44:17.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 logs logs-generator logs-generator --limit-bytes=1'
  Dec 19 11:44:17.432: INFO: stderr: ""
  Dec 19 11:44:17.432: INFO: stdout: "I"
  Dec 19 11:44:17.432: INFO: got output "I"
  STEP: exposing timestamps @ 12/19/23 11:44:17.432
  Dec 19 11:44:17.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 logs logs-generator logs-generator --tail=1 --timestamps'
  Dec 19 11:44:17.593: INFO: stderr: ""
  Dec 19 11:44:17.593: INFO: stdout: "2023-12-19T11:44:17.398546701Z I1219 11:44:17.398478       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/f2m 297\n"
  Dec 19 11:44:17.593: INFO: got output "2023-12-19T11:44:17.398546701Z I1219 11:44:17.398478       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/f2m 297\n"
  STEP: restricting to a time range @ 12/19/23 11:44:17.594
  E1219 11:44:17.837897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:18.838640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:19.839032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:20.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 logs logs-generator logs-generator --since=1s'
  Dec 19 11:44:20.307: INFO: stderr: ""
  Dec 19 11:44:20.307: INFO: stdout: "I1219 11:44:19.398648       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/6xlk 516\nI1219 11:44:19.599019       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/xzg 400\nI1219 11:44:19.798395       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/mqkh 250\nI1219 11:44:19.999147       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/d9b 552\nI1219 11:44:20.198918       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/487 392\n"
  Dec 19 11:44:20.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 logs logs-generator logs-generator --since=24h'
  Dec 19 11:44:20.491: INFO: stderr: ""
  Dec 19 11:44:20.491: INFO: stdout: "I1219 11:44:15.398278       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/vcnw 467\nI1219 11:44:15.598284       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/5q5 588\nI1219 11:44:15.799065       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/jjr 587\nI1219 11:44:15.998638       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/xd2k 528\nI1219 11:44:16.199059       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/ng7 397\nI1219 11:44:16.398542       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/m2lv 356\nI1219 11:44:16.598800       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/jn2 266\nI1219 11:44:16.799160       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/p4m8 566\nI1219 11:44:16.998734       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/zv9 497\nI1219 11:44:17.199008       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/f78 218\nI1219 11:44:17.398478       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/f2m 297\nI1219 11:44:17.598782       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/cpr 588\nI1219 11:44:17.798276       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/pbb 377\nI1219 11:44:17.999126       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/884w 519\nI1219 11:44:18.198294       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/g4b 460\nI1219 11:44:18.398800       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/tktb 528\nI1219 11:44:18.598203       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/k6rk 231\nI1219 11:44:18.798649       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/srl 348\nI1219 11:44:18.998370       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/98zv 553\nI1219 11:44:19.198630       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/54s 522\nI1219 11:44:19.398648       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/6xlk 516\nI1219 11:44:19.599019       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/xzg 400\nI1219 11:44:19.798395       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/mqkh 250\nI1219 11:44:19.999147       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/d9b 552\nI1219 11:44:20.198918       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/487 392\nI1219 11:44:20.399497       1 logs_generator.go:76] 25 POST /api/v1/namespaces/default/pods/kvt9 232\n"
  Dec 19 11:44:20.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-logs-5308 delete pod logs-generator'
  E1219 11:44:20.839731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:21.840407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:22.009: INFO: stderr: ""
  Dec 19 11:44:22.009: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Dec 19 11:44:22.009: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-5308" for this suite. @ 12/19/23 11:44:22.021
• [7.813 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 12/19/23 11:44:22.04
  Dec 19 11:44:22.040: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 11:44:22.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:22.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:22.113
  E1219 11:44:22.840681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:23.840735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:24.194: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5253" for this suite. @ 12/19/23 11:44:24.214
• [2.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 12/19/23 11:44:24.265
  Dec 19 11:44:24.266: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:44:24.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:24.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:24.326
  STEP: Setting up server cert @ 12/19/23 11:44:24.393
  E1219 11:44:24.840813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:44:25.578
  STEP: Deploying the webhook pod @ 12/19/23 11:44:25.596
  STEP: Wait for the deployment to be ready @ 12/19/23 11:44:25.616
  Dec 19 11:44:25.627: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 11:44:25.840950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:26.841152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:44:27.646
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:44:27.676
  E1219 11:44:27.842069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:28.676: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/19/23 11:44:28.824
  E1219 11:44:28.845005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:44:28.902
  STEP: Deleting the collection of validation webhooks @ 12/19/23 11:44:28.982
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:44:29.086
  Dec 19 11:44:29.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-731" for this suite. @ 12/19/23 11:44:29.235
  STEP: Destroying namespace "webhook-markers-9123" for this suite. @ 12/19/23 11:44:29.263
• [5.038 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 12/19/23 11:44:29.305
  Dec 19 11:44:29.306: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:44:29.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:29.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:29.373
  STEP: creating all guestbook components @ 12/19/23 11:44:29.384
  Dec 19 11:44:29.385: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Dec 19 11:44:29.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 create -f -'
  Dec 19 11:44:29.775: INFO: stderr: ""
  Dec 19 11:44:29.775: INFO: stdout: "service/agnhost-replica created\n"
  Dec 19 11:44:29.775: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Dec 19 11:44:29.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 create -f -'
  E1219 11:44:29.846082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:30.259: INFO: stderr: ""
  Dec 19 11:44:30.259: INFO: stdout: "service/agnhost-primary created\n"
  Dec 19 11:44:30.259: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Dec 19 11:44:30.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 create -f -'
  Dec 19 11:44:30.635: INFO: stderr: ""
  Dec 19 11:44:30.635: INFO: stdout: "service/frontend created\n"
  Dec 19 11:44:30.635: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Dec 19 11:44:30.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 create -f -'
  E1219 11:44:30.846364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:30.865: INFO: stderr: ""
  Dec 19 11:44:30.866: INFO: stdout: "deployment.apps/frontend created\n"
  Dec 19 11:44:30.867: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec 19 11:44:30.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 create -f -'
  Dec 19 11:44:31.235: INFO: stderr: ""
  Dec 19 11:44:31.235: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Dec 19 11:44:31.236: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec 19 11:44:31.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 create -f -'
  Dec 19 11:44:31.680: INFO: stderr: ""
  Dec 19 11:44:31.680: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 12/19/23 11:44:31.68
  Dec 19 11:44:31.681: INFO: Waiting for all frontend pods to be Running.
  E1219 11:44:31.847549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:32.849566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:33.848225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:34.848591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:35.849679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:36.733: INFO: Waiting for frontend to serve content.
  Dec 19 11:44:36.764: INFO: Trying to add a new entry to the guestbook.
  Dec 19 11:44:36.796: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 12/19/23 11:44:36.822
  Dec 19 11:44:36.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 delete --grace-period=0 --force -f -'
  E1219 11:44:36.850170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:37.015: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:44:37.015: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 11:44:37.016
  Dec 19 11:44:37.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 delete --grace-period=0 --force -f -'
  Dec 19 11:44:37.226: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:44:37.226: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 11:44:37.226
  Dec 19 11:44:37.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 delete --grace-period=0 --force -f -'
  Dec 19 11:44:37.395: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:44:37.395: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 11:44:37.395
  Dec 19 11:44:37.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 delete --grace-period=0 --force -f -'
  Dec 19 11:44:37.541: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:44:37.541: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 11:44:37.542
  Dec 19 11:44:37.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 delete --grace-period=0 --force -f -'
  Dec 19 11:44:37.743: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:44:37.743: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 11:44:37.743
  Dec 19 11:44:37.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-5142 delete --grace-period=0 --force -f -'
  E1219 11:44:37.854346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:37.976: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:44:37.976: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Dec 19 11:44:37.976: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5142" for this suite. @ 12/19/23 11:44:37.993
• [8.721 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 12/19/23 11:44:38.025
  Dec 19 11:44:38.025: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:44:38.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:38.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:38.13
  STEP: Creating projection with secret that has name projected-secret-test-6c66bc32-adca-40f9-88de-3617e3dbdcff @ 12/19/23 11:44:38.14
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:44:38.203
  E1219 11:44:38.854855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:39.855505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:44:40.36
  Dec 19 11:44:40.371: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-secrets-6c234f3c-8ce0-45f3-a4ff-68b8e4aa9e66 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:44:40.386
  Dec 19 11:44:40.415: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8201" for this suite. @ 12/19/23 11:44:40.425
• [2.410 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 12/19/23 11:44:40.437
  Dec 19 11:44:40.438: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:44:40.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:40.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:40.482
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:44:40.487
  E1219 11:44:40.855654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:41.856111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:42.857353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:43.857904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:44:44.528
  Dec 19 11:44:44.534: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-5deba2f3-26fd-4dca-b5f7-328d2a3b690e container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:44:44.557
  Dec 19 11:44:44.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9199" for this suite. @ 12/19/23 11:44:44.61
• [4.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 12/19/23 11:44:44.637
  Dec 19 11:44:44.637: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename taint-single-pod @ 12/19/23 11:44:44.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:44.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:44.689
  Dec 19 11:44:44.706: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:44:44.858279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:45.859344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:46.859719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:47.859935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:48.860917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:49.861056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:50.861578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:51.862292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:52.863419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:53.863894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:54.864154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:55.864955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:56.865094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:57.865318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:58.866130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:59.866303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:00.866850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:01.867244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:02.867910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:03.868605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:04.869525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:05.869660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:06.870565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:07.871654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:08.872644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:09.873016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:10.874034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:11.874773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:12.875146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:13.875817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:14.876483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:15.877595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:16.877781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:17.877904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:18.877905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:19.878638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:20.879642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:21.880221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:22.880524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:23.880837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:24.881048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:25.881681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:26.882451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:27.883175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:28.883739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:29.884034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:30.884172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:31.885133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:32.886125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:33.886866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:34.887725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:35.888523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:36.889025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:37.889891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:38.890838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:39.891341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:40.892107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:41.892302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:42.893244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:43.893821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:45:44.714: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 11:45:44.723: INFO: Starting informer...
  STEP: Starting pod... @ 12/19/23 11:45:44.724
  E1219 11:45:44.895502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:45:44.956: INFO: Pod is running on uikie9pei4sh-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/19/23 11:45:44.956
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 11:45:45.002
  STEP: Waiting short time to make sure Pod is queued for deletion @ 12/19/23 11:45:45.011
  Dec 19 11:45:45.011: INFO: Pod wasn't evicted. Proceeding
  Dec 19 11:45:45.011: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 11:45:45.043
  STEP: Waiting some time to make sure that toleration time passed. @ 12/19/23 11:45:45.068
  E1219 11:45:45.895551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:46.896808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:47.896864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:48.897991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:49.898174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:50.898746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:51.898978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:52.899165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:53.899686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:54.899905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:55.900210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:56.900489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:57.901086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:58.901823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:59.901977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:00.902199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:01.902386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:02.902584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:03.903661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:04.903878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:05.904050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:06.904371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:07.904554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:08.905558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:09.905799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:10.905959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:11.906136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:12.906532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:13.907131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:14.907304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:15.907577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:16.908398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:17.909407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:18.910505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:19.910703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:20.910916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:21.911299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:22.911699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:23.912590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:24.913110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:25.913758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:26.914119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:27.914924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:28.915730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:29.917389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:30.917605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:31.918221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:32.918670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:33.919072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:34.919409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:35.920292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:36.920551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:37.921743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:38.922743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:39.923015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:40.923276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:41.924249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:42.925019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:43.925867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:44.926844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:45.927396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:46.927188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:47.927396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:48.928284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:49.928523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:50.928813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:51.929117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:52.929366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:53.930580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:54.931015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:55.931473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:56.931844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:57.932399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:58.933331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:59.933697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:00.069: INFO: Pod wasn't evicted. Test successful
  Dec 19 11:47:00.070: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-8901" for this suite. @ 12/19/23 11:47:00.083
• [135.465 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 12/19/23 11:47:00.11
  Dec 19 11:47:00.110: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:47:00.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:47:00.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:47:00.158
  STEP: Setting up server cert @ 12/19/23 11:47:00.213
  E1219 11:47:00.934057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:47:01.804
  STEP: Deploying the webhook pod @ 12/19/23 11:47:01.82
  STEP: Wait for the deployment to be ready @ 12/19/23 11:47:01.844
  Dec 19 11:47:01.865: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:47:01.934689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:02.935566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:47:03.886
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:47:03.913
  E1219 11:47:03.936207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:04.914: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/19/23 11:47:04.929
  E1219 11:47:04.937133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/19/23 11:47:04.966
  STEP: Creating a dummy validating-webhook-configuration object @ 12/19/23 11:47:05.006
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 12/19/23 11:47:05.025
  STEP: Creating a dummy mutating-webhook-configuration object @ 12/19/23 11:47:05.035
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 12/19/23 11:47:05.051
  Dec 19 11:47:05.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2817" for this suite. @ 12/19/23 11:47:05.216
  STEP: Destroying namespace "webhook-markers-5336" for this suite. @ 12/19/23 11:47:05.23
• [5.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 12/19/23 11:47:05.249
  Dec 19 11:47:05.249: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:47:05.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:47:05.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:47:05.297
  STEP: Creating simple DaemonSet "daemon-set" @ 12/19/23 11:47:05.349
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:47:05.362
  Dec 19 11:47:05.384: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:47:05.385: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:47:05.937672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:06.394: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:47:06.394: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:47:06.937680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:07.380: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:47:07.381: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 12/19/23 11:47:07.388
  Dec 19 11:47:07.427: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 11:47:07.427: INFO: Node uikie9pei4sh-3 is running 0 daemon pod, expected 1
  E1219 11:47:07.938092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:08.431: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 11:47:08.432: INFO: Node uikie9pei4sh-3 is running 0 daemon pod, expected 1
  E1219 11:47:08.940354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:09.429: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:47:09.429: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 11:47:09.434
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8489, will wait for the garbage collector to delete the pods @ 12/19/23 11:47:09.434
  Dec 19 11:47:09.503: INFO: Deleting DaemonSet.extensions daemon-set took: 11.39002ms
  Dec 19 11:47:09.704: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.510581ms
  E1219 11:47:09.939345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:10.940420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:11.114: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:47:11.114: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 11:47:11.122: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36326"},"items":null}

  Dec 19 11:47:11.130: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36326"},"items":null}

  Dec 19 11:47:11.177: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8489" for this suite. @ 12/19/23 11:47:11.187
• [5.956 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 12/19/23 11:47:11.206
  Dec 19 11:47:11.206: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:47:11.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:47:11.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:47:11.26
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:47:11.273
  E1219 11:47:11.940617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:12.941335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:13.941761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:14.942528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:47:15.324
  Dec 19 11:47:15.333: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-bf6a1a4f-c918-4c62-963e-f25e82d0ba93 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:47:15.381
  Dec 19 11:47:15.419: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7377" for this suite. @ 12/19/23 11:47:15.432
• [4.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 12/19/23 11:47:15.461
  Dec 19 11:47:15.461: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:47:15.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:47:15.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:47:15.506
  STEP: Updating Namespace "namespaces-4290" @ 12/19/23 11:47:15.516
  Dec 19 11:47:15.571: INFO: Namespace "namespaces-4290" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"13f7c4b6-93cb-4d70-8a59-2a33698c5e74", "kubernetes.io/metadata.name":"namespaces-4290", "namespaces-4290":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Dec 19 11:47:15.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4290" for this suite. @ 12/19/23 11:47:15.581
• [0.140 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 12/19/23 11:47:15.602
  Dec 19 11:47:15.602: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:47:15.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:47:15.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:47:15.666
  Dec 19 11:47:15.711: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E1219 11:47:15.942715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:16.943343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:17.943576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:18.943603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:19.943991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:20.722: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:47:20.722
  Dec 19 11:47:20.722: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 12/19/23 11:47:20.743
  Dec 19 11:47:20.766: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8154",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d78d6cbd-4ce5-46f7-8fbf-6d288a81e34f",
      ResourceVersion: (string) (len=5) "36419",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838583240,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583240,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:47:20.778: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Dec 19 11:47:20.778: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Dec 19 11:47:20.779: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8154",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1fae1c62-af5a-453b-8b5f-fe401e2b4dc4",
      ResourceVersion: (string) (len=5) "36420",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838583235,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "d78d6cbd-4ce5-46f7-8fbf-6d288a81e34f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583235,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583236,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583240,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 64 37 38 64 36 63 62  |"uid\":\"d78d6cb|
              00000040  64 2d 34 63 65 35 2d 34  36 66 37 2d 38 66 62 66  |d-4ce5-46f7-8fbf|
              00000050  2d 36 64 32 38 38 61 38  31 65 33 34 66 5c 22 7d  |-6d288a81e34f\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:47:20.800: INFO: Pod "test-cleanup-controller-p96xm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-p96xm",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-8154",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "60333729-aaab-4e25-bb31-f9f3a3a7ec40",
      ResourceVersion: (string) (len=5) "36403",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838583235,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "1fae1c62-af5a-453b-8b5f-fe401e2b4dc4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583235,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  31 66 61 65 31 63 36 32  |uid\":\"1fae1c62|
              00000080  2d 61 66 35 61 2d 34 35  33 62 2d 38 62 35 66 2d  |-af5a-453b-8b5f-|
              00000090  66 65 34 30 31 65 32 62  34 64 63 34 5c 22 7d 22  |fe401e2b4dc4\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583236,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 39 37 5c 22 7d 22 3a  |.233.66.197\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8gwvz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8gwvz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "uikie9pei4sh-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583236,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583235,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583236,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583236,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838583235,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.201",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.201"
        }
      },
      PodIP: (string) (len=13) "10.233.66.197",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.197"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838583235,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838583236,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://0fdd4bce330565eb2101d8faeacf32131577d8fdb6ed8a74ab07006893b52010",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:47:20.880: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8154" for this suite. @ 12/19/23 11:47:20.896
• [5.312 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 12/19/23 11:47:20.919
  Dec 19 11:47:20.919: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename chunking @ 12/19/23 11:47:20.923
  E1219 11:47:20.944182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:47:20.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:47:20.972
  STEP: creating a large number of resources @ 12/19/23 11:47:20.982
  E1219 11:47:21.945121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:22.945318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:23.945442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:24.945826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:25.946408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:26.947372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:27.947777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:28.948850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:29.948906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:30.949166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:31.949556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:32.950034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:33.951050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:34.951869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:35.952179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:36.952552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:37.953639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 12/19/23 11:47:38.634
  Dec 19 11:47:38.687: INFO: Retrieved 40/40 results with rv 36893 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 12/19/23 11:47:38.688
  E1219 11:47:38.953953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:39.955195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:40.954404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:41.954544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:42.954765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:43.955825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:44.955964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:45.956237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:46.957203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:47.957392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:48.958006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:49.958350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:50.958442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:51.959127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:52.959202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:53.959591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:54.959663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:55.959898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:56.960098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:57.961032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:47:58.703: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:47:58.962204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:59.962948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:00.963150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:01.963966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:02.963957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:03.964884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:04.965162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:05.965373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:06.965554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:07.966405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:08.966600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:09.967338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:10.967658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:11.967902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:12.968155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:13.968981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:14.969036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:15.969197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:16.969940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:17.970139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:48:18.703: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:48:18.971454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:19.971437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:20.973196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:21.973959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:22.974489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:23.974786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:24.975676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:25.976355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:26.976791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:27.977870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:28.978740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:29.979109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:30.979292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:31.979425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:32.979423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:33.980262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:34.980397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:35.980640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:36.980978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:37.982086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:48:38.707: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:48:38.982189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:39.982379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:40.982558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:41.983683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:42.986154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:43.984968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:44.985494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:45.985891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:46.986295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:47.987212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:48.988091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:49.988266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:50.988676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:51.989588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:52.990035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:53.990780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:54.991177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:55.991663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:56.992439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:57.993220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:48:58.702: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:48:58.993626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:59.994196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:00.994620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:01.994841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:02.995032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:03.995910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:04.996068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:05.996288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:06.996939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:08.000910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:08.997828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:09.997914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:10.998099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:11.999023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:12.999418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:13.999989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:15.000596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:16.000876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:17.001437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:18.001497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:49:18.705: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:49:19.001692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:20.001953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:21.002891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:22.003117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:23.003431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:24.004104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:25.004189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:26.004303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:27.004538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:28.004706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:29.005265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:30.005436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:31.005671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:32.005865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:33.006089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:34.006674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:35.006935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:36.007216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:37.007281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:38.007444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:49:38.703: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:49:39.008952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:40.008897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:41.009451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:42.010043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:43.010945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:44.011184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:45.011235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:46.011278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:47.011484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:48.011772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:49.011920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:50.012157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:51.012380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:52.013115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:53.013345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:54.013928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:55.014623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:56.015533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:57.016352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:58.016449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:49:58.702: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:49:59.016973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:00.017323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:01.017388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:02.018126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:03.018435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:04.021108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:05.021282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:06.021715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:07.021886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:08.021982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:09.023144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:10.023356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:11.024312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:12.024936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:13.025124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:14.025774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:15.025923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:16.026140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:17.026391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:18.026586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:18.705: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:50:19.026911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:20.027409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:21.027440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:22.027682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:23.028064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:24.029122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:25.029332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:26.030335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:27.030447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:28.030643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:29.030777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:30.030959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:31.031562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:32.031782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:33.032052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:34.032802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:35.033091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:36.033634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:37.034085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:38.034783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:38.704: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:50:39.035531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:40.036024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:41.036030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:42.036166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:43.037029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:44.036884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:45.037399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:46.037979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:47.039535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:48.039236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:49.039959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:50.040468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:51.041079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:52.041177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:53.041366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:54.042034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:55.045077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:56.045578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:57.045677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:58.045919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:58.700: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:50:59.046561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:00.046820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:01.047862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:02.048247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:03.048666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:04.049386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:05.049763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:06.050111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:07.050465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:08.051198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:09.052047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:10.052423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:11.052810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:12.053062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:13.053239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:14.054063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:15.054592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:16.055342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:17.055680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:18.056355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:18.703: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:51:19.057563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:20.057827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:21.057941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:22.058734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:23.059181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:24.059579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:25.059624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:26.059899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:27.060831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:28.061411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:29.062091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:30.062309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:31.062516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:32.062710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:33.062909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:34.063943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:35.064109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:36.064981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:37.065113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:38.065266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:38.700: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:51:39.065487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:40.065748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:41.066396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:42.066611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:43.067455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:44.067601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:45.068270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:46.068700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:47.069025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:48.069185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:49.069238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:50.069566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:51.070093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:52.070813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:53.071570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:54.071722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:55.072263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:56.073367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:57.074050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:58.075185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:58.705: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:51:59.076301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:00.076556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:01.076857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:02.077997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:03.077472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:04.078190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:05.078090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:06.078275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:07.078651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:08.078896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:09.079693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:10.079879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:11.080987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:12.081752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:13.082150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:14.082928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:15.084034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:16.084478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:17.084724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:18.084967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:18.709: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:52:19.085130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:20.085709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:21.085927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:22.086528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:23.086735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:24.087879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:25.088165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:26.088411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:27.088955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:28.089752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:29.090806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:30.091443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:31.091659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:32.092395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:33.092614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:34.092800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:35.092979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:36.093605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:37.093750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:38.093945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:38.704: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:52:39.094985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:40.095769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:41.095928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:42.096660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:43.097189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:44.097852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:45.098380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:46.098501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:47.098644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:48.098672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:49.099800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:50.100479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:51.100797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:52.100983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:53.101154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:54.101868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:55.102042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:56.102246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:57.102436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:58.102631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:58.700: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:52:59.102727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:00.103261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:01.103445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:02.103593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:03.104051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:04.104927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:05.105211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:06.105355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:07.105612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:08.105917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:09.106699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:10.106915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:11.107113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:12.107294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:13.107500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:14.108419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:15.109271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:16.110094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:17.110214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:18.111039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:18.706: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:53:19.111323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:20.111985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:21.112810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:22.113047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:23.113151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:24.113308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:25.113610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:26.113812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:27.114033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:28.114266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:29.115022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:30.115410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:31.115891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:32.115940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:33.116807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:34.116869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:35.117574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:36.117588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:37.118649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:38.119590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:38.704: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:53:39.119881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:40.120550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:41.120712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:42.121320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:43.121940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:44.123035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:45.123240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:46.123639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:47.124450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:48.124652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:49.125129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:50.125388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:51.126037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:52.126208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:53.126875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:54.127761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:55.128140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:56.128401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:57.129050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:58.129774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:58.705: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:53:59.130567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:00.131688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:01.131769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:02.132661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:03.133100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:04.133938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:05.134189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:06.134612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:07.134842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:08.135113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:09.136060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:10.136762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:11.137084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:12.137348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:13.137523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:14.137781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:15.138791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:16.139887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:17.139323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:18.163029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:18.717: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:54:19.147327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:20.148852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:21.147943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:22.148246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:23.149130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:24.149028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:25.151395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:26.149315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:27.149661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:28.149907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:29.150773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:30.151163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:31.152082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:32.152250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:33.152648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:34.153035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:35.153544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:36.154309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:37.154611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:38.155827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:38.703: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:54:39.158696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:40.158155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:41.158628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:42.158586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:43.158920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:44.159989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:45.161135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:46.161644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:47.162432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:48.161994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:49.162528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:50.162907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:51.163949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:52.164372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:53.164630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:54.164973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:55.165203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:56.165692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:57.166124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:58.166363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:58.703: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:54:59.167359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:00.167473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:01.168092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:02.168333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:03.168535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:04.169569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:05.169861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:06.170507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:07.171046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:08.172024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:09.173078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:10.173619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:11.173746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:12.174283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:13.174549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:14.175263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:15.176385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:16.176810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:17.176989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:18.177367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:18.705: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:55:19.178398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:20.180066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:21.179666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:22.180102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:23.180528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:24.181520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:25.183990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:26.184348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:27.184365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:28.184549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:29.185865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:30.185925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:31.186773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:32.187075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:33.187670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:34.188264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:35.188400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:36.188629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:37.188776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:38.188994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:38.701: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzY4OTMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1219 11:55:39.189270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:40.189880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:41.190827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:42.191161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:43.191781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:44.191872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:45.192694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:46.193442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:47.194177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:48.195252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:49.195428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:50.195630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:51.196261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:52.196526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:53.197029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:54.198049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:55.198523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:56.198907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:57.199800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:58.199953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:58.699: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  Dec 19 11:55:58.699: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 12/19/23 11:55:58.699
  STEP: retrieving all remaining pages @ 12/19/23 11:55:58.71
  Dec 19 11:55:58.720: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  Dec 19 11:55:58.729: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  Dec 19 11:55:58.738: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  Dec 19 11:55:58.748: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  Dec 19 11:55:58.758: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  Dec 19 11:55:58.767: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  Dec 19 11:55:58.778: INFO: Retrieved 40/40 results with rv 37741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mzc3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  Dec 19 11:55:58.790: INFO: Retrieved 40/40 results with rv 37741 and continue 
  Dec 19 11:55:58.791: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6530" for this suite. @ 12/19/23 11:55:58.806
• [517.900 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 12/19/23 11:55:58.821
  Dec 19 11:55:58.821: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename podtemplate @ 12/19/23 11:55:58.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:58.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:58.864
  STEP: Create a pod template @ 12/19/23 11:55:58.871
  STEP: Replace a pod template @ 12/19/23 11:55:58.884
  Dec 19 11:55:58.904: INFO: Found updated podtemplate annotation: "true"

  Dec 19 11:55:58.904: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8213" for this suite. @ 12/19/23 11:55:58.92
• [0.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 12/19/23 11:55:58.94
  Dec 19 11:55:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:55:58.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:58.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:58.989
  STEP: Read namespace status @ 12/19/23 11:55:58.995
  Dec 19 11:55:59.004: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 12/19/23 11:55:59.004
  Dec 19 11:55:59.016: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 12/19/23 11:55:59.016
  Dec 19 11:55:59.037: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Dec 19 11:55:59.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7314" for this suite. @ 12/19/23 11:55:59.046
• [0.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 12/19/23 11:55:59.06
  Dec 19 11:55:59.060: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 11:55:59.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:59.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:59.107
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 12/19/23 11:55:59.113
  E1219 11:55:59.201527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:00.201579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 12/19/23 11:56:01.171
  STEP: Then the orphan pod is adopted @ 12/19/23 11:56:01.182
  E1219 11:56:01.202812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:02.196: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:56:02.202910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-4324" for this suite. @ 12/19/23 11:56:02.205
• [3.157 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 12/19/23 11:56:02.224
  Dec 19 11:56:02.224: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:56:02.227
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:02.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:02.26
  STEP: Setting up server cert @ 12/19/23 11:56:02.306
  E1219 11:56:03.203595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:56:03.347
  STEP: Deploying the webhook pod @ 12/19/23 11:56:03.367
  STEP: Wait for the deployment to be ready @ 12/19/23 11:56:03.392
  Dec 19 11:56:03.407: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:56:04.203859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:05.204927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:56:05.436
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:56:05.462
  E1219 11:56:06.205608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:06.462: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 11:56:06.476: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2052-crds.webhook.example.com via the AdmissionRegistration API @ 12/19/23 11:56:07.002
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/19/23 11:56:07.051
  E1219 11:56:07.206176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:08.206272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:09.206659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:09.977: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3140" for this suite. @ 12/19/23 11:56:09.995
  STEP: Destroying namespace "webhook-markers-5451" for this suite. @ 12/19/23 11:56:10.009
• [7.814 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 12/19/23 11:56:10.042
  Dec 19 11:56:10.043: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 11:56:10.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:10.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:10.094
  Dec 19 11:56:10.101: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  E1219 11:56:10.207364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:10.693: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2274" for this suite. @ 12/19/23 11:56:10.758
• [0.737 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 12/19/23 11:56:10.785
  Dec 19 11:56:10.786: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:56:10.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:10.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:10.89
  STEP: apply creating a deployment @ 12/19/23 11:56:10.899
  Dec 19 11:56:10.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7089" for this suite. @ 12/19/23 11:56:10.984
• [0.221 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 12/19/23 11:56:11.018
  Dec 19 11:56:11.018: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:56:11.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:11.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:11.1
  STEP: Creating Pod @ 12/19/23 11:56:11.107
  E1219 11:56:11.208128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:12.208627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 12/19/23 11:56:13.157
  Dec 19 11:56:13.158: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5660 PodName:pod-sharedvolume-270e4ce1-ab0e-4d98-837a-81e73eb0a7c3 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:56:13.158: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:56:13.162: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:56:13.162: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-5660/pods/pod-sharedvolume-270e4ce1-ab0e-4d98-837a-81e73eb0a7c3/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  E1219 11:56:13.208411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:13.325: INFO: Exec stderr: ""
  Dec 19 11:56:13.326: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5660" for this suite. @ 12/19/23 11:56:13.341
• [2.341 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 12/19/23 11:56:13.362
  Dec 19 11:56:13.362: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:56:13.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:13.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:13.414
  STEP: Creating a pod to test env composition @ 12/19/23 11:56:13.426
  E1219 11:56:14.208906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:15.208987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:16.209124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:17.210251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:56:17.475
  Dec 19 11:56:17.483: INFO: Trying to get logs from node uikie9pei4sh-3 pod var-expansion-d158aff2-1ce6-4f01-b6a7-c811f0d3b1c4 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:56:17.524
  Dec 19 11:56:17.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3379" for this suite. @ 12/19/23 11:56:17.591
• [4.252 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 12/19/23 11:56:17.615
  Dec 19 11:56:17.615: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:56:17.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:17.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:17.668
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/19/23 11:56:17.682
  E1219 11:56:18.210397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:19.211011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:20.211283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:21.211523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:56:21.729
  Dec 19 11:56:21.736: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-4adb58a3-3491-4a03-8b18-887d30d2c92e container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:56:21.75
  Dec 19 11:56:21.794: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7779" for this suite. @ 12/19/23 11:56:21.817
• [4.223 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 12/19/23 11:56:21.842
  Dec 19 11:56:21.842: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 11:56:21.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:21.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:21.909
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-276 @ 12/19/23 11:56:21.922
  STEP: changing the ExternalName service to type=ClusterIP @ 12/19/23 11:56:21.937
  STEP: creating replication controller externalname-service in namespace services-276 @ 12/19/23 11:56:21.983
  I1219 11:56:22.011417      13 runners.go:197] Created replication controller with name: externalname-service, namespace: services-276, replica count: 2
  E1219 11:56:22.212704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:23.213688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:24.213956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:56:25.064023      13 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:56:25.064: INFO: Creating new exec pod
  E1219 11:56:25.214088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:26.214726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:27.215549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:28.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-276 exec execpodclz9q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E1219 11:56:28.215833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:28.484: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec 19 11:56:28.484: INFO: stdout: "externalname-service-b4mqf"
  Dec 19 11:56:28.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=services-276 exec execpodclz9q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.9.9 80'
  Dec 19 11:56:28.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.9.9 80\nConnection to 10.233.9.9 80 port [tcp/http] succeeded!\n"
  Dec 19 11:56:28.785: INFO: stdout: "externalname-service-b4mqf"
  Dec 19 11:56:28.786: INFO: Cleaning up the ExternalName to ClusterIP test service
  Dec 19 11:56:28.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-276" for this suite. @ 12/19/23 11:56:28.844
• [7.019 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 12/19/23 11:56:28.862
  Dec 19 11:56:28.862: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:56:28.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:28.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:28.918
  STEP: Creating secret with name secret-test-3af4f3c2-65f5-4603-b641-465a059bc64d @ 12/19/23 11:56:28.923
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:56:28.94
  E1219 11:56:29.216066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:30.216812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:31.217479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:32.220340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:56:32.997
  Dec 19 11:56:33.006: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-secrets-50e90840-7842-4125-8b1d-b622e63c196c container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:56:33.027
  Dec 19 11:56:33.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3333" for this suite. @ 12/19/23 11:56:33.085
• [4.241 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 12/19/23 11:56:33.104
  Dec 19 11:56:33.104: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:56:33.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:33.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:33.152
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/19/23 11:56:33.158
  E1219 11:56:33.220227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:34.223720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:35.221333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:36.222520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:56:37.207
  Dec 19 11:56:37.215: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-c319a275-aea7-44ff-a60f-c6d54061e3b2 container test-container: <nil>
  E1219 11:56:37.222904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/19/23 11:56:37.235
  Dec 19 11:56:37.276: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2111" for this suite. @ 12/19/23 11:56:37.298
• [4.220 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 12/19/23 11:56:37.33
  Dec 19 11:56:37.331: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:56:37.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:37.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:37.391
  STEP: Creating projection with secret that has name projected-secret-test-map-950ff165-6eef-4ecd-8c8a-b493cbe4e0bf @ 12/19/23 11:56:37.402
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:56:37.417
  E1219 11:56:38.223564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:39.223826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:56:39.466
  Dec 19 11:56:39.474: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-secrets-b67a6c8a-b2f1-4f35-8b30-12b2e7dabcf1 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:56:39.491
  Dec 19 11:56:39.525: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2554" for this suite. @ 12/19/23 11:56:39.537
• [2.218 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 12/19/23 11:56:39.55
  Dec 19 11:56:39.550: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:56:39.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:39.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:39.675
  STEP: Setting up server cert @ 12/19/23 11:56:39.722
  E1219 11:56:40.224136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:56:40.947
  STEP: Deploying the webhook pod @ 12/19/23 11:56:40.965
  STEP: Wait for the deployment to be ready @ 12/19/23 11:56:40.995
  Dec 19 11:56:41.011: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 11:56:41.224392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:42.224481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:56:43.036
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:56:43.054
  E1219 11:56:43.225028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:44.056: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 12/19/23 11:56:44.076
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 12/19/23 11:56:44.125
  STEP: Creating a configMap that should not be mutated @ 12/19/23 11:56:44.149
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 12/19/23 11:56:44.175
  STEP: Creating a configMap that should be mutated @ 12/19/23 11:56:44.19
  E1219 11:56:44.225354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:44.362: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9284" for this suite. @ 12/19/23 11:56:44.374
  STEP: Destroying namespace "webhook-markers-265" for this suite. @ 12/19/23 11:56:44.39
• [4.858 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 12/19/23 11:56:44.408
  Dec 19 11:56:44.408: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:56:44.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:44.454
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:44.464
  Dec 19 11:56:44.546: INFO: Create a RollingUpdate DaemonSet
  Dec 19 11:56:44.570: INFO: Check that daemon pods launch on every node of the cluster
  Dec 19 11:56:44.586: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:44.586: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:56:45.226140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:45.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:45.604: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:56:46.226445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:46.588: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:56:46.588: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Dec 19 11:56:46.589: INFO: Update the DaemonSet to trigger a rollout
  Dec 19 11:56:46.618: INFO: Updating DaemonSet daemon-set
  E1219 11:56:47.227093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:48.227203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:49.227992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:49.658: INFO: Roll back the DaemonSet before rollout is complete
  Dec 19 11:56:49.699: INFO: Updating DaemonSet daemon-set
  Dec 19 11:56:49.699: INFO: Make sure DaemonSet rollback is complete
  Dec 19 11:56:49.709: INFO: Wrong image for pod: daemon-set-jrg95. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Dec 19 11:56:49.710: INFO: Pod daemon-set-jrg95 is not available
  E1219 11:56:50.228822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:51.229637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:52.229992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:53.230333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:54.230318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:54.709: INFO: Pod daemon-set-ptnqh is not available
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 11:56:54.742
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1470, will wait for the garbage collector to delete the pods @ 12/19/23 11:56:54.742
  Dec 19 11:56:54.818: INFO: Deleting DaemonSet.extensions daemon-set took: 14.089184ms
  Dec 19 11:56:54.920: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.698729ms
  E1219 11:56:55.231126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:56.231580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:56.529: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:56.529: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 11:56:56.535: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38796"},"items":null}

  Dec 19 11:56:56.541: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38796"},"items":null}

  Dec 19 11:56:56.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1470" for this suite. @ 12/19/23 11:56:56.594
• [12.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 12/19/23 11:56:56.613
  Dec 19 11:56:56.614: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:56:56.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:56:56.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:56:56.657
  Dec 19 11:56:56.708: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 12/19/23 11:56:56.719
  Dec 19 11:56:56.726: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:56.726: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 12/19/23 11:56:56.726
  Dec 19 11:56:56.776: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:56.778: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:56:57.232297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:57.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:57.778: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:56:58.232630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:58.775: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 11:56:58.775: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 12/19/23 11:56:58.782
  Dec 19 11:56:58.821: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 11:56:58.821: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E1219 11:56:59.233114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:59.823: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:59.823: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 12/19/23 11:56:59.823
  Dec 19 11:56:59.850: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:56:59.850: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:57:00.234934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:57:00.847: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:57:00.847: INFO: Node uikie9pei4sh-1 is running 0 daemon pod, expected 1
  E1219 11:57:01.234512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:57:01.845: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 11:57:01.845: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 11:57:01.859
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9794, will wait for the garbage collector to delete the pods @ 12/19/23 11:57:01.859
  Dec 19 11:57:01.934: INFO: Deleting DaemonSet.extensions daemon-set took: 14.041603ms
  Dec 19 11:57:02.035: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.557289ms
  E1219 11:57:02.235118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:57:03.043: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:57:03.043: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 11:57:03.049: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38896"},"items":null}

  Dec 19 11:57:03.056: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38896"},"items":null}

  Dec 19 11:57:03.117: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9794" for this suite. @ 12/19/23 11:57:03.125
• [6.527 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 12/19/23 11:57:03.144
  Dec 19 11:57:03.144: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 11:57:03.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:57:03.186
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:57:03.194
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 11:57:03.211
  E1219 11:57:03.235370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:04.237698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:05.237349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 11:57:05.254
  E1219 11:57:06.237922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:07.238015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/19/23 11:57:07.302
  STEP: delete the pod with lifecycle hook @ 12/19/23 11:57:07.317
  E1219 11:57:08.238577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:09.238740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:57:09.348: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1787" for this suite. @ 12/19/23 11:57:09.358
• [6.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 12/19/23 11:57:09.376
  Dec 19 11:57:09.377: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:57:09.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:57:09.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:57:09.425
  STEP: Starting the proxy @ 12/19/23 11:57:09.429
  Dec 19 11:57:09.430: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-6609 proxy --unix-socket=/tmp/kubectl-proxy-unix3313365636/test'
  STEP: retrieving proxy /api/ output @ 12/19/23 11:57:09.603
  Dec 19 11:57:09.606: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6609" for this suite. @ 12/19/23 11:57:09.615
• [0.251 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 12/19/23 11:57:09.628
  Dec 19 11:57:09.629: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:57:09.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:57:09.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:57:09.667
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:57:09.673
  E1219 11:57:10.239783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:11.240368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:57:11.704
  Dec 19 11:57:11.710: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-a85d970f-5d95-43f1-a704-3edcbf134730 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:57:11.726
  Dec 19 11:57:11.767: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9487" for this suite. @ 12/19/23 11:57:11.776
• [2.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 12/19/23 11:57:11.791
  Dec 19 11:57:11.791: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:57:11.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:57:11.825
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:57:11.831
  STEP: Creating service test in namespace statefulset-2243 @ 12/19/23 11:57:11.836
  STEP: Creating a new StatefulSet @ 12/19/23 11:57:11.853
  Dec 19 11:57:11.887: INFO: Found 0 stateful pods, waiting for 3
  E1219 11:57:12.241021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:13.242213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:14.243276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:15.244130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:16.244332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:17.244715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:18.245343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:19.246787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:20.247720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:21.247894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:57:21.890: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:57:21.891: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:57:21.891: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/19/23 11:57:21.912
  Dec 19 11:57:21.943: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/19/23 11:57:21.943
  E1219 11:57:22.248696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:23.249112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:24.249443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:25.249467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:26.249649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:27.249984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:28.250112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:29.250878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:30.251078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:31.251320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 12/19/23 11:57:31.965
  STEP: Performing a canary update @ 12/19/23 11:57:31.965
  Dec 19 11:57:31.997: INFO: Updating stateful set ss2
  Dec 19 11:57:32.049: INFO: Waiting for Pod statefulset-2243/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 11:57:32.251678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:33.251921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:34.252018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:35.252238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:36.253027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:37.253887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:38.254094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:39.254290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:40.254463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:41.255217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 12/19/23 11:57:42.014
  Dec 19 11:57:42.121: INFO: Found 1 stateful pods, waiting for 3
  E1219 11:57:42.256098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:43.256363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:44.256709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:45.257146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:46.257276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:47.257865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:48.258545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:49.258761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:50.259472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:51.259665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:57:52.121: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:57:52.121: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:57:52.121: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 12/19/23 11:57:52.137
  Dec 19 11:57:52.170: INFO: Updating stateful set ss2
  Dec 19 11:57:52.189: INFO: Waiting for Pod statefulset-2243/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 11:57:52.260439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:53.261093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:54.261334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:55.261921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:56.262280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:57.263224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:58.263964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:57:59.263842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:00.264210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:01.264824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:02.216: INFO: Updating stateful set ss2
  Dec 19 11:58:02.232: INFO: Waiting for StatefulSet statefulset-2243/ss2 to complete update
  Dec 19 11:58:02.233: INFO: Waiting for Pod statefulset-2243/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 11:58:02.264870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:03.265033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:04.266268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:05.266465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:06.266798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:07.268456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:08.269745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:09.268253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:10.268174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:11.269271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:12.238: INFO: Deleting all statefulset in ns statefulset-2243
  Dec 19 11:58:12.244: INFO: Scaling statefulset ss2 to 0
  E1219 11:58:12.269355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:13.270029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:14.271083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:15.271596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:16.271822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:17.272736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:18.272983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:19.274054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:20.274193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:21.274406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:22.274: INFO: Waiting for statefulset status.replicas updated to 0
  E1219 11:58:22.274860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:22.281: INFO: Deleting statefulset ss2
  Dec 19 11:58:22.315: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2243" for this suite. @ 12/19/23 11:58:22.344
• [70.576 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 12/19/23 11:58:22.371
  Dec 19 11:58:22.372: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename subpath @ 12/19/23 11:58:22.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:58:22.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:58:22.415
  STEP: Setting up data @ 12/19/23 11:58:22.421
  STEP: Creating pod pod-subpath-test-configmap-6zhj @ 12/19/23 11:58:22.439
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 11:58:22.439
  E1219 11:58:23.275371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:24.276286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:25.277216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:26.278189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:27.278697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:28.279030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:29.279251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:30.279508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:31.279961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:32.280636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:33.281136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:34.281481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:35.281642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:36.281855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:37.281994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:38.282240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:39.282326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:40.283024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:41.283371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:42.283861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:43.284222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:44.284315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:45.284485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:46.285150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:58:46.563
  Dec 19 11:58:46.569: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-subpath-test-configmap-6zhj container test-container-subpath-configmap-6zhj: <nil>
  STEP: delete the pod @ 12/19/23 11:58:46.612
  STEP: Deleting pod pod-subpath-test-configmap-6zhj @ 12/19/23 11:58:46.64
  Dec 19 11:58:46.640: INFO: Deleting pod "pod-subpath-test-configmap-6zhj" in namespace "subpath-3094"
  Dec 19 11:58:46.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3094" for this suite. @ 12/19/23 11:58:46.659
• [24.304 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 12/19/23 11:58:46.68
  Dec 19 11:58:46.681: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/19/23 11:58:46.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:58:46.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:58:46.728
  STEP: creating a target pod @ 12/19/23 11:58:46.735
  E1219 11:58:47.286035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:48.286088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/19/23 11:58:48.783
  E1219 11:58:49.286807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:50.287176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/19/23 11:58:50.831
  Dec 19 11:58:50.832: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-205 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:58:50.832: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:58:50.835: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:58:50.835: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-205/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec 19 11:58:50.963: INFO: Exec stderr: ""
  Dec 19 11:58:50.986: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-205" for this suite. @ 12/19/23 11:58:50.998
• [4.331 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 12/19/23 11:58:51.023
  Dec 19 11:58:51.024: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:58:51.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:58:51.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:58:51.075
  STEP: Setting up server cert @ 12/19/23 11:58:51.13
  E1219 11:58:51.287450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:58:51.766
  STEP: Deploying the webhook pod @ 12/19/23 11:58:51.79
  STEP: Wait for the deployment to be ready @ 12/19/23 11:58:51.821
  Dec 19 11:58:51.839: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 11:58:52.288883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:53.289182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:53.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:58:54.290258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:55.290211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:55.871: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:58:56.291382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:57.291747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:57.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:58:58.292254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:58:59.293084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:58:59.870: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:59:00.293389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:01.293997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:59:01.869: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 58, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:59:02.294272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:03.295113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:59:03.872
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:59:03.897
  E1219 11:59:04.295277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:59:04.899: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/19/23 11:59:04.912
  STEP: create a pod @ 12/19/23 11:59:04.946
  E1219 11:59:05.295943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:06.296959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 12/19/23 11:59:06.992
  Dec 19 11:59:06.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=webhook-4941 attach --namespace=webhook-4941 to-be-attached-pod -i -c=container1'
  Dec 19 11:59:07.212: INFO: rc: 1
  E1219 11:59:07.298334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:59:07.312: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4941" for this suite. @ 12/19/23 11:59:07.326
  STEP: Destroying namespace "webhook-markers-3449" for this suite. @ 12/19/23 11:59:07.345
• [16.359 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 12/19/23 11:59:07.384
  Dec 19 11:59:07.384: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:59:07.392
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:07.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:07.441
  STEP: starting the proxy server @ 12/19/23 11:59:07.448
  Dec 19 11:59:07.449: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-554747681 --namespace=kubectl-7385 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 12/19/23 11:59:07.588
  Dec 19 11:59:07.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7385" for this suite. @ 12/19/23 11:59:07.667
• [0.298 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 12/19/23 11:59:07.702
  Dec 19 11:59:07.702: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:59:07.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:07.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:07.749
  STEP: Creating configMap with name projected-configmap-test-volume-map-80b4f5ce-d02f-477e-8675-8efd6d15b693 @ 12/19/23 11:59:07.755
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:59:07.767
  E1219 11:59:08.298613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:09.299040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:10.301265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:11.300626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:59:11.812
  Dec 19 11:59:11.818: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-configmaps-3e9ba544-652f-4fad-990a-3bdd2a933778 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:59:11.834
  Dec 19 11:59:11.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6591" for this suite. @ 12/19/23 11:59:11.878
• [4.190 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 12/19/23 11:59:11.894
  Dec 19 11:59:11.894: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename csi-storageclass @ 12/19/23 11:59:11.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:11.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:11.937
  STEP: Creating a StorageClass @ 12/19/23 11:59:11.944
  STEP: Get StorageClass "e2e-99csw" @ 12/19/23 11:59:11.957
  STEP: Patching the StorageClass "e2e-99csw" @ 12/19/23 11:59:11.964
  STEP: Delete StorageClass "e2e-99csw" @ 12/19/23 11:59:11.98
  STEP: Confirm deletion of StorageClass "e2e-99csw" @ 12/19/23 11:59:11.994
  STEP: Create a replacement StorageClass @ 12/19/23 11:59:12.002
  STEP: Updating StorageClass "e2e-v2-sq9tp" @ 12/19/23 11:59:12.013
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-sq9tp=updated" @ 12/19/23 11:59:12.03
  STEP: Deleting StorageClass "e2e-v2-sq9tp" via DeleteCollection @ 12/19/23 11:59:12.036
  STEP: Confirm deletion of StorageClass "e2e-v2-sq9tp" @ 12/19/23 11:59:12.05
  Dec 19 11:59:12.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-7613" for this suite. @ 12/19/23 11:59:12.071
• [0.191 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 12/19/23 11:59:12.089
  Dec 19 11:59:12.089: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename init-container @ 12/19/23 11:59:12.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:12.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:12.13
  STEP: creating the pod @ 12/19/23 11:59:12.135
  Dec 19 11:59:12.136: INFO: PodSpec: initContainers in spec.initContainers
  E1219 11:59:12.301199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:13.301489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:14.302182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:15.302943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:59:16.264: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2597" for this suite. @ 12/19/23 11:59:16.282
  E1219 11:59:16.302797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.214 seconds]
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 12/19/23 11:59:16.306
  Dec 19 11:59:16.306: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 11:59:16.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:16.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:16.35
  STEP: Performing setup for networking test in namespace pod-network-test-4180 @ 12/19/23 11:59:16.357
  STEP: creating a selector @ 12/19/23 11:59:16.357
  STEP: Creating the service pods in kubernetes @ 12/19/23 11:59:16.357
  Dec 19 11:59:16.357: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 11:59:17.303809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:18.304268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:19.305079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:20.305578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:21.308842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:22.307413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:23.308682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:24.308639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:25.308877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:26.309123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:27.309856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:28.309893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:29.310072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:30.310451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:31.311525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:32.311808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:33.312518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:34.312795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:35.313148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:36.313441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:37.313957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:38.314100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:39.314619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:40.314897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:41.315934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:42.316910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 11:59:42.655
  E1219 11:59:43.317061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:44.317912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:59:44.688: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 11:59:44.688: INFO: Breadth first check of 10.233.64.147 on host 192.168.121.241...
  Dec 19 11:59:44.694: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.225:9080/dial?request=hostname&protocol=http&host=10.233.64.147&port=8083&tries=1'] Namespace:pod-network-test-4180 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:59:44.694: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:59:44.696: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:59:44.696: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4180/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.225%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.147%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 11:59:44.864: INFO: Waiting for responses: map[]
  Dec 19 11:59:44.865: INFO: reached 10.233.64.147 after 0/1 tries
  Dec 19 11:59:44.865: INFO: Breadth first check of 10.233.65.164 on host 192.168.121.77...
  Dec 19 11:59:44.874: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.225:9080/dial?request=hostname&protocol=http&host=10.233.65.164&port=8083&tries=1'] Namespace:pod-network-test-4180 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:59:44.874: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:59:44.876: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:59:44.876: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4180/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.225%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.164%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 11:59:45.007: INFO: Waiting for responses: map[]
  Dec 19 11:59:45.007: INFO: reached 10.233.65.164 after 0/1 tries
  Dec 19 11:59:45.008: INFO: Breadth first check of 10.233.66.224 on host 192.168.121.201...
  Dec 19 11:59:45.016: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.225:9080/dial?request=hostname&protocol=http&host=10.233.66.224&port=8083&tries=1'] Namespace:pod-network-test-4180 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:59:45.016: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  Dec 19 11:59:45.018: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:59:45.018: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4180/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.225%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.224%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 11:59:45.174: INFO: Waiting for responses: map[]
  Dec 19 11:59:45.174: INFO: reached 10.233.66.224 after 0/1 tries
  Dec 19 11:59:45.174: INFO: Going to retry 0 out of 3 pods....
  Dec 19 11:59:45.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4180" for this suite. @ 12/19/23 11:59:45.186
• [28.893 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 12/19/23 11:59:45.199
  Dec 19 11:59:45.199: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:59:45.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:45.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:45.238
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:59:45.243
  E1219 11:59:45.318087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:46.318455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:47.318314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:48.318819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:59:49.286
  Dec 19 11:59:49.293: INFO: Trying to get logs from node uikie9pei4sh-3 pod downwardapi-volume-1579609e-eeda-4adb-8958-06ce16ba9437 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:59:49.306
  E1219 11:59:49.319472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:59:49.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6101" for this suite. @ 12/19/23 11:59:49.36
• [4.174 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 12/19/23 11:59:49.374
  Dec 19 11:59:49.374: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename subpath @ 12/19/23 11:59:49.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:59:49.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:59:49.421
  STEP: Setting up data @ 12/19/23 11:59:49.426
  STEP: Creating pod pod-subpath-test-configmap-8jlm @ 12/19/23 11:59:49.443
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 11:59:49.443
  E1219 11:59:50.319288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:51.319511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:52.320833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:53.321480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:54.321202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:55.321204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:56.321855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:57.321846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:58.322384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:59:59.322660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:00.322658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:01.323850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:02.324023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:03.324649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:04.325736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:05.326474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:06.326728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:07.326824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:08.327224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:09.328188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:10.328824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:11.329091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:12.329421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:13.329890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 12:00:13.592
  Dec 19 12:00:13.604: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-subpath-test-configmap-8jlm container test-container-subpath-configmap-8jlm: <nil>
  STEP: delete the pod @ 12/19/23 12:00:13.628
  STEP: Deleting pod pod-subpath-test-configmap-8jlm @ 12/19/23 12:00:13.663
  Dec 19 12:00:13.664: INFO: Deleting pod "pod-subpath-test-configmap-8jlm" in namespace "subpath-2462"
  Dec 19 12:00:13.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2462" for this suite. @ 12/19/23 12:00:13.689
• [24.332 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 12/19/23 12:00:13.711
  Dec 19 12:00:13.711: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 12:00:13.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 12:00:13.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 12:00:13.764
  STEP: Creating a suspended cronjob @ 12/19/23 12:00:13.77
  STEP: Ensuring no jobs are scheduled @ 12/19/23 12:00:13.785
  E1219 12:00:14.329960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:15.330546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:16.330963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:17.331924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:18.332366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:19.333302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:20.333877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:21.334237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:22.334686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:23.335031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:24.335318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:25.336074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:26.337174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:27.337246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:28.338386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:29.339341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:30.339717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:31.340337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:32.341278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:33.341455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:34.341657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:35.341903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:36.342266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:37.343103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:38.343405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:39.344464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:40.344305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:41.344572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:42.344874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:43.345257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:44.345283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:45.345785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:46.346364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:47.346927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:48.347148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:49.348391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:50.348925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:51.349231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:52.351333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:53.352172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:54.352344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:55.352685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:56.354261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:57.353786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:58.353884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:00:59.354225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:00.354681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:01.355173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:02.354835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:03.355219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:04.355349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:05.355521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:06.356117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:07.357019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:08.357134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:09.358183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:10.359342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:11.360659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:12.360550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:13.360788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:14.361040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:15.361299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:16.361983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:17.363045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:18.363280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:19.364243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:20.365184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:21.366747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:22.366417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:23.366443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:24.366506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:25.366907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:26.367681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:27.368411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:28.369078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:29.369749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:30.369878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:31.370123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:32.371319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:33.372047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:34.373155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:35.373243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:36.373412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:37.373951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:38.374079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:39.374266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:40.374681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:41.375476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:42.375954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:43.376165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:44.377330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:45.377503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:46.377699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:47.377888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:48.379158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:49.380187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:50.380564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:51.381391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:52.382028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:53.382271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:54.382623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:55.382778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:56.383731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:57.384011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:58.384554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:01:59.385210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:00.385509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:01.385875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:02.386384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:03.386732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:04.387401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:05.388032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:06.389525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:07.389786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:08.389830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:09.390741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:10.390897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:11.391132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:12.391326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:13.391909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:14.392179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:15.393257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:16.393704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:17.394269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:18.394424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:19.395022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:20.396012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:21.396241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:22.397209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:23.397998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:24.398220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:25.399166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:26.399304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:27.400211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:28.401105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:29.402214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:30.402426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:31.402804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:32.402946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:33.403260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:34.403399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:35.403811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:36.403880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:37.404983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:38.405112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:39.405420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:40.405563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:41.405769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:42.406015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:43.407064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:44.406922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:45.407757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:46.408433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:47.409717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:48.409921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:49.410684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:50.410428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:51.410818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:52.411930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:53.412018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:54.412832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:55.413081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:56.413280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:57.414301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:58.414961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:02:59.415215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:00.415363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:01.415603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:02.416516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:03.417257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:04.417375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:05.417572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:06.417632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:07.417858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:08.418761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:09.418919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:10.419826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:11.420125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:12.420286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:13.420618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:14.420805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:15.420946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:16.421255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:17.422171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:18.422801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:19.423240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:20.423831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:21.424024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:22.424324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:23.424544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:24.425237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:25.425256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:26.425173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:27.425444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:28.425573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:29.425688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:30.425788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:31.425998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:32.426137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:33.426372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:34.427365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:35.427916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:36.428736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:37.428892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:38.429158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:39.430033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:40.430406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:41.430909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:42.431617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:43.432026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:44.432240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:45.432540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:46.433070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:47.433407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:48.433703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:49.434318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:50.434879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:51.435058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:52.435061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:53.435524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:54.435753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:55.436346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:56.436674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:57.436857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:58.438034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:03:59.438596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:00.438533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:01.439107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:02.439108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:03.439382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:04.439416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:05.439652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:06.440259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:07.440069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:08.440480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:09.441505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:10.441636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:11.442196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:12.442363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:13.443143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:14.443314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:15.444420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:16.444471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:17.445480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:18.446035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:19.446337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:20.446531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:21.447879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:22.447759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:23.448562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:24.448996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:25.449987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:26.450371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:27.451007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:28.451205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:29.451315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:30.451450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:31.452053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:32.452246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:33.453534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:34.454201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:35.454834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:36.455128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:37.456143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:38.456556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:39.456921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:40.457450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:41.458017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:42.458168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:43.458425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:44.458600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:45.458964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:46.460477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:47.461148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:48.461368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:49.461644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:50.462001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:51.462837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:52.463427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:53.463665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:54.464870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:55.465484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:56.465784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:57.466067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:58.466523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:04:59.466541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:00.466876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:01.467700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:02.468629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:03.469029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:04.469133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:05.469775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:06.470268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:07.471062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:08.471195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:09.472024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:10.471876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:11.472110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:12.473165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:13.473163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 12/19/23 12:05:13.814
  STEP: Removing cronjob @ 12/19/23 12:05:13.821
  Dec 19 12:05:13.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4757" for this suite. @ 12/19/23 12:05:13.846
• [300.152 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 12/19/23 12:05:13.864
  Dec 19 12:05:13.864: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename services @ 12/19/23 12:05:13.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 12:05:13.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 12:05:13.912
  STEP: creating a Service @ 12/19/23 12:05:13.922
  STEP: watching for the Service to be added @ 12/19/23 12:05:13.958
  Dec 19 12:05:13.962: INFO: Found Service test-service-hwhrr in namespace services-7432 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32649}]
  Dec 19 12:05:13.962: INFO: Service test-service-hwhrr created
  STEP: Getting /status @ 12/19/23 12:05:13.963
  Dec 19 12:05:13.976: INFO: Service test-service-hwhrr has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 12/19/23 12:05:13.977
  STEP: watching for the Service to be patched @ 12/19/23 12:05:14
  Dec 19 12:05:14.003: INFO: observed Service test-service-hwhrr in namespace services-7432 with annotations: map[] & LoadBalancer: {[]}
  Dec 19 12:05:14.004: INFO: Found Service test-service-hwhrr in namespace services-7432 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  Dec 19 12:05:14.004: INFO: Service test-service-hwhrr has service status patched
  STEP: updating the ServiceStatus @ 12/19/23 12:05:14.004
  Dec 19 12:05:14.026: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 12/19/23 12:05:14.028
  Dec 19 12:05:14.033: INFO: Observed Service test-service-hwhrr in namespace services-7432 with annotations: map[] & Conditions: {[]}
  Dec 19 12:05:14.034: INFO: Observed event: &Service{ObjectMeta:{test-service-hwhrr  services-7432  d18090ee-57f4-4351-b03a-f671f293608e 40520 0 2023-12-19 12:05:13 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-12-19 12:05:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-12-19 12:05:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:32649,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.13.193,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.13.193],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Dec 19 12:05:14.037: INFO: Found Service test-service-hwhrr in namespace services-7432 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 12:05:14.038: INFO: Service test-service-hwhrr has service status updated
  STEP: patching the service @ 12/19/23 12:05:14.039
  STEP: watching for the Service to be patched @ 12/19/23 12:05:14.205
  Dec 19 12:05:14.208: INFO: observed Service test-service-hwhrr in namespace services-7432 with labels: map[test-service-static:true]
  Dec 19 12:05:14.208: INFO: observed Service test-service-hwhrr in namespace services-7432 with labels: map[test-service-static:true]
  Dec 19 12:05:14.209: INFO: observed Service test-service-hwhrr in namespace services-7432 with labels: map[test-service-static:true]
  Dec 19 12:05:14.209: INFO: Found Service test-service-hwhrr in namespace services-7432 with labels: map[test-service:patched test-service-static:true]
  Dec 19 12:05:14.209: INFO: Service test-service-hwhrr patched
  STEP: deleting the service @ 12/19/23 12:05:14.209
  STEP: watching for the Service to be deleted @ 12/19/23 12:05:14.243
  Dec 19 12:05:14.247: INFO: Observed event: ADDED
  Dec 19 12:05:14.248: INFO: Observed event: MODIFIED
  Dec 19 12:05:14.248: INFO: Observed event: MODIFIED
  Dec 19 12:05:14.249: INFO: Observed event: MODIFIED
  Dec 19 12:05:14.250: INFO: Found Service test-service-hwhrr in namespace services-7432 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Dec 19 12:05:14.251: INFO: Service test-service-hwhrr deleted
  Dec 19 12:05:14.252: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7432" for this suite. @ 12/19/23 12:05:14.263
• [0.416 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 12/19/23 12:05:14.28
  Dec 19 12:05:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 12:05:14.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 12:05:14.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 12:05:14.346
  STEP: Given a ReplicationController is created @ 12/19/23 12:05:14.356
  STEP: When the matched label of one of its pods change @ 12/19/23 12:05:14.399
  Dec 19 12:05:14.407: INFO: Pod name pod-release: Found 0 pods out of 1
  E1219 12:05:14.473140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:15.473369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:16.473399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:17.473992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:18.474256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 12:05:19.423: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/19/23 12:05:19.445
  E1219 12:05:19.475765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 12:05:20.470: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 12:05:20.475832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-1972" for this suite. @ 12/19/23 12:05:20.486
• [6.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 12/19/23 12:05:20.512
  Dec 19 12:05:20.512: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 12:05:20.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 12:05:20.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 12:05:20.553
  STEP: Creating ServiceAccount "e2e-sa-pmmx2"  @ 12/19/23 12:05:20.565
  Dec 19 12:05:20.580: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-pmmx2"  @ 12/19/23 12:05:20.58
  Dec 19 12:05:20.602: INFO: AutomountServiceAccountToken: true
  Dec 19 12:05:20.602: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4507" for this suite. @ 12/19/23 12:05:20.613
• [0.119 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 12/19/23 12:05:20.631
  Dec 19 12:05:20.631: INFO: >>> kubeConfig: /tmp/kubeconfig-554747681
  STEP: Building a namespace api object, basename projected @ 12/19/23 12:05:20.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 12:05:20.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 12:05:20.676
  STEP: Creating projection with secret that has name projected-secret-test-35489f4f-d912-45cf-ab0a-ced7e88ab4af @ 12/19/23 12:05:20.683
  STEP: Creating a pod to test consume secrets @ 12/19/23 12:05:20.698
  E1219 12:05:21.475907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:22.476443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:23.476642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 12:05:24.476855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 12:05:24.742
  Dec 19 12:05:24.749: INFO: Trying to get logs from node uikie9pei4sh-3 pod pod-projected-secrets-9a8abd77-959e-4a3e-8a5c-396dd6b3eddd container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 12:05:24.79
  Dec 19 12:05:24.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7781" for this suite. @ 12/19/23 12:05:24.827
• [4.211 seconds]
------------------------------
SSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Dec 19 12:05:24.867: INFO: Running AfterSuite actions on node 1
  Dec 19 12:05:24.868: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.001 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.169 seconds]
------------------------------

Ran 388 of 7407 Specs in 7395.708 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 2h3m18.116771818s
Test Suite Passed
